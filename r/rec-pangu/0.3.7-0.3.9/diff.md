# Comparing `tmp/rec_pangu-0.3.7-py3-none-any.whl.zip` & `tmp/rec_pangu-0.3.9-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,78 +1,82 @@
-Zip file size: 106611 bytes, number of entries: 76
--rw-r--r--  2.0 unx      199 b- defN 23-Apr-11 02:21 rec_pangu/__init__.py
+Zip file size: 116591 bytes, number of entries: 80
+-rw-r--r--  2.0 unx      199 b- defN 23-Jul-11 05:53 rec_pangu/__init__.py
 -rw-r--r--  2.0 unx     5837 b- defN 23-Apr-03 08:03 rec_pangu/benchmark_trainer.py
 -rw-r--r--  2.0 unx     9722 b- defN 23-Mar-18 15:33 rec_pangu/gpt_ranktrainer.py
 -rw-r--r--  2.0 unx    14630 b- defN 23-Apr-03 08:03 rec_pangu/model_pipeline.py
 -rw-r--r--  2.0 unx     5448 b- defN 23-Mar-18 15:32 rec_pangu/old_ranktrainer.py
--rw-r--r--  2.0 unx    18650 b- defN 23-Apr-03 08:03 rec_pangu/trainer.py
+-rw-r--r--  2.0 unx    20415 b- defN 23-Jul-10 02:50 rec_pangu/trainer.py
 -rw-r--r--  2.0 unx      404 b- defN 23-Mar-05 10:13 rec_pangu/dataset/__init__.py
 -rw-r--r--  2.0 unx     4954 b- defN 23-Apr-03 08:02 rec_pangu/dataset/base_dataset.py
 -rw-r--r--  2.0 unx     3776 b- defN 23-Apr-03 08:02 rec_pangu/dataset/graph_dataset.py
 -rw-r--r--  2.0 unx     2812 b- defN 23-Apr-03 08:02 rec_pangu/dataset/multi_task_dataset.py
 -rw-r--r--  2.0 unx     3986 b- defN 23-Apr-03 08:02 rec_pangu/dataset/process_data.py
 -rw-r--r--  2.0 unx     5635 b- defN 23-Apr-03 08:02 rec_pangu/dataset/sequence_dataset.py
 -rw-r--r--  2.0 unx      117 b- defN 22-Jul-28 02:44 rec_pangu/models/__init__.py
--rw-r--r--  2.0 unx     9351 b- defN 23-Apr-03 08:03 rec_pangu/models/base_model.py
+-rw-r--r--  2.0 unx    10465 b- defN 23-Apr-16 10:52 rec_pangu/models/base_model.py
 -rw-r--r--  2.0 unx     8027 b- defN 23-Apr-03 08:03 rec_pangu/models/utils.py
 -rw-r--r--  2.0 unx      949 b- defN 22-Jul-28 02:44 rec_pangu/models/layers/LGConv.py
 -rw-r--r--  2.0 unx      456 b- defN 23-Apr-03 07:29 rec_pangu/models/layers/__init__.py
 -rw-r--r--  2.0 unx     1876 b- defN 23-Mar-20 16:44 rec_pangu/models/layers/activation.py
 -rw-r--r--  2.0 unx     4606 b- defN 23-Apr-03 08:02 rec_pangu/models/layers/attention.py
 -rw-r--r--  2.0 unx     7468 b- defN 23-Apr-03 08:02 rec_pangu/models/layers/conv.py
 -rw-r--r--  2.0 unx     3943 b- defN 23-Apr-03 08:02 rec_pangu/models/layers/deep.py
 -rw-r--r--  2.0 unx     2932 b- defN 23-Apr-03 08:02 rec_pangu/models/layers/embedding.py
 -rw-r--r--  2.0 unx     6164 b- defN 23-Apr-03 08:02 rec_pangu/models/layers/graph.py
 -rw-r--r--  2.0 unx    12947 b- defN 23-Apr-03 08:02 rec_pangu/models/layers/interaction.py
 -rw-r--r--  2.0 unx     8463 b- defN 23-Apr-03 08:02 rec_pangu/models/layers/multi_interest.py
--rw-r--r--  2.0 unx     5266 b- defN 23-Apr-03 08:19 rec_pangu/models/layers/sequence.py
+-rw-r--r--  2.0 unx    11805 b- defN 23-Jul-05 16:01 rec_pangu/models/layers/sequence.py
 -rw-r--r--  2.0 unx      852 b- defN 23-Apr-03 08:02 rec_pangu/models/layers/shallow.py
 -rw-r--r--  2.0 unx     9674 b- defN 23-Apr-03 08:02 rec_pangu/models/layers/trainformer.py
 -rw-r--r--  2.0 unx      272 b- defN 22-Jul-28 02:44 rec_pangu/models/multi_task/__init__.py
 -rw-r--r--  2.0 unx     3948 b- defN 23-Apr-03 08:02 rec_pangu/models/multi_task/aitm.py
 -rw-r--r--  2.0 unx     2609 b- defN 23-Mar-21 08:03 rec_pangu/models/multi_task/essm.py
 -rw-r--r--  2.0 unx     6268 b- defN 23-Mar-21 07:35 rec_pangu/models/multi_task/mlmmoe.py
 -rw-r--r--  2.0 unx     5723 b- defN 23-Mar-21 07:34 rec_pangu/models/multi_task/mmoe.py
 -rw-r--r--  2.0 unx     4599 b- defN 23-Mar-21 07:34 rec_pangu/models/multi_task/omoe.py
 -rw-r--r--  2.0 unx     4105 b- defN 23-Mar-21 07:34 rec_pangu/models/multi_task/sharebottom.py
 -rw-r--r--  2.0 unx      452 b- defN 23-Apr-02 09:11 rec_pangu/models/ranking/__init__.py
--rw-r--r--  2.0 unx     2590 b- defN 23-Apr-03 08:02 rec_pangu/models/ranking/afm.py
--rw-r--r--  2.0 unx     4454 b- defN 23-Apr-03 08:02 rec_pangu/models/ranking/afn.py
--rw-r--r--  2.0 unx     5225 b- defN 23-Apr-03 08:02 rec_pangu/models/ranking/aoanet.py
--rw-r--r--  2.0 unx     3669 b- defN 23-Apr-03 08:02 rec_pangu/models/ranking/autoint.py
--rw-r--r--  2.0 unx     4402 b- defN 23-Apr-03 08:02 rec_pangu/models/ranking/ccpm.py
--rw-r--r--  2.0 unx     2604 b- defN 23-Mar-20 17:01 rec_pangu/models/ranking/dcn.py
--rw-r--r--  2.0 unx     2593 b- defN 23-Apr-03 08:02 rec_pangu/models/ranking/deepfm.py
--rw-r--r--  2.0 unx     3146 b- defN 23-Mar-21 08:03 rec_pangu/models/ranking/fibinet.py
--rw-r--r--  2.0 unx     1894 b- defN 23-Mar-21 07:29 rec_pangu/models/ranking/fm.py
+-rw-r--r--  2.0 unx     2625 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/afm.py
+-rw-r--r--  2.0 unx     4448 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/afn.py
+-rw-r--r--  2.0 unx     5260 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/aoanet.py
+-rw-r--r--  2.0 unx     3703 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/autoint.py
+-rw-r--r--  2.0 unx     4436 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/ccpm.py
+-rw-r--r--  2.0 unx     2639 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/dcn.py
+-rw-r--r--  2.0 unx     2627 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/deepfm.py
+-rw-r--r--  2.0 unx     3180 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/fibinet.py
+-rw-r--r--  2.0 unx     1928 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/fm.py
 -rw-r--r--  2.0 unx     1920 b- defN 22-Jul-28 02:44 rec_pangu/models/ranking/lightgcn.py
--rw-r--r--  2.0 unx     1668 b- defN 23-Mar-20 17:01 rec_pangu/models/ranking/lr.py
--rw-r--r--  2.0 unx     3797 b- defN 23-Apr-02 09:21 rec_pangu/models/ranking/masknet.py
--rw-r--r--  2.0 unx     2875 b- defN 23-Mar-21 08:03 rec_pangu/models/ranking/nfm.py
--rw-r--r--  2.0 unx     2785 b- defN 23-Mar-21 08:03 rec_pangu/models/ranking/wdl.py
--rw-r--r--  2.0 unx     3162 b- defN 23-Mar-21 08:03 rec_pangu/models/ranking/xdeepfm.py
--rw-r--r--  2.0 unx      437 b- defN 23-Apr-03 08:24 rec_pangu/models/sequence/__init__.py
--rw-r--r--  2.0 unx     9009 b- defN 23-Apr-03 07:38 rec_pangu/models/sequence/cmi.py
--rw-r--r--  2.0 unx     4764 b- defN 23-Apr-03 07:38 rec_pangu/models/sequence/comirec.py
--rw-r--r--  2.0 unx     3807 b- defN 23-Apr-03 07:38 rec_pangu/models/sequence/gcsan.py
--rw-r--r--  2.0 unx     2425 b- defN 23-Apr-03 08:02 rec_pangu/models/sequence/mind.py
--rw-r--r--  2.0 unx     2977 b- defN 23-Apr-03 08:02 rec_pangu/models/sequence/narm.py
--rw-r--r--  2.0 unx     2146 b- defN 23-Apr-03 07:37 rec_pangu/models/sequence/nextitnet.py
--rw-r--r--  2.0 unx     3601 b- defN 23-Mar-28 08:15 rec_pangu/models/sequence/niser.py
--rw-r--r--  2.0 unx     8056 b- defN 23-Apr-03 08:02 rec_pangu/models/sequence/re4.py
--rw-r--r--  2.0 unx     2780 b- defN 23-Apr-03 08:02 rec_pangu/models/sequence/sasrec.py
--rw-r--r--  2.0 unx     3014 b- defN 23-Apr-03 08:02 rec_pangu/models/sequence/srgnn.py
--rw-r--r--  2.0 unx     1779 b- defN 23-Apr-03 08:24 rec_pangu/models/sequence/stamp.py
--rw-r--r--  2.0 unx     1587 b- defN 23-Apr-03 08:02 rec_pangu/models/sequence/yotubednn.py
+-rw-r--r--  2.0 unx     1700 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/lr.py
+-rw-r--r--  2.0 unx     3831 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/masknet.py
+-rw-r--r--  2.0 unx     2909 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/nfm.py
+-rw-r--r--  2.0 unx     2819 b- defN 23-Apr-16 10:54 rec_pangu/models/ranking/wdl.py
+-rw-r--r--  2.0 unx     3196 b- defN 23-Apr-16 10:55 rec_pangu/models/ranking/xdeepfm.py
+-rw-r--r--  2.0 unx      547 b- defN 23-Jul-06 08:07 rec_pangu/models/sequence/__init__.py
+-rw-r--r--  2.0 unx     3682 b- defN 23-Jul-06 08:19 rec_pangu/models/sequence/clrec.py
+-rw-r--r--  2.0 unx     9043 b- defN 23-Apr-11 14:28 rec_pangu/models/sequence/cmi.py
+-rw-r--r--  2.0 unx     4832 b- defN 23-Apr-11 14:29 rec_pangu/models/sequence/comirec.py
+-rw-r--r--  2.0 unx     6913 b- defN 23-Jul-06 07:54 rec_pangu/models/sequence/contrarec.py
+-rw-r--r--  2.0 unx     3841 b- defN 23-Apr-11 14:29 rec_pangu/models/sequence/gcsan.py
+-rw-r--r--  2.0 unx     1706 b- defN 23-Jul-05 16:02 rec_pangu/models/sequence/gru4rec.py
+-rw-r--r--  2.0 unx     2459 b- defN 23-Apr-11 14:29 rec_pangu/models/sequence/mind.py
+-rw-r--r--  2.0 unx     3011 b- defN 23-Apr-11 14:29 rec_pangu/models/sequence/narm.py
+-rw-r--r--  2.0 unx     2180 b- defN 23-Apr-11 14:29 rec_pangu/models/sequence/nextitnet.py
+-rw-r--r--  2.0 unx     3635 b- defN 23-Apr-11 14:29 rec_pangu/models/sequence/niser.py
+-rw-r--r--  2.0 unx     8090 b- defN 23-Apr-11 14:29 rec_pangu/models/sequence/re4.py
+-rw-r--r--  2.0 unx     2814 b- defN 23-Apr-11 14:29 rec_pangu/models/sequence/sasrec.py
+-rw-r--r--  2.0 unx     4679 b- defN 23-Jul-11 06:06 rec_pangu/models/sequence/sine.py
+-rw-r--r--  2.0 unx     3048 b- defN 23-Apr-11 14:29 rec_pangu/models/sequence/srgnn.py
+-rw-r--r--  2.0 unx     1813 b- defN 23-Apr-11 14:29 rec_pangu/models/sequence/stamp.py
+-rw-r--r--  2.0 unx     1621 b- defN 23-Apr-11 14:29 rec_pangu/models/sequence/yotubednn.py
 -rw-r--r--  2.0 unx      115 b- defN 23-Apr-11 01:35 rec_pangu/serving/__init__.py
 -rw-r--r--  2.0 unx     2211 b- defN 23-Apr-11 02:23 rec_pangu/serving/ranking_server.py
 -rw-r--r--  2.0 unx      301 b- defN 23-Mar-05 10:33 rec_pangu/utils/__init__.py
 -rw-r--r--  2.0 unx     1509 b- defN 23-Apr-03 08:03 rec_pangu/utils/check_version.py
 -rw-r--r--  2.0 unx     8756 b- defN 23-Apr-03 08:03 rec_pangu/utils/evaluate.py
--rw-r--r--  2.0 unx     1565 b- defN 23-Mar-20 16:15 rec_pangu/utils/gpu_utils.py
+-rw-r--r--  2.0 unx     1549 b- defN 23-Jul-11 06:55 rec_pangu/utils/gpu_utils.py
 -rw-r--r--  2.0 unx      668 b- defN 23-Apr-03 08:03 rec_pangu/utils/json_utils.py
--rw-r--r--  2.0 unx     1058 b- defN 23-Apr-11 02:23 rec_pangu-0.3.7.dist-info/LICENSE
--rw-r--r--  2.0 unx    14306 b- defN 23-Apr-11 02:23 rec_pangu-0.3.7.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-11 02:23 rec_pangu-0.3.7.dist-info/WHEEL
--rw-r--r--  2.0 unx       10 b- defN 23-Apr-11 02:23 rec_pangu-0.3.7.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     6776 b- defN 23-Apr-11 02:23 rec_pangu-0.3.7.dist-info/RECORD
-76 files, 317653 bytes uncompressed, 95793 bytes compressed:  69.8%
+-rw-r--r--  2.0 unx     1058 b- defN 23-Jul-11 06:56 rec_pangu-0.3.9.dist-info/LICENSE
+-rw-r--r--  2.0 unx    17906 b- defN 23-Jul-11 06:56 rec_pangu-0.3.9.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-11 06:56 rec_pangu-0.3.9.dist-info/WHEEL
+-rw-r--r--  2.0 unx       10 b- defN 23-Jul-11 06:56 rec_pangu-0.3.9.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     7147 b- defN 23-Jul-11 06:56 rec_pangu-0.3.9.dist-info/RECORD
+80 files, 348995 bytes uncompressed, 105187 bytes compressed:  69.9%
```

## zipnote {}

```diff
@@ -150,23 +150,32 @@
 
 Filename: rec_pangu/models/ranking/xdeepfm.py
 Comment: 
 
 Filename: rec_pangu/models/sequence/__init__.py
 Comment: 
 
+Filename: rec_pangu/models/sequence/clrec.py
+Comment: 
+
 Filename: rec_pangu/models/sequence/cmi.py
 Comment: 
 
 Filename: rec_pangu/models/sequence/comirec.py
 Comment: 
 
+Filename: rec_pangu/models/sequence/contrarec.py
+Comment: 
+
 Filename: rec_pangu/models/sequence/gcsan.py
 Comment: 
 
+Filename: rec_pangu/models/sequence/gru4rec.py
+Comment: 
+
 Filename: rec_pangu/models/sequence/mind.py
 Comment: 
 
 Filename: rec_pangu/models/sequence/narm.py
 Comment: 
 
 Filename: rec_pangu/models/sequence/nextitnet.py
@@ -177,14 +186,17 @@
 
 Filename: rec_pangu/models/sequence/re4.py
 Comment: 
 
 Filename: rec_pangu/models/sequence/sasrec.py
 Comment: 
 
+Filename: rec_pangu/models/sequence/sine.py
+Comment: 
+
 Filename: rec_pangu/models/sequence/srgnn.py
 Comment: 
 
 Filename: rec_pangu/models/sequence/stamp.py
 Comment: 
 
 Filename: rec_pangu/models/sequence/yotubednn.py
@@ -207,23 +219,23 @@
 
 Filename: rec_pangu/utils/gpu_utils.py
 Comment: 
 
 Filename: rec_pangu/utils/json_utils.py
 Comment: 
 
-Filename: rec_pangu-0.3.7.dist-info/LICENSE
+Filename: rec_pangu-0.3.9.dist-info/LICENSE
 Comment: 
 
-Filename: rec_pangu-0.3.7.dist-info/METADATA
+Filename: rec_pangu-0.3.9.dist-info/METADATA
 Comment: 
 
-Filename: rec_pangu-0.3.7.dist-info/WHEEL
+Filename: rec_pangu-0.3.9.dist-info/WHEEL
 Comment: 
 
-Filename: rec_pangu-0.3.7.dist-info/top_level.txt
+Filename: rec_pangu-0.3.9.dist-info/top_level.txt
 Comment: 
 
-Filename: rec_pangu-0.3.7.dist-info/RECORD
+Filename: rec_pangu-0.3.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## rec_pangu/__init__.py

```diff
@@ -1,9 +1,9 @@
 # -*- ecoding: utf-8 -*-
 # @ModuleName: __init__
 # @Author: wk
 # @Email: 306178200@qq.com
 # @Time: 2022/6/10 8:20 PM
 from .utils import check_version
 
-__version__ = '0.3.7'
+__version__ = '0.3.9'
 check_version(__version__)
```

## rec_pangu/trainer.py

```diff
@@ -13,14 +13,15 @@
 from .utils import beautify_json
 from .dataset import BaseDataset, MultiTaskDataset
 from loguru import logger
 import torch.utils.data as D
 import wandb
 from typing import List, Optional
 import pandas as pd
+from torch.optim import lr_scheduler
 
 
 class RankTrainer:
     """
     A class for training ranking models with single or multiple tasks.
 
     Attributes:
@@ -45,15 +46,16 @@
         self.use_wandb = self.wandb_config is not None
         if self.use_wandb:
             wandb.login(key=self.wandb_config['key'])
             self.wandb_config.pop('key')
 
     def fit(self, model, train_loader, valid_loader: Optional = None, epoch: int = 10, lr: float = 1e-3,
             device: torch.device = torch.device('cpu'), use_earlystopping: bool = False,
-            max_patience: int = 999, monitor_metric: Optional[str] = None):
+            max_patience: int = 999, monitor_metric: Optional[str] = None, lr_scheduler_type: str = "",
+            scheduler_params: Optional[dict] = {}):
         """
         Train the model using the given data loaders and hyperparameters.
 
         Args:
             model (nn.Module): The model to be trained.
             train_loader (DataLoader): The data loader for training data.
             valid_loader (DataLoader, optional): The data loader for validation data. Defaults to None.
@@ -64,25 +66,42 @@
             max_patience (int, optional): The maximum patience for early stopping. Defaults to 999.
             monitor_metric (str, optional): The metric to monitor for early stopping. Defaults to None.
         """
         if self.use_wandb:
             wandb.init(
                 **self.wandb_config
             )
+
         # Declare the optimizer
         optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)
         model = model.to(device)
+
+        # 根据选择的学习率衰减策略，初始化学习率衰减器
+        if lr_scheduler_type == 'StepLR':
+            scheduler = lr_scheduler.StepLR(optimizer, **scheduler_params)
+        elif lr_scheduler_type == 'ExponentialLR':
+            scheduler = lr_scheduler.ExponentialLR(optimizer, **scheduler_params)
+        elif lr_scheduler_type == 'CosineAnnealingLR':
+            scheduler = lr_scheduler.CosineAnnealingLR(optimizer, **scheduler_params)
+        elif lr_scheduler_type == "":
+            scheduler = None
+        else:
+            raise ValueError('Unknown scheduler type: {}'.format(lr_scheduler_type))
+
         # Model training process
         logger.info('Model Starting Training ')
         best_epoch = -1
         best_metric = -1
         for i in range(1, epoch + 1):
             # Model training
             train_metric = train_model(model, train_loader, optimizer=optimizer, device=device, num_task=self.num_task,
                                        use_wandb=self.use_wandb)
+            if scheduler is not None:
+                scheduler.step()
+                logger.info(f"Epoch {i} LR:{round(scheduler.get_lr(),6)}")
             logger.info(f"Train Metric:{train_metric}")
             # Model validation
             if valid_loader is not None:
                 valid_metric = test_model(model, valid_loader, device, num_task=self.num_task)
                 model_str = f'e_{i}'
                 self.save_train_model(model, self.model_ckpt_dir, model_str)
                 if self.use_wandb:
@@ -238,15 +257,16 @@
         if self.use_wandb:
             wandb.login(key=self.wandb_config['key'])
             self.wandb_config.pop('key')
 
     def fit(self, model, train_loader, valid_loader: Optional = None, epoch: int = 50, lr: float = 1e-3,
             device: torch.device = torch.device('cpu'), topk_list: Optional[List[int]] = None,
             use_earlystoping: bool = False, max_patience: int = 999, monitor_metric: Optional[str] = None,
-            log_rounds: int = 100):
+            log_rounds: int = 100, lr_scheduler_type: str = "",
+            scheduler_params: Optional[dict] = {}):
         """
         Fits the model using the given data loaders.
 
         Args:
             model: The model to train.
             train_loader: DataLoader for training data.
             valid_loader (Optional): DataLoader for validation data. Defaults to None.
@@ -267,24 +287,38 @@
                 **self.wandb_config
             )
 
         # Define the optimizer
         optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)
         model = model.to(device)
 
+        # 根据选择的学习率衰减策略，初始化学习率衰减器
+        if lr_scheduler_type == 'StepLR':
+            scheduler = lr_scheduler.StepLR(optimizer, **scheduler_params)
+        elif lr_scheduler_type == 'ExponentialLR':
+            scheduler = lr_scheduler.ExponentialLR(optimizer, **scheduler_params)
+        elif lr_scheduler_type == 'CosineAnnealingLR':
+            scheduler = lr_scheduler.CosineAnnealingLR(optimizer, **scheduler_params)
+        elif lr_scheduler_type == "":
+            scheduler = None
+        else:
+            raise ValueError('Unknown scheduler type: {}'.format(lr_scheduler_type))
         # Training process
         logger.info('Model Starting Training')
         best_epoch = -1
         best_metric = -1
         best_metric_dict = dict()
 
         for i in range(1, epoch + 1):
             # Train the model
             train_sequence_model(model, train_loader, optimizer=optimizer, device=device,
                                  use_wandb=self.use_wandb, log_rounds=log_rounds)
+            if scheduler is not None:
+                scheduler.step()
+                logger.info(f"Epoch {i} LR:{round(scheduler.get_lr()[-1], 6)}")
 
             # Validate the model
             if valid_loader is not None:
                 valid_metric = test_sequence_model(model=model, test_loader=valid_loader, topk_list=topk_list,
                                                    device=device, use_wandb=self.use_wandb)
                 valid_metric['phase'] = 'valid'
                 self.log_df = self.log_df.append(valid_metric, ignore_index=True)
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## rec_pangu/models/base_model.py

```diff
@@ -35,14 +35,32 @@
         if isinstance(module, nn.Embedding):
             xavier_normal_(module.weight.data)
         elif isinstance(module, nn.Linear):
             xavier_normal_(module.weight.data)
             if module.bias is not None:
                 constant_(module.bias.data, 0)
 
+    def reset_parameters(self):
+        """
+        Initializes the weights of the neural network.
+
+        Args:
+            self: The neural network object.
+
+        Returns:
+            None
+        """
+        for weight in self.parameters():
+            # If the weight is a bias term or a 1D tensor, set it to 0.
+            if len(weight.shape) == 1:
+                torch.nn.init.constant_(weight, 0)
+            # Otherwise, initialize the weight using Kaiming initialization.
+            else:
+                torch.nn.init.kaiming_normal_(weight)
+
     def set_pretrained_weights(self, col_name: str, pretrained_dict: dict, trainable: bool = True) -> None:
         """
         Set the pre-trained weights for the model.
 
         Args:
             col_name (str): Column name for the embedding layer.
             pretrained_dict (dict): A pre-trained embedding dictionary.
@@ -165,15 +183,15 @@
 
         subsequent_mask = (subsequent_mask == 0).unsqueeze(1).type_as(
             attention_mask)  # reshape and convert to attention_mask type
 
         extended_attention_mask = extended_attention_mask * subsequent_mask  # apply mask
 
         extended_attention_mask = (
-                                              1.0 - extended_attention_mask) * -1e6  # replace masked positions with -1e6 and unmasked positions with 0
+                                          1.0 - extended_attention_mask) * -1e6  # replace masked positions with -1e6 and unmasked positions with 0
 
         return extended_attention_mask
 
     def _init_weights(self, module: nn.Module):
         """
         Initializes the weight value for the given module.
 
@@ -181,14 +199,32 @@
         module (nn.Module): The module whose weights need to be initialized.
         """
         if isinstance(module, nn.Embedding):
             torch.nn.init.kaiming_normal_(module.weight.data)
         elif isinstance(module, nn.Linear):
             torch.nn.init.kaiming_normal_(module.weight.data)
 
+    def reset_parameters(self):
+        """
+        Initializes the weights of the neural network.
+
+        Args:
+            self: The neural network object.
+
+        Returns:
+            None
+        """
+        for weight in self.parameters():
+            # If the weight is a bias term or a 1D tensor, set it to 0.
+            if len(weight.shape) == 1:
+                torch.nn.init.constant_(weight, 0)
+            # Otherwise, initialize the weight using Kaiming initialization.
+            else:
+                torch.nn.init.kaiming_normal_(weight)
+
 
 class GraphBaseModel(nn.Module):
     def __int__(self, num_user, num_item, embedding_dim):
         super(GraphBaseModel, self).__init__()
         self.embedding_dim = embedding_dim
         self.num_user = num_item
         self.num_item = num_item
```

## rec_pangu/models/layers/sequence.py

```diff
@@ -2,22 +2,25 @@
 # @ModuleName: sequence
 # @Author: wk
 # @Email: 306178200@qq.com
 # @Time: 2022/6/10 7:40 PM
 
 from torch import nn
 import torch
+import torch.nn.functional as F
+import numpy as np
 
 
 class MaskedAveragePooling(nn.Module):
     """
     This module takes as input an embedding matrix,
     applies masked pooling, i.e. ignores zero-padding,
     and computes the average embedding vector for each input.
     """
+
     def __init__(self):
         super(MaskedAveragePooling, self).__init__()
 
     def forward(self, embedding_matrix: torch.Tensor) -> torch.Tensor:
         """
         Computes the average embedding vector.
 
@@ -35,14 +38,15 @@
 
 class MaskedSumPooling(nn.Module):
     """
     This module takes as input an embedding matrix,
     applies masked pooling, i.e. ignores zero-padding,
     and computes the sum embedding vector for each input.
     """
+
     def __init__(self):
         super(MaskedSumPooling, self).__init__()
 
     def forward(self, embedding_matrix: torch.Tensor) -> torch.Tensor:
         """
         Computes the sum embedding vector.
 
@@ -57,14 +61,15 @@
 
 
 class KMaxPooling(nn.Module):
     """
     This module takes as input an embedding matrix,
     and returns the k-max pooling along the specified axis.
     """
+
     def __init__(self, k: int, dim: int):
         super(KMaxPooling, self).__init__()
         self.k = k
         self.dim = dim
 
     def forward(self, X: torch.Tensor) -> torch.Tensor:
         """
@@ -133,7 +138,175 @@
 
         # calculate final output scores
         ha = self.fc_a(ma)
         ht = self.fc_t(xt)
         sr = ha * ht  # [batch_size, embedding_dim]
 
         return sr
+
+
+""" Encoder Layers """
+
+
+class MultiHeadAttention(nn.Module):
+    def __init__(self, d_model, n_heads, kq_same=False, bias=True):
+        super().__init__()
+        """
+        It has projection layer for getting keys, queries and values. Followed by attention.
+        """
+        self.d_model = d_model
+        self.h = n_heads
+        self.d_k = self.d_model // self.h
+        self.kq_same = kq_same
+
+        if not kq_same:
+            self.q_linear = nn.Linear(d_model, d_model, bias=bias)
+        self.k_linear = nn.Linear(d_model, d_model, bias=bias)
+        self.v_linear = nn.Linear(d_model, d_model, bias=bias)
+
+    def head_split(self, x):  # get dimensions bs * h * seq_len * d_k
+        new_x_shape = x.size()[:-1] + (self.h, self.d_k)
+        return x.view(*new_x_shape).transpose(-2, -3)
+
+    def forward(self, q, k, v, mask=None):
+        origin_shape = q.size()
+
+        # perform linear operation and split into h heads
+        if not self.kq_same:
+            q = self.head_split(self.q_linear(q))
+        else:
+            q = self.head_split(self.k_linear(q))
+        k = self.head_split(self.k_linear(k))
+        v = self.head_split(self.v_linear(v))
+
+        # calculate attention using function we will define next
+        output = self.scaled_dot_product_attention(q, k, v, self.d_k, mask)
+
+        # concatenate heads and put through final linear layer
+        output = output.transpose(-2, -3).reshape(origin_shape)
+        return output
+
+    @staticmethod
+    def scaled_dot_product_attention(q, k, v, d_k, mask=None):
+        """
+        This is called by Multi-head attention object to find the values.
+        """
+        scores = torch.matmul(q, k.transpose(-2, -1)) / d_k ** 0.5  # bs, head, q_len, k_len
+        if mask is not None:
+            scores = scores.masked_fill(mask == 0, -np.inf)
+        scores = (scores - scores.max()).softmax(dim=-1)
+        scores = scores.masked_fill(torch.isnan(scores), 0)
+        output = torch.matmul(scores, v)  # bs, head, q_len, d_k
+        return output
+
+
+class TransformerLayer(nn.Module):
+    def __init__(self, d_model, d_ff, n_heads, dropout=0, kq_same=False):
+        super().__init__()
+        """
+        This is a Basic Block of Transformer. It contains one Multi-head attention object. 
+        Followed by layer norm and position wise feedforward net and dropout layer.
+        """
+        # Multi-Head Attention Block
+        self.masked_attn_head = MultiHeadAttention(d_model, n_heads, kq_same=kq_same)
+
+        # Two layer norm layer and two dropout layer
+        self.layer_norm1 = nn.LayerNorm(d_model)
+        self.dropout1 = nn.Dropout(dropout)
+
+        self.linear1 = nn.Linear(d_model, d_ff)
+        self.linear2 = nn.Linear(d_ff, d_model)
+
+        self.layer_norm2 = nn.LayerNorm(d_model)
+        self.dropout2 = nn.Dropout(dropout)
+
+    def forward(self, seq, mask=None):
+        context = self.masked_attn_head(seq, seq, seq, mask)
+        context = self.layer_norm1(self.dropout1(context) + seq)
+        output = self.linear1(context).relu()
+        output = self.linear2(output)
+        output = self.layer_norm2(self.dropout2(output) + context)
+        return output
+
+
+class GRU4RecEncoder(nn.Module):
+    def __init__(self, emb_size, hidden_size=128, num_layers=2):
+        super().__init__()
+        self.rnn = nn.GRU(input_size=emb_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)
+        self.out = nn.Linear(hidden_size, emb_size, bias=False)
+
+    def forward(self, seq, lengths):
+        # Sort and Pack
+        sort_lengths, sort_idx = torch.topk(lengths, k=len(lengths))
+        sort_seq = seq.index_select(dim=0, index=sort_idx)
+        seq_packed = torch.nn.utils.rnn.pack_padded_sequence(sort_seq, sort_lengths.cpu(), batch_first=True)
+
+        # RNN
+        output, hidden = self.rnn(seq_packed, None)
+
+        # Unsort
+        sort_rnn_vector = self.out(hidden[-1])
+        unsort_idx = torch.topk(sort_idx, k=len(lengths), largest=False)[1]
+        rnn_vector = sort_rnn_vector.index_select(dim=0, index=unsort_idx)
+
+        return rnn_vector
+
+
+class CaserEncoder(nn.Module):
+    def __init__(self, emb_size, max_his, num_horizon=16, num_vertical=8, l=5):
+        super().__init__()
+        self.max_his = max_his
+        lengths = [i + 1 for i in range(l)]
+        self.conv_h = nn.ModuleList(
+            [nn.Conv2d(in_channels=1, out_channels=num_horizon, kernel_size=(i, emb_size)) for i in lengths])
+        self.conv_v = nn.Conv2d(in_channels=1, out_channels=num_vertical, kernel_size=(max_his, 1))
+        self.fc_dim_h = num_horizon * len(lengths)
+        self.fc_dim_v = num_vertical * emb_size
+        fc_dim_in = self.fc_dim_v + self.fc_dim_h
+        self.fc = nn.Linear(fc_dim_in, emb_size)
+
+    def forward(self, seq, lengths):
+        batch_size, seq_len = seq.size(0), seq.size(1)
+        pad_len = self.max_his - seq_len
+        seq = F.pad(seq, [0, 0, 0, pad_len]).unsqueeze(1)
+
+        # Convolution Layers
+        out_v = self.conv_v(seq).view(-1, self.fc_dim_v)
+        out_hs = list()
+        for conv in self.conv_h:
+            conv_out = conv(seq).squeeze(3).relu()
+            pool_out = F.max_pool1d(conv_out, conv_out.size(2)).squeeze(2)
+            out_hs.append(pool_out)
+        out_h = torch.cat(out_hs, 1)
+
+        # Fully-connected Layers
+        his_vector = self.fc(torch.cat([out_v, out_h], 1))
+        return his_vector
+
+
+class BERT4RecEncoder(nn.Module):
+    def __init__(self, emb_size, max_his, num_layers=2, num_heads=2):
+        super().__init__()
+        self.p_embeddings = nn.Embedding(max_his + 1, emb_size)
+        self.transformer_block = nn.ModuleList([
+            TransformerLayer(d_model=emb_size, d_ff=emb_size, n_heads=num_heads)
+            for _ in range(num_layers)
+        ])
+
+    def forward(self, seq, lengths):
+        batch_size, seq_len = seq.size(0), seq.size(1)
+        len_range = torch.from_numpy(np.arange(seq_len)).to(seq.device)
+        valid_mask = len_range[None, :] < lengths[:, None]
+
+        # Position embedding
+        position = len_range[None, :] * valid_mask.long()
+        pos_vectors = self.p_embeddings(position)
+        seq = seq + pos_vectors
+
+        # Self-attention
+        attn_mask = valid_mask.view(batch_size, 1, 1, seq_len)
+        for block in self.transformer_block:
+            seq = block(seq, attn_mask)
+        seq = seq * valid_mask[:, :, None].float()
+
+        his_vector = seq[torch.arange(batch_size), lengths - 1]
+        return his_vector
```

## rec_pangu/models/ranking/afm.py

```diff
@@ -5,15 +5,15 @@
 # @Time: 2022/6/10 7:40 PM
 import torch
 from ..layers import MLP, LR_Layer, SENET_Layer, BilinearInteractionLayer
 from ..utils import get_feature_num, get_linear_input
 from ..base_model import BaseModel
 
 
-# TODO: change the current code of AFM with the right version.
+# Fixme: change the current code of AFM with the right version.
 
 class AFM(BaseModel):
     def __init__(self,
                  embedding_dim=32,
                  hidden_units=[64, 64, 64],
                  loss_fun='torch.nn.BCELoss()',
                  enc_dict=None):
@@ -28,15 +28,16 @@
         self.lr = LR_Layer(enc_dict=self.enc_dict)
         self.senet_layer = SENET_Layer(self.num_sparse, 3)
         self.bilinear_interaction = BilinearInteractionLayer(self.num_sparse, embedding_dim, 'field_interaction')
 
         input_dim = self.num_sparse * (self.num_sparse - 1) * self.embedding_dim + self.num_dense
         self.dnn = MLP(input_dim=input_dim, output_dim=1, hidden_units=self.hidden_units,
                        hidden_activations='relu', dropout_rates=0)
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data, is_training=True):
         """
         Perform forward propagation on the AFM model.
 
         Args:
             data (Dict[str, torch.Tensor]): The input data in the form of a dictionary containing the features and labels.
```

## rec_pangu/models/ranking/afn.py

```diff
@@ -44,24 +44,25 @@
         self.dense_layer = MLP(input_dim=embedding_dim * logarithmic_neurons,
                                output_dim=1,
                                hidden_units=afn_hidden_units,
                                use_bias=True)
         self.log_batch_norm = nn.BatchNorm1d(self.num_sparse)
         self.exp_batch_norm = nn.BatchNorm1d(logarithmic_neurons)
         self.ensemble_dnn = ensemble_dnn
-        self.apply(self._init_weights)
 
         if ensemble_dnn:
             self.embedding_layer2 = EmbeddingLayer(enc_dict=self.enc_dict, embedding_dim=self.embedding_dim)
             self.dnn = MLP(input_dim=embedding_dim * self.num_sparse,
                            output_dim=1,
                            hidden_units=dnn_hidden_units,
                            use_bias=True)
             self.fc = nn.Linear(2, 1)
 
+        self.reset_parameters()
+
     def forward(self, data, is_training=True):
         """
         Perform forward propagation on the AFN model.
 
         Args:
             data (Dict[str, torch.Tensor]): The input data in the form of a dictionary containing the features and labels.
             is_training (bool): If True, compute the loss. Default is True.
```

## rec_pangu/models/ranking/aoanet.py

```diff
@@ -42,15 +42,17 @@
                        output_dim=None,
                        hidden_units=self.dnn_hidden_units)
         self.gin = GeneralizedInteractionNet(num_interaction_layers,
                                              num_subspaces,
                                              self.num_sparse,
                                              self.embedding_dim)
         self.fc = nn.Linear(dnn_hidden_units[-1] + num_subspaces * self.embedding_dim, 1)
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
+
 
     def forward(self, data, is_training=True):
         """
         Perform forward propagation on the AoaNet model.
 
         Args:
             data (Dict[str, torch.Tensor]): The input data in the form of a dictionary containing the features and labels.
```

## rec_pangu/models/ranking/autoint.py

```diff
@@ -49,15 +49,16 @@
         self.self_attention = nn.Sequential(
             *[MultiHeadSelfAttention(self.embedding_dim if i == 0 else num_heads * attention_dim,
                                      attention_dim=attention_dim,
                                      num_heads=num_heads,
                                      align_to="output")
               for i in range(attention_layers)])
         self.fc = nn.Linear(self.num_sparse * attention_dim * num_heads, 1)
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data, is_training=True):
         """
         Perform forward propagation on the AutoInt model.
 
         Args:
             data (Dict[str, torch.Tensor]): The input data in the form of a dictionary containing the features and labels.
```

## rec_pangu/models/ranking/ccpm.py

```diff
@@ -39,15 +39,16 @@
 
         self.conv_layer = CCPM_ConvLayer(self.num_sparse,
                                          channels=channels,
                                          kernel_heights=kernel_heights)
         conv_out_dim = 3 * embedding_dim * channels[-1]  # 3 is k-max-pooling size of the last layer
         self.fc = nn.Linear(conv_out_dim, 1)
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data, is_training=True):
         """
         Perform forward propagation on the CCPM model.
 
         Args:
             data (Dict[str, torch.Tensor]): The input data in the form of a dictionary containing the features and labels.
```

## rec_pangu/models/ranking/dcn.py

```diff
@@ -35,15 +35,17 @@
 
         self.num_sparse, self.num_dense = get_feature_num(self.enc_dict)
         input_dim = self.num_sparse * self.embedding_dim + self.num_dense
         self.crossnet = CrossNet(input_dim, crossing_layers)
 
         self.fc = nn.Linear(input_dim, 1)
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
+
 
     def forward(self, data, is_training=True):
         """
         Perform forward propagation on the DCN model.
 
         Args:
             data (Dict[str, torch.Tensor]): The input data in the form of a dictionary containing the features and labels.
```

## rec_pangu/models/ranking/deepfm.py

```diff
@@ -31,15 +31,16 @@
         self.loss_fun = eval(loss_fun)
         self.enc_dict = enc_dict
 
         self.fm = FM_Layer()
         self.dnn_input_dim = get_dnn_input_dim(self.enc_dict, self.embedding_dim)
         self.dnn = MLP(input_dim=self.dnn_input_dim, output_dim=1, hidden_units=self.hidden_units,
                        hidden_activations='relu', dropout_rates=0)
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data, is_training=True):
         """
         Perform forward propagation on the DeepFM model.
 
         Args:
             data (Dict[str, torch.Tensor]): The input data in the form of a dictionary containing the features and labels.
```

## rec_pangu/models/ranking/fibinet.py

```diff
@@ -36,15 +36,16 @@
         self.lr = LR_Layer(enc_dict=self.enc_dict)
         self.senet_layer = SENET_Layer(self.num_sparse, 3)
         self.bilinear_interaction = BilinearInteractionLayer(self.num_sparse, embedding_dim, 'field_interaction')
 
         input_dim = self.num_sparse * (self.num_sparse - 1) * self.embedding_dim + self.num_dense
         self.dnn = MLP(input_dim=input_dim, output_dim=1, hidden_units=self.hidden_units,
                        hidden_activations='relu', dropout_rates=0)
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.Tensor],
                 is_training: bool = True) -> Dict[str, torch.Tensor]:
         """
         Perform forward propagation on the FiBiNet model.
 
         Args:
```

## rec_pangu/models/ranking/fm.py

```diff
@@ -24,15 +24,16 @@
         """
         super(FM, self).__init__(enc_dict, embedding_dim)
 
         self.loss_fun = eval(loss_fun)
         self.enc_dict = enc_dict
         self.fm = FM_Layer()
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.Tensor],
                 is_training: bool = True) -> Dict[str, torch.Tensor]:
         """
         Perform forward propagation on the FM model.
 
         Args:
```

## rec_pangu/models/ranking/lr.py

```diff
@@ -21,14 +21,15 @@
             enc_dict (Dict[str, int]): The dictionary containing the encoding information for the features.
         """
         super(LR, self).__init__()
 
         self.loss_fun = eval(loss_fun)
         self.enc_dict = enc_dict
         self.lr_layer = LR_Layer(enc_dict=self.enc_dict)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.Tensor],
                 is_training: bool = True) -> Dict[str, torch.Tensor]:
         """
         Perform forward propagation on the LR model.
 
         Args:
```

## rec_pangu/models/ranking/masknet.py

```diff
@@ -45,15 +45,16 @@
             self.mask_block_list.append(MaskBlock(self.input_dim, self.mask_input_dim,
                                                   self.block_output_dim, self.reduction_factor))
 
         self.mlp = MLP(self.block_output_dim,
                        hidden_units=self.hidden_units,
                        output_dim=1)
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data, is_training=True):
         """
         Perform forward propagation on the MaskNet model.
 
         Args:
             data (Dict[str, torch.Tensor]): The input data in the form of a dictionary containing the features and labels.
```

## rec_pangu/models/ranking/nfm.py

```diff
@@ -33,15 +33,16 @@
 
         self.lr = LR_Layer(enc_dict=self.enc_dict)
 
         self.inner_product_layer = InnerProductLayer(output="Bi_interaction_pooling")
         self.dnn_input_dim = get_dnn_input_dim(self.enc_dict, self.embedding_dim)
         self.dnn = MLP(input_dim=self.embedding_dim, output_dim=1, hidden_units=self.hidden_units,
                        hidden_activations='relu', dropout_rates=0)
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.Tensor], is_training: bool = True) -> Dict[str, torch.Tensor]:
         """
         Perform forward propagation on the NFM model.
 
         Args:
             data (Dict[str, torch.Tensor]): The input data in the form of a dictionary containing the features and labels.
```

## rec_pangu/models/ranking/wdl.py

```diff
@@ -32,15 +32,16 @@
         self.enc_dict = enc_dict
         # Wide part
         self.lr = LR_Layer(enc_dict=self.enc_dict)
         # Deep part
         self.dnn_input_dim = get_dnn_input_dim(self.enc_dict, self.embedding_dim)
         self.dnn = MLP(input_dim=self.dnn_input_dim, output_dim=1, hidden_units=self.hidden_units,
                        hidden_activations='relu', dropout_rates=0)
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.Tensor], is_training: bool = True) -> Dict[str, torch.Tensor]:
         """
         Perform forward propagation on the WDL model.
 
         Args:
             data (Dict[str, torch.Tensor]): The input data in the form of a dictionary containing the features and labels.
```

## rec_pangu/models/ranking/xdeepfm.py

```diff
@@ -38,15 +38,16 @@
 
         self.dnn = MLP(input_dim=self.num_sparse * self.embedding_dim + self.num_dense,
                        output_dim=1,
                        hidden_units=self.dnn_hidden_units)
         self.lr_layer = LR_Layer(enc_dict=self.enc_dict)
         self.cin = CompressedInteractionNet(self.num_sparse, cin_layer_units, output_dim=1)
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.Tensor], is_training: bool = True) -> Dict[str, torch.Tensor]:
         """
         Perform forward propagation on the xDeepFM model.
 
         Args:
             data (Dict[str, torch.Tensor]): The input data in the form of a dictionary containing the features and labels.
```

## rec_pangu/models/sequence/__init__.py

```diff
@@ -11,7 +11,11 @@
 from .narm import NARM
 from .sasrec import SASRec
 from .srgnn import SRGNN
 from .gcsan import GCSAN
 from .niser import NISER
 from .nextitnet import NextItNet
 from .stamp import STAMP
+from .gru4rec import GRU4Rec
+from .sine import SINE
+from .contrarec import ContraRec
+from .clrec import CLRec
```

## rec_pangu/models/sequence/cmi.py

```diff
@@ -39,15 +39,16 @@
             batch_first=True,
         )
         self.mlp = nn.Sequential(
             nn.Linear(self.embedding_dim, self.embedding_dim, bias=True),
             nn.ReLU()
         )
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         """
         This method initializes the forward step to compute the user embeddings which will then be used for 
         recommendations.
 
         Args:
```

## rec_pangu/models/sequence/comirec.py

```diff
@@ -12,15 +12,16 @@
 class ComirecSA(SequenceBaseModel):
 
     def __init__(self, enc_dict, config):
         super(ComirecSA, self).__init__(enc_dict, config)
 
         self.multi_interest_sa = MultiInterestSelfAttention(embedding_dim=self.embedding_dim,
                                                             num_attention_heads=self.config['K'])
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         """
         This method initializes the forward step to compute the user embeddings which will then be used for 
         recommendations.
 
         Args:
@@ -66,15 +67,16 @@
 class ComirecDR(SequenceBaseModel):
 
     def __init__(self, enc_dict, config):
         super(ComirecDR, self).__init__(enc_dict, config)
 
         self.capsule = CapsuleNetwork(self.embedding_dim, self.max_length,
                                       bilinear_type=2, interest_num=self.config['K'])
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         f"""
         This method initializes the forward step to compute the user embeddings which will then be used for 
         recommendations.
 
         Args:
```

## rec_pangu/models/sequence/gcsan.py

```diff
@@ -40,15 +40,16 @@
             inner_size=self.inner_size,
             hidden_dropout_prob=self.hidden_dropout_prob,
             attn_dropout_prob=self.attn_dropout_prob,
             hidden_act=self.hidden_act,
             layer_norm_eps=self.layer_norm_eps
         )
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         """
         This method initializes the forward step to compute the user embeddings which will then be used for
         recommendations.
 
         Args:
```

## rec_pangu/models/sequence/mind.py

```diff
@@ -11,15 +11,16 @@
 
 class MIND(SequenceBaseModel):
     def __init__(self, enc_dict, config):
         super(MIND, self).__init__(enc_dict, config)
 
         self.capsule = CapsuleNetwork(self.embedding_dim, self.max_length, bilinear_type=0,
                                       interest_num=self.config['K'])
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         """
         This method initializes the forward step to compute the user embeddings which will then be used for 
         recommendations.
 
         Args:
```

## rec_pangu/models/sequence/narm.py

```diff
@@ -21,15 +21,16 @@
         self.gru = nn.GRU(self.embedding_dim, self.hidden_size, self.n_layers, bias=False, batch_first=True)
         self.a_1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)
         self.a_2 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)
         self.v_t = nn.Linear(self.hidden_size, 1, bias=False)
         self.ct_dropout = nn.Dropout(self.dropout_probs[1])
         self.b = nn.Linear(2 * self.hidden_size, self.embedding_dim, bias=False)
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         """
         This method initializes the forward step to compute the user embeddings which will then be used for 
         recommendations.
 
         Args:
```

## rec_pangu/models/sequence/nextitnet.py

```diff
@@ -19,15 +19,16 @@
         self.feat_drop = self.config.get('feat_drop', 0)
 
         self.nextit_layer = NextItNetLayer(
             self.embedding_dim, self.dilations, self.one_masked, self.kernel_size, feat_drop=self.feat_drop
         )
         self.fc = torch.nn.Linear(self.embedding_dim, self.embedding_dim, bias=False)
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         """
         This method initializes the forward step to compute the user embeddings which will then be used for
         recommendations.
 
         Args:
```

## rec_pangu/models/sequence/niser.py

```diff
@@ -24,15 +24,16 @@
 
         self.gnncell = SRGNNCell(self.embedding_dim)
         self.linear_one = nn.Linear(self.embedding_dim, self.embedding_dim)
         self.linear_two = nn.Linear(self.embedding_dim, self.embedding_dim)
         self.linear_three = nn.Linear(self.embedding_dim, 1, bias=False)
         self.linear_transform = nn.Linear(self.embedding_dim * 2, self.embedding_dim)
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         """
         This method initializes the forward step to compute the user embeddings which will then be used for
         recommendations.
 
         Args:
```

## rec_pangu/models/sequence/re4.py

```diff
@@ -33,15 +33,16 @@
 
         self.fc1 = nn.Linear(self.embedding_dim, self.embedding_dim)
         self.fc_cons = nn.Linear(self.embedding_dim, self.embedding_dim * self.max_length)
 
         self.mse_loss = nn.MSELoss(reduce=True, size_average=True)
         self.recons_mse_loss = nn.MSELoss(reduce=False)
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         """
         This method initializes the forward step to compute the user embeddings which will then be used for 
         recommendations.
 
         Args:
```

## rec_pangu/models/sequence/sasrec.py

```diff
@@ -30,15 +30,16 @@
             inner_size=self.inner_size,
             hidden_dropout_prob=self.hidden_dropout_prob,
             attn_dropout_prob=self.attn_dropout_prob,
             hidden_act=self.hidden_act,
             layer_norm_eps=self.layer_norm_eps
         )
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         """
         This method initializes the forward step to compute the user embeddings which will then be used for
         recommendations.
 
         Args:
```

## rec_pangu/models/sequence/srgnn.py

```diff
@@ -20,15 +20,16 @@
 
         self.gnncell = SRGNNCell(self.embedding_dim)
         self.linear_one = nn.Linear(self.embedding_dim, self.embedding_dim)
         self.linear_two = nn.Linear(self.embedding_dim, self.embedding_dim)
         self.linear_three = nn.Linear(self.embedding_dim, 1, bias=False)
         self.linear_transform = nn.Linear(self.embedding_dim * 2, self.embedding_dim)
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         """
         This method initializes the forward step to compute the user embeddings which will then be used for 
         recommendations.
 
         Args:
```

## rec_pangu/models/sequence/stamp.py

```diff
@@ -12,15 +12,16 @@
 class STAMP(SequenceBaseModel):
     def __init__(self, enc_dict, config):
         super(STAMP, self).__init__(enc_dict, config)
 
         self.feat_drop = self.config.get('feat_drop', 0)
 
         self.stamp_layer = STAMPLayer(self.embedding_dim, feat_drop=self.feat_drop)
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         """
         This method initializes the forward step to compute the user embeddings which will then be used for
         recommendations.
 
         Args:
```

## rec_pangu/models/sequence/yotubednn.py

```diff
@@ -8,15 +8,16 @@
 from rec_pangu.models.base_model import SequenceBaseModel
 
 
 class YotubeDNN(SequenceBaseModel):
     def __init__(self, enc_dict, config):
         super(YotubeDNN, self).__init__(enc_dict, config)
 
-        self.apply(self._init_weights)
+        # self.apply(self._init_weights)
+        self.reset_parameters()
 
     def forward(self, data: Dict[str, torch.tensor], is_training: bool = True):
         """
         This method initializes the forward step to compute the user embeddings which will then be used for 
         recommendations.
 
         Args:
```

## rec_pangu/utils/gpu_utils.py

```diff
@@ -15,15 +15,15 @@
 
     reserved = torch.cuda.max_memory_reserved(device) / 1024 ** 3
     total = torch.cuda.get_device_properties(device).total_memory / 1024 ** 3
 
     return '{:.2f} G/{:.2f} G'.format(reserved, total)
 
 
-def set_device(device_id: int = -1) -> torch.device:
+def set_device(device_id: int = -1):
     """
     Sets the device to be used for tensor computations.
 
     Args:
         device_id: int, optional
             An integer indicating the index of the GPU device to use for tensor computations.
             `device_id` < 0 indicates that the computation should be performed on the CPU. Default -1.
```

## Comparing `rec_pangu-0.3.7.dist-info/LICENSE` & `rec_pangu-0.3.9.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `rec_pangu-0.3.7.dist-info/METADATA` & `rec_pangu-0.3.9.dist-info/METADATA`

 * *Files 16% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: rec-pangu
-Version: 0.3.7
+Version: 0.3.9
 Summary: Some Rank/Multi-task model implemented by Pytorch
 Home-page: https://github.com/HaSai666/rec_pangu
 Author: wk
 Author-email: 306178200@qq.com
 Keywords: rank,multi task,deep learning,pytorch,recsys,recommendation
 Platform: all
 Classifier: Intended Audience :: Developers
@@ -90,36 +90,49 @@
 ## 5.序列召回模型
 
 目前支持如下类型的序列召回模型:
 
 - 经典序列召回模型
 - 基于图的序列召回模型
 - 多兴趣序列召回模型
+- 基于LLM的序列召回模型
 
 
-| 模型        | 类型     | 论文                                                                                                                                     | 年份   | 
-|-----------|--------|-------------------------------------------------------------------------------------------------------------------------------------------|------|
-| YotubeDNN | 经典序列召回 |[Deep Neural Networks for YouTube Recommendations](https://dl.acm.org/doi/pdf/10.1145/2959100.2959190?utm_campaign=Weekly%20dose%20of%20Machine%20Learning&utm_medium=email&utm_source=Revue%20newsletter) | 2016 |
-| Gru4Rec   | 经典序列召回 |[Session-based recommendations with recurrent neural networks](https://arxiv.org/pdf/1511.06939) | 2015 |
-| Narm      | 经典序列召回 |[Neural Attentive Session-based Recommendation](https://arxiv.org/pdf/1711.04725) | 2017 |
-| NextItNet | 经典序列召回 |[A Simple Convolutional Generative Network for Next Item](https://arxiv.org/pdf/1808.05163) | 2019 |
-| ComirecSA | 多兴趣召回  |[Controllable multi-interest framework for recommendation](https://arxiv.org/pdf/2005.09347) | 2020 |
-| ComirecDR | 多兴趣召回  |[Controllable multi-interest framework for recommendation](https://arxiv.org/pdf/2005.09347) | 2020 |
-| Mind      | 多兴趣召回  |[Multi-Interest Network with Dynamic Routing for Recommendation at Tmall](https://arxiv.org/pdf/1904.08030) | 2019 |
-| Re4       | 多兴趣召回  |[Re4: Learning to Re-contrast, Re-attend, Re-construct for Multi-interest Recommendation](https://dl.acm.org/doi/10.1145/3485447.3512094) | 2022 |
-| CMI       | 多兴趣召回  |[mproving Micro-video Recommendation via Contrastive Multiple Interests](https://arxiv.org/pdf/2205.09593) | 2022 |
-| SRGNN     | 图序列召回  |[Session-based Recommendation with Graph Neural Networks](https://ojs.aaai.org/index.php/AAAI/article/view/3804/3682) | 2019 |
-| GC-SAN    | 图序列召回  |[SGraph Contextualized Self-Attention Network for Session-based Recommendation](https://www.ijcai.org/proceedings/2019/0547.pdf) | 2019 |
-| NISER     | 图序列召回  |[NISER: Normalized Item and Session Representations to Handle Popularity Bias](https://arxiv.org/pdf/1909.04276) | 2019 |
+| 模型              | 类型      | 论文                                                                                                                                                                                                         | 年份   | 
+|-----------------|---------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------|
+| YotubeDNN       | 经典序列召回  | [Deep Neural Networks for YouTube Recommendations](https://dl.acm.org/doi/pdf/10.1145/2959100.2959190?utm_campaign=Weekly%20dose%20of%20Machine%20Learning&utm_medium=email&utm_source=Revue%20newsletter) | 2016 |
+| Gru4Rec         | 经典序列召回  | [Session-based recommendations with recurrent neural networks](https://arxiv.org/pdf/1511.06939)                                                                                                           | 2015 |
+| Narm            | 经典序列召回  | [Neural Attentive Session-based Recommendation](https://arxiv.org/pdf/1711.04725)                                                                                                                          | 2017 |
+| NextItNet       | 经典序列召回  | [A Simple Convolutional Generative Network for Next Item](https://arxiv.org/pdf/1808.05163)                                                                                                                | 2019 |
+| ContraRec       | 序列对比学习  | [Sequential Recommendation with Multiple Contrast Signals](https://dl.acm.org/doi/pdf/10.1145/3522673)                                                                                                     |      |
+| ComirecSA       | 多兴趣召回   | [Controllable multi-interest framework for recommendation](https://arxiv.org/pdf/2005.09347)                                                                                                               | 2020 |
+| ComirecDR       | 多兴趣召回   | [Controllable multi-interest framework for recommendation](https://arxiv.org/pdf/2005.09347)                                                                                                               | 2020 |
+| Mind            | 多兴趣召回   | [Multi-Interest Network with Dynamic Routing for Recommendation at Tmall](https://arxiv.org/pdf/1904.08030)                                                                                                | 2019 |
+| Re4             | 多兴趣召回   | [Re4: Learning to Re-contrast, Re-attend, Re-construct for Multi-interest Recommendation](https://dl.acm.org/doi/10.1145/3485447.3512094)                                                                  | 2022 |
+| CMI             | 多兴趣召回   | [mproving Micro-video Recommendation via Contrastive Multiple Interests](https://arxiv.org/pdf/2205.09593)                                                                                                 | 2022 |
+| SRGNN           | 图序列召回   | [Session-based Recommendation with Graph Neural Networks](https://ojs.aaai.org/index.php/AAAI/article/view/3804/3682)                                                                                      | 2019 |
+| GC-SAN          | 图序列召回   | [SGraph Contextualized Self-Attention Network for Session-based Recommendation](https://www.ijcai.org/proceedings/2019/0547.pdf)                                                                           | 2019 |
+| NISER           | 图序列召回   | [NISER: Normalized Item and Session Representations to Handle Popularity Bias](https://arxiv.org/pdf/1909.04276)                                                                                           | 2019 |
+| GCE-GNN(ToDo)   | 图序列召回   | [Global Context Enhanced Graph Neural Networks for Session-based Recommendation](https://arxiv.org/pdf/2106.05081.pdf)                                                                                     | 2020 |
+| Recformer(ToDo) | LLM序列召回 | [Text Is All You Need: Learning Language Representations for Sequential Recommendation](https://arxiv.org/pdf/2305.13731.pdf)                                                                              | 2023 |
+
 
 
 
 ## 6.图协同过滤模型
 
-TODO
+
+| 模型             | 类型          | 论文                                                                                                                          | 年份   | 
+|----------------|-------------|-----------------------------------------------------------------------------------------------------------------------------|------|
+| NGCF(ToDo)     | 图协同过滤       | [Neural Graph Collaborative Filtering](https://arxiv.org/pdf/1905.08108.pdf)                                                | 2019 |
+| LightGCN(ToDo)   | 图协同过滤       | [LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation](https://arxiv.org/pdf/2002.02126.pdf)     | 2019 |
+| NCL(ToDo)       | 图对比学习       | [Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning](https://arxiv.org/pdf/2202.06200) | 2022 |
+| SimGCL(ToDo)    | 图对比学习       | [Are Graph Augmentations Necessary? Simple Graph Contrastive Learning for Recommendation](https://www.researchgate.net/profile/Junliang-Yu/publication/359788233_Are_Graph_Augmentations_Necessary_Simple_Graph_Contrastive_Learning_for_Recommendation/links/624e802ad726197cfd426f81/Are-Graph-Augmentations-Necessary-Simple-Graph-Contrastive-Learning-for-Recommendation.pdf?ref=https://githubhelp.com) | 2022 |
+| SGL(ToDo)      | 图对比学习       | [Self-supervised Graph Learning for Recommendation](https://arxiv.org/pdf/2010.10783)                                       | 2021 |
+
 
 ## 7.Demo
 我们的Rank和多任务模型所对外暴露的接口十分相似,同时我们这里也支持使用wandb来实时监测模型训练指标,我们下面会分别给出Rank,多任务模型,wandb的demo
 ### 7.1 排序任务Demo
 
 ```python
 # 声明数据schema
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: rec-pangu Version: 0.3.7 Summary: Some Rank/Multi-
+Metadata-Version: 2.1 Name: rec-pangu Version: 0.3.9 Summary: Some Rank/Multi-
 task model implemented by Pytorch Home-page: https://github.com/HaSai666/
 rec_pangu Author: wk Author-email: 306178200@qq.com Keywords: rank,multi
 task,deep learning,pytorch,recsys,recommendation Platform: all Classifier:
 Intended Audience :: Developers Classifier: Intended Audience :: Education
 Classifier: Intended Audience :: Science/Research Classifier: Operating System
 :: OS Independent Classifier: Programming Language :: Python :: 3 Classifier:
 Programming Language :: Python :: 3.7 Classifier: Programming Language ::
@@ -69,42 +69,66 @@
 Conversion Rate](https://arxiv.org/pdf/1804.07931.pdf) | 2018 | | OMOE |
 [Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-
 Experts](https://dl.acm.org/doi/pdf/10.1145/3219819.3220007) | 2018 | | MLMMOE
 | / | / | | AITM | [Modeling the Sequential Dependence among Audience Multi-
 step Conversions with Multi-task Learning in Targeted Display Advertising]
 (https://arxiv.org/pdf/2105.08489.pdf)| 2019 | ## 5.åºåå¬åæ¨¡å
 ç®åæ¯æå¦ä¸ç±»åçåºåå¬åæ¨¡å: - ç»å¸åºåå¬åæ¨¡å -
-åºäºå¾çåºåå¬åæ¨¡å - å¤å´è¶£åºåå¬åæ¨¡å | æ¨¡å | ç±»å
-| è®ºæ | å¹´ä»½ | |-----------|--------|-------------------------------------
+åºäºå¾çåºåå¬åæ¨¡å - å¤å´è¶£åºåå¬åæ¨¡å -
+åºäºLLMçåºåå¬åæ¨¡å | æ¨¡å | ç±»å | è®ºæ | å¹´ä»½ | |---------
+--------|---------|------------------------------------------------------------
 -------------------------------------------------------------------------------
------------------------|------| | YotubeDNN | ç»å¸åºåå¬å |[Deep Neural
-Networks for YouTube Recommendations](https://dl.acm.org/doi/pdf/10.1145/
+-----------------------------------------------------------------|------| |
+YotubeDNN | ç»å¸åºåå¬å | [Deep Neural Networks for YouTube
+Recommendations](https://dl.acm.org/doi/pdf/10.1145/
 2959100.2959190?utm_campaign=Weekly%20dose%20of%20Machine%20Learning&utm_medium=email&utm_source=Revue%20newsletter)
-| 2016 | | Gru4Rec | ç»å¸åºåå¬å |[Session-based recommendations with
+| 2016 | | Gru4Rec | ç»å¸åºåå¬å | [Session-based recommendations with
 recurrent neural networks](https://arxiv.org/pdf/1511.06939) | 2015 | | Narm |
-ç»å¸åºåå¬å |[Neural Attentive Session-based Recommendation](https://
-arxiv.org/pdf/1711.04725) | 2017 | | NextItNet | ç»å¸åºåå¬å |[A Simple
+ç»å¸åºåå¬å | [Neural Attentive Session-based Recommendation](https://
+arxiv.org/pdf/1711.04725) | 2017 | | NextItNet | ç»å¸åºåå¬å | [A Simple
 Convolutional Generative Network for Next Item](https://arxiv.org/pdf/
-1808.05163) | 2019 | | ComirecSA | å¤å´è¶£å¬å |[Controllable multi-
+1808.05163) | 2019 | | ContraRec | åºåå¯¹æ¯å­¦ä¹  | [Sequential
+Recommendation with Multiple Contrast Signals](https://dl.acm.org/doi/pdf/
+10.1145/3522673) | | | ComirecSA | å¤å´è¶£å¬å | [Controllable multi-
 interest framework for recommendation](https://arxiv.org/pdf/2005.09347) | 2020
-| | ComirecDR | å¤å´è¶£å¬å |[Controllable multi-interest framework for
+| | ComirecDR | å¤å´è¶£å¬å | [Controllable multi-interest framework for
 recommendation](https://arxiv.org/pdf/2005.09347) | 2020 | | Mind |
-å¤å´è¶£å¬å |[Multi-Interest Network with Dynamic Routing for
+å¤å´è¶£å¬å | [Multi-Interest Network with Dynamic Routing for
 Recommendation at Tmall](https://arxiv.org/pdf/1904.08030) | 2019 | | Re4 |
-å¤å´è¶£å¬å |[Re4: Learning to Re-contrast, Re-attend, Re-construct for
+å¤å´è¶£å¬å | [Re4: Learning to Re-contrast, Re-attend, Re-construct for
 Multi-interest Recommendation](https://dl.acm.org/doi/10.1145/3485447.3512094)
-| 2022 | | CMI | å¤å´è¶£å¬å |[mproving Micro-video Recommendation via
+| 2022 | | CMI | å¤å´è¶£å¬å | [mproving Micro-video Recommendation via
 Contrastive Multiple Interests](https://arxiv.org/pdf/2205.09593) | 2022 | |
-SRGNN | å¾åºåå¬å |[Session-based Recommendation with Graph Neural
+SRGNN | å¾åºåå¬å | [Session-based Recommendation with Graph Neural
 Networks](https://ojs.aaai.org/index.php/AAAI/article/view/3804/3682) | 2019 |
-| GC-SAN | å¾åºåå¬å |[SGraph Contextualized Self-Attention Network for
+| GC-SAN | å¾åºåå¬å | [SGraph Contextualized Self-Attention Network for
 Session-based Recommendation](https://www.ijcai.org/proceedings/2019/0547.pdf)
-| 2019 | | NISER | å¾åºåå¬å |[NISER: Normalized Item and Session
+| 2019 | | NISER | å¾åºåå¬å | [NISER: Normalized Item and Session
 Representations to Handle Popularity Bias](https://arxiv.org/pdf/1909.04276) |
-2019 | ## 6.å¾ååè¿æ»¤æ¨¡å TODO ## 7.Demo
+2019 | | GCE-GNN(ToDo) | å¾åºåå¬å | [Global Context Enhanced Graph
+Neural Networks for Session-based Recommendation](https://arxiv.org/pdf/
+2106.05081.pdf) | 2020 | | Recformer(ToDo) | LLMåºåå¬å | [Text Is All You
+Need: Learning Language Representations for Sequential Recommendation](https://
+arxiv.org/pdf/2305.13731.pdf) | 2023 | ## 6.å¾ååè¿æ»¤æ¨¡å | æ¨¡å |
+ç±»å | è®ºæ | å¹´ä»½ | |----------------|-------------|--------------------
+-------------------------------------------------------------------------------
+--------------------------|------| | NGCF(ToDo) | å¾ååè¿æ»¤ | [Neural
+Graph Collaborative Filtering](https://arxiv.org/pdf/1905.08108.pdf) | 2019 | |
+LightGCN(ToDo) | å¾ååè¿æ»¤ | [LightGCN: Simplifying and Powering Graph
+Convolution Network for Recommendation](https://arxiv.org/pdf/2002.02126.pdf) |
+2019 | | NCL(ToDo) | å¾å¯¹æ¯å­¦ä¹  | [Improving Graph Collaborative Filtering
+with Neighborhood-enriched Contrastive Learning](https://arxiv.org/pdf/
+2202.06200) | 2022 | | SimGCL(ToDo) | å¾å¯¹æ¯å­¦ä¹  | [Are Graph
+Augmentations Necessary? Simple Graph Contrastive Learning for Recommendation]
+(https://www.researchgate.net/profile/Junliang-Yu/publication/
+359788233_Are_Graph_Augmentations_Necessary_Simple_Graph_Contrastive_Learning_for_Recommendation/
+links/624e802ad726197cfd426f81/Are-Graph-Augmentations-Necessary-Simple-Graph-
+Contrastive-Learning-for-Recommendation.pdf?ref=https://githubhelp.com) | 2022
+| | SGL(ToDo) | å¾å¯¹æ¯å­¦ä¹  | [Self-supervised Graph Learning for
+Recommendation](https://arxiv.org/pdf/2010.10783) | 2021 | ## 7.Demo
 æä»¬çRankåå¤ä»»å¡æ¨¡åæå¯¹å¤æ´é²çæ¥å£ååç¸ä¼¼,åæ¶æä»¬è¿éä¹æ¯æä½¿ç¨wandbæ¥å®æ¶çæµæ¨¡åè®­ç»ææ ,æä»¬ä¸é¢ä¼åå«ç»åºRank,å¤ä»»å¡æ¨¡å,wandbçdemo
 ### 7.1 æåºä»»å¡Demo ```python # å£°ææ°æ®schema import torch from
 rec_pangu.dataset import get_dataloader from rec_pangu.models.ranking import
 WDL, DeepFM, NFM, FiBiNet, AFM, AFN, AOANet, AutoInt, CCPM, LR, FM, xDeepFM
 from rec_pangu.trainer import RankTrainer import pandas as pd if __name__ ==
 '__main__': df = pd.read_csv('sample_data/ranking_sample_data.csv') print
 (df.head()) # å£°ææ°æ®schema schema = { "sparse_cols": ['user_id',
```

## Comparing `rec_pangu-0.3.7.dist-info/RECORD` & `rec_pangu-0.3.9.dist-info/RECORD`

 * *Files 15% similar despite different names*

```diff
@@ -1,76 +1,80 @@
-rec_pangu/__init__.py,sha256=UwrGjzeD-SJkYPgYEpKnX_0exJ4Vf4Oot4aQQ2z1Kn4,199
+rec_pangu/__init__.py,sha256=3d4L4HogVAkvgd7pAX91RzJtDXd29vh87mUI6zYqv8c,199
 rec_pangu/benchmark_trainer.py,sha256=J5kGL93iq4O7TW1k60oJZksrYRW4OniJa-JoVjmmelk,5837
 rec_pangu/gpt_ranktrainer.py,sha256=cHLZu4OgbpqL9vVMqtR1pvqMeNpLtyO_EdaJHMjWq08,9722
 rec_pangu/model_pipeline.py,sha256=y2_EnjqjU0jY1VpVC6r9sUYePtdQlpqznSskCmxMDn4,14630
 rec_pangu/old_ranktrainer.py,sha256=lMwui-xDAxMvyuxJyp8XKCV3BtQGWl39zbIL_bj6LUM,5448
-rec_pangu/trainer.py,sha256=8joVSeeZE8W7WLvLW5XwwM04SsM3b2egnQqfTFKH1f4,18650
+rec_pangu/trainer.py,sha256=VTpGls-SaFh5rFsfD-VSI_Hx2AdoOZHl_OeA6aH_Xyw,20415
 rec_pangu/dataset/__init__.py,sha256=o53SpwAQVsmLQp7CUWmIy7kikwH3ZBD-VBrW_5p2ToA,404
 rec_pangu/dataset/base_dataset.py,sha256=iImLln0AwCbDWizCuJzahz5eL1etRU7XP0Y2vklLzRs,4954
 rec_pangu/dataset/graph_dataset.py,sha256=Sz_PB9ibzf8X3zBncN8ozXY40k1Q5-ceRAWW0X5LMmk,3776
 rec_pangu/dataset/multi_task_dataset.py,sha256=XnQUTsvwWcYYWq52OtaBfpgfQ0jvLzaowaISNUhMjWg,2812
 rec_pangu/dataset/process_data.py,sha256=DRgqDeVwAym2PCZolwS-wHPBs9VU9p2mSlfaGxZUC3k,3986
 rec_pangu/dataset/sequence_dataset.py,sha256=Jr-SMzdqwquxh2W4yODeL7k5fmIjd07fgNLbQclnsYI,5635
 rec_pangu/models/__init__.py,sha256=ZTUYJ8guxLRAXkbK6TxxvRJw8Q153cUDA1XBcJwjqsI,117
-rec_pangu/models/base_model.py,sha256=9VlZOAIaRUGuvKWfTDLiCXy0-t9jbv9bjAD7tOg3UFY,9351
+rec_pangu/models/base_model.py,sha256=-sjlaqezWodIItmVy7x74H4V8slQHBi0fSyB9SX6ynw,10465
 rec_pangu/models/utils.py,sha256=0_thQaedHWmVEfuJ7C1eqF4L-Ya0Wc7ouw8AxHqM3e0,8027
 rec_pangu/models/layers/LGConv.py,sha256=ZvqwTQ0zkmCK5XdwNZNChytFrCUtNT-AAFNqxp2WtLA,949
 rec_pangu/models/layers/__init__.py,sha256=5nIwNU6Rh0hFRypJV6wAbpQhVmRm3nxlP-c0P9sVEt0,456
 rec_pangu/models/layers/activation.py,sha256=vXcVU5Cvk-Xmoxzhv6A3sk-zjHY5z1Is488SlBhTjPY,1876
 rec_pangu/models/layers/attention.py,sha256=Jp1XOZfXrScOfwCf8OkH3OXwGKoYYlK2EcnTBuII9BE,4606
 rec_pangu/models/layers/conv.py,sha256=qDdETiJLruwQuG9vOTpscWjwbZjjqn_xCMGywg08axU,7468
 rec_pangu/models/layers/deep.py,sha256=Oin-CzDL8wMb34ATQpBZ6_o1VHxPA7RuePPCSa231Ks,3943
 rec_pangu/models/layers/embedding.py,sha256=dxii_wTx7SxaJzDgmnvihpbYhIkU6Uog2xHQ688R2BE,2932
 rec_pangu/models/layers/graph.py,sha256=SMYmK87qrxNBWF-Zo3wYOPynnNNsEqq0Bjljc4Y_CY8,6164
 rec_pangu/models/layers/interaction.py,sha256=xJcrDH-cLRyVCTlhNJA-3KWUJEicwm1QEVyRZIelYN0,12947
 rec_pangu/models/layers/multi_interest.py,sha256=ueMpO6UC2OrbbN48WThokIdJ2FXKaTEU9FRq-lrJAZk,8463
-rec_pangu/models/layers/sequence.py,sha256=8YtL2WblpZkrjSHdiTIxQQVRZ7KUFfhkQVCk4NU8VwU,5266
+rec_pangu/models/layers/sequence.py,sha256=goh9Xp6nHitCU4gsjybVX4QYAm1oGvitSnn_XWZjtd4,11805
 rec_pangu/models/layers/shallow.py,sha256=vrV2jZNjbzOT92aSnkIXkHoZendrh2i5Yn5hLWd_lIE,852
 rec_pangu/models/layers/trainformer.py,sha256=5W9A-QOuijjXdSD42rHuyOwtjziUW29OO2FslK8k3lo,9674
 rec_pangu/models/multi_task/__init__.py,sha256=0r9Q2nDklTxGFgD52RgkZIu-jV3y6ojH1Chxw5nZjpo,272
 rec_pangu/models/multi_task/aitm.py,sha256=cvAz7lOxbA2Z9wJ6zektYlBmmbv_IonCeZF0Og0SWPE,3948
 rec_pangu/models/multi_task/essm.py,sha256=6_eYZ7zRREmoRgCFrdrauRFqpjor_YrnTGAeyBldpu4,2609
 rec_pangu/models/multi_task/mlmmoe.py,sha256=l_xtuGG2qAlqOrvsPbN3ptX-IGzibCh8rTQymBnqnT4,6268
 rec_pangu/models/multi_task/mmoe.py,sha256=KLm5iEvejz64xLzCjY2B7Tj1oKUR8t18s_p2GC83Hb4,5723
 rec_pangu/models/multi_task/omoe.py,sha256=3xDHlRu1Y0CBpqGGe2j_5HTvHcgRcz20voaa6lOnXdQ,4599
 rec_pangu/models/multi_task/sharebottom.py,sha256=rCVfj2GgoRvpbgQw5g3o4l4Nzx1E2wCZx69Dkpa6jkw,4105
 rec_pangu/models/ranking/__init__.py,sha256=mgaEFoyKmdRRfzc89rPGaMQp4ReMKuWRA1BMyyJtN68,452
-rec_pangu/models/ranking/afm.py,sha256=xuHAAb3X-vWfarsdPV4yYPbtEzOmwieqVQqPew332Ck,2590
-rec_pangu/models/ranking/afn.py,sha256=3Z7un8FsZnW29Qjq6aOXbG9EfncbF5KYnO7DkX214_k,4454
-rec_pangu/models/ranking/aoanet.py,sha256=jB0bHfcP_G1nbnm_iSv_QsVUg-FQCQJJ653RlUuofXc,5225
-rec_pangu/models/ranking/autoint.py,sha256=TkCFz3NwmCix7TcMdvwUmVbpxQE69Oks2gbTaPSQo-k,3669
-rec_pangu/models/ranking/ccpm.py,sha256=tZXN79xlB99itzyVfiiQgEKU3FSJxY_F5no-nKw-o88,4402
-rec_pangu/models/ranking/dcn.py,sha256=xJldzOrmzL_mm6_X8Zp7a2zvrW5pSdLj7IWxK9s2xYU,2604
-rec_pangu/models/ranking/deepfm.py,sha256=5628mi3C_5ZZbuAp7m3jmD1dXbMqxiSSld6qQ7vJGAg,2593
-rec_pangu/models/ranking/fibinet.py,sha256=xbOEV5D1cR3NICbbZ7IsjdkdS9V_7XbdrTNj51uPvm8,3146
-rec_pangu/models/ranking/fm.py,sha256=-TDvov-WYN4lAHj9d5JIm7f4ueb0q0pN6cgsEtStMUI,1894
+rec_pangu/models/ranking/afm.py,sha256=XgkuIagpG6IbwTCBuc9Zg1UcHs9kXxUGqUkXnSPZDqk,2625
+rec_pangu/models/ranking/afn.py,sha256=2aT8ONnVQza1djvEB2MT1-DN2yYQYIGodU00mb9vPrQ,4448
+rec_pangu/models/ranking/aoanet.py,sha256=cC4iBlFS2D-qryO1fhn8NzPOFe8-WQ4CWJ40dlLt0qw,5260
+rec_pangu/models/ranking/autoint.py,sha256=7eJqVmCimR9l7yrktJnSTrWyMQ3ay0X4SbkenQwIHDo,3703
+rec_pangu/models/ranking/ccpm.py,sha256=qA6HbGM3E-_h-HcadMk2lW8b3AzzXL65L8zB-fVu-Vo,4436
+rec_pangu/models/ranking/dcn.py,sha256=ZcxHk9k2VLk6j8PFctIYzdSS1kay4k6IFioC2-77zaE,2639
+rec_pangu/models/ranking/deepfm.py,sha256=y6CjdVPQzbfX-XZECAZHt9Nbc0ycf7eTJ1cWG52CGhY,2627
+rec_pangu/models/ranking/fibinet.py,sha256=6KUrt1icILm_j3gEOup-UjULBXxpdJa2Qoty3UBKD9s,3180
+rec_pangu/models/ranking/fm.py,sha256=oM3SDc4v7oGEXSLae-DXhuQ0JBfcG4CLQpMOtk_rgUI,1928
 rec_pangu/models/ranking/lightgcn.py,sha256=zjv5b7N95UxuZpFtzGTYg2IvoecS0Lkrim1-reE45QA,1920
-rec_pangu/models/ranking/lr.py,sha256=vBD4bOFc8pPHbN5nfN0ACU_k_fuwz36EmxjBYw6YuFg,1668
-rec_pangu/models/ranking/masknet.py,sha256=7hXGUhJLuPK2mZ1aeTtofdnyrkYzQiTHAmJrw6QV7sM,3797
-rec_pangu/models/ranking/nfm.py,sha256=4XoPxhhFkPWBofhqYlweClAXoQtrkgyf-CFOkgPYoIk,2875
-rec_pangu/models/ranking/wdl.py,sha256=it-m0RA3vWAYAv2dVlEkkpNHgJzW5BdVx7x8eQg_4Ao,2785
-rec_pangu/models/ranking/xdeepfm.py,sha256=Y72SLHIGUfXQbjdPUrmWkuCGOYAofm03mjxxo70hirU,3162
-rec_pangu/models/sequence/__init__.py,sha256=qvxm6FfhrkPmNnhPDKfMDyFLhak9mdjnVbE8ZDvKQvg,437
-rec_pangu/models/sequence/cmi.py,sha256=pyXRK02pY0Do2qPaXNhpg7OKsasCPRg_daP2TO8iGEw,9009
-rec_pangu/models/sequence/comirec.py,sha256=-wsYrhc2BlKiqlnGEymo7dG8tyoLwcEzpDE05pns2hI,4764
-rec_pangu/models/sequence/gcsan.py,sha256=_S85-gEEfeE-spWU1N2DetFKMOJzpf0iu9cTdODPiLk,3807
-rec_pangu/models/sequence/mind.py,sha256=6R_2HuKi5Y3n390GZnh72igbL-fodYqTyOqiHFtVENg,2425
-rec_pangu/models/sequence/narm.py,sha256=EjCKgo39qlFHxCgS4V87GHljxGnAbNWXY84Az3iORRc,2977
-rec_pangu/models/sequence/nextitnet.py,sha256=EW-1XkUXGoLB47MJ1-qKLYn0MbB8ueJQfwSkAbj_l7I,2146
-rec_pangu/models/sequence/niser.py,sha256=F7mRUZpDnbxus6ajMdZMgs7-dRW7uD4iEgbDHZyh9mU,3601
-rec_pangu/models/sequence/re4.py,sha256=YwXzssDsnqTuBn2A8ryYNzdQpPGGZ5XKyW1GxeEM_7M,8056
-rec_pangu/models/sequence/sasrec.py,sha256=OVfpDAXzgPRC71IrPySql4sTCXTO8O3rkB1VNYD1Di0,2780
-rec_pangu/models/sequence/srgnn.py,sha256=mowlvjcDwDTyoI6cTs4NyD48Cg61VpzLPCdn1FwG1Vs,3014
-rec_pangu/models/sequence/stamp.py,sha256=xCVDD4pD1KcUlhK92trpZCYmUlHqj6484i9BPEhJDy8,1779
-rec_pangu/models/sequence/yotubednn.py,sha256=44ZDo-Q9WdLeUJ7fixdR8_yeX1rULcSFbgJJtNcROCc,1587
+rec_pangu/models/ranking/lr.py,sha256=vFLQIjYSkTID25srDlpjhkMxxU0bC04M-s_ANf5i3cw,1700
+rec_pangu/models/ranking/masknet.py,sha256=v_RrG4J4Qz231UIZBAglBwBT5UOUmlkM8F_9QsPCMKc,3831
+rec_pangu/models/ranking/nfm.py,sha256=JH1cND8VWdYq0CCSeDZRWHJUqWlEKpFkLLyZ46OCVmA,2909
+rec_pangu/models/ranking/wdl.py,sha256=BYAYnbmPi3W8-WMIbcdPXlcAJ02ij2Wjyj34pODaBaA,2819
+rec_pangu/models/ranking/xdeepfm.py,sha256=mLoc1zrM2hWeoQLc9p-SFFeHb96o23cRk3IJRpR0Olg,3196
+rec_pangu/models/sequence/__init__.py,sha256=-OYpPynJWbXp4M2JkqO00xTGMdMoqC3hH-Nv5cZh9vQ,547
+rec_pangu/models/sequence/clrec.py,sha256=WVmSGxUIUJl0FB3b3EQ6yoHEvR6UXQWoauZOHzgYhsM,3682
+rec_pangu/models/sequence/cmi.py,sha256=-l9okOs8FL4kY_wvUBqbVjBRrWBX8XecCbCV_F5n4M0,9043
+rec_pangu/models/sequence/comirec.py,sha256=ThfdQWVysmmnW94wIRI9vRuyjLDjEa9ZH7EO4zRgaGE,4832
+rec_pangu/models/sequence/contrarec.py,sha256=5W3Zh4FUYq1Q5f9dNgCVrSV0mMAsyvGNsUGyFqtUy20,6913
+rec_pangu/models/sequence/gcsan.py,sha256=f_qEoV8muiUwNbyp0jtIf66lHOSfi0Mi8DQGC6tdAUU,3841
+rec_pangu/models/sequence/gru4rec.py,sha256=kt1pv2FXfvYpYSgs4MlyaNkDEVQgZpKIaU2jT2EuN8s,1706
+rec_pangu/models/sequence/mind.py,sha256=95-9NPRtyDRMoM3hVxkfGws-jZP0uGKYhW6t3tkvI-U,2459
+rec_pangu/models/sequence/narm.py,sha256=QhuMhqxxnlm_T0JpxyY_bFdztr2snOwG9OXOPMxmssk,3011
+rec_pangu/models/sequence/nextitnet.py,sha256=rlWRxpg_dm73TxWfhOAJePGkM5TLQ-5Ir3ueJeCjG3M,2180
+rec_pangu/models/sequence/niser.py,sha256=YRo9wA0rN-K8K-NuODpH3L2Slh7WMAYTMDjBZH0xGcM,3635
+rec_pangu/models/sequence/re4.py,sha256=aw0iNyxreDc5CrEjNJoQi1-pclkF3EgiUyNOF4hgDK8,8090
+rec_pangu/models/sequence/sasrec.py,sha256=TiyChBDEqw98QHJivqw9Y1hI7mRWYHlrkfgeWebJLHM,2814
+rec_pangu/models/sequence/sine.py,sha256=JG2Cdtu-gZ6b_oMZdPsKeK70S4o7RVb9qTvhjGRlOdc,4679
+rec_pangu/models/sequence/srgnn.py,sha256=69-a9si8O4CXD_oW5au3XyCGMMoKJ1heKPROX-L0n_M,3048
+rec_pangu/models/sequence/stamp.py,sha256=PTethq9B9yea5Ihw7YvC3e1owIWo8y4bO9j-7BoZmtI,1813
+rec_pangu/models/sequence/yotubednn.py,sha256=TMKwhKp11_vcWp3OH1rIh-9vw7oxjBtgWc7y4_ZMzVk,1621
 rec_pangu/serving/__init__.py,sha256=twv9kol32GZD16l-6Xu5hiaYDHK72UIA1GGJmwcJi2A,115
 rec_pangu/serving/ranking_server.py,sha256=IR3IrhFEVPXnngaMCerunExdoo3XeeAryziEgwjOQQI,2211
 rec_pangu/utils/__init__.py,sha256=dF7uxiBraZf82Do_VlkQqicD4WsNcguSgebsO6dyyag,301
 rec_pangu/utils/check_version.py,sha256=ONSdf0hw-hPTHjJpHldDz5HdlNHo4kqrm2icjDPkUtg,1509
 rec_pangu/utils/evaluate.py,sha256=-OabWaxaItSLheTzMV3vir05J0yJg6cAr6NPmaKiPFQ,8756
-rec_pangu/utils/gpu_utils.py,sha256=V5-yE_XaHjGELIElhr5J9MWNTeaJS1HiA37CwF3tvrM,1565
+rec_pangu/utils/gpu_utils.py,sha256=heBMMGrcZkNuycj193Z8jtQeZ4htYJNLYyTf20LOJZM,1549
 rec_pangu/utils/json_utils.py,sha256=2NbJgYTDACZXQIX11h5U4l0L5fHwyXNVdVksgWwiccI,668
-rec_pangu-0.3.7.dist-info/LICENSE,sha256=5t15gkJb51GDxbB-lVcG2ZMTYLHbccXypC-X_GK-kPw,1058
-rec_pangu-0.3.7.dist-info/METADATA,sha256=OHM85clUqzuhkG_LNgQFcc7nsyiJRLv1111AFQ3sXDk,14306
-rec_pangu-0.3.7.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-rec_pangu-0.3.7.dist-info/top_level.txt,sha256=VQeGX3ukDrCpoYzPshLjJWRzJ6lzbymbmBqfQQCUOYE,10
-rec_pangu-0.3.7.dist-info/RECORD,,
+rec_pangu-0.3.9.dist-info/LICENSE,sha256=5t15gkJb51GDxbB-lVcG2ZMTYLHbccXypC-X_GK-kPw,1058
+rec_pangu-0.3.9.dist-info/METADATA,sha256=x1y1MtDsw2lbzq-iqK0WjHwpA63ubZP4MLG3mHVMBGs,17906
+rec_pangu-0.3.9.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+rec_pangu-0.3.9.dist-info/top_level.txt,sha256=VQeGX3ukDrCpoYzPshLjJWRzJ6lzbymbmBqfQQCUOYE,10
+rec_pangu-0.3.9.dist-info/RECORD,,
```

