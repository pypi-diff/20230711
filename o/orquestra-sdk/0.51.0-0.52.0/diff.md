# Comparing `tmp/orquestra_sdk-0.51.0-py3-none-any.whl.zip` & `tmp/orquestra_sdk-0.52.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,117 +1,123 @@
-Zip file size: 221783 bytes, number of entries: 115
--rw-r--r--  2.0 unx     1800 b- defN 23-Jun-22 14:27 orquestra/sdk/__init__.py
--rw-r--r--  2.0 unx     7183 b- defN 23-Jun-22 14:27 orquestra/sdk/exceptions.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-22 14:27 orquestra/sdk/py.typed
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/__init__.py
--rw-r--r--  2.0 unx     8232 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_ast.py
--rw-r--r--  2.0 unx    25046 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_config.py
--rw-r--r--  2.0 unx    37402 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_dsl.py
--rw-r--r--  2.0 unx     2461 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_env.py
--rw-r--r--  2.0 unx     2465 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_exec_ctx.py
--rw-r--r--  2.0 unx     1776 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_factory.py
--rw-r--r--  2.0 unx     3703 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_git_url_utils.py
--rw-r--r--  2.0 unx     3021 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_graphs.py
--rw-r--r--  2.0 unx    13216 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_in_process_runtime.py
--rw-r--r--  2.0 unx     1104 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_jwt.py
--rw-r--r--  2.0 unx     5245 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_log_adapter.py
--rw-r--r--  2.0 unx     1407 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_retry.py
--rw-r--r--  2.0 unx     4180 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_services.py
--rw-r--r--  2.0 unx    32365 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_traversal.py
--rw-r--r--  2.0 unx     4629 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_viz.py
--rw-r--r--  2.0 unx    24415 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_workflow.py
--rw-r--r--  2.0 unx     8205 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/abc.py
--rw-r--r--  2.0 unx    11948 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/dispatch.py
--rw-r--r--  2.0 unx     6001 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/loader.py
--rw-r--r--  2.0 unx     7004 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/serde.py
--rw-r--r--  2.0 unx      664 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_api/__init__.py
--rw-r--r--  2.0 unx    18506 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_api/_config.py
--rw-r--r--  2.0 unx    13764 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_api/_task_run.py
--rw-r--r--  2.0 unx    25934 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_api/_wf_run.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_conversions/__init__.py
--rw-r--r--  2.0 unx     3509 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_conversions/_ids.py
--rw-r--r--  2.0 unx     7074 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_conversions/_imports.py
--rw-r--r--  2.0 unx    12943 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_conversions/_invocations.py
--rw-r--r--  2.0 unx     3905 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_conversions/_yaml_exporter.py
--rw-r--r--  2.0 unx      360 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_db/__init__.py
--rw-r--r--  2.0 unx     5285 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_db/_db.py
--rw-r--r--  2.0 unx     1331 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_db/_migration.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_driver/__init__.py
--rw-r--r--  2.0 unx    21708 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_driver/_ce_runtime.py
--rw-r--r--  2.0 unx    28297 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_driver/_client.py
--rw-r--r--  2.0 unx     4748 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_driver/_exceptions.py
--rw-r--r--  2.0 unx    14128 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_driver/_models.py
--rw-r--r--  2.0 unx     2037 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_logs/_interfaces.py
--rw-r--r--  2.0 unx      869 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_logs/_regrouping.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_qe/__init__.py
--rw-r--r--  2.0 unx     7212 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_qe/_client.py
--rw-r--r--  2.0 unx    35757 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_qe/_qe_runtime.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_spaces/__init__.py
--rw-r--r--  2.0 unx     1734 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_spaces/_api.py
--rw-r--r--  2.0 unx     1555 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_spaces/_resolver.py
--rw-r--r--  2.0 unx      704 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_spaces/_structs.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_testing/__init__.py
--rw-r--r--  2.0 unx     4031 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_testing/_connections.py
--rw-r--r--  2.0 unx     8219 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_testing/_example_wfs.py
--rw-r--r--  2.0 unx     1754 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_testing/_ipc.py
--rw-r--r--  2.0 unx      261 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_testing/_long_import.py
--rw-r--r--  2.0 unx    17090 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py
--rw-r--r--  2.0 unx      698 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_cli_logs.py
--rw-r--r--  2.0 unx     3032 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_dumpers.py
--rw-r--r--  2.0 unx    11607 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_entry.py
--rw-r--r--  2.0 unx    23358 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_repos.py
--rw-r--r--  2.0 unx     5417 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_login/_login.py
--rw-r--r--  2.0 unx     1694 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_login/_login_server.py
--rw-r--r--  2.0 unx     1621 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_services/_down.py
--rw-r--r--  2.0 unx     1327 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_services/_status.py
--rw-r--r--  2.0 unx     2656 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_services/_up.py
--rw-r--r--  2.0 unx     3106 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_task/_logs.py
--rw-r--r--  2.0 unx     3626 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_task/_results.py
--rw-r--r--  2.0 unx      367 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/__init__.py
--rw-r--r--  2.0 unx     5520 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/_errors.py
--rw-r--r--  2.0 unx     1648 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/_models.py
--rw-r--r--  2.0 unx    12703 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py
--rw-r--r--  2.0 unx    10249 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py
--rw-r--r--  2.0 unx      624 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/color.py
--rw-r--r--  2.0 unx     7794 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/per_command.py
--rw-r--r--  2.0 unx     5180 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_workflow/_list.py
--rw-r--r--  2.0 unx     2739 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_workflow/_logs.py
--rw-r--r--  2.0 unx     3140 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_workflow/_results.py
--rw-r--r--  2.0 unx     2621 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_workflow/_stop.py
--rw-r--r--  2.0 unx     5087 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_workflow/_submit.py
--rw-r--r--  2.0 unx     2138 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_workflow/_view.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/__init__.py
--rw-r--r--  2.0 unx    18425 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/_build_workflow.py
--rw-r--r--  2.0 unx     6644 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/_client.py
--rw-r--r--  2.0 unx    21405 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/_dag.py
--rw-r--r--  2.0 unx      867 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/_id_gen.py
--rw-r--r--  2.0 unx     5064 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/_ray_logs.py
--rw-r--r--  2.0 unx     1278 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/_wf_metadata.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/examples/__init__.py
--rw-r--r--  2.0 unx     1558 b- defN 23-Jun-22 14:27 orquestra/sdk/examples/exportable_wf.py
--rw-r--r--  2.0 unx     1116 b- defN 23-Jun-22 14:27 orquestra/sdk/examples/workflow_defs.py
--rw-r--r--  2.0 unx      318 b- defN 23-Jun-22 14:27 orquestra/sdk/kubernetes/__init__.py
--rw-r--r--  2.0 unx     2420 b- defN 23-Jun-22 14:27 orquestra/sdk/kubernetes/quantity.py
--rw-r--r--  2.0 unx      427 b- defN 23-Jun-22 14:27 orquestra/sdk/packaging/__init__.py
--rw-r--r--  2.0 unx     4144 b- defN 23-Jun-22 14:27 orquestra/sdk/packaging/_versions.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/__init__.py
--rw-r--r--  2.0 unx     1874 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/_compat.py
--rw-r--r--  2.0 unx     1578 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/configs.py
--rw-r--r--  2.0 unx    15130 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/ir.py
--rw-r--r--  2.0 unx      848 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/local_database.py
--rw-r--r--  2.0 unx     4745 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/responses.py
--rw-r--r--  2.0 unx     1596 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/workflow_run.py
--rw-r--r--  2.0 unx     4114 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/yaml_model.py
--rw-r--r--  2.0 unx     1104 b- defN 23-Jun-22 14:27 orquestra/sdk/secrets/__init__.py
--rw-r--r--  2.0 unx     6658 b- defN 23-Jun-22 14:27 orquestra/sdk/secrets/_api.py
--rw-r--r--  2.0 unx     2090 b- defN 23-Jun-22 14:27 orquestra/sdk/secrets/_auth.py
--rw-r--r--  2.0 unx     5600 b- defN 23-Jun-22 14:27 orquestra/sdk/secrets/_client.py
--rw-r--r--  2.0 unx     1222 b- defN 23-Jun-22 14:27 orquestra/sdk/secrets/_exceptions.py
--rw-r--r--  2.0 unx     1679 b- defN 23-Jun-22 14:27 orquestra/sdk/secrets/_models.py
--rw-r--r--  2.0 unx     1072 b- defN 23-Jun-22 14:27 orquestra/sdk/v2/__init__.py
--rw-r--r--  2.0 unx    11357 b- defN 23-Jun-22 14:27 orquestra_sdk-0.51.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     3147 b- defN 23-Jun-22 14:27 orquestra_sdk-0.51.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-22 14:27 orquestra_sdk-0.51.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       66 b- defN 23-Jun-22 14:27 orquestra_sdk-0.51.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       10 b- defN 23-Jun-22 14:27 orquestra_sdk-0.51.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    10799 b- defN 23-Jun-22 14:27 orquestra_sdk-0.51.0.dist-info/RECORD
-115 files, 714422 bytes uncompressed, 204411 bytes compressed:  71.4%
+Zip file size: 230510 bytes, number of entries: 121
+-rw-r--r--  2.0 unx     1822 b- defN 23-Jul-11 07:19 orquestra/sdk/__init__.py
+-rw-r--r--  2.0 unx     7183 b- defN 23-Jul-11 07:19 orquestra/sdk/exceptions.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-11 07:19 orquestra/sdk/py.typed
+-rw-r--r--  2.0 unx      204 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/__init__.py
+-rw-r--r--  2.0 unx     8232 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_ast.py
+-rw-r--r--  2.0 unx    21113 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_config.py
+-rw-r--r--  2.0 unx     2878 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_dates.py
+-rw-r--r--  2.0 unx    37777 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_dsl.py
+-rw-r--r--  2.0 unx     2461 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_env.py
+-rw-r--r--  2.0 unx     2465 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_exec_ctx.py
+-rw-r--r--  2.0 unx     2524 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_factory.py
+-rw-r--r--  2.0 unx     3703 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_git_url_utils.py
+-rw-r--r--  2.0 unx     3714 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_graphs.py
+-rw-r--r--  2.0 unx    13182 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_in_process_runtime.py
+-rw-r--r--  2.0 unx     1104 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_jwt.py
+-rw-r--r--  2.0 unx     1541 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_log_adapter.py
+-rw-r--r--  2.0 unx     1407 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_retry.py
+-rw-r--r--  2.0 unx     4180 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_services.py
+-rw-r--r--  2.0 unx    32365 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_traversal.py
+-rw-r--r--  2.0 unx     4629 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_viz.py
+-rw-r--r--  2.0 unx    23663 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_workflow.py
+-rw-r--r--  2.0 unx     7902 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/abc.py
+-rw-r--r--  2.0 unx    11948 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/dispatch.py
+-rw-r--r--  2.0 unx     6001 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/loader.py
+-rw-r--r--  2.0 unx     7004 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/serde.py
+-rw-r--r--  2.0 unx      664 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_api/__init__.py
+-rw-r--r--  2.0 unx    16964 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_api/_config.py
+-rw-r--r--  2.0 unx    13819 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_api/_task_run.py
+-rw-r--r--  2.0 unx    26367 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_api/_wf_run.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_conversions/__init__.py
+-rw-r--r--  2.0 unx     3509 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_conversions/_ids.py
+-rw-r--r--  2.0 unx     7074 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_conversions/_imports.py
+-rw-r--r--  2.0 unx    12943 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_conversions/_invocations.py
+-rw-r--r--  2.0 unx     3905 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_conversions/_yaml_exporter.py
+-rw-r--r--  2.0 unx      360 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_db/__init__.py
+-rw-r--r--  2.0 unx     5285 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_db/_db.py
+-rw-r--r--  2.0 unx     1331 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_db/_migration.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_driver/__init__.py
+-rw-r--r--  2.0 unx    21385 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_driver/_ce_runtime.py
+-rw-r--r--  2.0 unx    29246 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_driver/_client.py
+-rw-r--r--  2.0 unx     4748 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_driver/_exceptions.py
+-rw-r--r--  2.0 unx    14142 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_driver/_models.py
+-rw-r--r--  2.0 unx     3049 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_logs/_interfaces.py
+-rw-r--r--  2.0 unx     4506 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_logs/_markers.py
+-rw-r--r--  2.0 unx      869 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_logs/_regrouping.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_qe/__init__.py
+-rw-r--r--  2.0 unx     7212 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_qe/_client.py
+-rw-r--r--  2.0 unx    34798 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_qe/_qe_runtime.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_spaces/__init__.py
+-rw-r--r--  2.0 unx     1734 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_spaces/_api.py
+-rw-r--r--  2.0 unx     1358 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_spaces/_resolver.py
+-rw-r--r--  2.0 unx      704 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_spaces/_structs.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_testing/__init__.py
+-rw-r--r--  2.0 unx     4031 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_testing/_connections.py
+-rw-r--r--  2.0 unx     8104 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_testing/_example_wfs.py
+-rw-r--r--  2.0 unx     1754 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_testing/_ipc.py
+-rw-r--r--  2.0 unx      261 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/_testing/_long_import.py
+-rw-r--r--  2.0 unx    20208 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py
+-rw-r--r--  2.0 unx      698 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_cli_logs.py
+-rw-r--r--  2.0 unx     4406 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_dumpers.py
+-rw-r--r--  2.0 unx    13077 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_entry.py
+-rw-r--r--  2.0 unx    23721 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_repos.py
+-rw-r--r--  2.0 unx     2255 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_config/_list.py
+-rw-r--r--  2.0 unx     5438 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_login/_login.py
+-rw-r--r--  2.0 unx     1694 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_login/_login_server.py
+-rw-r--r--  2.0 unx     1621 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_services/_down.py
+-rw-r--r--  2.0 unx     1327 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_services/_status.py
+-rw-r--r--  2.0 unx     2656 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_services/_up.py
+-rw-r--r--  2.0 unx     3106 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_task/_logs.py
+-rw-r--r--  2.0 unx     3626 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_task/_results.py
+-rw-r--r--  2.0 unx      367 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_ui/__init__.py
+-rw-r--r--  2.0 unx     6344 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_ui/_click_default_group.py
+-rw-r--r--  2.0 unx     5520 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_ui/_errors.py
+-rw-r--r--  2.0 unx     1668 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_ui/_models.py
+-rw-r--r--  2.0 unx    16101 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py
+-rw-r--r--  2.0 unx    10601 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py
+-rw-r--r--  2.0 unx      624 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/color.py
+-rw-r--r--  2.0 unx     7815 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/per_command.py
+-rw-r--r--  2.0 unx     5180 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_workflow/_list.py
+-rw-r--r--  2.0 unx     4012 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_workflow/_logs.py
+-rw-r--r--  2.0 unx     3140 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_workflow/_results.py
+-rw-r--r--  2.0 unx     2621 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_workflow/_stop.py
+-rw-r--r--  2.0 unx     5087 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_workflow/_submit.py
+-rw-r--r--  2.0 unx     2138 b- defN 23-Jul-11 07:19 orquestra/sdk/_base/cli/_dorq/_workflow/_view.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jul-11 07:19 orquestra/sdk/_ray/__init__.py
+-rw-r--r--  2.0 unx    20192 b- defN 23-Jul-11 07:19 orquestra/sdk/_ray/_build_workflow.py
+-rw-r--r--  2.0 unx     6644 b- defN 23-Jul-11 07:19 orquestra/sdk/_ray/_client.py
+-rw-r--r--  2.0 unx    19522 b- defN 23-Jul-11 07:19 orquestra/sdk/_ray/_dag.py
+-rw-r--r--  2.0 unx      867 b- defN 23-Jul-11 07:19 orquestra/sdk/_ray/_id_gen.py
+-rw-r--r--  2.0 unx     7327 b- defN 23-Jul-11 07:19 orquestra/sdk/_ray/_ray_logs.py
+-rw-r--r--  2.0 unx     1278 b- defN 23-Jul-11 07:19 orquestra/sdk/_ray/_wf_metadata.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jul-11 07:19 orquestra/sdk/examples/__init__.py
+-rw-r--r--  2.0 unx     1558 b- defN 23-Jul-11 07:19 orquestra/sdk/examples/exportable_wf.py
+-rw-r--r--  2.0 unx     1116 b- defN 23-Jul-11 07:19 orquestra/sdk/examples/workflow_defs.py
+-rw-r--r--  2.0 unx      318 b- defN 23-Jul-11 07:19 orquestra/sdk/kubernetes/__init__.py
+-rw-r--r--  2.0 unx     2420 b- defN 23-Jul-11 07:19 orquestra/sdk/kubernetes/quantity.py
+-rw-r--r--  2.0 unx      370 b- defN 23-Jul-11 07:19 orquestra/sdk/mlflow/__init__.py
+-rw-r--r--  2.0 unx     1319 b- defN 23-Jul-11 07:19 orquestra/sdk/mlflow/_connection_utils.py
+-rw-r--r--  2.0 unx      427 b- defN 23-Jul-11 07:19 orquestra/sdk/packaging/__init__.py
+-rw-r--r--  2.0 unx     4144 b- defN 23-Jul-11 07:19 orquestra/sdk/packaging/_versions.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jul-11 07:19 orquestra/sdk/schema/__init__.py
+-rw-r--r--  2.0 unx     1874 b- defN 23-Jul-11 07:19 orquestra/sdk/schema/_compat.py
+-rw-r--r--  2.0 unx     1578 b- defN 23-Jul-11 07:19 orquestra/sdk/schema/configs.py
+-rw-r--r--  2.0 unx    15130 b- defN 23-Jul-11 07:19 orquestra/sdk/schema/ir.py
+-rw-r--r--  2.0 unx      848 b- defN 23-Jul-11 07:19 orquestra/sdk/schema/local_database.py
+-rw-r--r--  2.0 unx     4745 b- defN 23-Jul-11 07:19 orquestra/sdk/schema/responses.py
+-rw-r--r--  2.0 unx     1611 b- defN 23-Jul-11 07:19 orquestra/sdk/schema/workflow_run.py
+-rw-r--r--  2.0 unx     4114 b- defN 23-Jul-11 07:19 orquestra/sdk/schema/yaml_model.py
+-rw-r--r--  2.0 unx     1104 b- defN 23-Jul-11 07:19 orquestra/sdk/secrets/__init__.py
+-rw-r--r--  2.0 unx     7254 b- defN 23-Jul-11 07:19 orquestra/sdk/secrets/_api.py
+-rw-r--r--  2.0 unx     2232 b- defN 23-Jul-11 07:19 orquestra/sdk/secrets/_auth.py
+-rw-r--r--  2.0 unx     5600 b- defN 23-Jul-11 07:19 orquestra/sdk/secrets/_client.py
+-rw-r--r--  2.0 unx     1222 b- defN 23-Jul-11 07:19 orquestra/sdk/secrets/_exceptions.py
+-rw-r--r--  2.0 unx     1679 b- defN 23-Jul-11 07:19 orquestra/sdk/secrets/_models.py
+-rw-r--r--  2.0 unx     1072 b- defN 23-Jul-11 07:19 orquestra/sdk/v2/__init__.py
+-rw-r--r--  2.0 unx    11357 b- defN 23-Jul-11 07:19 orquestra_sdk-0.52.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3147 b- defN 23-Jul-11 07:19 orquestra_sdk-0.52.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-11 07:19 orquestra_sdk-0.52.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       66 b- defN 23-Jul-11 07:19 orquestra_sdk-0.52.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       10 b- defN 23-Jul-11 07:19 orquestra_sdk-0.52.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    11382 b- defN 23-Jul-11 07:19 orquestra_sdk-0.52.0.dist-info/RECORD
+121 files, 739426 bytes uncompressed, 212198 bytes compressed:  71.3%
```

## zipnote {}

```diff
@@ -12,14 +12,17 @@
 
 Filename: orquestra/sdk/_base/_ast.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_config.py
 Comment: 
 
+Filename: orquestra/sdk/_base/_dates.py
+Comment: 
+
 Filename: orquestra/sdk/_base/_dsl.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_env.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_exec_ctx.py
@@ -120,14 +123,17 @@
 
 Filename: orquestra/sdk/_base/_driver/_models.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_logs/_interfaces.py
 Comment: 
 
+Filename: orquestra/sdk/_base/_logs/_markers.py
+Comment: 
+
 Filename: orquestra/sdk/_base/_logs/_regrouping.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_qe/__init__.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_qe/_client.py
@@ -174,14 +180,17 @@
 
 Filename: orquestra/sdk/_base/cli/_dorq/_entry.py
 Comment: 
 
 Filename: orquestra/sdk/_base/cli/_dorq/_repos.py
 Comment: 
 
+Filename: orquestra/sdk/_base/cli/_dorq/_config/_list.py
+Comment: 
+
 Filename: orquestra/sdk/_base/cli/_dorq/_login/_login.py
 Comment: 
 
 Filename: orquestra/sdk/_base/cli/_dorq/_login/_login_server.py
 Comment: 
 
 Filename: orquestra/sdk/_base/cli/_dorq/_services/_down.py
@@ -198,14 +207,17 @@
 
 Filename: orquestra/sdk/_base/cli/_dorq/_task/_results.py
 Comment: 
 
 Filename: orquestra/sdk/_base/cli/_dorq/_ui/__init__.py
 Comment: 
 
+Filename: orquestra/sdk/_base/cli/_dorq/_ui/_click_default_group.py
+Comment: 
+
 Filename: orquestra/sdk/_base/cli/_dorq/_ui/_errors.py
 Comment: 
 
 Filename: orquestra/sdk/_base/cli/_dorq/_ui/_models.py
 Comment: 
 
 Filename: orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py
@@ -270,14 +282,20 @@
 
 Filename: orquestra/sdk/kubernetes/__init__.py
 Comment: 
 
 Filename: orquestra/sdk/kubernetes/quantity.py
 Comment: 
 
+Filename: orquestra/sdk/mlflow/__init__.py
+Comment: 
+
+Filename: orquestra/sdk/mlflow/_connection_utils.py
+Comment: 
+
 Filename: orquestra/sdk/packaging/__init__.py
 Comment: 
 
 Filename: orquestra/sdk/packaging/_versions.py
 Comment: 
 
 Filename: orquestra/sdk/schema/__init__.py
@@ -321,26 +339,26 @@
 
 Filename: orquestra/sdk/secrets/_models.py
 Comment: 
 
 Filename: orquestra/sdk/v2/__init__.py
 Comment: 
 
-Filename: orquestra_sdk-0.51.0.dist-info/LICENSE
+Filename: orquestra_sdk-0.52.0.dist-info/LICENSE
 Comment: 
 
-Filename: orquestra_sdk-0.51.0.dist-info/METADATA
+Filename: orquestra_sdk-0.52.0.dist-info/METADATA
 Comment: 
 
-Filename: orquestra_sdk-0.51.0.dist-info/WHEEL
+Filename: orquestra_sdk-0.52.0.dist-info/WHEEL
 Comment: 
 
-Filename: orquestra_sdk-0.51.0.dist-info/entry_points.txt
+Filename: orquestra_sdk-0.52.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: orquestra_sdk-0.51.0.dist-info/top_level.txt
+Filename: orquestra_sdk-0.52.0.dist-info/top_level.txt
 Comment: 
 
-Filename: orquestra_sdk-0.51.0.dist-info/RECORD
+Filename: orquestra_sdk-0.52.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## orquestra/sdk/__init__.py

```diff
@@ -1,13 +1,13 @@
 ################################################################################
 # © Copyright 2021-2023 Zapata Computing Inc.
 ################################################################################
 """Orquestra SDK allows to define computational workflows using Python DSL."""
 
-from . import secrets
+from . import mlflow, secrets
 from ._base._api import (
     RuntimeConfig,
     TaskRun,
     WorkflowRun,
     current_run_ids,
     list_workflow_runs,
     migrate_config_file,
@@ -41,14 +41,15 @@
     "DataAggregation",
     "current_run_ids",
     "GithubImport",
     "GitImport",
     "Import",
     "InlineImport",
     "LocalImport",
+    "mlflow",
     "NotATaskWarning",
     "PythonImports",
     "Resources",
     "RuntimeConfig",
     "Secret",
     "TaskDef",
     "TaskRun",
```

## orquestra/sdk/_base/_config.py

```diff
@@ -301,26 +301,14 @@
 ) -> Optional[RuntimeConfiguration]:
     if prev_config_file is not None:
         return prev_config_file.configs.get(new_config_name)
     else:
         return EMPTY_CONFIG_FILE.configs.get(new_config_name)
 
 
-def _resolve_config_name_for_writing(
-    config_name: Optional[str],
-    prev_config_file: Optional[RuntimeConfigurationFile] = None,
-) -> str:
-    resolved_config_name = _resolve_config_name(config_name, prev_config_file)
-
-    if resolved_config_name in SPECIAL_CONFIG_NAME_DICT:
-        raise ValueError(f"Can't write {config_name}, it's a reserved name")
-
-    return resolved_config_name
-
-
 def _validate_runtime_options(
     runtime_name: RuntimeName,
     runtime_options: Optional[Mapping[str, Any]] = None,
 ) -> dict:
     """
     Check that the combination of configuration options is valid.
 
@@ -360,31 +348,33 @@
                 f"'{key}' is not a valid option for the {runtime_name} runtime."
             )
 
     return dict(runtime_options)
 
 
 def save_or_update(config_name, runtime_name, runtime_options):
+    if config_name in SPECIAL_CONFIG_NAME_DICT:
+        raise ValueError(f"Can't update {config_name}, it's a reserved name")
+
     if config_name in read_config_names():
         update_config(config_name, runtime_name, runtime_options)
     else:
         write_config(config_name, runtime_name, runtime_options)
 
 
 def write_config(
-    config_name: Optional[str],
+    config_name: str,
     runtime_name: Union[RuntimeName, str],
     runtime_options: dict,
 ) -> Tuple[RuntimeConfiguration, Path]:
     """
     Write a new configuration to the file.
 
     Args:
-        config_name: The name under which to save the configuration. If set to None, a
-            unique name will be generated for the config.
+        config_name: The name under which to save the configuration.
         runtime_name: The runtime to which this configuration relates.
         runtime_options: The runtime options contained within this configuration.
 
     Returns:
         RuntimeConfiguration: the configuration as saved.
         Path: The path of the file to which the configuration was written.
     """
@@ -396,57 +386,50 @@
     # Check that the runtime name is valid and that the runtime options relate to it.
     resolved_runtime_name: RuntimeName = RuntimeName(runtime_name)
     resolved_runtime_options = _validate_runtime_options(
         resolved_runtime_name, runtime_options
     )
 
     with filelock.FileLock(_get_config_directory() / LOCK_FILE_NAME):
-        # Get the config name to save under - either the user-defined one, or an auto
-        # generated one if the config_name parameter is None. Either way we need to
-        # pass it through _resolve_config_name_for_writing() as this handles the
-        # protected names like 'local'.
-        resolved_config_name: ConfigName = _resolve_config_name_for_writing(config_name)
-
         resolved_prev_config_file = _resolve_config_file_for_writing()
 
         new_config_file = _resolve_new_config_file(
-            resolved_config_name,
+            config_name,
             resolved_runtime_name,
             resolved_runtime_options,
             resolved_prev_config_file,
         )
 
         saved_config = RuntimeConfiguration(
-            config_name=resolved_config_name,
+            config_name=config_name,
             runtime_name=resolved_runtime_name,
             runtime_options=resolved_runtime_options,
         )
 
         return (
             saved_config,
             _save_config_file(new_config_file),
         )
 
 
 def update_config(
-    config_name: Optional[ConfigName] = None,
+    config_name: ConfigName,
     runtime_name: Optional[RuntimeName] = None,
     new_runtime_options: Optional[Mapping[str, Any]] = None,
 ) -> Tuple[RuntimeConfiguration, Path]:
     """
     Ensures that whatever non-None argument is passed here will end up saved to
     the config file under `~/.orquestra/config.json`.
 
     Note that a single config file has multiple "entry" configurations, a
-    reserved "local", and a "default" one.
+    reserved "local"
 
     Args:
         config_name: A config file has multiple "entry" configurations. This
-            tells which entry we want to update. If `None`, this will be
-            inferred from the "default config name" stored in the file.
+            tells which entry we want to update.
         runtime_name: if not None, it will be stored under the appropriate config entry.
         new_runtime_options: if not None, any entries in this dictionary will
             be added to the config entry's runtime options. The remaining
             runtime_options key-values that are already in the file will be
             left intact.
 
     Returns:
@@ -456,92 +439,59 @@
     Raises:
         ValueError:
             - if `config_name` was resolved to "local".
             - if `config_name` couldn't be resolved automatically.
         KeyError:
             - if one or more runtime options are not valid for this runtime.
     """
-
     with filelock.FileLock(_get_config_directory() / LOCK_FILE_NAME):
         # We need to retain a lock because we save the config file at the end
         # of this function.
 
         resolved_prev_config_file = _resolve_config_file_for_writing()
 
-        resolved_config_name = _resolve_config_name_for_writing(
-            config_name, resolved_prev_config_file
-        )
-
         resolved_prev_config_entry = _resolve_prev_config_entry_for_writing(
-            resolved_prev_config_file, resolved_config_name
+            resolved_prev_config_file, config_name
         )
 
         resolved_runtime_name = _resolve_runtime_name_for_writing(
-            runtime_name, resolved_prev_config_entry, resolved_config_name
+            runtime_name, resolved_prev_config_entry, config_name
         )
 
         resolved_runtime_options = _validate_runtime_options(
             resolved_runtime_name,
             _resolve_runtime_options_for_writing(
                 new_runtime_options,
-                resolved_config_name,
+                config_name,
                 resolved_prev_config_entry,
             ),
         )
 
         new_config_file = _resolve_new_config_file(
-            resolved_config_name,
+            config_name,
             resolved_runtime_name,
             resolved_runtime_options,
             resolved_prev_config_file,
         )
 
         return RuntimeConfiguration(
-            config_name=resolved_config_name,
+            config_name=config_name,
             runtime_name=resolved_runtime_name,
             runtime_options=resolved_runtime_options,
         ), _save_config_file(new_config_file)
 
 
 def _resolve_config_file_for_reading() -> Optional[RuntimeConfigurationFile]:
     try:
         with filelock.FileLock(_get_config_directory() / LOCK_FILE_NAME):
             return _open_config_file()
     except exceptions.ConfigFileNotFoundError:
         return None
 
 
-def _resolve_config_name_for_reading(
-    config_name: Optional[str], config_file: Optional[RuntimeConfigurationFile]
-) -> str:
-    return _resolve_config_name(config_name, config_file)
-
-
-def _resolve_config_name(
-    config_name: Optional[str], config_file: Optional[RuntimeConfigurationFile]
-) -> str:
-    """Turns out we can reuse this logic for both reading and writing"""
-    if config_name in SPECIAL_CONFIG_NAME_DICT:
-        # the built-in hardcoded value
-        return config_name
-    elif config_name is not None:
-        # the caller passed it in explicitly
-        return config_name
-    elif config_file is not None:
-        # Caller didn't pass config name. The config file exists, and we're
-        # using the default value.
-        return config_file.default_config_name
-    else:
-        # config_name == None & config_file == None
-        raise ValueError(
-            "Couldn't resolve an appropriate config name to read the "
-            "configuration from. Please pass it explicitly."
-        )
-
-
 def _resolve_config_entry_for_reading(
     config_name: str, config_file: Optional[RuntimeConfigurationFile]
 ) -> RuntimeConfiguration:
     """
     Resolve the specified configuration.
 
     Args:
@@ -558,15 +508,14 @@
 
     Returns:
         RuntimeConfiguration
     """
     # Deal with special cases
     if config_name in SPECIAL_CONFIG_NAME_DICT:
         return _handle_config_name_special_cases(config_name)
-
     # Handle missing file or config not in file
     if config_file is None:
         raise exceptions.ConfigFileNotFoundError("Could not locate config file.")
     if config_name not in config_file.configs:
         raise exceptions.ConfigNameNotFoundError(
             f"No config '{config_name}' found in file"
         )
@@ -602,67 +551,42 @@
 
 
 def _generate_cluster_uri_name(uri: str) -> str:
     return str(urlparse(uri).netloc).split(".")[0]
 
 
 def read_config(
-    config_name: Optional[str],
+    config_name: str,
 ) -> RuntimeConfiguration:
     """
     Reads a runtime configuration from the configuration file
 
     Arguments:
         config_name: the name of the configuration to read
             - if it's 'local': this function returns the hardcoded local configuration
-            - if it's None: this function returns the configuration set as the
-              default one. The default configuration can be user-specified
-              (read from the file) or a hardcoded, "local" one.
 
     Returns:
         a runtime configuration
 
     Raises:
         orquestra.sdk.exceptions.ConfigNameNotFoundError: when no runtime
             config matching `config_name` exists.
     """
     resolved_config_file = _resolve_config_file_for_reading()
-    resolved_config_name = _resolve_config_name_for_reading(
-        config_name, resolved_config_file
-    )
     resolved_config_entry = _resolve_config_entry_for_reading(
-        resolved_config_name, resolved_config_file
+        config_name, resolved_config_file
     )
 
     return resolved_config_entry
 
 
-def read_default_config_name() -> str:
-    """
-    Reads a default configuration name from the configuration file, or returns
-    the built-in default ("local").
-    """
-
-    try:
-        with filelock.FileLock(_get_config_directory() / LOCK_FILE_NAME):
-            config_file = _open_config_file()
-    except (exceptions.ConfigFileNotFoundError, FileNotFoundError):
-        return BUILT_IN_CONFIG_NAME
-
-    return config_file.default_config_name
-
-
 def read_config_names() -> List[str]:
     """
     Reads the names of all configurations stored in the configuration file.
 
-    Arguments:
-        config_file_path: the path to the file where the configurations are saved. If
-            omitted, the default file location is used.
-
     Returns:
         list: a list of strings, each containing the name of a saved configuration. If
             the file does not exist, returns an empty list.
     """
     try:
         with filelock.FileLock(_get_config_directory() / LOCK_FILE_NAME, timeout=3):
             return _read_config_names()
@@ -681,46 +605,21 @@
     """
     Reads the names of all configurations stored in the configuration file.
 
     This function is intended for internal use in cases where we already have a
     filelock for the config file. If you aren't wrapping the call to this function in
     `with filelock...`, you should probably be using `read_config_names` instead.
 
-    Arguments:
-        config_file_path: the path to the file where the configurations are saved. If
-            omitted, the default file location is used.
-
     Returns:
         list: a list of strings, each containing the name of a saved configuration. If
             the file does not exist, returns an empty list.
     """
 
     try:
         config_file = _open_config_file()
     except (
         exceptions.ConfigFileNotFoundError,
         FileNotFoundError,
         ValidationError,
     ):
         return []
     return [name for name in config_file.configs]
-
-
-def update_default_config_name(default_config_name: str):
-    """
-    Sets the "default_config_name" field in the user config. Creates the config
-    file if it didn't exist already. Isn't expected to raise any exceptions.
-
-    Args:
-        default_config_name: the name of the configuration to update
-    """
-
-    with filelock.FileLock(_get_config_directory() / LOCK_FILE_NAME):
-        prev_config_file = _resolve_config_file_for_writing()
-
-        if prev_config_file is not None:
-            new_config_file = prev_config_file.copy(deep=True)
-        else:
-            new_config_file = EMPTY_CONFIG_FILE.copy(deep=True)
-
-        new_config_file.default_config_name = default_config_name
-        _save_config_file(new_config_file)
```

## orquestra/sdk/_base/_dsl.py

```diff
@@ -155,14 +155,22 @@
             )
         else:
             errmsg = (
                 "`personal_access_token` must be of type `sdk.Secret`, "
                 f"not {type(personal_access_token).__name__}."
             )
         raise TypeError(errmsg)
+    if personal_access_token is not None and isinstance(personal_access_token, Secret):
+        if personal_access_token.workspace_id is None:
+            warnings.warn(
+                "Please specify workspace ID directly for accessing secrets."
+                " Support for default workspaces will be sunset in the future.",
+                FutureWarning,
+            )
+
     return GitImportWithAuth(
         repo_url=f"https://github.com/{repo}.git",
         git_ref=git_ref,
         username=username,
         auth_secret=personal_access_token,
     )
```

## orquestra/sdk/_base/_factory.py

```diff
@@ -18,28 +18,53 @@
     There are a couple of runtime runtime integrations implemented as separate
     classes. This factory function solves the problem of figuring out which
     class to use.
     """
     # Imports are deferred to cut down on the import graph for CLI latency. The
     # subgraphs for Ray and for QE are distinct, and both take a lot of time to
     # import.
-    selected_runtime: t.Type[RuntimeInterface]
     if config.runtime_name == RuntimeName.RAY_LOCAL:
         import orquestra.sdk._ray._dag
 
-        selected_runtime = orquestra.sdk._ray._dag.RayRuntime
+        return orquestra.sdk._ray._dag.RayRuntime(
+            project_dir=project_dir,
+            config=config,
+        )
     elif config.runtime_name == RuntimeName.QE_REMOTE:
         import orquestra.sdk._base._qe._qe_runtime
 
-        selected_runtime = orquestra.sdk._base._qe._qe_runtime.QERuntime
-    elif config.runtime_name == RuntimeName.CE_REMOTE:
-        import orquestra.sdk._base._driver._ce_runtime
+        return orquestra.sdk._base._qe._qe_runtime.QERuntime(
+            project_dir=project_dir, config=config, verbose=verbose
+        )
 
-        selected_runtime = orquestra.sdk._base._driver._ce_runtime.CERuntime
+    elif config.runtime_name == RuntimeName.CE_REMOTE:
+        return _build_ce_runtime(config, verbose)
     else:
         raise exceptions.NotFoundError(f"Unknown runtime: {config.runtime_name}")
 
-    return selected_runtime.from_runtime_configuration(
-        project_dir=project_dir,
+
+def _build_ce_runtime(config: RuntimeConfiguration, verbose: bool):
+    import orquestra.sdk._base._driver._ce_runtime
+    import orquestra.sdk._base._driver._client
+
+    # We're using a reusable session to allow shared headers
+    # In the future we can store cookies, etc too.
+
+    try:
+        base_uri = config.runtime_options["uri"]
+        token = config.runtime_options["token"]
+    except KeyError as e:
+        raise exceptions.RuntimeConfigError(
+            "Invalid CE configuration. Did you login first?"
+        ) from e
+
+    uri_provider = orquestra.sdk._base._driver._client.ExternalUriProvider(base_uri)
+
+    client = orquestra.sdk._base._driver._client.DriverClient.from_token(
+        token=token, uri_provider=uri_provider
+    )
+
+    return orquestra.sdk._base._driver._ce_runtime.CERuntime(
         config=config,
+        client=client,
         verbose=verbose,
     )
```

## orquestra/sdk/_base/_graphs.py

```diff
@@ -1,30 +1,36 @@
 ################################################################################
 # © Copyright 2023 Zapata Computing Inc.
 ################################################################################
 import typing as t
+from copy import copy
 
 from orquestra.sdk.schema import ir
 
 Node = str
-Graph = t.Dict[Node, t.Set[Node]]
+
+# Graph uses dict with Nones instead of set because dict is ordered, and set is not
+# and we need the order to be deterministic
+Graph = t.Dict[Node, t.Dict[Node, None]]
 
 
 def _invert_graph(graph: Graph) -> Graph:
     inverted: Graph = {}
     for node, deps in graph.items():
         for dep in deps:
-            inverted.setdefault(dep, set()).add(node)
+            # Graph uses dict with Nones instead of set because dict is ordered
+            inverted.setdefault(dep, dict())[node] = None
     return inverted
 
 
-def _root_nodes(graph: Graph) -> t.Set[Node]:
-    all_nodes = {v for node, deps in graph.items() for v in [node, *deps]}
-    needed_nodes = {dep for deps in graph.values() for dep in deps}
-    return all_nodes - needed_nodes
+def _root_nodes(graph: Graph) -> t.Dict[Node, None]:
+    all_nodes = {v: None for node, deps in graph.items() for v in [node, *deps]}
+    needed_nodes = {dep: None for deps in graph.values() for dep in deps}
+    # return all_nodes - needed_nodes
+    return {v: None for v in all_nodes.keys() if v not in needed_nodes}
 
 
 def topological_sort(graph_to_sort: Graph) -> t.List[Node]:
     """Returns a flat list of nodes that reflect walking over nodes without ever moving
     against the arrow in the DAG.
 
     Implements Kahn's algorithm. See listing at:
@@ -34,54 +40,61 @@
     since Python 3.9.
 
     Args:
         graph_to_sort: key – node of interest, value – successors. The key needs to be
         visited before any of the successors.
     """
     # We need a local copy because Kahn's algorithm mutates data.
-    graph = {node: set(successors) for node, successors in graph_to_sort.items()}
+    graph = {node: copy(successors) for node, successors in graph_to_sort.items()}
 
     # We'll need this to check if a node has any incoming edges/dependencies (line 9 in
     # the algorithm).
     inverted_graph = _invert_graph(graph)
 
     # List that will contain the sorted elements.
     L = []
     # Set of all nodes with no incoming edge.
     S = _root_nodes(graph)
 
     while S:
-        n = S.pop()
+        n = S.popitem()[0]
         L.append(n)
         n_deps = list(graph.get(n, []))
         for m in n_deps:
-            graph[n].remove(m)
-            inverted_graph.get(m, set()).remove(n)
+            graph[n].pop(m)
 
-            if not inverted_graph.get(m):
-                S.add(m)
+            node = inverted_graph.get(m)
+            # <m> should always be a member of inverted_graph
+            assert node is not None
+            node.pop(n)
+
+            if node == {}:
+                # Graph uses dict with Nones instead of set because dict is ordered
+                S[m] = None
 
     for deps in graph.values():
         if deps:
             raise ValueError("Graph has at least one cycle")
 
     return L
 
 
 def iter_invocations_topologically(wf: ir.WorkflowDef):
     # The graph is like: [I need this node first]->[successors].
     graph: Graph = {}
     for invocation in wf.task_invocations.values():
         for arg_id in [*invocation.args_ids, *invocation.kwargs_ids.values()]:
             # We need the argument before we can run the invocation
-            graph.setdefault(arg_id, set()).add(invocation.id)
+            # Graph uses dict with Nones instead of set because dict is ordered
+            graph.setdefault(arg_id, dict())[invocation.id] = None
 
         for output_id in invocation.output_ids:
             # We need to run the invocation before we can have the output
-            graph.setdefault(invocation.id, set()).add(output_id)
+            # Graph uses dict with Nones instead of set because dict is ordered
+            graph.setdefault(invocation.id, dict())[output_id] = None
 
     sorted_node_ids = topological_sort(graph)
 
     for node_id in sorted_node_ids:
         # The DAG nodes are constants, artifacts, and invocations. Here, we only want
         # the invocations.
         if node_id in wf.task_invocations:
```

## orquestra/sdk/_base/_in_process_runtime.py

```diff
@@ -7,15 +7,15 @@
 
 import typing as t
 import warnings
 from contextlib import contextmanager
 from datetime import datetime, timedelta, timezone
 
 from orquestra.sdk import exceptions
-from orquestra.sdk._base import abc
+from orquestra.sdk._base import _dates, abc
 from orquestra.sdk._base._spaces._structs import ProjectRef
 from orquestra.sdk.schema import ir
 from orquestra.sdk.schema.responses import WorkflowResult
 from orquestra.sdk.schema.workflow_run import (
     ProjectId,
     RunStatus,
     State,
@@ -139,15 +139,15 @@
                 "in_process runtime doesn't support project-scoped workflows. "
                 "Project and workspace IDs will be ignored.",
                 category=exceptions.UnsupportedRuntimeFeature,
             )
 
         run_id = self._gen_next_run_id(workflow_def)
 
-        self._start_time_store[run_id] = datetime.now(timezone.utc)
+        self._start_time_store[run_id] = _dates.now()
 
         # We deserialize the constants in one go, instead of as needed
         consts: t.Dict[ir.ConstantNodeId, t.Any] = {
             id: serde.deserialize(node)
             for id, node in workflow_def.constant_nodes.items()
         }
         for id, secret in workflow_def.secret_nodes.items():
@@ -190,15 +190,15 @@
 
         # Ordinary functions return `obj` or `tuple(obj, obj)`
         outputs = tuple(
             _get_args(consts, self._artifact_store[run_id], workflow_def.output_ids)
         )
         self._output_store[run_id] = outputs
 
-        self._end_time_store[run_id] = datetime.now(timezone.utc)
+        self._end_time_store[run_id] = _dates.now()
         self._workflow_def_store[run_id] = workflow_def
         return run_id
 
     def get_workflow_run_outputs_non_blocking(
         self, workflow_run_id: WfRunId
     ) -> t.Tuple[WorkflowResult, ...]:
         return (
@@ -299,15 +299,15 @@
         Raises:
             WorkspacesNotSupportedError: when a workspace or project is specified.
         """
         if workspace or project:
             raise exceptions.WorkspacesNotSupportedError(
                 "Filtering by workspace is not supported on In Process runtimes."
             )
-        now = datetime.now(timezone.utc)
+        now = _dates.now()
 
         if state is not None:
             if not isinstance(state, list):
                 state_list = [state]
             else:
                 state_list = state
         else:
```

## orquestra/sdk/_base/_log_adapter.py

```diff
@@ -1,145 +1,57 @@
 ################################################################################
-# © Copyright 2022 Zapata Computing Inc.
+# © Copyright 2022 - 2023 Zapata Computing Inc.
 ################################################################################
 """
 Log adapter adds a workflow context to logs, Workflow ID and Task ID.
 """
 
-import json
 import logging
-import typing as t
-from datetime import datetime, timezone
+import warnings
 
-from orquestra.sdk._base._api._task_run import current_run_ids
-from orquestra.sdk.schema.ir import TaskInvocationId
-from orquestra.sdk.schema.workflow_run import TaskRunId, WorkflowRunId
 
-# NOTE: the `message`, `wf_run_id`, and `task_run_id` value placeholders don't come with
-# "" quotes. We already add them when we json.dumps() the value. This ensure proper JSON
-# escaping and handling null values.
-FORMAT = '{"timestamp": "%(asctime)s", "level": "%(levelname)s", "filename": "%(filename)s:%(lineno)s", "message": %(message)s, "wf_run_id": %(wf_run_id)s, "task_inv_id": %(task_inv_id)s, "task_run_id": %(task_run_id)s}'  # noqa
-
-
-class TaggedWorkflowTaskLogger(logging.LoggerAdapter):
-    """
-    Adding a workflow/task context to log outputs.
-    """
-
-    def process(
-        self, msg, kwargs: t.Mapping[str, t.Any]
-    ) -> t.Tuple[str, t.MutableMapping[str, t.Any]]:
-        """
-        Args:
-            msg: message passed to the standard logger method calls. The type of this
-                object depends on internals of ``logging``, but we're assuming it's a
-                string, or something close to it.
-            kwargs: custom kwargs passed to the standard logger method calls.
-        """
-
-        # Ensure the message can be stored as a JSON. This will escape any
-        # JSON-forbidden chars.
-        new_msg = json.dumps(str(msg))
-
-        # Workaround cases where run IDs are nulls.
-        old_extra = self.extra or {}
-        new_extra = dict(old_extra)
-        for key in ["wf_run_id", "task_inv_id", "task_run_id"]:
-            new_extra[key] = json.dumps(old_extra[key])
-
-        # Mimic default behavior of logging.LoggerAdapter. Note we keep run IDs as
-        # extras.
-        new_kwargs = {**kwargs, "extra": new_extra}
-        return new_msg, new_kwargs
-
-
-class ISOFormatter(logging.Formatter):
-    """
-    Overrides the default date formatting to produce ISO 8601 strings.
-    """
-
-    def formatTime(self, record, datefmt=None) -> str:
-        """
-        Override for logging.Formatter.formatTime.
-
-        Example output: ``2023-02-02T11:45:21.504754+00:00``
-        """
-        utc_timestamp = record.created
-        instant = datetime.fromtimestamp(utc_timestamp, timezone.utc)
-        return instant.isoformat()
-
-
-def _make_logger(
-    wf_run_id: t.Optional[WorkflowRunId],
-    task_inv_id: t.Optional[TaskInvocationId],
-    task_run_id: t.Optional[TaskRunId],
-):
-    # Note: there are two loggers: "nested logger" and "main logger".
-    #
-    # The "nested logger" is a singleton managed by `logging`. It's likely to be
-    # retained across task and workflow runs, as long as the worker process lives.
-    # It knows about the log message formats and log levels.
-    #
-    # The "main logger" is the one we expose to the user. It wraps the "nested logger"
-    # to inject contextual information that changes _often_. We use it to pass
-    # `wf_run_id` and `task_run_id` because these values can be different for each
-    # executed task run. The "main logger" should not be retained. We create it every
-    # time user asks us.
-    nested_logger = logging.getLogger(__name__)
-
-    # Note: `logging.basicConfig` does a similar thing like the following few lines. We
-    # can't use the shorthand because it would configure the root logger. Here, we only
-    # want to affect the workflow logger.
-    formatter = ISOFormatter(FORMAT)
+def make_logger():
+    logger = logging.getLogger(__name__)
 
+    # Ensure it prints somewhere
     handler = logging.StreamHandler()
-    handler.setFormatter(formatter)
+    logger.addHandler(handler)
+    logger.setLevel(logging.INFO)
 
-    # We need to ensure that a proper handler with proper formatter is hooked up with
-    # the logger. The only way to that is to remove all handlers from the logger and add
-    # the one we care about.
-    nested_logger.handlers.clear()
-    nested_logger.addHandler(handler)
-
-    nested_logger.setLevel(logging.INFO)
-
-    main_logger = TaggedWorkflowTaskLogger(
-        nested_logger,
-        extra={
-            "wf_run_id": wf_run_id,
-            "task_inv_id": task_inv_id,
-            "task_run_id": task_run_id,
-        },
-    )
-
-    return main_logger
+    return logger
 
 
-def workflow_logger() -> logging.LoggerAdapter:
+def workflow_logger() -> logging.Logger:
     """
+    Deprecated: please use the standard ``logging`` module.
+
     Returns a Logger instance with a context of current workflow/task.
 
     Each call of this function creates a new object. It shouldn't be retained across
     task runs.
     """
-    wf_run_id: t.Optional[WorkflowRunId]
-    task_inv_id: t.Optional[TaskInvocationId]
-    task_run_id: t.Optional[TaskRunId]
-    try:
-        wf_run_id, task_inv_id, task_run_id = current_run_ids()
-    except ModuleNotFoundError:
-        # Ray is not installed
-        wf_run_id, task_inv_id, task_run_id = None, None, None
-
-    logger = _make_logger(
-        wf_run_id=wf_run_id, task_inv_id=task_inv_id, task_run_id=task_run_id
+    warnings.warn(
+        "`sdk.workflow_logger()` is deprecated. Please use the standard `logging` module.",  # noqa: E501
+        FutureWarning,
     )
 
-    return logger
+    # TODO: remove this function.
+    # https://zapatacomputing.atlassian.net/browse/ORQSDK-887
+
+    return make_logger()
 
 
 def wfprint(*values):
     """
+    Deprecated: please use a standard ``print()``.
+
     This function wraps prints from workflow tasks.
     """
+    warnings.warn(
+        "`sdk.wfprint()` is deprecated. Please use a standard `print()`.",
+        FutureWarning,
+    )
+
+    # TODO: remove this function.
+    # https://zapatacomputing.atlassian.net/browse/ORQSDK-887
     logger = workflow_logger()
     logger.info(msg=" ".join(values))
```

## orquestra/sdk/_base/_workflow.py

```diff
@@ -156,15 +156,15 @@
         _dsl.DIRECT_EXECUTION = True
         result = self._fn(*self._workflow_args, **self._workflow_kwargs)
         _dsl.DIRECT_EXECUTION = False
         return result
 
     def run(
         self,
-        config: Optional[Union[_api.RuntimeConfig, str]] = None,
+        config: Union[_api.RuntimeConfig, str],
         project_dir: Optional[Union[str, Path]] = None,
         workspace_id: Optional[WorkspaceId] = None,
         project_id: Optional[ProjectId] = None,
     ) -> _api.WorkflowRun:
         """
         Schedules workflow for execution.
 
@@ -180,27 +180,14 @@
         Raises:
             orquestra.sdk.exceptions.DirtyGitRepo: (warning) when a task def used by
                 this workflow def has a "GitImport" and the git repo that contains it
                 has uncommitted changes.
             ProjectInvalidError: when only 1 out of project and workspace is passed
 
         """
-        # This exists for users who have gotten used to doing `run()`. Once this has
-        # been released, the following release should make config a required argument
-        # and remove this check.
-        if config is None:
-            raise FutureWarning(
-                "Please specify the runtime configuration for this run. "
-                "The built in `local` and `in_process` configurations can be used by "
-                'calling `run("local")` and `run("in_process")` respectively. '
-                "User defined configurations can be specified by providing the name "
-                "under which they are saved, or passing in the RuntimeConfig object "
-                "directly. "
-            )
-
         _config: _api.RuntimeConfig
         if isinstance(config, _api.RuntimeConfig):
             _config = config
         elif isinstance(config, str):
             _config = _api.RuntimeConfig.load(config)
         else:
             raise TypeError(
@@ -214,15 +201,15 @@
 
         # In close future there will be multiple ways of figuring out the
         # appropriate runtime to use, based on `config`. Regardless of this
         # logic, the runtime should always be resolved.
         assert runtime is not None
 
         _project: Optional[ProjectRef] = resolve_studio_project_ref(
-            workspace_id, project_id, _config.name
+            workspace_id, project_id
         )
 
         # The DirtyGitRepo warning can be raised here.
         wf_def_model = self.model
 
         wf_run = _api.WorkflowRun._start(
             wf_def=wf_def_model,
```

## orquestra/sdk/_base/abc.py

```diff
@@ -37,22 +37,14 @@
 
 class RuntimeInterface(ABC, LogReader):
     """
     The main abstraction for managing Orquestra workflows. Allows swapping the
     implementations related to local vs remote runs.
     """
 
-    @classmethod
-    @abstractmethod
-    def from_runtime_configuration(
-        cls, project_dir: Path, config: RuntimeConfiguration, verbose: bool
-    ) -> "RuntimeInterface":
-        """Returns an initilaised version of the class from a "Runtime options" JSON"""
-        raise NotImplementedError()
-
     @abstractmethod
     def create_workflow_run(
         self, workflow_def: WorkflowDef, project: t.Optional[ProjectRef]
     ) -> WorkflowRunId:
         """Schedules a workflow definition for execution
 
         Args:
```

## orquestra/sdk/_base/_api/_config.py

```diff
@@ -6,14 +6,16 @@
 import logging
 import typing as t
 import warnings
 from pathlib import Path
 
 from packaging.version import parse as parse_version
 
+from orquestra.sdk._base._factory import build_runtime_from_config
+
 from ...exceptions import (
     ConfigFileNotFoundError,
     ConfigNameNotFoundError,
     RuntimeConfigError,
     UnsavedConfigChangesError,
 )
 from ...schema.configs import (
@@ -220,44 +222,40 @@
                 working directory is used.
         Raises:
             ModuleNotFoundError: when orquestra.sdk._base is not installed.
 
         Returns:
             Runtime: The runtime specified by the configuration.
         """
-
         _project_dir: Path = Path(project_dir or Path.cwd())
 
         runtime_options = {}
         for key in _config.RUNTIME_OPTION_NAMES:
             try:
                 runtime_options[key] = getattr(self, key)
             except AttributeError:
                 continue
 
-        return _build_runtime(
-            _project_dir,
-            RuntimeConfiguration(
-                config_name=str(self._name),
-                runtime_name=self._runtime_name,
-                runtime_options=runtime_options,
-            ),
+        runtime_configuration = RuntimeConfiguration(
+            config_name=str(self._name),
+            runtime_name=self._runtime_name,
+            runtime_options=runtime_options,
+        )
+
+        return build_runtime_from_config(
+            project_dir=_project_dir, config=runtime_configuration
         )
 
     # region LOADING FROM FILE
     @classmethod
     def list_configs(
         cls,
     ) -> list:
         """List previously saved configurations.
 
-        Args:
-            config_save_file: The path to the config file from which to read. If
-                omitted, the default config file will be used.
-
         Returns:
             list: list of configurations within the save file.
         """
         configs = _config.read_config_names() + list(_config.UNIQUE_CONFIGS)
         if _config.is_passport_file_available():
             configs.append(_config.AUTO_CONFIG_NAME)
         return configs
@@ -327,31 +325,14 @@
 
         config = cls._config_from_runtimeconfiguration(config_data)
         config._config_save_file = _config_save_file
 
         return config
 
     @classmethod
-    def load_default(
-        cls,
-    ) -> "RuntimeConfig":
-        """Load the default configuration from a file.
-
-        Args:
-            config_save_file (optional): The path to the file in which configurations
-                are stored. If omitted, the default file location is used.
-
-        Returns:
-            RuntimeConfig: The configuration as loaded from the file.
-        """
-
-        config_data: RuntimeConfiguration = _config.read_config(None)
-        return cls._config_from_runtimeconfiguration(config_data)
-
-    @classmethod
     def _config_from_runtimeconfiguration(
         cls, config: RuntimeConfiguration
     ) -> "RuntimeConfig":
         """
         Convert a RuntimeConfiguration object (as used by the under-the-hood
         mechanisms) to a RuntimeConfig (python API) object.
 
@@ -485,41 +466,14 @@
         f"Updated {len(changed)} entr{'y' if len(changed)==1 else 'ies'}"
         f"{'.' if len(changed)==0 else ':'}"
     )
     for config_name in changed:
         print(f" - {config_name}")
 
 
-def _build_runtime(
-    project_dir: Path, runtime_configuration: RuntimeConfiguration
-) -> RuntimeInterface:  # pragma: no cover - tested in runtime repo.
-    """
-    Extracted from RuntimeConfig._get_runtime() to be able to mock in unit tests.
-
-    Hopefully we'll be able to get rid of this when we merge SDK and Runtime repos.
-    """
-    import orquestra.sdk._base._factory  # type: ignore
-
-    try:
-        return orquestra.sdk._base._factory.build_runtime_from_config(
-            project_dir=project_dir, config=runtime_configuration
-        )
-    except KeyError as e:
-        outstr = (
-            f"Runtime configuration '{runtime_configuration.config_name}' "
-            f"lacks the required field '{e}'."
-        )
-        if e == "temp_dir":
-            outstr += (
-                " You may need to migrate your config file using "
-                "`sdk.migrate_config_file()`"
-            )
-        raise RuntimeConfigError(outstr) from e
-
-
 def _resolve_config(
     config: t.Union[ConfigName, "RuntimeConfig"],
 ) -> "RuntimeConfig":
     if isinstance(config, RuntimeConfig):
         # EZ. Passed-in explicitly.
         resolved_config = config
     elif isinstance(config, str):
```

## orquestra/sdk/_base/_api/_task_run.py

```diff
@@ -300,17 +300,21 @@
     Get the workflow run, task invocation, and task run IDs from Ray.
 
     Raises:
         ModuleNotFoundError: when Ray isn't installed.
         WorkflowRunIDNotFoundError: When the workflow run ID can't be recovered.
     """
     # Deferred import because Ray isn't installed when running on QE.
-    import orquestra.sdk._ray._dag
+    import orquestra.sdk._ray._build_workflow
 
-    wf_run_id, task_inv_id, task_run_id = orquestra.sdk._ray._dag.get_current_ids()
+    (
+        wf_run_id,
+        task_inv_id,
+        task_run_id,
+    ) = orquestra.sdk._ray._build_workflow.get_current_ids()
 
     if wf_run_id is None:
         raise WorkflowRunIDNotFoundError("Could not recover Workflow Run ID")
 
     return wf_run_id, task_inv_id, task_run_id
```

## orquestra/sdk/_base/_api/_wf_run.py

```diff
@@ -28,14 +28,15 @@
 from ...schema.responses import WorkflowResult
 from ...schema.workflow_run import ProjectId, State
 from ...schema.workflow_run import TaskRun as TaskRunModel
 from ...schema.workflow_run import TaskRunId
 from ...schema.workflow_run import WorkflowRun as WorkflowRunModel
 from ...schema.workflow_run import WorkflowRunId, WorkflowRunMinimal, WorkspaceId
 from .. import serde
+from .._graphs import iter_invocations_topologically
 from .._in_process_runtime import InProcessRuntime
 from .._logs._interfaces import WorkflowLogs
 from .._spaces._resolver import resolve_studio_project_ref
 from .._spaces._structs import ProjectRef
 from ..abc import RuntimeInterface
 from ._config import RuntimeConfig, _resolve_config
 from ._task_run import TaskRun
@@ -168,15 +169,16 @@
             runtime = InProcessRuntime()
         else:
             runtime = _config._get_runtime()
 
         assert runtime is not None
 
         _project: t.Optional[ProjectRef] = resolve_studio_project_ref(
-            workspace_id, project_id, _config.name
+            workspace_id,
+            project_id,
         )
 
         wf_run = cls._start(
             wf_def=wf_def, runtime=runtime, config=_config, project=_project
         )
 
         return wf_run
@@ -515,15 +517,15 @@
     def get_tasks(
         self,
         *,
         state: t.Optional[t.Union[State, t.List[State]]] = None,
         function_name: t.Optional[str] = None,
         task_run_id: t.Optional[t.Union[str, TaskRunId]] = None,
         task_invocation_id: t.Optional[t.Union[str, ir.TaskInvocationId]] = None,
-    ) -> t.Set[TaskRun]:
+    ) -> t.List[TaskRun]:
         """
         Returns TaskRun representations of the tasks executed as part of this workflow.
 
         Args:
             state: If specified, only tasks with matching states will be returned.
             function_name: A function name, or regex string matching the desired
                 function name(s). If specified, only tasks with matching function names
@@ -536,17 +538,25 @@
                 task invocation IDs will be returned.
 
         Returns:
             An iterable of TaskRuns
         """
 
         wf_run_model: WorkflowRunModel = self.get_status_model()
+        wf_ir = self._wf_def
+        sorted_invs: t.List[ir.TaskInvocationId] = [
+            inv.id for inv in iter_invocations_topologically(wf_ir)
+        ]
+        task_runs: t.Mapping[ir.TaskInvocationId, TaskRunModel] = {
+            task_run.invocation_id: task_run for task_run in wf_run_model.task_runs
+        }
+        sorted_task_runs = [task_runs[inv_id] for inv_id in sorted_invs]
 
-        tasks = set()
-        for task_model in wf_run_model.task_runs:
+        tasks = []
+        for task_model in sorted_task_runs:
             if not self._task_matches_schema_filters(
                 task_model,
                 state=state,
                 task_run_id=task_run_id,
                 task_invocation_id=task_invocation_id,
             ):
                 continue
@@ -558,15 +568,15 @@
                 wf_def=self._wf_def,
             )
             if not self._task_matches_api_filters(
                 task,
                 task_fn_name=function_name,
             ):
                 continue
-            tasks.add(task)
+            tasks.append(task)
 
         return tasks
 
 
 def list_workflow_runs(
     config: t.Union[ConfigName, "RuntimeConfig"],
     *,
@@ -611,15 +621,16 @@
     _project_dir = Path(project_dir or Path.cwd())
 
     # Resolve config
     resolved_config: RuntimeConfig = _resolve_config(config)
     # If user wasn't specific with workspace and project, we might want to resolve it
     if workspace is None and project is None:
         if _project := resolve_studio_project_ref(
-            workspace, project, resolved_config.name
+            workspace,
+            project,
         ):
             workspace = _project.workspace_id
             project = _project.project_id
 
     # resolve runtime
     runtime = resolved_config._get_runtime(_project_dir)
```

## orquestra/sdk/_base/_driver/_ce_runtime.py

```diff
@@ -56,14 +56,15 @@
     """
     A runtime for communicating with the Compute Engine API endpoints
     """
 
     def __init__(
         self,
         config: RuntimeConfiguration,
+        client: _client.DriverClient,
         verbose: bool = False,
     ):
         """
         Args:
             config: contains the runtime configuration, including the name of the
                 config being used and the associated runtime options. These options
                 control how to connect to a CE cluster.
@@ -72,32 +73,15 @@
 
         Raises:
             RuntimeConfigError: when the config is invalid
         """
         self._config = config
         self._verbose = verbose
 
-        # We're using a reusable session to allow shared headers
-        # In the future we can store cookies, etc too.
-        try:
-            base_uri = self._config.runtime_options["uri"]
-            token = self._config.runtime_options["token"]
-        except KeyError as e:
-            raise exceptions.RuntimeConfigError(
-                "Invalid CE configuration. Did you login first?"
-            ) from e
-
-        self._client = _client.DriverClient.from_token(base_uri=base_uri, token=token)
-
-    @classmethod
-    def from_runtime_configuration(
-        cls, project_dir: Path, config: RuntimeConfiguration, verbose: bool
-    ) -> "RuntimeInterface":
-        """Returns an initilaised version of the class from a runtime configuration"""
-        return cls(config, verbose)
+        self._client = client
 
     def create_workflow_run(
         self, workflow_def: WorkflowDef, project: Optional[ProjectRef]
     ) -> WorkflowRunId:
         """
         Schedules a workflow definition for execution
 
@@ -137,15 +121,25 @@
                 "Unable to start the workflow run "
                 "- there are errors in the workflow definition."
             ) from e
         except _exceptions.InvalidWorkflowRunRequest as e:
             raise exceptions.WorkflowRunNotStarted(
                 "Unable to start the workflow run."
             ) from e
-        except (_exceptions.InvalidTokenError, _exceptions.ForbiddenError) as e:
+        except _exceptions.ForbiddenError as e:
+            if project:
+                raise exceptions.ProjectInvalidError(
+                    f"Unable to start the workflow run "
+                    f"invalid workspace: {project.workspace_id}"
+                ) from e
+            else:
+                raise exceptions.UnauthorizedError(
+                    "Unable to start the workflow run "
+                ) from e
+        except _exceptions.InvalidTokenError as e:
             raise exceptions.UnauthorizedError(
                 "Unable to start the workflow run "
                 "- the authorization token was rejected by the remote cluster."
             ) from e
 
         with WorkflowDB.open_db() as db:
             db.save_workflow_run(
```

## orquestra/sdk/_base/_driver/_client.py

```diff
@@ -7,15 +7,15 @@
 Implemented API spec:
     https://github.com/zapatacomputing/workflow-driver/tree/2b3534/openapi
 """
 
 import io
 import zlib
 from tarfile import TarFile
-from typing import Generic, List, Mapping, Optional, TypeVar, Union
+from typing import Generic, List, Mapping, Optional, Tuple, TypeVar, Union
 from urllib.parse import urljoin
 
 import pydantic
 import requests
 from requests import codes
 
 from orquestra.sdk import ProjectRef
@@ -27,41 +27,54 @@
     WorkflowRunMinimal,
     WorkspaceId,
 )
 
 from . import _exceptions, _models
 from ._models import K8sEventLog
 
-API_ACTIONS = {
-    # Workflow Definitions
-    "create_workflow_def": "/api/workflow-definitions",
-    "list_workflow_defs": "/api/workflow-definitions",
-    "get_workflow_def": "/api/workflow-definitions/{}",
-    "delete_workflow_def": "/api/workflow-definitions/{}",
-    # Workflow Runs
-    "create_workflow_run": "/api/workflow-runs",
-    "list_workflow_runs": "/api/workflow-runs",
-    "get_workflow_run": "/api/workflow-runs/{}",
-    "terminate_workflow_run": "/api/workflow-runs/{}/terminate",
-    # Artifacts
-    "get_workflow_run_artifacts": "/api/artifacts",
-    "get_artifact": "/api/artifacts/{}",
-    # Run results
-    "get_workflow_run_results": "/api/run-results",
-    "get_workflow_run_result": "/api/run-results/{}",
-    # Logs
-    "get_workflow_run_logs": "/api/workflow-run-logs",
-    "get_task_run_logs": "/api/task-run-logs",
-    "get_workflow_run_system_logs": "/api/workflow-run-logs/system",
-    # Login
-    "get_login_url": "/api/login",
-    # Workspaces
-    "list_workspaces": "/api/catalog/workspaces",
-    "list_projects": "/api/catalog/workspaces/{}/projects",
-}
+
+class ExternalUriProvider:
+    API_ACTIONS = {
+        # Workflow Definitions
+        "create_workflow_def": "/api/workflow-definitions",
+        "list_workflow_defs": "/api/workflow-definitions",
+        "get_workflow_def": "/api/workflow-definitions/{}",
+        "delete_workflow_def": "/api/workflow-definitions/{}",
+        # Workflow Runs
+        "create_workflow_run": "/api/workflow-runs",
+        "list_workflow_runs": "/api/workflow-runs",
+        "get_workflow_run": "/api/workflow-runs/{}",
+        "terminate_workflow_run": "/api/workflow-runs/{}/terminate",
+        # Artifacts
+        "get_workflow_run_artifacts": "/api/artifacts",
+        "get_artifact": "/api/artifacts/{}",
+        # Run results
+        "get_workflow_run_results": "/api/run-results",
+        "get_workflow_run_result": "/api/run-results/{}",
+        # Logs
+        "get_workflow_run_logs": "/api/workflow-run-logs",
+        "get_task_run_logs": "/api/task-run-logs",
+        "get_workflow_run_system_logs": "/api/workflow-run-logs/system",
+        # Login
+        "get_login_url": "/api/login",
+        # Workspaces
+        "list_workspaces": "/api/catalog/workspaces",
+        "list_projects": "/api/catalog/workspaces/{}/projects",
+    }
+
+    def __init__(self, base_uri):
+        self._base_uri = base_uri
+
+    def uri_for(
+        self, action_id: str, parameters: Optional[Tuple[str, ...]] = None
+    ) -> str:
+        endpoint = ExternalUriProvider.API_ACTIONS[action_id]
+        if parameters:
+            endpoint = endpoint.format(*parameters)
+        return urljoin(self._base_uri, endpoint)
 
 
 def _handle_common_errors(response: requests.Response):
     if response.status_code == codes.UNAUTHORIZED:
         raise _exceptions.InvalidTokenError()
     elif response.status_code == codes.FORBIDDEN:
         raise _exceptions.ForbiddenError()
@@ -115,64 +128,64 @@
 
 
 class DriverClient:
     """
     Client for interacting with the Workflow Driver API via HTTP.
     """
 
-    def __init__(self, base_uri: str, session: requests.Session):
-        self._base_uri = base_uri
+    def __init__(self, session: requests.Session, uri_provider: ExternalUriProvider):
+        self._uri_provider = uri_provider
         self._session = session
 
     @classmethod
-    def from_token(cls, base_uri: str, token: str):
+    def from_token(cls, token: str, uri_provider: ExternalUriProvider):
         """
         Args:
-            base_uri: Orquestra cluster URI, like 'https://foobar.orquestra.io'.
             token: Auth token taken from logging in.
+            uri_provider: Class that provides URIS for http requests
         """
         session = requests.Session()
         session.headers["Content-Type"] = "application/json"
         session.headers["Authorization"] = f"Bearer {token}"
-        return cls(base_uri=base_uri, session=session)
+        return cls(session=session, uri_provider=uri_provider)
 
     # --- helpers ---
 
     def _get(
         self,
-        endpoint: str,
+        uri: str,
         query_params: Optional[Mapping],
         allow_redirects: bool = True,
     ) -> requests.Response:
         """Helper method for GET requests"""
         response = self._session.get(
-            urljoin(self._base_uri, endpoint),
+            uri,
             params=query_params,
             allow_redirects=allow_redirects,
         )
 
         return response
 
     def _post(
         self,
-        endpoint: str,
+        uri: str,
         body_params: Optional[Mapping],
         query_params: Optional[Mapping] = None,
     ) -> requests.Response:
         """Helper method for POST requests"""
         response = self._session.post(
-            urljoin(self._base_uri, endpoint),
+            uri,
             json=body_params,
             params=query_params,
         )
         return response
 
-    def _delete(self, endpoint: str) -> requests.Response:
+    def _delete(self, uri: str) -> requests.Response:
         """Helper method for DELETE requests"""
-        response = self._session.delete(urljoin(self._base_uri, endpoint))
+        response = self._session.delete(uri)
 
         return response
 
     # --- queries ---
 
     # ---- Worklow Defs ----
 
@@ -198,15 +211,15 @@
                 workspaceId=project.workspace_id,
                 projectId=project.project_id,
             ).dict()
             if project
             else None
         )
         resp = self._post(
-            API_ACTIONS["create_workflow_def"],
+            self._uri_provider.uri_for("create_workflow_def"),
             body_params=workflow_def.dict(),
             query_params=query_params,
         )
 
         if resp.status_code == codes.BAD_REQUEST:
             error = _models.Error.parse_obj(resp.json())
             raise _exceptions.InvalidWorkflowDef(
@@ -229,15 +242,15 @@
 
         Raises:
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
         resp = self._get(
-            API_ACTIONS["list_workflow_defs"],
+            self._uri_provider.uri_for("list_workflow_defs"),
             query_params=_models.ListWorkflowDefsRequest(
                 pageSize=page_size,
                 pageToken=page_token,
             ).dict(),
         )
 
         _handle_common_errors(resp)
@@ -260,15 +273,15 @@
         """First step in the auth flow. Fetches the URL that the user has to visit.
 
         Raises:
             requests.ConnectionError: if the request fails.
             KeyError: if the URL couldn't be found in the response.
         """
         resp = self._get(
-            API_ACTIONS["get_login_url"],
+            self._uri_provider.uri_for("get_login_url"),
             query_params={"port": f"{redirect_port}"},
             allow_redirects=False,
         )
         _handle_common_errors(resp)
         return resp.headers["Location"]
 
     def get_workflow_def(
@@ -284,15 +297,17 @@
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
 
         Returns:
             a parsed WorkflowDef
         """
         resp = self._get(
-            API_ACTIONS["get_workflow_def"].format(workflow_def_id),
+            self._uri_provider.uri_for(
+                "get_workflow_def", parameters=(workflow_def_id,)
+            ),
             query_params=None,
         )
 
         if resp.status_code == codes.BAD_REQUEST:
             raise _exceptions.InvalidWorkflowDefID(workflow_def_id)
         elif resp.status_code == codes.NOT_FOUND:
             raise _exceptions.WorkflowDefNotFound(workflow_def_id)
@@ -313,15 +328,17 @@
             InvalidWorkflowDefID: see the exception's docstring
             WorkflowDefNotFound: see the exception's docstring
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
         resp = self._delete(
-            API_ACTIONS["delete_workflow_def"].format(workflow_def_id),
+            self._uri_provider.uri_for(
+                "delete_workflow_def", parameters=(workflow_def_id,)
+            ),
         )
 
         if resp.status_code == codes.BAD_REQUEST:
             raise _exceptions.InvalidWorkflowDefID(workflow_def_id)
         elif resp.status_code == codes.NOT_FOUND:
             raise _exceptions.WorkflowDefNotFound(workflow_def_id)
 
@@ -338,15 +355,15 @@
         Raises:
             InvalidWorkflowRunRequest: see the exception's docstring
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
         resp = self._post(
-            API_ACTIONS["create_workflow_run"],
+            self._uri_provider.uri_for("create_workflow_run"),
             body_params=_models.CreateWorkflowRunRequest(
                 workflowDefinitionID=workflow_def_id, resources=resources
             ).dict(),
         )
 
         if resp.status_code == codes.BAD_REQUEST:
             error = _models.Error.parse_obj(resp.json())
@@ -376,15 +393,15 @@
         Raises:
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
         # Schema: https://github.com/zapatacomputing/workflow-driver/blob/fa3eb17f1132d9c7f4960331ffe7ddbd31e02f8c/openapi/src/resources/workflow-runs.yaml#L10 # noqa: E501
         resp = self._get(
-            API_ACTIONS["list_workflow_runs"],
+            self._uri_provider.uri_for("list_workflow_runs"),
             query_params=_models.ListWorkflowRunsRequest(
                 workflowDefinitionID=workflow_def_id,
                 pageSize=page_size,
                 pageToken=page_token,
                 workspaceId=workspace,
                 projectId=project,
             ).dict(),
@@ -420,15 +437,15 @@
             WorkflowRunNotFound: see the exception's docstring
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
 
         resp = self._get(
-            API_ACTIONS["get_workflow_run"].format(wf_run_id),
+            self._uri_provider.uri_for("get_workflow_run", parameters=(wf_run_id,)),
             query_params=None,
         )
 
         if resp.status_code == codes.BAD_REQUEST:
             raise _exceptions.InvalidWorkflowRunID(wf_run_id)
         elif resp.status_code == codes.NOT_FOUND:
             raise _exceptions.WorkflowRunNotFound(wf_run_id)
@@ -457,15 +474,17 @@
             WorkflowRunNotFound: see the exception's docstring
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
 
         resp = self._post(
-            API_ACTIONS["terminate_workflow_run"].format(wf_run_id),
+            self._uri_provider.uri_for(
+                "terminate_workflow_run", parameters=(wf_run_id,)
+            ),
             body_params=None,
             query_params=_models.TerminateWorkflowRunRequest(force=force).dict(),
         )
 
         if resp.status_code == codes.NOT_FOUND:
             raise _exceptions.WorkflowRunNotFound(wf_run_id)
 
@@ -484,15 +503,17 @@
             WorkflowRunNotFound: see the exception's docstring
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
 
         resp = self._get(
-            API_ACTIONS["get_workflow_run_artifacts"],
+            self._uri_provider.uri_for(
+                "get_workflow_run_artifacts",
+            ),
             query_params=_models.GetWorkflowRunArtifactsRequest(
                 workflowRunId=wf_run_id
             ).dict(),
         )
 
         if resp.status_code == codes.NOT_FOUND:
             raise _exceptions.WorkflowRunNotFound(wf_run_id)
@@ -518,15 +539,15 @@
             WorkflowRunArtifactNotFound: see the exception's docstring
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
 
         resp = self._get(
-            API_ACTIONS["get_artifact"].format(artifact_id),
+            self._uri_provider.uri_for("get_artifact", parameters=(artifact_id,)),
             query_params=None,
         )
 
         if resp.status_code == codes.NOT_FOUND:
             raise _exceptions.WorkflowRunArtifactNotFound(artifact_id)
         elif resp.status_code == codes.BAD_REQUEST:
             raise _exceptions.InvalidWorkflowRunArtifactID(artifact_id)
@@ -552,15 +573,15 @@
             WorkflowRunNotFound: see the exception's docstring
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
 
         resp = self._get(
-            API_ACTIONS["get_workflow_run_results"],
+            self._uri_provider.uri_for("get_workflow_run_results"),
             query_params=_models.GetWorkflowRunResultsRequest(
                 workflowRunId=wf_run_id
             ).dict(),
         )
 
         if resp.status_code == codes.BAD_REQUEST:
             raise _exceptions.InvalidWorkflowRunID(wf_run_id)
@@ -586,15 +607,18 @@
             WorkflowRunResultNotFound: see the exception's docstring
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
 
         resp = self._get(
-            API_ACTIONS["get_workflow_run_result"].format(result_id), query_params=None
+            self._uri_provider.uri_for(
+                "get_workflow_run_result", parameters=(result_id,)
+            ),
+            query_params=None,
         )
 
         if resp.status_code == codes.NOT_FOUND:
             raise _exceptions.WorkflowRunResultNotFound(result_id)
         elif resp.status_code == codes.BAD_REQUEST:
             raise _exceptions.InvalidWorkflowRunResultID(result_id)
 
@@ -637,15 +661,15 @@
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
             WorkflowRunLogsNotReadable: see the exception's docstring
         """
 
         resp = self._get(
-            API_ACTIONS["get_workflow_run_logs"],
+            self._uri_provider.uri_for("get_workflow_run_logs"),
             query_params=_models.GetWorkflowRunLogsRequest(
                 workflowRunId=wf_run_id
             ).dict(),
         )
 
         # Handle errors
         if resp.status_code == codes.NOT_FOUND:
@@ -685,15 +709,15 @@
         Raises:
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
 
         resp = self._get(
-            API_ACTIONS["get_task_run_logs"],
+            self._uri_provider.uri_for("get_task_run_logs"),
             query_params=_models.GetTaskRunLogsRequest(taskRunId=task_run_id).dict(),
         )
 
         # TODO: Handle other errors, not specified in spec yet (ORQSDK-655)
         _handle_common_errors(resp)
 
         # TODO: unzip, get logs (ORQSDK-654)
@@ -710,15 +734,15 @@
             WorkflowRunLogsNotFound: see the exception's docstring
             WorkflowRunLogsNotReadable: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
             NotImplementedError: when a log object's source_type is not a recognised
                 value, or is a value for a schema has not been defined.
         """
         resp = self._get(
-            API_ACTIONS["get_workflow_run_system_logs"],
+            self._uri_provider.uri_for("get_workflow_run_system_logs"),
             query_params=_models.GetWorkflowRunLogsRequest(
                 workflowRunId=wf_run_id
             ).dict(),
         )
 
         # Handle errors
         if resp.status_code == codes.NOT_FOUND:
@@ -751,15 +775,15 @@
 
     def list_workspaces(self):
         """
         Gets the list of all workspaces
         """
 
         resp = self._get(
-            API_ACTIONS["list_workspaces"],
+            self._uri_provider.uri_for("list_workspaces"),
             query_params=None,
         )
 
         _handle_common_errors(resp)
 
         parsed_response = pydantic.parse_obj_as(
             _models.ListWorkspacesResponse, resp.json()
@@ -779,15 +803,15 @@
         # based on https://zapatacomputing.atlassian.net/wiki/spaces/Platform/pages/512787664/2022-09-26+Zapata+Resource+Identifiers+ZRIs  # noqa
         workspace_zri = (
             f"zri:v1::{default_tenant_id}:"
             f"{special_workspace}:{zri_type}:{workspace_id}"
         )
 
         resp = self._get(
-            API_ACTIONS["list_projects"].format(workspace_zri),
+            self._uri_provider.uri_for("list_projects", parameters=(workspace_zri,)),
             query_params=None,
         )
 
         if resp.status_code == codes.BAD_REQUEST:
             raise _exceptions.InvalidWorkspaceZRI(workspace_zri)
 
         _handle_common_errors(resp)
@@ -807,15 +831,15 @@
             WorkflowRunNotFound: see the exception's docstring
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
 
         resp = self._get(
-            API_ACTIONS["get_workflow_run"].format(wf_run_id),
+            self._uri_provider.uri_for("get_workflow_run", parameters=(wf_run_id,)),
             query_params=None,
         )
 
         if resp.status_code == codes.BAD_REQUEST:
             raise _exceptions.InvalidWorkflowRunID(wf_run_id)
         elif resp.status_code == codes.NOT_FOUND:
             raise _exceptions.WorkflowRunNotFound(wf_run_id)
```

## orquestra/sdk/_base/_driver/_models.py

```diff
@@ -1,14 +1,13 @@
 ################################################################################
 # © Copyright 2022 - 2023 Zapata Computing Inc.
 ################################################################################
 """
 Internal models for the workflow driver API
 """
-from datetime import datetime
 from enum import Enum
 from typing import (
     Generic,
     List,
     Literal,
     Mapping,
     NamedTuple,
@@ -18,14 +17,15 @@
     Union,
 )
 
 import pydantic
 from pydantic.generics import GenericModel
 from typing_extensions import Annotated
 
+from orquestra.sdk._base._dates import Instant
 from orquestra.sdk.schema.ir import WorkflowDef
 from orquestra.sdk.schema.workflow_run import (
     ProjectId,
     RunStatus,
     State,
     TaskRun,
     WorkflowRun,
@@ -95,15 +95,15 @@
 class GetWorkflowDefResponse(pydantic.BaseModel):
     """
     Implements:
         https://github.com/zapatacomputing/workflow-driver/blob/cb61512e9f3da24addd933c7259aa4584ab04e4f/openapi/src/schemas/WorkflowDefinition.yaml
     """
 
     id: WorkflowDefID
-    created: datetime
+    created: Instant
     owner: str
     workflow: WorkflowDef
     workspaceId: WorkspaceId
     project: ProjectId
     sdkVersion: str
 
 
@@ -154,16 +154,16 @@
 class RunStatusResponse(pydantic.BaseModel):
     """
     Implements:
         https://github.com/zapatacomputing/workflow-driver/blob/34eba4253b56266772795a8a59d6ec7edf88c65a/openapi/src/schemas/RunStatus.yaml#L1
     """
 
     state: StateResponse
-    startTime: Optional[datetime]
-    endTime: Optional[datetime]
+    startTime: Optional[Instant]
+    endTime: Optional[Instant]
 
     def to_ir(self) -> RunStatus:
         return RunStatus(
             state=State(self.state),
             start_time=self.startTime,
             end_time=self.endTime,
         )
```

## orquestra/sdk/_base/_logs/_interfaces.py

```diff
@@ -2,14 +2,15 @@
 # © Copyright 2023 Zapata Computing Inc.
 ################################################################################
 """
 Logs-related interfaces.
 """
 import typing as t
 from dataclasses import dataclass
+from enum import Enum
 
 from orquestra.sdk.schema.ir import TaskInvocationId
 from orquestra.sdk.schema.workflow_run import WorkflowRunId
 
 
 @dataclass(frozen=True)
 class WorkflowLogs:
@@ -36,14 +37,43 @@
     """
     Log lines that don't match any other category we support at the moment. If this
     contains useful information, please consider upgrading with
     ``pip install --uprade orquestra-sdk`` or report your use case to the SDK Team at
     Zapata Computing.
     """
 
+    def get_log_type(
+        self, log_type
+    ) -> t.Union[t.Mapping[TaskInvocationId, t.Sequence[str]], t.Sequence[str]]:
+        """
+        Return the specified log type.
+
+        This method wraps the regular attribute getters in order to allow parametrised
+        access to individual log types.
+        """
+        if log_type == self.WorkflowLogTypeName.PER_TASK:
+            return self.per_task
+        elif log_type == self.WorkflowLogTypeName.SYSTEM:
+            return self.system
+        elif log_type == self.WorkflowLogTypeName.ENV_SETUP:
+            return self.env_setup
+        elif log_type == self.WorkflowLogTypeName.OTHER:
+            return self.other
+        raise ValueError(f"Unknown workflow log type '{log_type}'.")
+
+    class WorkflowLogTypeName(Enum):
+        """
+        Enum for specifying the individual types of Workflow log.
+        """
+
+        PER_TASK = "per_task"
+        SYSTEM = "system"
+        ENV_SETUP = "env_setup"
+        OTHER = "other"
+
 
 class LogReader(t.Protocol):
     """
     A component that reads logs produced by tasks and workflows.
     """
 
     def get_task_logs(
```

## orquestra/sdk/_base/_qe/_qe_runtime.py

```diff
@@ -18,15 +18,15 @@
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Sequence, Tuple, Union
 
 import pydantic
 import requests
 
 from orquestra.sdk import exceptions
-from orquestra.sdk._base import serde
+from orquestra.sdk._base import _dates, serde
 from orquestra.sdk._base._conversions._yaml_exporter import (
     pydantic_to_yaml,
     workflow_to_yaml,
 )
 from orquestra.sdk._base._db import WorkflowDB
 from orquestra.sdk._base._logs._interfaces import WorkflowLogs
 from orquestra.sdk._base._spaces._structs import ProjectRef
@@ -429,37 +429,14 @@
             )
 
         session = requests.Session()
         session.headers["Content-Type"] = "application/json; charset=utf-8"
         session.headers["Authorization"] = f"Bearer {token}"
         self._client = _client.QEClient(session=session, base_uri=base_uri)
 
-    @classmethod
-    def from_runtime_configuration(
-        cls,
-        project_dir: Path,
-        config: RuntimeConfiguration,
-        verbose: bool = False,
-    ) -> "QERuntime":
-        """
-        Args:
-            config: contains the runtime configuration, including the name of the
-                config being used and the associated runtime options. These options
-                control how to connect to a QE cluster.
-            project_dir: the project directory, either Path-like or a string.
-                This is to (de)serialise the WorkflowDef associated with this workflow
-                run.
-            verbose: boolean, if TRUE the QERuntime is set to print information about
-                        its inner working, useful to debug
-
-        Raises:
-            orquestra.sdk.exceptions.RuntimeConfigError: when the config is invalid
-        """
-        return cls(project_dir=project_dir, config=config, verbose=verbose)
-
     def _get_task_run_logs(
         self, wf_run_id: WorkflowRunId, task_run_id: TaskRunId
     ) -> List[str]:
         """Returns the logs for a specific task run.
 
         Raises:
             orquestra.sdk.exceptions.UnauthorizedError if QE returns 401
@@ -881,15 +858,15 @@
             A list of the workflow runs
         """
         if workspace or project:
             raise exceptions.WorkspacesNotSupportedError(
                 "Filtering by workspace or project is not supported on QE runtimes."
             )
 
-        now = datetime.now(timezone.utc)
+        now = _dates.now()
 
         # Grab the workflows we know about from the DB
         with WorkflowDB.open_project_db(self._project_dir) as db:
             stored_runs = db.get_workflow_runs_list(
                 config_name=self._config.config_name
             )
```

## orquestra/sdk/_base/_spaces/_resolver.py

```diff
@@ -11,30 +11,25 @@
 from .._env import CURRENT_PROJECT_ENV, CURRENT_WORKSPACE_ENV
 from ._structs import ProjectRef
 
 
 def resolve_studio_project_ref(
     workspace_id: Optional[WorkspaceId],
     project_id: Optional[ProjectId],
-    config_name: Optional[str],
 ) -> Optional[ProjectRef]:
     # Passed explicitly
     if workspace_id and project_id:
         return ProjectRef(workspace_id=workspace_id, project_id=project_id)
     # passed explicitly only 1 value. Invalid entry
     elif workspace_id or project_id:
         raise ProjectInvalidError(
             "Invalid project ID. Either explicitly pass workspace_id "
             "and project_id, or omit both"
         )
 
-    # Infer workspace and project from studio ONLY when using "auto" config-name
-    if config_name is None or config_name != AUTO_CONFIG_NAME:
-        return None
-
     # Currently no way to figure out workspace and projects without env vars
     try:
         current_workspace = os.environ[CURRENT_WORKSPACE_ENV]
         current_project = os.environ[CURRENT_PROJECT_ENV]
     except KeyError:
         return None
```

## orquestra/sdk/_base/_testing/_example_wfs.py

```diff
@@ -273,18 +273,15 @@
     future3 = add(future2, future2)
 
     return [future3]
 
 
 @sdk.task
 def add_with_log(a, b, msg: str):
-    import orquestra.sdk._base._log_adapter
-
-    logger = orquestra.sdk._base._log_adapter.workflow_logger()
-    logger.info(msg)
+    print(msg)
     return a + b
 
 
 @sdk.workflow
 def wf_with_log(msg: str):
     return [add_with_log(12, 34, msg)]
```

## orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py

```diff
@@ -3,18 +3,20 @@
 ################################################################################
 """
 When the user doesn't pass in all the required information as CLI arguments we need to
 resolve the information from other sources. This module contains the CLI argument
 resolution logic extracted as components reusable across similar CLI commands.
 """
 import typing as t
+import warnings
 
 from orquestra.sdk import exceptions
 from orquestra.sdk._base import _services
 from orquestra.sdk._base._config import IN_PROCESS_CONFIG_NAME
+from orquestra.sdk._base._logs._interfaces import WorkflowLogs
 from orquestra.sdk._base._spaces._structs import ProjectRef
 from orquestra.sdk.schema.configs import ConfigName
 from orquestra.sdk.schema.ir import TaskInvocationId
 from orquestra.sdk.schema.workflow_run import (
     ProjectId,
     State,
     TaskRunId,
@@ -172,17 +174,16 @@
         If the ID hasn't been specified, prompts the user to pick from the available
         workspaces.
         """
         if workspace_id is not None:
             return workspace_id
 
         workspaces = self._spaces_repo.list_workspaces(config)
-        labels, workspaces = self._presenter.workspaces_list_to_prompt(
-            workspaces, config
-        )
+        labels, workspaces = self._presenter.workspaces_list_to_prompt(workspaces)
+
         prompt_choices = [(label, ws) for label, ws in zip(labels, workspaces)]
         selected_id = self._prompter.choice(prompt_choices, message="Workspace")
 
         return selected_id.workspace_id
 
     def resolve_project_id(
         self,
@@ -201,15 +202,15 @@
         ID.
         """
 
         if project_id is not None:
             return project_id
 
         projects = self._spaces_repo.list_projects(config, workspace_id)
-        labels, projects = self._presenter.project_list_to_prompt(projects, config)
+        labels, projects = self._presenter.project_list_to_prompt(projects)
         if optional:
             projects.append(None)
             labels.append("All")
         prompt_choices = [(label, project) for label, project in zip(labels, projects)]
 
         selected_id = self._prompter.choice(prompt_choices, message="Projects")
         if selected_id is not None:
@@ -282,14 +283,85 @@
         runs, tabulated_labels = self._presenter.wf_list_for_prompt(runs)
         prompt_choices = [(label, wf) for label, wf in zip(tabulated_labels, runs)]
 
         selected_run = self._prompter.choice(prompt_choices, message="Workflow run ID")
 
         return selected_run
 
+    def resolve_log_switches(
+        self,
+        task: t.Optional[bool],
+        system: t.Optional[bool],
+        env_setup: t.Optional[bool],
+        other: t.Optional[bool],
+        logs: WorkflowLogs,
+    ) -> t.Mapping[WorkflowLogs.WorkflowLogTypeName, bool]:
+        """
+        Resolve the switches for various types of logs.
+
+        Each switch controls whether a specific type of log is shown. If any of the
+        switches are active we assume that the user has specified what they want and we
+        don't interfere. If none are active we prompt the user to select one log type,
+        or all of them.
+        """
+        user_switch_values: t.Mapping[
+            WorkflowLogs.WorkflowLogTypeName, t.Optional[bool]
+        ] = {
+            WorkflowLogs.WorkflowLogTypeName.PER_TASK: task,
+            WorkflowLogs.WorkflowLogTypeName.SYSTEM: system,
+            WorkflowLogs.WorkflowLogTypeName.ENV_SETUP: env_setup,
+            WorkflowLogs.WorkflowLogTypeName.OTHER: other,
+        }
+        log_availibility: t.Mapping[WorkflowLogs.WorkflowLogTypeName, bool] = {
+            log_type: len(logs.get_log_type(log_type)) >= 1
+            for log_type in WorkflowLogs.WorkflowLogTypeName
+        }
+        ret_switch_values: t.Dict[WorkflowLogs.WorkflowLogTypeName, bool] = {
+            log_type: False for log_type in user_switch_values
+        }
+
+        # If the user has set one or more switches to True, check them against the
+        # availability and unset any that can't be fulfilled. We assume that any unset
+        # switches are intended to be false.
+        if True in user_switch_values.values():
+            for log_type in user_switch_values:
+                if bool(user_switch_values[log_type]):
+                    if not log_availibility[log_type]:
+                        warnings.warn(
+                            f"No '{log_type.value}' logs are available "
+                            "for this workflow"
+                        )
+                    else:
+                        ret_switch_values[log_type] = True
+            return ret_switch_values
+
+        # If the user has not set any switches, or has only set switches to False,
+        # prompt them to choose from the available logs they haven't already ruled out.
+        valid_switches: t.List[WorkflowLogs.WorkflowLogTypeName] = [
+            log_type
+            for log_type in user_switch_values
+            if log_availibility[log_type] and user_switch_values[log_type] is None
+        ]
+
+        choice: t.Union[str, WorkflowLogs.WorkflowLogTypeName] = self._prompter.choice(
+            [(switch.value, switch) for switch in valid_switches],
+            message="available logs",
+            default="all",
+            allow_all=True,
+        )
+
+        # Construct the return dict according to the user's choices.
+        if choice == "all":
+            for switch in valid_switches:
+                ret_switch_values[switch] = True
+        else:
+            ret_switch_values[WorkflowLogs.WorkflowLogTypeName(choice)] = True
+
+        return ret_switch_values
+
 
 class TaskInvIDResolver:
     """
     Finds task invocation ID. Assumes workflow run ID and config were already
     resolved.
     """
```

## orquestra/sdk/_base/cli/_dorq/_dumpers.py

```diff
@@ -2,17 +2,19 @@
 # © Copyright 2023 Zapata Computing Inc.
 ################################################################################
 
 """
 Code that stores values on disk as a result of a CLI command.
 """
 import typing as t
+from functools import singledispatchmethod
 from pathlib import Path
 
 from orquestra.sdk._base import serde
+from orquestra.sdk._base._logs._interfaces import WorkflowLogs
 from orquestra.sdk.schema.workflow_run import TaskInvocationId, WorkflowRunId
 
 
 class WFOutputDumper:
     """
     Writes a workflow run's output artifacts to a file.
     """
@@ -78,31 +80,69 @@
 
 
 class LogsDumper:
     """
     Writes logs to files.
     """
 
+    @staticmethod
+    def _get_logs_file(
+        dir_path: Path,
+        wf_run_id: WorkflowRunId,
+        log_type: t.Optional[WorkflowLogs.WorkflowLogTypeName] = None,
+    ) -> Path:
+        dir_path.mkdir(parents=True, exist_ok=True)
+        if log_type:
+            return (
+                dir_path / f"{wf_run_id}_{log_type.value.lower().replace(' ', '_')}.log"
+            )
+        return dir_path / f"{wf_run_id}.log"
+
     def dump(
         self,
-        logs: t.Mapping[TaskInvocationId, t.Sequence[str]],
+        logs: t.Union[t.Mapping[TaskInvocationId, t.Sequence[str]], t.Sequence[str]],
         wf_run_id: WorkflowRunId,
         dir_path: Path,
-    ) -> Path:
+        log_type: t.Optional[WorkflowLogs.WorkflowLogTypeName] = None,
+    ):
         """
-        Save logs from wf into a file
+        Save logs from wf into a file.
 
         Creates missing directories. Generates filenames based on ``wf_run_id``
         No standard errors are expected to be raised.
         """
-        dir_path.mkdir(parents=True, exist_ok=True)
+        logs_file = self._get_logs_file(dir_path, wf_run_id, log_type=log_type)
 
-        logs_file = dir_path / f"{wf_run_id}.log"
+        log_lines = self._construct_output_log_lines(logs)
 
         with logs_file.open("w") as f:
-            for task_invocation in logs:
-                f.write(f"Logs for task invocation: {task_invocation}:\n\n")
-                for log in logs[task_invocation]:
-                    f.write(log + "\n")
-                f.write("\n\n")
+            f.writelines(log_lines)
 
         return logs_file
+
+    @singledispatchmethod
+    @staticmethod
+    def _construct_output_log_lines(self, *args) -> t.List[str]:
+        """
+        Construct a list of log lines to be printed.
+
+        This method has overloads for dict and list arguments.
+        """
+        raise NotImplementedError(
+            f"No log lines constructor for args {args}"
+        )  # pragma: no cover
+
+    @_construct_output_log_lines.register(dict)
+    @staticmethod
+    def _(logs: dict) -> t.List[str]:
+        outlines = []
+        for task_invocation in logs:
+            outlines.append(f"Logs for task invocation: {task_invocation}:\n\n")
+            for log in logs[task_invocation]:
+                outlines.append(log + "\n")
+            outlines.append("\n\n")
+        return outlines
+
+    @_construct_output_log_lines.register(list)
+    @staticmethod
+    def _(logs: list) -> t.List[str]:
+        return [log + "\n" for log in logs]
```

## orquestra/sdk/_base/cli/_dorq/_entry.py

```diff
@@ -8,14 +8,15 @@
 """
 import typing as t
 from pathlib import Path
 
 import click
 import cloup
 
+from orquestra.sdk._base.cli._dorq._ui._click_default_group import DefaultGroup
 from orquestra.sdk.schema.configs import RemoteRuntime, RuntimeName
 
 from . import _cli_logs
 
 # Adds '-h' alias for '--help'
 CLICK_CTX_SETTINGS = {"help_option_names": ["-h", "--help"]}
 
@@ -181,30 +182,56 @@
     )
 
 
 @workflow.command(name="logs")
 @cloup.argument("wf_run_id", required=False)
 @CONFIG_OPTION
 @DOWNLOAD_DIR_OPTION
+@cloup.option(
+    "--task/--no-task", is_flag=True, default=None, help="Show per-task logs."
+)
+@cloup.option(
+    "--system/--no-system", is_flag=True, default=None, help="Show system-level logs."
+)
+@cloup.option(
+    "--env-setup/--no-env-setup",
+    is_flag=True,
+    default=None,
+    help="Show env-setup logs.",
+)
+@cloup.option(
+    "--other/--no-other",
+    is_flag=True,
+    default=None,
+    help="Show logs not included in the per-task, system, or env-setup logs.",
+)
 def wf_logs(
     wf_run_id: t.Optional[str],
     config: t.Optional[str],
     download_dir: t.Optional[Path],
+    task: t.Optional[bool],
+    system: t.Optional[bool],
+    env_setup: t.Optional[bool],
+    other: t.Optional[bool],
 ):
     """
     Shows logs gathered during execution of a workflow produced by all tasks.
     """
 
     from ._workflow._logs import Action
 
     action = Action()
     action.on_cmd_call(
         wf_run_id=wf_run_id,
         config=config,
         download_dir=download_dir,
+        task=task,
+        system=system,
+        env_setup=env_setup,
+        other=other,
     )
 
 
 @workflow.command()
 @cloup.argument("wf_run_id", required=False)
 @CONFIG_OPTION
 @cloup.option(
@@ -392,44 +419,61 @@
 dorq.section(
     "Service Management",
     up,
     down,
     status,
 )
 
+
+# region: login
+class GroupWithDefaultCommand(cloup.Group, DefaultGroup):
+    ...
+
+    def get_help(self, ctx) -> str:
+        # Hack to get the help for `orq login` to make sense
+        sub = super().get_help(ctx).split("\n")
+        return auth.get_help(ctx) + "\n\n" + "\n".join(sub[sub.index("Commands:") :])
+
+
+@dorq.group(cls=GroupWithDefaultCommand, default="auth", invoke_without_command=False)
+def login():
+    """Commands related to logging in to clusters."""
+    pass
+
+
 server_config_group = cloup.OptionGroup(
     "Server configuration", constraint=cloup.constraints.RequireExactly(1)
 )
 
 
-@dorq.command()
+@login.command(hidden=True)
 @server_config_group.option(
     "-c", "--config", required=False, help="The name of an existing configureation."
 )
 @server_config_group.option(
-    "-s", "--server", required=False, help="server URI that you want to log into"
+    "-s", "--server", required=False, help="The server URI that you want to log into."
 )
 @cloup.option(
     "-t",
     "--token",
     required=False,
-    help="User Token to given server. To generate token, use this command without -t"
-    "option first",
+    help="User Token to given server. To generate token, use this command without the "
+    "-t option first.",
 )
 @cloup.option_group(
     "Remote Environment",
     cloup.option(
         "--qe", is_flag=True, default=False, help="Log in to Quantum Engine. (Default)"
     ),
     cloup.option("--ce", is_flag=True, default=False, help="Log in to Compute Engine."),
     constraint=cloup.constraints.mutually_exclusive,
 )
-def login(config: str, server: str, token: t.Optional[str], ce: bool, qe: bool):
+def auth(config: str, server: str, token: t.Optional[str], ce: bool, qe: bool):
     """
-    Login in to remote cluster
+    Log in to remote cluster
     """
     from ._login._login import Action
 
     runtime_name: RemoteRuntime
     if qe:
         runtime_name = RuntimeName.QE_REMOTE
     else:
@@ -437,13 +481,27 @@
 
     action = Action()
     action.on_cmd_call(
         config=config, url=server, token=token, runtime_name=runtime_name
     )
 
 
+@login.command(
+    help="List the stored logins.",
+    aliases=["-l", "list"],
+)
+def __list():
+    from ._config._list import Action
+
+    action = Action()
+    action.on_cmd_call()
+
+
+# endregion
+
+
 def main():
     dorq()
 
 
 if __name__ == "__main__":
     main()
```

## orquestra/sdk/_base/cli/_dorq/_repos.py

```diff
@@ -2,30 +2,30 @@
 # © Copyright 2022-2023 Zapata Computing Inc.
 ################################################################################
 """
 Repositories that encapsulate data access used by dorq commands.
 
 The "data" layer. Shouldn't directly depend on the "view" layer.
 """
-import datetime
 import importlib
 import os
 import sys
 import typing as t
 import warnings
 from contextlib import contextmanager
 
 import requests
 from typing_extensions import assert_never
 
 from orquestra import sdk
 from orquestra.sdk import exceptions
-from orquestra.sdk._base import _config, _db, loader
-from orquestra.sdk._base._driver._client import DriverClient
+from orquestra.sdk._base import _config, _dates, _db, loader
+from orquestra.sdk._base._driver._client import DriverClient, ExternalUriProvider
 from orquestra.sdk._base._jwt import check_jwt_without_signature_verification
+from orquestra.sdk._base._logs._interfaces import WorkflowLogs
 from orquestra.sdk._base._qe import _client
 from orquestra.sdk._base._spaces._structs import ProjectRef
 from orquestra.sdk._base.abc import ArtifactValue
 from orquestra.sdk.schema import _compat
 from orquestra.sdk.schema.configs import (
     ConfigName,
     RemoteRuntime,
@@ -372,15 +372,15 @@
             if wf_def.tasks[inv.task_id].fn_ref.function_name == task_fn_name
         ]
 
         return matching_inv_ids
 
     def get_wf_logs(
         self, wf_run_id: WorkflowRunId, config_name: ConfigName
-    ) -> t.Mapping[TaskInvocationId, t.Sequence[str]]:
+    ) -> WorkflowLogs:
         """
         Raises:
             ConnectionError: when connection with Ray failed.
             orquestra.sdk.exceptions.UnauthorizedError: when connection with runtime
                 failed because of an auth error.
         """
         try:
@@ -392,15 +392,15 @@
             # While this method can also raise WorkflowRunNotStarted error we don't ever
             # expect it to happen, because we're getting workflow run by ID. Workflows
             # get their IDs at the start time.
             logs = wf_run.get_logs()
         except (ConnectionError, exceptions.UnauthorizedError):
             raise
 
-        return logs.per_task
+        return logs
 
     def get_task_logs(
         self,
         wf_run_id: WorkflowRunId,
         task_inv_id: TaskInvocationId,
         config_name: ConfigName,
     ) -> t.Mapping[TaskInvocationId, t.Sequence[str]]:
@@ -491,17 +491,15 @@
             n_task_invocations_total=n_total,
         )
 
     def wf_list_summary(self, wf_runs: t.List[WorkflowRun]) -> ui_models.WFList:
         wf_runs.sort(
             key=lambda wf_run: wf_run.status.start_time
             if wf_run.status.start_time
-            else datetime.datetime.fromtimestamp(0).replace(
-                tzinfo=datetime.timezone.utc
-            )
+            else _dates.from_unix_time(0)
         )
 
         return ui_models.WFList(wf_rows=[_ui_model_from_wf(wf) for wf in wf_runs])
 
 
 class ConfigRepo:
     """
@@ -511,14 +509,24 @@
     def list_config_names(self) -> t.Sequence[ConfigName]:
         return [
             config
             for config in sdk.RuntimeConfig.list_configs()
             if config not in _config.CLI_IGNORED_CONFIGS
         ]
 
+    def list_remote_config_names(self) -> t.Sequence[ConfigName]:
+        """
+        List config names that are not part of the local 'special cases'.
+        """
+        return [
+            config
+            for config in sdk.RuntimeConfig.list_configs()
+            if config not in _config.SPECIAL_CONFIG_NAME_DICT
+        ]
+
     def store_token_in_config(self, uri: str, token: str, runtime_name: RemoteRuntime):
         """
         Saves the token in the config file
 
         Raises:
             ExpiredTokenError: if the token is expired
             InvalidTokenError: if the token is not a valid format
@@ -569,15 +577,16 @@
         self,
         uri: str,
         runtime_name: RemoteRuntime,
         redirect_port: int,
     ):
         client: t.Union[DriverClient, _client.QEClient]
         if runtime_name == RuntimeName.CE_REMOTE:
-            client = DriverClient(base_uri=uri, session=requests.Session())
+            uri_provider = ExternalUriProvider(base_uri=uri)
+            client = DriverClient(session=requests.Session(), uri_provider=uri_provider)
         elif runtime_name == RuntimeName.QE_REMOTE:
             client = _client.QEClient(session=requests.Session(), base_uri=uri)
         else:
             assert_never(runtime_name)
         try:
             target_url = client.get_login_url(redirect_port)
         except requests.RequestException as e:
```

## orquestra/sdk/_base/cli/_dorq/_login/_login.py

```diff
@@ -1,9 +1,9 @@
 ################################################################################
-# © Copyright 2022 Zapata Computing Inc.
+# © Copyright 2022 - 2023 Zapata Computing Inc.
 ################################################################################
 """
 Code for 'orq login'.
 """
 import asyncio
 import typing as t
 
@@ -121,15 +121,15 @@
             # In this case, print out the manual instructions
             self._login_presenter.prompt_for_login(self._login_url, url, runtime_name)
             return
         self._save_token(url, self._login_server.token, runtime_name)
 
     def _save_token(self, url, token, runtime_name: RemoteRuntime):
         config_name = self._config_repo.store_token_in_config(url, token, runtime_name)
-        self._login_presenter.prompt_config_saved(url, config_name)
+        self._login_presenter.prompt_config_saved(url, config_name, runtime_name)
 
     async def _get_token_from_server(
         self, url: str, runtime_name: RemoteRuntime, timeout: int
     ):
         try:
             port = await self._login_server.start(url)
             self._login_url = self._runtime_repo.get_login_url(url, runtime_name, port)
```

## orquestra/sdk/_base/cli/_dorq/_ui/_models.py

```diff
@@ -2,21 +2,21 @@
 # © Copyright 2022-2023 Zapata Computing Inc.
 ################################################################################
 """
 UI models. Common data structures between the "data" and "view" layers.
 
 Classes here are containers for information we show to the users in the CLI UI.
 Ideally, most data transformations would be already done (like counting the number of
-inished tasks) but should be easy to assert on in tests (e.g. we prefer ``datetime``
+inished tasks) but should be easy to assert on in tests (e.g. we prefer ``Instant``
 objects instead of date strings).
 """
-import datetime
 import typing as t
 from dataclasses import dataclass
 
+from orquestra.sdk._base._dates import Instant
 from orquestra.sdk.schema import ir
 from orquestra.sdk.schema.workflow_run import RunStatus, WorkflowRunId
 
 
 @dataclass(frozen=True)
 class WFRunSummary:
     """
@@ -48,10 +48,10 @@
     """
 
     @dataclass(frozen=True)
     class WFRow:
         workflow_run_id: str
         status: str
         tasks_succeeded: str
-        start_time: t.Optional[datetime.datetime]
+        start_time: t.Optional[Instant]
 
     wf_rows: t.Sequence[WFRow]
```

## orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py

```diff
@@ -7,23 +7,26 @@
 """
 import os
 import pprint
 import sys
 import typing as t
 import webbrowser
 from contextlib import contextmanager
-from datetime import datetime, timezone
+from functools import singledispatchmethod
 from pathlib import Path
 from typing import Iterable, Iterator, List, Sequence
 
 import click
 from tabulate import tabulate
 
-from orquestra.sdk._base import _config, _env, _services, serde
+from orquestra.sdk._base import _config, _dates, _env, _services, serde
+from orquestra.sdk._base._dates import Instant
+from orquestra.sdk._base._logs._interfaces import WorkflowLogs
 from orquestra.sdk.schema import responses
+from orquestra.sdk.schema.configs import ConfigName, RuntimeConfiguration, RuntimeName
 from orquestra.sdk.schema.ir import ArtifactFormat
 from orquestra.sdk.schema.workflow_run import (
     TaskInvocationId,
     WorkflowRun,
     WorkflowRunId,
     WorkflowRunOnlyID,
 )
@@ -59,41 +62,86 @@
             workflow_runs=[WorkflowRunOnlyID(id=wf_run_id)],
         )
         per_command.pretty_print_response(resp, project_dir=None)
 
     def show_stopped_wf_run(self, wf_run_id: WorkflowRunId):
         click.echo(f"Workflow run {wf_run_id} stopped.")
 
-    def show_dumped_wf_logs(self, path: Path):
-        click.echo(f"Workflow logs saved at {path}")
+    def show_dumped_wf_logs(
+        self, path: Path, log_type: t.Optional[WorkflowLogs.WorkflowLogTypeName] = None
+    ):
+        """
+        Tell the user where logs have been saved.
+
+        Args:
+            path: The path to the dump file.
+            log_type: additional information identify the type of logs saved.
+        """
+        click.echo(
+            f"Workflow {log_type.value + ' ' if log_type else ''}logs saved at {path}"
+        )
+
+    @singledispatchmethod
+    @staticmethod
+    def _format_logs(*args) -> t.List[str]:
+        """
+        Format the logs into a list of strings to be printed.
+        """
+        raise NotImplementedError(
+            f"No log lines constructor for args {args}"
+        )  # pragma: no cover
 
+    @_format_logs.register(dict)
     @staticmethod
-    def _format_log_dict(logs: t.Mapping[TaskInvocationId, t.Sequence[str]]):
+    def _(logs: dict):
         return [
             line
             for invocation_id, invocation_lines in logs.items()
             for line in (f"task-invocation-id: {invocation_id}", *invocation_lines)
         ]
 
-    def show_logs(self, logs: t.Mapping[TaskInvocationId, t.Sequence[str]]):
+    @_format_logs.register(list)
+    @staticmethod
+    def _(logs: list):
+        return logs
+
+    def show_logs(
+        self,
+        logs: t.Union[t.Mapping[TaskInvocationId, t.Sequence[str]], t.Sequence[str]],
+        log_type: t.Optional[WorkflowLogs.WorkflowLogTypeName] = None,
+    ):
+        """
+        Present logs to the user.
+        """
+        _logs = self._format_logs(logs)
+
         resp = responses.GetLogsResponse(
             meta=responses.ResponseMetadata(
                 success=True,
                 code=responses.ResponseStatusCode.OK,
                 message="Successfully got workflow run logs.",
             ),
-            logs=self._format_log_dict(logs),
+            logs=_logs,
         )
+
+        if log_type:
+            _log_type = f"{log_type.value} logs".replace("_", " ")
+            click.echo(f"=== {_log_type.upper()} " + "=" * (75 - len(_log_type)))
         per_command.pretty_print_response(resp, project_dir=None)
+        if log_type:
+            click.echo("=" * 80 + "\n\n")
 
     def show_error(self, exception: Exception):
         status_code = _errors.pretty_print_exception(exception)
 
         sys.exit(status_code.value)
 
+    def show_message(self, message: str):
+        click.echo(message=message)
+
 
 class ArtifactPresenter:
     def show_task_outputs(
         self,
         values: t.Sequence[t.Any],
         wf_run_id: WorkflowRunId,
         task_inv_id: TaskInvocationId,
@@ -193,40 +241,99 @@
     def show_failure(self, service_responses: Sequence[responses.ServiceResponse]):
         self.show_services(service_responses)
 
         sys.exit(responses.ResponseStatusCode.SERVICES_ERROR.value)
 
 
 class LoginPresenter:
+    """User-facing presentation for the steps of the login process."""
+
     def prompt_for_login(self, login_url, url, ce):
+        """Instruct the user how to log in manually."""
         click.echo("We were unable to automatically log you in.")
         click.echo("Please login to your Orquestra account using the following URL.")
         click.echo(login_url)
         click.echo(
             (
                 "Then save the token using command: \n"
                 f"orq login -s {url} -t <paste your token here>"
             )
-            + (" --ce" if ce else "")
+            + (" --ce" if ce else " --qe")
         )
 
-    def prompt_config_saved(self, url, config_name):
+    def prompt_config_saved(self, url, config_name, runtime_name):
+        """Report that the config has been successfully saved."""
         click.echo("Token saved in config file.")
-        click.echo(f"Configuration name for {url} is {config_name}")
+        click.echo(
+            f"Configuration name for {url} with runtime {runtime_name} "
+            f"is '{config_name}'."
+        )
 
     def print_login_help(self):
+        """Direct the user to their browser for the login process."""
         click.echo(
             "Continue the login process in your web browser. Press [ctrl-c] to cancel."
         )
 
     def open_url_in_browser(self, url) -> bool:
+        """Open the login url in the user's browser."""
         return webbrowser.open(url)
 
 
-def _format_datetime(dt: t.Optional[datetime]) -> str:
+class ConfigPresenter:
+    """
+    Present config information to the user.
+    """
+
+    def print_configs_list(
+        self,
+        configs: t.Sequence[RuntimeConfiguration],
+        status: t.Mapping[ConfigName, bool],
+        message: t.Optional[str] = "Stored configs:",
+    ):
+        """
+        Print a list of stored configs.
+        """
+        click.echo(message)
+        click.echo(
+            tabulate(
+                [
+                    [
+                        # show config name
+                        click.style(config.config_name, bold=True),
+                        #
+                        # show runtime name, colour coded blue for CE and green for QE
+                        click.style(config.runtime_name, fg="blue")
+                        if config.runtime_name == RuntimeName.CE_REMOTE
+                        else click.style(config.runtime_name, fg="green"),
+                        #
+                        # show cluster URI
+                        config.runtime_options["uri"],
+                        #
+                        # show a green tick if the token is current, and a red cross if
+                        # it is not.
+                        click.style("\u2713", fg="green")
+                        if status[config.config_name]
+                        else click.style("\u2A09", fg="red"),
+                    ]
+                    for config in configs
+                ],
+                colalign=("left",),
+                tablefmt="plain",
+                headers=[
+                    click.style("Config Name", underline=True),
+                    click.style("Runtime", underline=True),
+                    click.style("Server URI", underline=True),
+                    click.style("Current Token", underline=True),
+                ],
+            ),
+        )
+
+
+def _format_datetime(dt: t.Optional[Instant]) -> str:
     return dt.astimezone().replace(tzinfo=None).ctime() if dt else ""
 
 
 def _format_tasks_succeeded(summary: ui_models.WFRunSummary) -> str:
     return f"{summary.n_tasks_succeeded} / {summary.n_task_invocations_total}"
 
 
@@ -290,63 +397,63 @@
         # Label is <wf_id> <start_time> tabulated nicely to create good-looking
         # table
         # There is also expectations that labels correspond to matching wfs list indices
         wfs = sorted(
             wfs,
             key=lambda wf: wf.status.start_time
             if wf.status.start_time
-            else datetime.fromtimestamp(0).replace(tzinfo=timezone.utc),
+            else _dates.from_unix_time(0),
             reverse=True,
         )
 
         labels = [[wf.id, _format_datetime(wf.status.start_time)] for wf in wfs]
         tabulated_labels = tabulate(labels, tablefmt="plain").split("\n")
 
         return wfs, tabulated_labels
 
-    def workspaces_list_to_prompt(self, workspaces, config_name=None):
+    def workspaces_list_to_prompt(self, workspaces):
         # Create labels of workspaces that are printed by prompter
         # Label is <display_name> <id> tabulated nicely to create good-looking
         # table
         labels = [[ws.name, ws.workspace_id] for ws in workspaces]
 
-        if config_name == _config.AUTO_CONFIG_NAME:
-            try:
-                curr_ws = os.environ[_env.CURRENT_WORKSPACE_ENV]
-                for index, label in enumerate(labels):
-                    if label[1] == curr_ws:
-                        label.append("(CURRENT WORKSPACE)")
-                        # put current workspace at the top of the list so it is
-                        # auto-selected
-                        labels.insert(0, labels.pop(index))
-                        workspaces = workspaces[:]
-                        workspaces.insert(0, workspaces.pop(index))
-                        break
-            except KeyError:
-                pass
+        try:
+            curr_ws = os.environ[_env.CURRENT_WORKSPACE_ENV]
+            for index, label in enumerate(labels):
+                if label[1] == curr_ws:
+                    label.append("(CURRENT WORKSPACE)")
+                    # put current workspace at the top of the list so it is
+                    # auto-selected
+                    labels.insert(0, labels.pop(index))
+                    workspaces = workspaces[:]
+                    workspaces.insert(0, workspaces.pop(index))
+                    break
+        except KeyError:
+            pass
 
         tabulated_labels = tabulate(labels, tablefmt="plain").split("\n")
 
         return tabulated_labels, workspaces
 
-    def project_list_to_prompt(self, projects, config_name=None):
+    def project_list_to_prompt(self, projects):
         # Create labels of projects that are printed by prompter
         # Label is <display_name> <id> tabulated nicely to create good-looking
         # table
         labels = [[p.name, p.project_id] for p in projects]
-        if config_name == _config.AUTO_CONFIG_NAME:
-            try:
-                curr_proj = os.environ[_env.CURRENT_PROJECT_ENV]
-                for index, label in enumerate(labels):
-                    if label[1] == curr_proj:
-                        label.append("(CURRENT PROJECT)")
-                        # put current project at the top of the list so it is
-                        # auto-selected
-                        labels.insert(0, labels.pop(index))
-                        projects = projects[:]
-                        projects.insert(0, projects.pop(index))
-                        break
-            except KeyError:
-                pass
+
+        try:
+            curr_proj = os.environ[_env.CURRENT_PROJECT_ENV]
+            for index, label in enumerate(labels):
+                if label[1] == curr_proj:
+                    label.append("(CURRENT PROJECT)")
+                    # put current project at the top of the list so it is
+                    # auto-selected
+                    labels.insert(0, labels.pop(index))
+                    projects = projects[:]
+                    projects.insert(0, projects.pop(index))
+                    break
+        except KeyError:
+            pass
+
         tabulated_labels = tabulate(labels, tablefmt="plain").split("\n")
 
         return tabulated_labels, projects
```

## orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py

```diff
@@ -34,31 +34,34 @@
 
     @overload
     def choice(
         self,
         choices: t.Sequence[ChoiceID],
         message: str,
         default: t.Optional[str] = None,
+        allow_all: t.Optional[bool] = False,
     ) -> ChoiceID:
         ...
 
     @overload
     def choice(
         self,
         choices: t.Sequence[t.Tuple[ChoiceID, T]],
         message: str,
         default: t.Optional[str] = None,
+        allow_all: t.Optional[bool] = False,
     ) -> T:
         ...
 
     def choice(
         self,
         choices: t.Sequence[t.Union[ChoiceID, t.Tuple[ChoiceID, T]]],
         message: str,
         default: t.Optional[str] = None,
+        allow_all: t.Optional[bool] = False,
     ) -> t.Union[ChoiceID, T]:
         """
         Presents the user a choice and returns what they selected.
 
         If only one option is available, the user is prompted to confirm that this is
         the intended outcome and, if so, that option is selected automatically.
 
@@ -82,18 +85,24 @@
             raise exceptions.NoOptionsAvailableError(message)
 
         # If there's only one choice, select it automatically and confirm with the user
         # that that's what they want to do.
         if len(choices) == 1:
             return self._handle_single_option(message, choices[0])
 
+        # We may need to be able to modify the list of choices to add an 'all' option,
+        # so cast it to a list instance.
+        _choices = list(choices)
+        if allow_all:
+            _choices += ["all"]
+
         question = inquirer.List(
             SINGLE_INPUT,
             message=message,
-            choices=choices,
+            choices=_choices,
             default=default,
             carousel=True,
         )
         answers = inquirer.prompt([question])
 
         # If the user cancels the prompt, via ctrl-c, answers will be `None`.
         if answers is None:
```

## orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/per_command.py

```diff
@@ -1,19 +1,19 @@
 ################################################################################
 # © Copyright 2022 Zapata Computing Inc.
 ################################################################################
 import json
 import pathlib
 import typing as t
-from datetime import datetime
 from functools import singledispatch
 
 import pydantic
 import tabulate
 
+from orquestra.sdk._base import _dates
 from orquestra.sdk.schema import ir, responses, workflow_run
 
 
 @singledispatch
 def pretty_print_response(
     response: pydantic.BaseModel,
     project_dir: t.Optional[str],
@@ -184,20 +184,20 @@
 
         else:
             print(res)
 
         print()
 
 
-def _format_datetime(dt: t.Optional[datetime]) -> str:
+def _format_datetime(dt: t.Optional[_dates.Instant]) -> str:
     if dt is None:
         # Print empty table cell
         return ""
 
-    return dt.isoformat()
+    return _dates.isoformat(dt)
 
 
 def _print_single_run(run: responses.WorkflowRun, project_dir: t.Optional[str]):
     analyzer = _WorkflowDefAnalyzer(run.workflow_def)
 
     print("Workflow overview")
     print(
```

## orquestra/sdk/_base/cli/_dorq/_workflow/_logs.py

```diff
@@ -1,16 +1,18 @@
 ################################################################################
 # © Copyright 2023 Zapata Computing Inc.
 ################################################################################
 """
 Code for 'orq workflow logs'.
 """
 import typing as t
+import warnings
 from pathlib import Path
 
+from orquestra.sdk._base._logs._interfaces import WorkflowLogs
 from orquestra.sdk.schema.configs import ConfigName
 from orquestra.sdk.schema.workflow_run import WorkflowRunId
 
 from .. import _arg_resolvers, _dumpers, _repos
 from .._ui import _presenters
 
 
@@ -43,42 +45,76 @@
         self._dumper = dumper
 
     def on_cmd_call(
         self,
         wf_run_id: t.Optional[WorkflowRunId],
         config: t.Optional[ConfigName],
         download_dir: t.Optional[Path],
+        task: t.Optional[bool],
+        system: t.Optional[bool],
+        env_setup: t.Optional[bool],
+        other: t.Optional[bool],
     ):
         try:
             self._on_cmd_call_with_exceptions(
                 wf_run_id=wf_run_id,
                 download_dir=download_dir,
                 config=config,
+                task=task,
+                system=system,
+                env_setup=env_setup,
+                other=other,
             )
         except Exception as e:
             self._presenter.show_error(e)
 
     def _on_cmd_call_with_exceptions(
         self,
         wf_run_id: t.Optional[WorkflowRunId],
         config: t.Optional[ConfigName],
         download_dir: t.Optional[Path],
+        task: t.Optional[bool],
+        system: t.Optional[bool],
+        env_setup: t.Optional[bool],
+        other: t.Optional[bool],
     ):
         # The order of resolving config and run ID is important. It dictates the flow
         # user sees, and possible choices in the prompts.
         resolved_config = self._config_resolver.resolve(wf_run_id, config)
         resolved_wf_run_id = self._wf_run_resolver.resolve_id(
             wf_run_id, resolved_config
         )
-        logs = self._wf_run_repo.get_wf_logs(
+
+        # Get the available logs
+        logs: WorkflowLogs = self._wf_run_repo.get_wf_logs(
             wf_run_id=resolved_wf_run_id, config_name=resolved_config
         )
 
-        if download_dir is not None:
-            dump_path = self._dumper.dump(
-                logs=logs,
-                wf_run_id=resolved_wf_run_id,
-                dir_path=download_dir,
-            )
-            self._presenter.show_dumped_wf_logs(dump_path)
-        else:
-            self._presenter.show_logs(logs)
+        # Resolve the log type switches. This must happen after getting the logs as we
+        # need to check against which logs are available.
+        switches: t.Mapping[
+            WorkflowLogs.WorkflowLogTypeName, bool
+        ] = self._wf_run_resolver.resolve_log_switches(
+            task, system, env_setup, other, logs
+        )
+
+        for log_type in switches:
+            if not switches[log_type]:
+                continue
+
+            log = logs.get_log_type(log_type)
+
+            if len(log) < 1:
+                warnings.warn(f"No {log_type} logs found.", category=UserWarning)
+                continue
+            print("HERE2")
+            if download_dir:
+                dump_path = self._dumper.dump(
+                    logs=log,
+                    wf_run_id=resolved_wf_run_id,
+                    dir_path=download_dir,
+                    log_type=log_type,
+                )
+
+                self._presenter.show_dumped_wf_logs(dump_path, log_type=log_type)
+            else:
+                self._presenter.show_logs(log, log_type=log_type)
```

## orquestra/sdk/_ray/_build_workflow.py

```diff
@@ -1,27 +1,28 @@
 ################################################################################
 # © Copyright 2023 Zapata Computing Inc.
 ################################################################################
 """
 Translates IR workflow def into a Ray workflow.
 """
 import os
-import traceback
 import typing as t
 from functools import singledispatch
 from pathlib import Path
 
+import pydantic
 from typing_extensions import assert_never
 
 from .. import exceptions, secrets
-from .._base import _exec_ctx, _git_url_utils, _graphs, _log_adapter, dispatch, serde
+from .._base import _exec_ctx, _git_url_utils, _graphs, dispatch, serde
 from .._base._env import (
     RAY_DOWNLOAD_GIT_IMPORTS_ENV,
     RAY_SET_CUSTOM_IMAGE_RESOURCES_ENV,
 )
+from .._base._logs import _markers
 from ..kubernetes.quantity import parse_quantity
 from ..schema import _compat, ir, responses, workflow_run
 from . import _client, _id_gen
 from ._client import RayClient
 from ._wf_metadata import InvUserMetadata, pydatic_to_json_dict
 
 DEFAULT_IMAGE_TEMPLATE = "hub.nexus.orquestra.io/zapatacomputing/orquestra-sdk-base:{}"
@@ -182,34 +183,41 @@
         project_dir: the working directory the workflow was submitted from
         user_fn_ref: function reference for a function to be executed by Ray.
             if None - executes data aggregation step
     """
 
     @client.remote
     def _ray_remote(*inner_args, **inner_kwargs):
-        if project_dir is not None:
-            dispatch.ensure_sys_paths([str(project_dir)])
-
-        if user_fn_ref is None:
-            serialization = False
-            user_fn = _aggregate_outputs
-        else:
-            serialization = True
-            user_fn = _locate_user_fn(user_fn_ref)
+        with _exec_ctx.ray():
+            # We need to emit task start marker log as soon as possible. Otherwise, we
+            # risk an exception won't be visible to the user.
+            #
+            # TODO: make the IDs required and raise an error if they're not present.
+            # https://zapatacomputing.atlassian.net/browse/ORQSDK-530
+            wf_run_id, task_inv_id, _ = get_current_ids()
+            with _markers.printed_task_markers(
+                wf_run_id=wf_run_id, task_inv_id=task_inv_id
+            ):
+                if project_dir is not None:
+                    dispatch.ensure_sys_paths([str(project_dir)])
+
+                if user_fn_ref is None:
+                    serialization = False
+                    user_fn = _aggregate_outputs
+                else:
+                    serialization = True
+                    user_fn = _locate_user_fn(user_fn_ref)
 
-        wrapped = ArgumentUnwrapper(
-            user_fn=user_fn,
-            args_artifact_nodes=args_artifact_nodes,
-            kwargs_artifact_nodes=kwargs_artifact_nodes,
-            deserialize=serialization,
-        )
+                wrapped = ArgumentUnwrapper(
+                    user_fn=user_fn,
+                    args_artifact_nodes=args_artifact_nodes,
+                    kwargs_artifact_nodes=kwargs_artifact_nodes,
+                    deserialize=serialization,
+                )
 
-        with _exec_ctx.ray():
-            logger = _log_adapter.workflow_logger()
-            try:
                 wrapped_return = wrapped(*inner_args, **inner_kwargs)
 
                 packed: responses.WorkflowResult = (
                     serde.result_from_artifact(wrapped_return, ir.ArtifactFormat.AUTO)
                     if serialization
                     else wrapped_return
                 )
@@ -222,26 +230,18 @@
                         )
                         if serialization
                         else wrapped_return[i]
                         for i in range(n_outputs)
                     )
                 else:
                     unpacked = (packed,)
-
                 return TaskResult(
                     packed=packed,
                     unpacked=unpacked,
                 )
-            except Exception as e:
-                # Log the stacktrace as a single log line.
-                logger.exception(traceback.format_exc())
-
-                # We need to stop further execution of this workflow. If we don't
-                # raise, Ray will think the task succeeded with a return value `None`.
-                raise e
 
     named_remote = client.add_options(_ray_remote, **ray_options)
     dag_node = named_remote.bind(*ray_args, **ray_kwargs)
 
     return dag_node
 
 
@@ -474,7 +474,50 @@
                 ) from err
             else:
                 raise err
         else:
             return result[0]
 
     return handle_data_aggregation_error.bind(last_future)
+
+
+def get_current_ids() -> (
+    t.Tuple[
+        t.Optional[workflow_run.WorkflowRunId],
+        t.Optional[ir.TaskInvocationId],
+        t.Optional[workflow_run.TaskRunId],
+    ]
+):
+    """
+    Uses Ray context to figure out what are the IDs of the currently running workflow
+    and task.
+
+    The returned TaskInvocationID and TaskRunID are None if we weren't able to get them
+    from current Ray context.
+    """
+    # NOTE: this is tightly coupled with how we create Ray workflow DAG, how we assign
+    # IDs and metadata.
+    client = _client.RayClient()
+
+    try:
+        wf_run_id = client.get_current_workflow_id()
+    except AssertionError:
+        # Ray has an 'assert' about checking the workflow context outside of a workflow
+        return None, None, None
+
+    # We don't need to care what kind of ID it is, we only need it to get the metadata
+    # dict.
+    ray_task_name = client.get_current_task_id()
+    task_meta: dict = client.get_task_metadata(
+        workflow_id=wf_run_id, name=ray_task_name
+    )
+
+    try:
+        user_meta = InvUserMetadata.parse_obj(task_meta.get("user_metadata"))
+    except pydantic.ValidationError:
+        # This ray task wasn't annotated with InvUserMetadata. It happens when
+        # `get_current_ids()` is used from a context that's not a regular Orquestra Task
+        # run. One example is the one-off task that we use to construct Ray DAG inside a
+        # Ray worker process.
+        return wf_run_id, None, None
+
+    return wf_run_id, user_meta.task_invocation_id, user_meta.task_run_id
```

## orquestra/sdk/_ray/_dag.py

```diff
@@ -9,23 +9,23 @@
 
 import dataclasses
 import logging
 import os
 import re
 import typing as t
 import warnings
-from datetime import datetime, timedelta, timezone
+from datetime import timedelta
 from pathlib import Path
 
 import pydantic
 
 from orquestra.sdk.schema.responses import WorkflowResult
 
 from .. import exceptions
-from .._base import _services, serde
+from .._base import _dates, _services, serde
 from .._base._db import WorkflowDB
 from .._base._env import RAY_GLOBAL_WF_RUN_ID_ENV
 from .._base._logs._interfaces import LogReader
 from .._base._spaces._structs import ProjectRef
 from .._base.abc import RuntimeInterface
 from ..schema import ir
 from ..schema.configs import RuntimeConfiguration
@@ -43,22 +43,20 @@
 )
 from . import _client, _id_gen, _ray_logs
 from ._build_workflow import TaskResult, make_ray_dag
 from ._client import RayClient
 from ._wf_metadata import InvUserMetadata, WfUserMetadata, pydatic_to_json_dict
 
 
-def _instant_from_timestamp(unix_timestamp: t.Optional[float]) -> t.Optional[datetime]:
-    """
-    Parses a unix epoch timestamp (UTC seconds since 1970) into a
-    timezone-aware datetime object.
-    """
+def _instant_from_timestamp(
+    unix_timestamp: t.Optional[float],
+) -> t.Optional[_dates.Instant]:
     if unix_timestamp is None:
         return None
-    return datetime.fromtimestamp(unix_timestamp, timezone.utc)
+    return _dates.from_unix_time(unix_timestamp)
 
 
 def _generate_wf_run_id(wf_def: ir.WorkflowDef):
     """
     Implements the "tagging" design doc:
     https://zapatacomputing.atlassian.net/wiki/spaces/ORQSRUN/pages/479920161/Logging+Tagging
 
@@ -185,41 +183,35 @@
 # Sometimes, Ray behaves unintuitively.
 JUST_IN_CASE_TIMEOUT = 10.0
 
 
 class RayRuntime(RuntimeInterface):
     def __init__(
         self,
-        client: RayClient,
         config: RuntimeConfiguration,
         project_dir: Path,
+        client: t.Optional[RayClient] = None,
     ):
-        self._client = client
-        self._config = config
-        self._project_dir = project_dir
-
-        self._log_reader: LogReader = _ray_logs.DirectRayReader(
-            _services.ray_temp_path()
-        )
-
-    @classmethod
-    def from_runtime_configuration(
-        cls, project_dir: Path, config: RuntimeConfiguration, verbose: bool
-    ) -> "RuntimeInterface":
-        client = RayClient()
+        self._client = client or RayClient()
 
         ray_params = RayParams(
             address=config.runtime_options["address"],
             log_to_driver=config.runtime_options["log_to_driver"],
             storage=config.runtime_options["storage"],
             _temp_dir=config.runtime_options["temp_dir"],
             configure_logging=config.runtime_options["configure_logging"],
         )
-        cls.startup(ray_params)
-        return RayRuntime(client=client, config=config, project_dir=project_dir)
+        self.startup(ray_params)
+
+        self._config = config
+        self._project_dir = project_dir
+
+        self._log_reader: LogReader = _ray_logs.DirectRayReader(
+            _services.ray_temp_path()
+        )
 
     @classmethod
     def startup(cls, ray_params: RayParams):
         """
         Initialize a global Ray connection. If you need a separate connection
         with different params, you need to call .shutdown first(). Globals
         suck.
@@ -510,15 +502,15 @@
         Raises:
             WorkspacesNotSupportedError: when a workspace or project is specified.
         """
         if workspace or project:
             raise exceptions.WorkspacesNotSupportedError(
                 "Filtering by workspace or project is not supported on Ray runtimes."
             )
-        now = datetime.now(timezone.utc)
+        now = _dates.now()
 
         if state is not None:
             if not isinstance(state, list):
                 state_list = [state]
             else:
                 state_list = state
         else:
@@ -549,48 +541,7 @@
             wf_runs = sorted(wf_runs, key=lambda run: run.status.start_time or now)[
                 -limit:
             ]
         return wf_runs
 
     def get_workflow_project(self, wf_run_id: WorkflowRunId):
         raise exceptions.WorkspacesNotSupportedError()
-
-
-def get_current_ids() -> (
-    t.Tuple[
-        t.Optional[WorkflowRunId], t.Optional[TaskInvocationId], t.Optional[TaskRunId]
-    ]
-):
-    """
-    Uses Ray context to figure out what are the IDs of the currently running workflow
-    and task.
-
-    The returned TaskInvocationID and TaskRunID are None if we weren't able to get them
-    from current Ray context.
-    """
-    # NOTE: this is tightly coupled with how we create Ray workflow DAG, how we assign
-    # IDs and metadata.
-    client = _client.RayClient()
-
-    try:
-        wf_run_id = client.get_current_workflow_id()
-    except AssertionError:
-        # Ray has an 'assert' about checking the workflow context outside of a workflow
-        return None, None, None
-
-    # We don't need to care what kind of ID it is, we only need it to get the metadata
-    # dict.
-    ray_task_name = client.get_current_task_id()
-    task_meta: dict = client.get_task_metadata(
-        workflow_id=wf_run_id, name=ray_task_name
-    )
-
-    try:
-        user_meta = InvUserMetadata.parse_obj(task_meta.get("user_metadata"))
-    except pydantic.ValidationError:
-        # This ray task wasn't annotated with InvUserMetadata. It happens when
-        # `get_current_ids()` is used from a context that's not a regular Orquestra Task
-        # run. One example is the one-off task that we use to construct Ray DAG inside a
-        # Ray worker process.
-        return wf_run_id, None, None
-
-    return wf_run_id, user_meta.task_invocation_id, user_meta.task_run_id
```

## orquestra/sdk/_ray/_ray_logs.py

```diff
@@ -1,75 +1,26 @@
 ################################################################################
 # © Copyright 2022 - 2023 Zapata Computing Inc.
 ################################################################################
 """
 Class to get logs from Ray for particular Workflow, both historical and live.
 """
-import json
 import typing as t
-
-# from dataclasses import dataclass
-from datetime import datetime
 from pathlib import Path
 
-import pydantic
-
-from orquestra.sdk._base._logs import _regrouping
+from orquestra.sdk._base._logs import _markers, _regrouping
 from orquestra.sdk._base._logs._interfaces import WorkflowLogs
 from orquestra.sdk.schema.ir import TaskInvocationId
-from orquestra.sdk.schema.workflow_run import TaskRunId, WorkflowRunId
-
-from . import _client
-
-
-class WFLog(pydantic.BaseModel):
-    """
-    Log line produced inside a task run. Parsed. Coupled with the logging format set in
-    ``orquestra.sdk._base._log_adater``.
-    """
+from orquestra.sdk.schema.workflow_run import WorkflowRunId
 
-    # Timezone-aware date+time.
-    timestamp: datetime
-    # Log level name, consistent with Python logging.
-    level: str
-    filename: str
-    # User-specified message string.
-    message: str
-    # ID of the workflow that was run when this line was produced.
-    wf_run_id: t.Optional[WorkflowRunId]
-    # ID of the task invocation (node inside the workflow def graph).
-    task_inv_id: t.Optional[TaskInvocationId]
-    # ID of the task that was run when this line was produced.
-    task_run_id: t.Optional[TaskRunId]
-
-
-def _parse_obj_or_none(model_class, json_dict):
-    try:
-        return model_class.parse_obj(json_dict)
-    except pydantic.error_wrappers.ValidationError:
-        return None
-
-
-def parse_log_line(raw_line: bytes) -> t.Optional[WFLog]:
-    line = raw_line.decode("utf-8", "replace").rstrip("\r\n")
-    if line.startswith(_client.LogPrefixActorName) or line.startswith(
-        _client.LogPrefixTaskName
-    ):
-        return None
-
-    try:
-        json_obj = json.loads(line)
-    except (ValueError, TypeError):
-        return None
-
-    # Fixes log lines that are valid JSON literals but not objects
-    if not isinstance(json_obj, dict):
-        return None
 
-    return _parse_obj_or_none(WFLog, json_obj)
+class CapturedLogLines(t.NamedTuple):
+    captured_lines: t.Sequence[str]
+    workflow_run_id: WorkflowRunId
+    task_invocation_id: TaskInvocationId
 
 
 def _iter_logs_paths(ray_temp: Path) -> t.Iterator[Path]:
     seen_paths: t.MutableSet[Path] = set()
     for file_path in ray_temp.glob("session_*/logs/*"):
         real_path = file_path.resolve()
         if real_path in seen_paths:
@@ -90,14 +41,82 @@
 
 def _iter_log_lines(paths: t.Iterable[Path]) -> t.Iterator[bytes]:
     for path in paths:
         with path.open("rb") as f:
             yield from f
 
 
+def iter_task_logs(
+    worker_file_path: Path,
+) -> t.Iterator[CapturedLogLines]:
+    """
+    A generator over logs contained in a Ray worker's output file
+
+    Ray workers can be reused, so this generator has to handle a number of edge cases.
+        - Happy path: a Ray worker has a single "task start" and "task end" marker.
+        - a Ray worker has multiple "task start" and "task end" markers.
+          This happens after a worker has being reused.
+        - Two (or more) "task start" markers in a row.
+          This may happen when if a worker is reused and the previous "task end" marker
+          failed.
+        - Missing "task end" marker.
+          This may happen if a worker crashes or the "task end" marker is not captured.
+
+    Args:
+        worker_file_path: The path to the output of a Ray worker.
+
+    Returns:
+        A generator that yields batches of logs relating to specific workflow runs and
+        task invocations.
+    """
+
+    with worker_file_path.open() as f:
+        marker_context: t.Optional[_markers.TaskStartMarker] = None
+        collected_lines: t.List[str] = []
+
+        for line in f:
+            if (marker := _markers.parse_line(line)) is not None:
+                if isinstance(marker, _markers.TaskStartMarker):
+                    if marker_context is not None:
+                        # Seeing two start markers in the row: edge case when the end
+                        # marker is missing. We want to return the logs to the user
+                        # anyway. They might be noisy, but it's better than nothing.
+                        yield CapturedLogLines(
+                            collected_lines,
+                            marker_context.wf_run_id,
+                            marker_context.task_inv_id,
+                        )
+
+                    marker_context = marker
+                    collected_lines = []
+                elif isinstance(marker, _markers.TaskEndMarker):
+                    if marker_context is not None:
+                        yield CapturedLogLines(
+                            collected_lines,
+                            marker_context.wf_run_id,
+                            marker_context.task_inv_id,
+                        )
+                        collected_lines = []
+
+                    marker_context = None
+
+            else:
+                # This is a standard, non-marker line.
+                collected_lines.append(line.strip())
+
+        # If something goes wrong, e.g. Ray worker crashes, the log file can end without
+        # the task end marker. We want to capture the logs anyway.
+        if marker_context is not None:
+            yield CapturedLogLines(
+                collected_lines,
+                marker_context.wf_run_id,
+                marker_context.task_inv_id,
+            )
+
+
 class DirectRayReader:
     """
     Directly reads log files produced by Ray.
     Implements the ``LogReader`` interface.
 
     Requires ``ray_temp`` to be consistent with the path passed when initializing the
     Ray cluster. For example, if the cluster was started with::
@@ -112,56 +131,68 @@
     def __init__(self, ray_temp: Path):
         """
         Args:
             ray_temp: directory where Ray keeps its data, like ``~/.orquestra/ray``.
         """
         self._ray_temp = ray_temp
 
-    def _get_user_log_lines(self) -> t.Sequence[WFLog]:
-        log_paths = iter_user_log_paths(self._ray_temp)
-        log_line_bytes = _iter_log_lines(log_paths)
-
-        return [
-            parsed_log
-            for log_line in log_line_bytes
-            if (parsed_log := parse_log_line(raw_line=log_line)) is not None
-        ]
-
     def _get_env_setup_lines(self) -> t.Sequence[str]:
         log_paths = iter_env_log_paths(self._ray_temp)
         log_line_bytes = _iter_log_lines(log_paths)
 
         return [line.decode() for line in log_line_bytes]
 
+    def _get_system_log_lines(self) -> t.Sequence[str]:
+        # There is currently no concrete rule for which log files fall into the
+        # category of 'system'. Since the log files exist locally for the user, we
+        # simply point them to the appropriate directory rather than trying to
+        # construct the category for them.
+        system_warning = (
+            "WARNING: we don't parse system logs for the local runtime. "
+            "The log files can be found in the directory "
+            f"'{self._ray_temp}'"
+        )
+        return [system_warning]
+
+    def _get_other_log_lines(self) -> t.Sequence[str]:
+        other_warning = (
+            "WARNING: we don't parse uncategorized logs for the local runtime. "
+            "The log files can be found in the directory "
+            f"'{self._ray_temp}'"
+        )
+        return [other_warning]
+
     def get_task_logs(
         self, wf_run_id: WorkflowRunId, task_inv_id: TaskInvocationId
     ) -> t.List[str]:
-        user_logs = self._get_user_log_lines()
+        collected_logs: t.List[str] = []
+        for log_path in iter_user_log_paths(self._ray_temp):
+            for logs_batch2, wf_run_id2, task_inv_id2 in iter_task_logs(log_path):
+                if wf_run_id2 != wf_run_id:
+                    continue
 
-        task_logs = [
-            log
-            for log in user_logs
-            if log.wf_run_id == wf_run_id and log.task_inv_id == task_inv_id
-        ]
-        return [log.json() for log in task_logs]
+                if task_inv_id2 != task_inv_id:
+                    continue
 
-    def get_workflow_logs(self, wf_run_id: WorkflowRunId) -> WorkflowLogs:
-        user_logs = self._get_user_log_lines()
+                collected_logs.extend(logs_batch2)
+        return collected_logs
 
+    def get_workflow_logs(self, wf_run_id: WorkflowRunId) -> WorkflowLogs:
+        log_paths = iter_user_log_paths(self._ray_temp)
         logs_dict: t.Dict[TaskInvocationId, t.List[str]] = {}
-        for log in user_logs:
-            if log.wf_run_id != wf_run_id:
-                continue
-
-            if log.task_inv_id is None:
-                continue
+        for log_path in log_paths:
+            for logs_batch2, wf_run_id2, task_inv_id2 in iter_task_logs(log_path):
+                if wf_run_id2 != wf_run_id:
+                    continue
 
-            logs_dict.setdefault(log.task_inv_id, []).append(log.json())
+                logs_dict.setdefault(task_inv_id2, []).extend(logs_batch2)
 
         env_setup = self._get_env_setup_lines()
+        system = self._get_system_log_lines()
+        other = self._get_other_log_lines()
 
         return WorkflowLogs(
             per_task=logs_dict,
             env_setup=env_setup,
-            system=[],
-            other=[],
+            system=system,
+            other=other,
         )
```

## orquestra/sdk/schema/workflow_run.py

```diff
@@ -5,18 +5,18 @@
 
 The classes here are used only for purposes of schema definition. Every data
 structure here is JSON-serializable.
 """
 
 import enum
 import typing as t
-from datetime import datetime
 
 from pydantic import BaseModel
 
+from orquestra.sdk._base._dates import Instant
 from orquestra.sdk.schema.ir import TaskInvocationId, WorkflowDef
 
 WorkflowRunId = str
 TaskRunId = str
 WorkspaceId = str
 ProjectId = str
 
@@ -34,16 +34,16 @@
     @classmethod
     def _missing_(cls, _):
         return cls.UNKNOWN
 
 
 class RunStatus(BaseModel):
     state: State
-    start_time: t.Optional[datetime]
-    end_time: t.Optional[datetime]
+    start_time: t.Optional[Instant]
+    end_time: t.Optional[Instant]
 
 
 class TaskRun(BaseModel):
     id: TaskRunId
     invocation_id: TaskInvocationId
     status: RunStatus
     message: t.Optional[str] = None
```

## orquestra/sdk/secrets/_api.py

```diff
@@ -1,27 +1,38 @@
 ################################################################################
 # © Copyright 2022 Zapata Computing Inc.
 ################################################################################
 """
 Code for user-facing utilities related to secrets.
 """
 import typing as t
+import warnings
 
 from .. import exceptions as sdk_exc
 from .._base import _dsl, _exec_ctx
+from ..schema.workflow_run import WorkspaceId
 from . import _auth, _exceptions, _models
 
 
-def _translate_to_zri(workspace_id: str, secret_name: str) -> str:
+def _translate_to_zri(workspace_id: WorkspaceId, secret_name: str) -> str:
     """
     Create ZRI from workspace_id and secret_name
     """
     return f"zri:v1::0:{workspace_id}:secret:{secret_name}"
 
 
+def _raise_warning_for_none_workspace(workspace: t.Optional[WorkspaceId]):
+    if workspace is None:
+        warnings.warn(
+            "Please specify workspace ID directly for accessing secrets."
+            " Support for default workspaces will be sunset in the future.",
+            FutureWarning,
+        )
+
+
 def get(
     name: str,
     *,
     workspace_id: t.Optional[str] = None,
     config_name: t.Optional[str] = None,
 ) -> str:
     """
@@ -46,14 +57,16 @@
     Returns:
         Either:
         - the value of the secret
         - if used inside a workflow function (a function decorated with @sdk.workflow),
             this function will return a "future" which will be used to retrieve the
             secret at execution time.
     """
+    _raise_warning_for_none_workspace(workspace_id)
+
     if _exec_ctx.global_context == _exec_ctx.ExecContext.WORKFLOW_BUILD:
         return t.cast(
             str,
             _dsl.Secret(name=name, config_name=config_name, workspace_id=workspace_id),
         )
 
     try:
@@ -92,14 +105,16 @@
         orquestra.sdk.exceptions.ConfigNameNotFoundError: when no matching config was
             found.
         orquestra.sdk.exceptions.NotFoundError: when no secret with the given name
             was found.
         orquestra.sdk.exceptions.UnauthorizedError: when the authorization with the
             remote vault failed.
     """
+    _raise_warning_for_none_workspace(workspace_id)
+
     try:
         client = _auth.authorized_client(config_name)
     except sdk_exc.ConfigNameNotFoundError:
         raise
 
     try:
         return [obj.name for obj in client.list_secrets(workspace_id)]
@@ -129,14 +144,16 @@
 
     Raises:
         orquestra.sdk.exceptions.ConfigNameNotFoundError: when no matching config was
             found.
         orquestra.sdk.exceptions.UnauthorizedError: when the authorization with the
             remote vault failed.
     """
+    _raise_warning_for_none_workspace(workspace_id)
+
     try:
         client = _auth.authorized_client(config_name)
     except sdk_exc.ConfigNameNotFoundError:
         raise
 
     try:
         try:
@@ -175,14 +192,16 @@
         orquestra.sdk.exceptions.ConfigNameNotFoundError: when no matching config was
             found.
         orquestra.sdk.exceptions.NotFoundError: when the secret ``name`` couldn't be
             found.
         orquestra.sdk.exceptions.UnauthorizedError: when the authorization with the
             remote vault failed.
     """
+    _raise_warning_for_none_workspace(workspace_id)
+
     try:
         client = _auth.authorized_client(config_name)
     except sdk_exc.ConfigNameNotFoundError:
         raise
     if workspace_id:
         name = _translate_to_zri(workspace_id, name)
     try:
```

## orquestra/sdk/secrets/_auth.py

```diff
@@ -21,25 +21,25 @@
     if (passport_path := os.getenv(PASSPORT_FILE_ENV)) is None:
         return None
 
     passport_token = Path(passport_path).read_text()
     return SecretsClient.from_token(base_uri=BASE_URI, token=passport_token)
 
 
-def _read_config_opts(config_name: t.Optional[ConfigName]):
+def _read_config_opts(config_name: ConfigName):
     try:
         cfg = _config.read_config(config_name=config_name)
     except exceptions.ConfigNameNotFoundError:
         raise
 
     return cfg.runtime_options
 
 
 def _authorize_with_config(
-    config_name: t.Optional[ConfigName],
+    config_name: ConfigName,
 ) -> SecretsClient:
     try:
         opts = _read_config_opts(config_name)
     except exceptions.ConfigNameNotFoundError:
         raise
 
     return SecretsClient.from_token(base_uri=opts["uri"], token=opts["token"])
@@ -53,11 +53,16 @@
     """
     # At the moment there are only two ways to authorize the secrets client: passport
     # and config file. If more schemes are developed in the future, they should be
     # added here.
     if (passport_client := _authorize_with_passport()) is not None:
         return passport_client
 
+    if config_name is None:
+        raise exceptions.ConfigNameNotFoundError(
+            "Please provide config name while accessing the secrets locally"
+        )
+
     try:
         return _authorize_with_config(config_name)
     except exceptions.ConfigNameNotFoundError:
         raise
```

## Comparing `orquestra_sdk-0.51.0.dist-info/LICENSE` & `orquestra_sdk-0.52.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `orquestra_sdk-0.51.0.dist-info/METADATA` & `orquestra_sdk-0.52.0.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: orquestra-sdk
-Version: 0.51.0
+Version: 0.52.0
 Summary: "Compose Orquestra workflows using a Python DSL"
 Home-page: https://github.com/zapatacomputing/orquestra-workflow-sdk
 Author: Zapata Computing Inc.
 Author-email: info@zapatacomputing.com
 License: Apache License 2.0
 Classifier: Programming Language :: Python :: 3
 Classifier: Operating System :: OS Independent
```

## Comparing `orquestra_sdk-0.51.0.dist-info/RECORD` & `orquestra_sdk-0.52.0.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,115 +1,121 @@
-orquestra/sdk/__init__.py,sha256=cuW-nPV4RHSSCuEbBMBsHj0gR_ypFduE_SbRx6BXIrg,1800
+orquestra/sdk/__init__.py,sha256=YHAknfyqy3XDNUbLwqj0ySUaDpUvCJR2gGckhohLsrc,1822
 orquestra/sdk/exceptions.py,sha256=dchEASsrb2hmJDuFJMquA8zV2I2WTjSpxPK3GlvT8zc,7183
 orquestra/sdk/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 orquestra/sdk/_base/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_ast.py,sha256=3H4PUZctbpmYYhHLS5n5bdkh2jR1Zpl4YTdcoy-LBD4,8232
-orquestra/sdk/_base/_config.py,sha256=QEjzwEepdBN4BZMOURcd5wr8qGjXbMEXzXc4rzSIKWI,25046
-orquestra/sdk/_base/_dsl.py,sha256=1eyXjD8LO-7XtC6IjRVrC3Qgqx22hYnLN3btFEm8BJ0,37402
+orquestra/sdk/_base/_config.py,sha256=dQvPDIDOapGpq5o8O_C1d-oM1_1OhBcXP52AoEzAa1g,21113
+orquestra/sdk/_base/_dates.py,sha256=qQtt206iFNuap_tOZnPRES95KhsqFdPMZ3CYnZ2Rr2M,2878
+orquestra/sdk/_base/_dsl.py,sha256=vNSAymi7w74zitwrCnJ01ZlDEnHEjSlJwGgbcXAWYAQ,37777
 orquestra/sdk/_base/_env.py,sha256=BZ5aP0S3GIKEe7RBzfF63lKXOWQK8HYfnutU9n4B9mU,2461
 orquestra/sdk/_base/_exec_ctx.py,sha256=1ZoMjsF9H-9oFym9BP5T6M_A7u4Q0133kOIBAK-2lD4,2465
-orquestra/sdk/_base/_factory.py,sha256=3c77X5DIR7PomySU1tmRjWsqnNLN_4zwjT5-7S_OfkI,1776
+orquestra/sdk/_base/_factory.py,sha256=VmkV2hJbByFzAatxRwoHUC7jBQEk3ACKf_gDs_liyaM,2524
 orquestra/sdk/_base/_git_url_utils.py,sha256=w_vrLwI0fNV6as0w-cCS-SI4Vu9iHTO9QrpnCqqA8B4,3703
-orquestra/sdk/_base/_graphs.py,sha256=fkoDOjh65a79y9hC8IWe6CZL6fcSO5tXXpgWqK52hNM,3021
-orquestra/sdk/_base/_in_process_runtime.py,sha256=u8zfKejgvuP0A9uxk9d3EnpHSTwO2fHCOaPKS_V7_K8,13216
+orquestra/sdk/_base/_graphs.py,sha256=UsT7KuCoJ5mwcmO2pqt9Mk4r46Of43cP1AqZ62QBecY,3714
+orquestra/sdk/_base/_in_process_runtime.py,sha256=NxrX6r1n--ZQ655tWW3QC7MQWJ65ocAvD3Q1cfeM5UY,13182
 orquestra/sdk/_base/_jwt.py,sha256=-VH1s1KHXxvdwNI8U7OgXXCB2-6l1OW-N9hsiMvsP-c,1104
-orquestra/sdk/_base/_log_adapter.py,sha256=OE1kFfnj5pmLERcVkSXbJqflrzpVW3R06qp6DhMPTOw,5245
+orquestra/sdk/_base/_log_adapter.py,sha256=fgv_QbmfNmvsUdnRLgHtYj3t2XvkH64uGhJDIRL-RnQ,1541
 orquestra/sdk/_base/_retry.py,sha256=2wtkwRPYNyT_eBQ4NuA7AweIsyGeX8WHiLAk3KpuJ34,1407
 orquestra/sdk/_base/_services.py,sha256=MlUZDt8cWhmMA41mLzSghX1-inzGUj24QYDmR9uvjG4,4180
 orquestra/sdk/_base/_traversal.py,sha256=ilvF3IuTBO_a5bIjb_mzLoaGO3Zr9LXlo_aIfdMphlg,32365
 orquestra/sdk/_base/_viz.py,sha256=gVPZ7ZgKsbdAMF6ojlOIdMHIRJZPztTwHUmdP27hNQA,4629
-orquestra/sdk/_base/_workflow.py,sha256=Elab8nSbZQNwb7_NwGZ4m3UMrmNfU4T4QmK0htJ0e-o,24415
-orquestra/sdk/_base/abc.py,sha256=aIxcCskk-DUR1H0Dj76RFrKHZ9pyGkgfxgV2db26Wh0,8205
+orquestra/sdk/_base/_workflow.py,sha256=t99v2hsOjkagKJy8nIvV2W38EFr35g5YodVvRzf4Rbs,23663
+orquestra/sdk/_base/abc.py,sha256=MkwV5HSl978IqONX9sXOOLbs89EMpGMThL42TpPUJJ0,7902
 orquestra/sdk/_base/dispatch.py,sha256=CkqfzvMp-hG9EZCvoaREavZ5VqXHx4iA0O_1kA497iw,11948
 orquestra/sdk/_base/loader.py,sha256=D7pAsKiAQXUoTL-jR_dOGZ2Kb4qL5Nd3PuFlcx2awgQ,6001
 orquestra/sdk/_base/serde.py,sha256=jpoW-hWRiVFkXqv6vtRgebZjZZPBPq5dDzUJG10uYJY,7004
 orquestra/sdk/_base/_api/__init__.py,sha256=1vzKQsIbKwhBl-dr5Jp_g8iJdDga7duGm_yXAeW00Xw,664
-orquestra/sdk/_base/_api/_config.py,sha256=B5IlN1BQO9xjiNI19RspzUzV-2zkvUSEB8g8o55Rcik,18506
-orquestra/sdk/_base/_api/_task_run.py,sha256=ZHc6eYh1rp_7N_nHIBZvJjIbZqUIuDhdqoR6HO9Ejag,13764
-orquestra/sdk/_base/_api/_wf_run.py,sha256=nQTNT2dJA3gD2ZkALQ2fDQaPjuRXXDha8d-6WTclY9I,25934
+orquestra/sdk/_base/_api/_config.py,sha256=FG72P-T3Y7DPt_UZ-N8w8J6GIXJaRs6tNJ_X3hhRMM8,16964
+orquestra/sdk/_base/_api/_task_run.py,sha256=FMOnBPlhPZ_ht7L4WWVJV3jF0Stfql-0p1T-Lt_5-oI,13819
+orquestra/sdk/_base/_api/_wf_run.py,sha256=yAtyjptn4m-f9DmAMgKPL0p2pyxcEFsKAJ06VAOT2ok,26367
 orquestra/sdk/_base/_conversions/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_conversions/_ids.py,sha256=XzGDloJatAsYT0Xh2xxa8wjoVrHCcyd5GjB7d4tiuq0,3509
 orquestra/sdk/_base/_conversions/_imports.py,sha256=bSBe5hze_nIQNFP8QDp6EbVS7tQnxONLyW_IfvyFlvA,7074
 orquestra/sdk/_base/_conversions/_invocations.py,sha256=HbjQJUBaxIRySl-SxBf5NgDm2cUZPLayzzODtuMzTZw,12943
 orquestra/sdk/_base/_conversions/_yaml_exporter.py,sha256=Jkzsl9ewDPaPMIUokTgEHMvZjNrgrN4mXG0S8oBnrz8,3905
 orquestra/sdk/_base/_db/__init__.py,sha256=PuHjzdpfVyenO9-b6kYLAgss_Zote-j3ypBjCxf9pA0,360
 orquestra/sdk/_base/_db/_db.py,sha256=AqEu3trs04bg5eAW_8kXavTgFtXjCjipyxxYfia8nso,5285
 orquestra/sdk/_base/_db/_migration.py,sha256=wjhxSBsN4Xr0jLEQuW75Eu92P2WRujeBPUU_B4UO3sQ,1331
 orquestra/sdk/_base/_driver/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
-orquestra/sdk/_base/_driver/_ce_runtime.py,sha256=oA7-wFrm_TYd3jjHDhIxYkXMOTbu8QzkjhHzQUDOF-Q,21708
-orquestra/sdk/_base/_driver/_client.py,sha256=U6oc8NJfJ74mnGvDfYNPpk787FkLmNQSZnuibuO_yRs,28297
+orquestra/sdk/_base/_driver/_ce_runtime.py,sha256=hTj42ivm4MRz_lrYJHPQb6tz1do3YsXOKfmzHxezsjw,21385
+orquestra/sdk/_base/_driver/_client.py,sha256=7nSoORkczrsU4oIb-dEZnAfrTshXemK6ABZnA9dd7qA,29246
 orquestra/sdk/_base/_driver/_exceptions.py,sha256=93BSuSRJYU9sR_IW_Awr9Q-bOms4JUtYwpD5YySC5Xs,4748
-orquestra/sdk/_base/_driver/_models.py,sha256=A5c32EQ_OgkqyJnKLXrfr_lgCYNiWUh5w8KX_B1CcxA,14128
-orquestra/sdk/_base/_logs/_interfaces.py,sha256=-YqnZsDb4FTyJzvjYj8cgnQNTqDip3PyplU38LSlIJY,2037
+orquestra/sdk/_base/_driver/_models.py,sha256=b414iuctztD1ENJRcEZ06pDArTR6vN76rxsTV4rJrCA,14142
+orquestra/sdk/_base/_logs/_interfaces.py,sha256=U8XGAcJErpwyUiQfGqNfcstNvut1uzOdQCsF6_rNKn0,3049
+orquestra/sdk/_base/_logs/_markers.py,sha256=LnYlnAn6ALVMMz9eNmLf9a7JTlJ-gesR1rUa5F8TNgU,4506
 orquestra/sdk/_base/_logs/_regrouping.py,sha256=ZGGKxOliVr7LtCzyPhT1kq4WSri4ZQh7IpMObwkPX4w,869
 orquestra/sdk/_base/_qe/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_qe/_client.py,sha256=qrlEGDobbrEVhGNzUtwO7kcgFC9Ia6CU-8UfqbTLjQ8,7212
-orquestra/sdk/_base/_qe/_qe_runtime.py,sha256=TcZzPaw1UV24rrT0TyfR9GrGW1Jb2-lj0Y0va19vPJs,35757
+orquestra/sdk/_base/_qe/_qe_runtime.py,sha256=SbQtD-9wVfOKEPnfmj4cWrBghMRu6nZtuhcKvw8LWuM,34798
 orquestra/sdk/_base/_spaces/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_spaces/_api.py,sha256=Ghu1h67ntZ4vB5SJiCD7x4g6z8aua4JY8eWYYZ_j2QM,1734
-orquestra/sdk/_base/_spaces/_resolver.py,sha256=dyrEf0i3KxBH7ouf_Ze05YkbQj_HJaFuMqkgjE8A8Wk,1555
+orquestra/sdk/_base/_spaces/_resolver.py,sha256=8HwVEq_uhon160VO4Bekn71HojZJXYezIy6n5INL1N4,1358
 orquestra/sdk/_base/_spaces/_structs.py,sha256=8EdEm9QOQ7tm2aUSkAIycSHOoiuSmGANCn29wPXWcMw,704
 orquestra/sdk/_base/_testing/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_testing/_connections.py,sha256=rWJR4jOytfFy9Hol7fREeHKmg5NuC3-panAstzY-MKE,4031
-orquestra/sdk/_base/_testing/_example_wfs.py,sha256=3hTCKUA5zYxyDZ9d522PKyc700QzEtLwRRoxvQ9aCzc,8219
+orquestra/sdk/_base/_testing/_example_wfs.py,sha256=T7DMXwchssseugsORdHd6nvhdM8T1fbg0p8MEfPg6mg,8104
 orquestra/sdk/_base/_testing/_ipc.py,sha256=jDpwNAfGBuYj-Vf8k5C-8JQnFvoBVldkEswshfnvIzY,1754
 orquestra/sdk/_base/_testing/_long_import.py,sha256=CQ2vLXnvZmmSrX0c4vi9agcWVox7S7Bxuy7eouQ_FZA,261
-orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py,sha256=hdUiVNb9Xk4xex1sjPbbb-LVbqyirSNq0zmvzfU88ow,17090
+orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py,sha256=WlORTKONPa339tVB8ZZnm7Z_ZAP7gi0ApgdWknGSR0Y,20208
 orquestra/sdk/_base/cli/_dorq/_cli_logs.py,sha256=XRSkORkipkHgdOyX41u7BOwszB3qp9kvY836BGqP0jw,698
-orquestra/sdk/_base/cli/_dorq/_dumpers.py,sha256=jb189V-isc1QeCN0Ti-erUH2v8-GAbhftoBhBGKi_Mc,3032
-orquestra/sdk/_base/cli/_dorq/_entry.py,sha256=pe5VBr3R8_TuCKjAPp0eRXiajwtF2E5VMrEbCUdsg3Q,11607
-orquestra/sdk/_base/cli/_dorq/_repos.py,sha256=Q5XlmbtdNEDST_TUftAJgcBPutW5ODkerJBjK4Dv09c,23358
-orquestra/sdk/_base/cli/_dorq/_login/_login.py,sha256=35v0FS6xs4_lJaFSSIWDTOLQAKmN9P494gjjjIq0pJE,5417
+orquestra/sdk/_base/cli/_dorq/_dumpers.py,sha256=ExXqqD943KHZGsGd3FX2hd4svld0SPNnAFquxsUTKzU,4406
+orquestra/sdk/_base/cli/_dorq/_entry.py,sha256=-1AggCO-jb99lAZkFaxP1d7TRmWfbNEvknpNqwWVy7w,13077
+orquestra/sdk/_base/cli/_dorq/_repos.py,sha256=Xe6k2PjPWzzp8SefInW_MPGtRXFLCjkgcG4uf_fZazE,23721
+orquestra/sdk/_base/cli/_dorq/_config/_list.py,sha256=DyN-JWmcEsVxNlMZgKNDIPIsgFMKgJ0qayr31Fi_OfQ,2255
+orquestra/sdk/_base/cli/_dorq/_login/_login.py,sha256=m5sVXVzrozOK5GT_YoAxdq2jdWvFq-9hejgF1GiWkKQ,5438
 orquestra/sdk/_base/cli/_dorq/_login/_login_server.py,sha256=hAC9M8PZaNNhj-nbkBajyMQoxu0dQgwFesmlwGcjVpc,1694
 orquestra/sdk/_base/cli/_dorq/_services/_down.py,sha256=7hW0i4fen-3f_CRyklcF0RMlR4VMQjDvkfEYzYWNiwQ,1621
 orquestra/sdk/_base/cli/_dorq/_services/_status.py,sha256=WGYYMAC8pUfIb9Jv0HJ7WMtiriiRBAYhk2O1MqY4M-U,1327
 orquestra/sdk/_base/cli/_dorq/_services/_up.py,sha256=P3tnCe6Pvj7MaJaZUXo3zaTiw52Y6hFQoo6_OPg1qE0,2656
 orquestra/sdk/_base/cli/_dorq/_task/_logs.py,sha256=4ea8Lg5KivWP6B3VyiS1Tv7fyUUQ_T6DLTvk5LBAMU8,3106
 orquestra/sdk/_base/cli/_dorq/_task/_results.py,sha256=2m8wEQ4YyBgz3QkIRQ8vDNNNdfsoVcmOGBSMRUHl1UM,3626
 orquestra/sdk/_base/cli/_dorq/_ui/__init__.py,sha256=nyIdSAJuZC_UDkwayYOvKpw-YJNvKu7n-vFY0I2-2tQ,367
+orquestra/sdk/_base/cli/_dorq/_ui/_click_default_group.py,sha256=s5zKcuUHNteDUrTLu52HzUVn9l0BvJRZuj_YfK4zdQc,6344
 orquestra/sdk/_base/cli/_dorq/_ui/_errors.py,sha256=lk1DtH38D2NEdxXDlNLYVDpS1K4CotI-9GMDJt63EnU,5520
-orquestra/sdk/_base/cli/_dorq/_ui/_models.py,sha256=Zr2f7gEPahHq7KHdOFSG7gxFFniOe_DcLX32kQKUrtA,1648
-orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py,sha256=yn1K153wDOovRWfy6sqwckaemp1mM0Z-2u_wdRwsvL8,12703
-orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py,sha256=asiXA775dItSKeEeKebWKw65W4o-AfXF68h3O3Zp49w,10249
+orquestra/sdk/_base/cli/_dorq/_ui/_models.py,sha256=TsJmfZdb5_GWoJbVNA9VofXiFEcjG6px_aU32QeRYzw,1668
+orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py,sha256=R_xl0W1RZ-YeZoM6EwB5Z0JNNz5r-nF0umVFl0ZCgxY,16101
+orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py,sha256=Ahb-KOBQ4nD2nl0z2DWYVo-jAwrdZR_c963nFa71f4U,10601
 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/color.py,sha256=FyabLjvjXvTHHVPjz7kCt05AcYhy3CjVvqq-UAQxrss,624
-orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/per_command.py,sha256=GJuqOLZq2BfCgSn14DODYXM_-eJBd6x3a78JDG_4f94,7794
+orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/per_command.py,sha256=UAMWhitOqBlTBk64b6KG-WVrS3t1ZEad6aV_2He6EsY,7815
 orquestra/sdk/_base/cli/_dorq/_workflow/_list.py,sha256=4CANU1u-auE7FEiuLwYwOka-H3tTynIT5i5nqEhqVHk,5180
-orquestra/sdk/_base/cli/_dorq/_workflow/_logs.py,sha256=ZoVMk1OmXdS8950_zfb88yXS0yUb5dpM50QOSiRWoCI,2739
+orquestra/sdk/_base/cli/_dorq/_workflow/_logs.py,sha256=IIQpRWL_B2pWQiDGwWjgDZAeCdMSINJLstg4qwCo7rI,4012
 orquestra/sdk/_base/cli/_dorq/_workflow/_results.py,sha256=3rbRSBSvOfyAia2-NREeMUWxaRbldPdVQ-norwWjOl8,3140
 orquestra/sdk/_base/cli/_dorq/_workflow/_stop.py,sha256=qHtdYjsWymV__J0yHeb54DgxbipeAJiJLZCLKdnSWFY,2621
 orquestra/sdk/_base/cli/_dorq/_workflow/_submit.py,sha256=bP6MvjXeXCZyVo0f-4GUleySxwRcvaQ9WolBqeBVJfk,5087
 orquestra/sdk/_base/cli/_dorq/_workflow/_view.py,sha256=2bnKN1kMTbacy0PUMXAFGhfQ4GPZlaIhwnTaI8Zu9zg,2138
 orquestra/sdk/_ray/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
-orquestra/sdk/_ray/_build_workflow.py,sha256=2fgHSmxri1AE30KozaUOrojfoXhyUTwHxGbtoUIYOvo,18425
+orquestra/sdk/_ray/_build_workflow.py,sha256=OLsFO8oXHyhRrdpWjFkw4pvjC6uEMpc5pG9iXh0ZCu0,20192
 orquestra/sdk/_ray/_client.py,sha256=ce1rCGH5zHqz--aneOGb7hjwcJmL8mCSkcImsqih4Rc,6644
-orquestra/sdk/_ray/_dag.py,sha256=74eR99_cRFJe3jjlTFExQcwopOAs7EBQZxxvTR9n0Mk,21405
+orquestra/sdk/_ray/_dag.py,sha256=jDJctvv_OwcdWVoCydTFOYs5LVtTiNsfWsyjqDZQu9k,19522
 orquestra/sdk/_ray/_id_gen.py,sha256=VELgM5qq2pmHZIuDIKdbtYACcGRdY2aZvt9jxOEmJQ8,867
-orquestra/sdk/_ray/_ray_logs.py,sha256=NWcTnESfOSe3zeqv-Wj9jVpMUBgo9ZEFW0San4nybxo,5064
+orquestra/sdk/_ray/_ray_logs.py,sha256=Y-gTMeaasOaHxTJ49PiMP5vb69mpTonXa7TPzzUvgoM,7327
 orquestra/sdk/_ray/_wf_metadata.py,sha256=9DKDFw5rUepke5PYYm7cMEknvlqMH12Zl71pmbVxFbA,1278
 orquestra/sdk/examples/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/examples/exportable_wf.py,sha256=vd7yx2aelszLOwxpWJkrvzZ9HSl22Je-fB6LEzEna68,1558
 orquestra/sdk/examples/workflow_defs.py,sha256=1z_MrqEPnScNescLLF4eWDepm5fwxcIIagMU8AFfUKs,1116
 orquestra/sdk/kubernetes/__init__.py,sha256=fmqiLNRiTWLjlWlynWbcgaBq6N5YkP-qoM2qgZluuM4,318
 orquestra/sdk/kubernetes/quantity.py,sha256=4t43AJQQYBXiugNruhSHMIlmxK5kunod5TkP8EZTjVU,2420
+orquestra/sdk/mlflow/__init__.py,sha256=yt5_ZrIvSC6M6NIMA1FOnshNh9IbVguA_z4Qoel0EnI,370
+orquestra/sdk/mlflow/_connection_utils.py,sha256=dRYX40k75Mej53VuS3iTDIAN0OVKo4a1bzhFicNpIyM,1319
 orquestra/sdk/packaging/__init__.py,sha256=fj3mB81q3BZa_-_o8UvipKA6Yvr41x6OtCv56p4HPls,427
 orquestra/sdk/packaging/_versions.py,sha256=cI9TKy7HmJYC516bry7kByaP6B2OL18REqYLTClb0Bg,4144
 orquestra/sdk/schema/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/schema/_compat.py,sha256=1rG5HFCaGfuFpmmDuzMTs5TH0OnHdB2xblBzRTecAUs,1874
 orquestra/sdk/schema/configs.py,sha256=ZR1VJ962yquyJYTWY-5HAyTEhSE8AOMz1KAcDDRMIkk,1578
 orquestra/sdk/schema/ir.py,sha256=fF-MHVT1ApUH41KX0NSEvPpMBCUe7HD79za3jsufI0M,15130
 orquestra/sdk/schema/local_database.py,sha256=7h7_qUs9lJV0Ers0wjscTyQ3r4L6z0-Id5qB-hUBuPw,848
 orquestra/sdk/schema/responses.py,sha256=sYCGJOhkHYcJ_08v8KapqlJwrZQah-7Ipp7dI3HoFjA,4745
-orquestra/sdk/schema/workflow_run.py,sha256=Fok_7F6tmzMAb02pnMLLYnXpRpymem4yrsGuYisWXUY,1596
+orquestra/sdk/schema/workflow_run.py,sha256=_rVA4MSNoMotK5r18vBERzKB0pK1FEokTHunxRXwwrA,1611
 orquestra/sdk/schema/yaml_model.py,sha256=Y58Hm6rHILeOx3rMp6L7BQKkR35U3iprOexDqoGi6ro,4114
 orquestra/sdk/secrets/__init__.py,sha256=Ayi-FYjTmw7TwuQiDPf06in9q26o7jJ27ZTCvGEwc98,1104
-orquestra/sdk/secrets/_api.py,sha256=7NfFuUmQnPqRYUhavRzey4ls-665l_wj0NPmsOyejME,6658
-orquestra/sdk/secrets/_auth.py,sha256=bubkhPp1K557VeUNOKMvBwStUsL1Oet1ZwW5ldsrsjo,2090
+orquestra/sdk/secrets/_api.py,sha256=sf2-dTqJB-02uCV5dG1N0VineJwq_QJaSm6NAwUxGmo,7254
+orquestra/sdk/secrets/_auth.py,sha256=qvzDs82hNOxrRSIqrKlx85VEUR9ks8EPtYJpm-75Lmk,2232
 orquestra/sdk/secrets/_client.py,sha256=MOfBkqHQOpHCaznHZhvvP20x9u0XFrVg_tGtCoGtF6c,5600
 orquestra/sdk/secrets/_exceptions.py,sha256=V7I9v07EAp4gcaJqtkONqJcnGvH8khJInQ_P5IF4sP8,1222
 orquestra/sdk/secrets/_models.py,sha256=kzVe5R3J5wTZAHwosjMXyI0mSpTp0bpyXI73M0IPgb4,1679
 orquestra/sdk/v2/__init__.py,sha256=hXnYIFBFQmJ59Bf-2XpFl2F1qyzWo1QHBG32cdSxlds,1072
-orquestra_sdk-0.51.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-orquestra_sdk-0.51.0.dist-info/METADATA,sha256=Rym3WD2RzBOiysWjopUeLVoKCGHKYcIluofZpYw980k,3147
-orquestra_sdk-0.51.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-orquestra_sdk-0.51.0.dist-info/entry_points.txt,sha256=LAvqi1JMVvS8kqr1VpGrTE8PxbuQiQ5Q9FqgD3k0JqI,66
-orquestra_sdk-0.51.0.dist-info/top_level.txt,sha256=I3GLQbK_gqa5pjIjuEVYddNALTZjwfdtgqvscclR78M,10
-orquestra_sdk-0.51.0.dist-info/RECORD,,
+orquestra_sdk-0.52.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+orquestra_sdk-0.52.0.dist-info/METADATA,sha256=qNSMDC_OIuOUbG-5Q_qcYTD2Oh1UtBuCjyaPV7AUDjg,3147
+orquestra_sdk-0.52.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+orquestra_sdk-0.52.0.dist-info/entry_points.txt,sha256=LAvqi1JMVvS8kqr1VpGrTE8PxbuQiQ5Q9FqgD3k0JqI,66
+orquestra_sdk-0.52.0.dist-info/top_level.txt,sha256=I3GLQbK_gqa5pjIjuEVYddNALTZjwfdtgqvscclR78M,10
+orquestra_sdk-0.52.0.dist-info/RECORD,,
```

