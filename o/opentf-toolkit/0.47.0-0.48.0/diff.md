# Comparing `tmp/opentf_toolkit-0.47.0-py3-none-any.whl.zip` & `tmp/opentf_toolkit-0.48.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,48 +1,49 @@
-Zip file size: 71188 bytes, number of entries: 46
--rw-r--r--  2.0 unx    40202 b- defN 23-May-25 07:20 opentf/commons/__init__.py
--rw-r--r--  2.0 unx    14520 b- defN 23-May-25 07:20 opentf/commons/expressions.py
--rw-r--r--  2.0 unx     5521 b- defN 23-May-25 07:20 opentf/commons/selectors.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-25 07:20 opentf/schemas/__init__.py
--rw-rw-rw-  2.0 unx     2105 b- defN 23-May-25 07:20 opentf/schemas/abac.opentestfactory.org/v1alpha1/Policy.json
--rw-rw-rw-  2.0 unx     1230 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/AgentRegistration.json
--rw-rw-rw-  2.0 unx     1366 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/AllureCollectorOutput.json
--rw-rw-rw-  2.0 unx     1239 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/ChannelHandlerHooks.json
--rw-rw-rw-  2.0 unx     2174 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/EventBusConfig.json
--rw-rw-rw-  2.0 unx     2702 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/ExecutionCommand.json
--rw-rw-rw-  2.0 unx     1347 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/ExecutionError.json
--rw-rw-rw-  2.0 unx     3050 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/ExecutionResult.json
--rw-rw-rw-  2.0 unx     1754 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/GeneratorCommand.json
--rw-rw-rw-  2.0 unx     6633 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/GeneratorResult.json
--rw-rw-rw-  2.0 unx     3790 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/Notification.json
--rw-rw-rw-  2.0 unx     2803 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/PluginMetadata.json
--rw-rw-rw-  2.0 unx     2875 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/ProviderCommand.json
--rw-rw-rw-  2.0 unx     3878 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/ProviderConfig.json
--rw-rw-rw-  2.0 unx     4259 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/ProviderResult.json
--rw-rw-rw-  2.0 unx     6301 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/SSHServiceConfig.json
--rw-rw-rw-  2.0 unx     2835 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/ServiceConfig.json
--rw-rw-rw-  2.0 unx     2810 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/Subscription.json
--rw-rw-rw-  2.0 unx     9899 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/Workflow.json
--rw-rw-rw-  2.0 unx     1351 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/WorkflowCanceled.json
--rw-rw-rw-  2.0 unx     1292 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/WorkflowCompleted.json
--rw-rw-rw-  2.0 unx     1577 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha1/WorkflowResult.json
--rw-rw-rw-  2.0 unx     2232 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha2/Notification.json
--rw-rw-rw-  2.0 unx     6612 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1alpha2/SSHServiceConfig.json
--rw-rw-rw-  2.0 unx     4273 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1beta1/ExecutionCommand.json
--rw-rw-rw-  2.0 unx    10205 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1beta1/GeneratorResult.json
--rw-rw-rw-  2.0 unx     4581 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1beta1/ProviderCommand.json
--rw-rw-rw-  2.0 unx     4563 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1beta1/ProviderConfig.json
--rw-rw-rw-  2.0 unx     7494 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1beta1/ProviderResult.json
--rw-rw-rw-  2.0 unx     2850 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1beta1/ServiceConfig.json
--rw-rw-rw-  2.0 unx    15424 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1beta1/Workflow.json
--rw-rw-rw-  2.0 unx     3517 b- defN 23-May-25 07:20 opentf/schemas/opentestfactory.org/v1beta2/ServiceConfig.json
--rw-rw-rw-  2.0 unx     1579 b- defN 23-May-25 07:20 opentf/scripts/launch_java_service.sh
--rw-r--r--  2.0 unx    18703 b- defN 23-May-25 07:20 opentf/scripts/startup.py
--rw-r--r--  2.0 unx    18927 b- defN 23-May-25 07:20 opentf/toolkit/__init__.py
--rw-r--r--  2.0 unx    13130 b- defN 23-May-25 07:20 opentf/toolkit/channels.py
--rw-r--r--  2.0 unx     7314 b- defN 23-May-25 07:20 opentf/toolkit/core.py
--rw-rw-rw-  2.0 unx    11357 b- defN 23-May-25 07:20 opentf_toolkit-0.47.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     1875 b- defN 23-May-25 07:20 opentf_toolkit-0.47.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-25 07:20 opentf_toolkit-0.47.0.dist-info/WHEEL
--rw-r--r--  2.0 unx        7 b- defN 23-May-25 07:20 opentf_toolkit-0.47.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     5030 b- defN 23-May-25 07:20 opentf_toolkit-0.47.0.dist-info/RECORD
-46 files, 267278 bytes uncompressed, 62746 bytes compressed:  76.5%
+Zip file size: 73248 bytes, number of entries: 47
+-rw-r--r--  2.0 unx    40261 b- defN 23-Jul-11 10:19 opentf/commons/__init__.py
+-rw-r--r--  2.0 unx    17538 b- defN 23-Jul-11 10:19 opentf/commons/expressions.py
+-rw-r--r--  2.0 unx     5521 b- defN 23-Jul-11 10:19 opentf/commons/selectors.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-11 10:19 opentf/schemas/__init__.py
+-rw-rw-rw-  2.0 unx     2105 b- defN 23-Jul-11 10:19 opentf/schemas/abac.opentestfactory.org/v1alpha1/Policy.json
+-rw-rw-rw-  2.0 unx     1230 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/AgentRegistration.json
+-rw-rw-rw-  2.0 unx     1366 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/AllureCollectorOutput.json
+-rw-rw-rw-  2.0 unx     1239 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/ChannelHandlerHooks.json
+-rw-rw-rw-  2.0 unx     2174 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/EventBusConfig.json
+-rw-rw-rw-  2.0 unx     2702 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/ExecutionCommand.json
+-rw-rw-rw-  2.0 unx     1347 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/ExecutionError.json
+-rw-rw-rw-  2.0 unx     3050 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/ExecutionResult.json
+-rw-rw-rw-  2.0 unx     1754 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/GeneratorCommand.json
+-rw-rw-rw-  2.0 unx     6633 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/GeneratorResult.json
+-rw-rw-rw-  2.0 unx     3790 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/Notification.json
+-rw-rw-rw-  2.0 unx     2803 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/PluginMetadata.json
+-rw-rw-rw-  2.0 unx     2875 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/ProviderCommand.json
+-rw-rw-rw-  2.0 unx     3878 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/ProviderConfig.json
+-rw-rw-rw-  2.0 unx     4259 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/ProviderResult.json
+-rw-rw-rw-  2.0 unx     2898 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/QualityGate.json
+-rw-rw-rw-  2.0 unx     6301 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/SSHServiceConfig.json
+-rw-rw-rw-  2.0 unx     2835 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/ServiceConfig.json
+-rw-rw-rw-  2.0 unx     2810 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/Subscription.json
+-rw-rw-rw-  2.0 unx     9899 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/Workflow.json
+-rw-rw-rw-  2.0 unx     1351 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/WorkflowCanceled.json
+-rw-rw-rw-  2.0 unx     1292 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/WorkflowCompleted.json
+-rw-rw-rw-  2.0 unx     1577 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha1/WorkflowResult.json
+-rw-rw-rw-  2.0 unx     2232 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha2/Notification.json
+-rw-rw-rw-  2.0 unx     6612 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1alpha2/SSHServiceConfig.json
+-rw-rw-rw-  2.0 unx     4273 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1beta1/ExecutionCommand.json
+-rw-rw-rw-  2.0 unx    10205 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1beta1/GeneratorResult.json
+-rw-rw-rw-  2.0 unx     4581 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1beta1/ProviderCommand.json
+-rw-rw-rw-  2.0 unx     4563 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1beta1/ProviderConfig.json
+-rw-rw-rw-  2.0 unx     7494 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1beta1/ProviderResult.json
+-rw-rw-rw-  2.0 unx     2850 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1beta1/ServiceConfig.json
+-rw-rw-rw-  2.0 unx    15424 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1beta1/Workflow.json
+-rw-rw-rw-  2.0 unx     3517 b- defN 23-Jul-11 10:19 opentf/schemas/opentestfactory.org/v1beta2/ServiceConfig.json
+-rw-rw-rw-  2.0 unx     1579 b- defN 23-Jul-11 10:19 opentf/scripts/launch_java_service.sh
+-rw-r--r--  2.0 unx    18703 b- defN 23-Jul-11 10:19 opentf/scripts/startup.py
+-rw-r--r--  2.0 unx    19227 b- defN 23-Jul-11 10:19 opentf/toolkit/__init__.py
+-rw-r--r--  2.0 unx    16089 b- defN 23-Jul-11 10:19 opentf/toolkit/channels.py
+-rw-r--r--  2.0 unx     7314 b- defN 23-Jul-11 10:19 opentf/toolkit/core.py
+-rw-rw-rw-  2.0 unx    11357 b- defN 23-Jul-11 10:19 opentf_toolkit-0.48.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     1966 b- defN 23-Jul-11 10:19 opentf_toolkit-0.48.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-11 10:19 opentf_toolkit-0.48.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        7 b- defN 23-Jul-11 10:19 opentf_toolkit-0.48.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     5147 b- defN 23-Jul-11 10:19 opentf_toolkit-0.48.0.dist-info/RECORD
+47 files, 276720 bytes uncompressed, 64610 bytes compressed:  76.7%
```

## zipnote {}

```diff
@@ -51,14 +51,17 @@
 
 Filename: opentf/schemas/opentestfactory.org/v1alpha1/ProviderConfig.json
 Comment: 
 
 Filename: opentf/schemas/opentestfactory.org/v1alpha1/ProviderResult.json
 Comment: 
 
+Filename: opentf/schemas/opentestfactory.org/v1alpha1/QualityGate.json
+Comment: 
+
 Filename: opentf/schemas/opentestfactory.org/v1alpha1/SSHServiceConfig.json
 Comment: 
 
 Filename: opentf/schemas/opentestfactory.org/v1alpha1/ServiceConfig.json
 Comment: 
 
 Filename: opentf/schemas/opentestfactory.org/v1alpha1/Subscription.json
@@ -117,23 +120,23 @@
 
 Filename: opentf/toolkit/channels.py
 Comment: 
 
 Filename: opentf/toolkit/core.py
 Comment: 
 
-Filename: opentf_toolkit-0.47.0.dist-info/LICENSE
+Filename: opentf_toolkit-0.48.0.dist-info/LICENSE
 Comment: 
 
-Filename: opentf_toolkit-0.47.0.dist-info/METADATA
+Filename: opentf_toolkit-0.48.0.dist-info/METADATA
 Comment: 
 
-Filename: opentf_toolkit-0.47.0.dist-info/WHEEL
+Filename: opentf_toolkit-0.48.0.dist-info/WHEEL
 Comment: 
 
-Filename: opentf_toolkit-0.47.0.dist-info/top_level.txt
+Filename: opentf_toolkit-0.48.0.dist-info/top_level.txt
 Comment: 
 
-Filename: opentf_toolkit-0.47.0.dist-info/RECORD
+Filename: opentf_toolkit-0.48.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## opentf/commons/__init__.py

```diff
@@ -75,14 +75,16 @@
 
 NOTIFICATION = 'opentestfactory.org/v1alpha1/Notification'
 
 ALLURE_COLLECTOR_OUTPUT = 'opentestfactory.org/v1alpha1/AllureCollectorOutput'
 
 CHANNEL_HOOKS = 'opentestfactory.org/v1alpha1/ChannelHandlerHooks'
 
+QUALITY_GATE = 'opentestfactory.org/v1alpha1/QualityGate'
+
 POLICY = 'abac.opentestfactory.org/v1alpha1/Policy'
 
 DEFAULT_HEADERS = {
     'Content-Type': 'application/json',
     'Strict-Transport-Security': 'max-age=31536000; includeSubdomains',
     'X-Frame-Options': 'SAMEORIGIN',
     'X-Content-Type-Options': 'nosniff',
```

## opentf/commons/expressions.py

```diff
@@ -10,44 +10,52 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Expressions helpers"""
 
-from typing import Any, Dict, List, Optional, Tuple
+from typing import Any, Dict, List, Optional, Tuple, Union
 
+import json
 import re
 
-
 ## Expressions
 
 STRING = r'(\'([^\']*)\')+'
 IDENTIFIER = r'^[a-zA-Z_][a-zA-Z0-9_-]*'
 NUMBER = r'^(0x[0-9a-fA-F]+)|(-?\d+(\.\d+)?)'
-OPERATOR = r'^(==|!=|!|<=|<|>=|>|\[|\]|\(|\)|\.|&&|\|\||~=)'
+OPERATOR = r'^(==|!=|!|<=|<|>=|>|\[|\]|\(|\)|\.|&&|\|\||~=|,)'
 
-INFIX_OPERATOR = ['==', '!=', '<=', '<', '>', '>=', '&&', '||', '~=']
+INFIX_OPERATOR = ('==', '!=', '<=', '<', '>', '>=', '&&', '||', '~=')
 
 VALUE = 0
 KIND = 1
 
-STRING_TOKEN = 1
-IDENTIFIER_TOKEN = 2
-NUMBER_TOKEN = 3
-OPERATOR_TOKEN = 4
-END_TOKEN = 0
-
-TOKEN = Tuple[Optional[str], int]
+STRING_KIND = 1
+IDENTIFIER_KIND = 2
+NUMBER_KIND = 3
+OPERATOR_KIND = 4
+END_KIND = 0
+
+TOKEN_VALUE = Union[str, int, float]
+TOKEN = Tuple[Optional[TOKEN_VALUE], int]
+
+DEREFERENCE_TOKEN: TOKEN = ('.', OPERATOR_KIND)
+INDEX_TOKEN: TOKEN = ('[', OPERATOR_KIND)
+LPAREN_TOKEN: TOKEN = ('(', OPERATOR_KIND)
+RPAREN_TOKEN: TOKEN = (')', OPERATOR_KIND)
+COMMA_TOKEN: TOKEN = (',', OPERATOR_KIND)
+END_TOKEN: TOKEN = (None, END_KIND)
 
 ########################################################################
 ## Tokenizer
 
 
-def get_token(expr: str):
+def get_token(expr: str) -> Tuple[TOKEN_VALUE, int, str]:
     """Get first token in expr.
 
     # Required parameters
 
     - expr: a string
 
     # Returned value
@@ -55,30 +63,30 @@
     A tuple of three elements: `token`, `kind`, `expr`.
 
     # Raised exceptions
 
     A _ValueError_ exception is raised if the token is invalid.
     """
     if match := re.match(IDENTIFIER, expr):
-        return match.group(0), IDENTIFIER_TOKEN, expr[match.end() :].strip()
+        return match.group(0), IDENTIFIER_KIND, expr[match.end() :].strip()
     if match := re.match(STRING, expr):
         return (
             match.group(0)[1:-1].replace("''", "'"),
-            STRING_TOKEN,
+            STRING_KIND,
             expr[match.end() :].strip(),
         )
     if match := re.match(NUMBER, expr):
         num = match.group(0)
         if num.startswith('0x'):
             num = int(num, 16)
         else:
             num = float(num)
-        return num, NUMBER_TOKEN, expr[match.end() :].strip()
+        return num, NUMBER_KIND, expr[match.end() :].strip()
     if match := re.match(OPERATOR, expr):
-        return match.group(0), OPERATOR_TOKEN, expr[match.end() :].strip()
+        return match.group(0), OPERATOR_KIND, expr[match.end() :].strip()
     raise ValueError(f'Invalid token {expr}')
 
 
 def tokenize(expr: str) -> List[TOKEN]:
     """Return a list of tokens found in expr.
 
     # Required parameters
@@ -90,52 +98,36 @@
     A list of _tokens_.  Each token is a (value, kind) pair.  The list
     ends with an `(None, END_TOKEN)` pair.
 
     # Raised exceptions
 
     A _ValueError_ is raised if `expr` contains an invalid token.
     """
-    tokens = []
+    tokens: List[TOKEN] = []
     while expr:
         token, kind, expr = get_token(expr)
         tokens.append((token, kind))
-    tokens.append((None, END_TOKEN))
+    tokens.append(END_TOKEN)
     return tokens
 
 
 ########################################################################
 ## Operators helpers
 
 
 def _is_infix_operator(token: TOKEN) -> bool:
-    return token[KIND] == OPERATOR_TOKEN and token[VALUE] in INFIX_OPERATOR
-
-
-def _is_dereference(token: TOKEN) -> bool:
-    return token[KIND] == OPERATOR_TOKEN and token[VALUE] == '.'
-
-
-def _is_index(token: TOKEN) -> bool:
-    return token[KIND] == OPERATOR_TOKEN and token[VALUE] == '['
+    return token[KIND] == OPERATOR_KIND and token[VALUE] in INFIX_OPERATOR
 
 
 def _is_segment_start(token: TOKEN) -> bool:
-    return _is_dereference(token) or _is_index(token)
-
-
-def _is_lparen(token: TOKEN) -> bool:
-    return token[KIND] == OPERATOR_TOKEN and token[VALUE] == '('
-
-
-def _is_rparen(token: TOKEN) -> bool:
-    return token[KIND] == OPERATOR_TOKEN and token[VALUE] == ')'
+    return token in (DEREFERENCE_TOKEN, INDEX_TOKEN)
 
 
 def _is_identifier(token: TOKEN) -> bool:
-    return token[KIND] == IDENTIFIER_TOKEN
+    return token[KIND] == IDENTIFIER_KIND
 
 
 def _is_boolean(token: TOKEN) -> bool:
     return (
         _is_identifier(token)
         and isinstance(value := token[VALUE], str)
         and value.lower() in ('true', 'false')
@@ -147,15 +139,40 @@
         _is_identifier(token)
         and isinstance(value := token[VALUE], str)
         and value.lower() == 'null'
     )
 
 
 def _is_string(token: TOKEN) -> bool:
-    return token[KIND] == STRING_TOKEN
+    return token[KIND] == STRING_KIND
+
+
+def _to_number(val: Any) -> float:
+    if val is None or val == '':
+        return 0
+    if isinstance(val, bool):
+        return 1 if val else 0
+    if isinstance(val, str):
+        try:
+            return float(val)
+        except ValueError:
+            return float('nan')
+    if isinstance(val, (int, float)):
+        return float(val)
+    return float('nan')
+
+
+def _to_string(val: Any) -> str:
+    if val is None:
+        return ''
+    if isinstance(val, bool):
+        return str(val).lower()
+    if isinstance(val, float) and float(int(val)) == val:
+        return str(int(val))
+    return str(val)
 
 
 ########################################################################
 ## Path helpers
 
 
 def find_path(tokens: List[TOKEN], start: int) -> int:
@@ -163,15 +180,15 @@
 
     A _path_ is an identifier, possibly followed by segments.  Segments
     are of the form `.identifier` or `[term]`, where `term` is either a
     path or a string.
     """
     path_len = 1
     while _is_segment_start(tokens[start + path_len]):
-        if _is_dereference(tokens[start + path_len]):
+        if tokens[start + path_len] == DEREFERENCE_TOKEN:
             if not _is_identifier(tokens[start + path_len + 1]):
                 raise ValueError(
                     f'Invalid token, was expecting identifier {tokens[start+path_len+1]}'
                 )
             path_len += 2
         else:
             if _is_string(tokens[start + path_len + 1]):
@@ -181,61 +198,56 @@
             else:
                 raise ValueError(
                     f'Invalid token, was expecting identifier or string {tokens[start+path_len+1]}'
                 )
     return path_len
 
 
-def evaluate_path(path, contexts):
+def evaluate_path(
+    path: List[TOKEN], contexts: Dict[str, Any]
+) -> Union[str, Dict[str, Any]]:
     """Evaluate path using contexts.
 
     The path is syntactically valid.
+
+    If the final part of `path` does not exist in `contexts`, returns
+    an empty string.
+
+    # Raised exceptions
+
+    A _ValueError_ exception is raised if `path` does not start with
+    a context available in `contexts`.
     """
 
-    def _evaluate_segments(start, value):
+    def _evaluate_segments(start: int, value):
         if not _is_segment_start(path[start]):
             return value
-        if _is_dereference(path[start]):
+        if path[start] == DEREFERENCE_TOKEN:
             if _is_segment_start(path[start + 2]):
                 return _evaluate_segments(start + 2, value[path[start + 1][VALUE]])
-            return value[path[start + 1][VALUE]]
+            return value.get(path[start + 1][VALUE], '')
 
-        if path[start + 1][KIND] == STRING_TOKEN:
+        if path[start + 1][KIND] == STRING_KIND:
             what = path[start + 1][VALUE]
             if _is_segment_start(path[start + 3]):
                 return _evaluate_segments(start + 3, value[what])
         else:
             path_len = find_path(path, start + 1)
             what = evaluate_path(path[start + 1 : start + 1 + path_len + 1], contexts)
             if _is_segment_start(path[start + 1 + path_len + 1]):
                 return _evaluate_segments(start + 1 + path_len + 1, value[what])
-        return value[what]
+        return value.get(what, '')
 
     segment = path[0][VALUE]
     if segment not in contexts:
         raise ValueError(f'Invalid segment {segment} or incorrect function call')
 
     return _evaluate_segments(1, contexts[segment])
 
 
-def _to_number(val: Any) -> float:
-    if val is None or val == '':
-        return 0
-    if isinstance(val, bool):
-        return 1 if val else 0
-    if isinstance(val, str):
-        try:
-            return float(val)
-        except ValueError:
-            return float('nan')
-    if isinstance(val, (int, float)):
-        return float(val)
-    return float('nan')
-
-
 def evaluate_operation(lhs, operator: str, rhs) -> bool:
     """Perform binary operation evaluation.
 
     Type casting performed as per specification.
 
     # Required parameters
 
@@ -255,15 +267,15 @@
         rhs = _to_number(rhs)
     if operator == '==':
         return lhs == rhs
     if operator == '!=':
         return lhs != rhs
     if operator == '~=':
         if isinstance(lhs, str) and isinstance(rhs, str):
-            return re.search(rhs, lhs) != None
+            return re.search(rhs, lhs) is not None
         raise ValueError(
             f'Operator {operator} requires strings, got {lhs!r} and {rhs!r}.'
         )
     if operator == '<':
         return lhs < rhs  # type: ignore
     if operator == '<=':
         return lhs <= rhs  # type: ignore
@@ -275,57 +287,96 @@
         return lhs and rhs  # type: ignore
     if operator == '||':
         return lhs or rhs  # type: ignore
     raise ValueError(f'Unknown operator {operator}')
 
 
 def evaluate_tokenized(
-    tokens: List[TOKEN], contexts, start: int, end_token=(None, END_TOKEN)
-) -> Tuple[Optional[int], Any]:
+    tokens: List[TOKEN],
+    contexts: Dict[str, Any],
+    start: int,
+    end_token: Union[TOKEN, List[TOKEN]] = END_TOKEN,
+) -> Tuple[Optional[int], Optional[Any]]:
     """Perform tokenized expression evaluation, using contexts.
 
     # Required parameters
 
     - tokens: a list of _tokens_
     - contexts: a dictionary
     - start: an integer
 
+    # Optional parameters
+
+    - end_token: a pair (integer or None, token)
+
     # Returned value
 
     An object (depending on `tokens`).  Could be a boolean, a number, a
     string, a list, or a dictionary.
+
+    # Raised exceptions
+
+    A _ValueError_ exception is raised if the expression is not valid.
     """
     kind = tokens[start][KIND]
-    if kind == END_TOKEN:
+    if kind == END_KIND:
         return None, None
-    if kind == IDENTIFIER_TOKEN:
+    if kind == IDENTIFIER_KIND:
         if _is_boolean(tokens[start]):
             what = tokens[start][VALUE].lower() == 'true'  # type: ignore
             path = 1
         elif _is_null(tokens[start]):
             what = None
             path = 1
-        elif _is_lparen(tokens[start + 1]) and _is_rparen(tokens[start + 2]):
+        elif tokens[start + 1] == LPAREN_TOKEN and tokens[start + 2] == RPAREN_TOKEN:
             what = evaluate_status_function(tokens[start][VALUE], contexts)  # type: ignore
             path = 3
+        elif tokens[start + 1] == LPAREN_TOKEN:
+            function_name: str = tokens[start][VALUE]  # type: ignore
+            path, what = evaluate_tokenized(
+                tokens, contexts, start + 2, [COMMA_TOKEN, RPAREN_TOKEN]
+            )
+            if path is None:
+                raise ValueError(
+                    'Unexpected end of expression, was expecting comma or right parenthesis'
+                )
+            if tokens[start + 1 + path + 1] == COMMA_TOKEN:
+                path2, what2 = evaluate_tokenized(
+                    tokens, contexts, start + 1 + path + 2, RPAREN_TOKEN
+                )
+                if path2 is None:
+                    raise ValueError(
+                        'Unexpected end of expression, was expecting right parenthesis'
+                    )
+                if tokens[start + 1 + path + path2 + 2] != RPAREN_TOKEN:
+                    raise ValueError(
+                        f'Invalid token, was expecting right parenthesis: {tokens[start+1+path+path2+1]}'
+                    )
+                what = evaluate_function_arity_2(function_name, what, what2)
+                path = 1 + path + path2 + 3
+            elif tokens[start + 1 + path + 1] == RPAREN_TOKEN:
+                what = evaluate_function_arity_1(function_name, what)
+                path += 3
+            else:
+                raise ValueError(
+                    f'Invalid token, was expecting comma or right parenthesis: {tokens[start+1+path+1]}'
+                )
         else:
             path = find_path(tokens, start)
             what = evaluate_path(tokens[start : start + path + 1], contexts)
-    elif kind in (STRING_TOKEN, NUMBER_TOKEN):
+    elif kind in (STRING_KIND, NUMBER_KIND):
         what = tokens[start][VALUE]
         path = 1
-    elif _is_lparen(tokens[start]):
-        path, what = evaluate_tokenized(
-            tokens, contexts, start + 1, (')', OPERATOR_TOKEN)
-        )
+    elif tokens[start] == LPAREN_TOKEN:
+        path, what = evaluate_tokenized(tokens, contexts, start + 1, RPAREN_TOKEN)
         if path is None:
             raise ValueError(
                 'Unexpected end of expression, was expecting right parenthesis'
             )
-        if not _is_rparen(tokens[start + path + 1]):
+        if tokens[start + path + 1] != RPAREN_TOKEN:
             raise ValueError(
                 f'Invalid token, was expecting right parenthesis: {tokens[start+path+1]}'
             )
         path += 2
     else:
         raise ValueError(
             f'Invalid token, was expecting identifier, string or number, got: {tokens[start]}'
@@ -337,25 +388,60 @@
         if path_rhs is None:
             raise ValueError(
                 f'Unexpected end of expression after: {tokens[start+path]}'
             )
         return path + 1 + path_rhs, evaluate_operation(
             what, tokens[start + path][VALUE], rhs  # type: ignore
         )
-    if tokens[start + path] == end_token:
+
+    if tokens[start + path] == end_token or tokens[start + path] in end_token:
         return path, what
 
     eot = '' if end_token[0] is None else f' or "{end_token[0]}"'
     if tokens[start + path][0] is None:
         raise ValueError(f'Unexpected end of expression, was expecting operator{eot}')
     raise ValueError(
         f'Invalid token, was expecting operator{eot}, got: {tokens[start+path]}'
     )
 
 
+def evaluate_function_arity_1(name: str, arg) -> Any:
+    if name == 'fromJSON':
+        return json.loads(arg)
+    if name == 'toJSON':
+        return json.dumps(arg)
+    raise ValueError(f'Unknown function {name}(arg)')
+
+
+def evaluate_function_arity_2(name: str, arg1, arg2) -> bool:
+    if name == 'contains':
+        needle = _to_string(arg2).lower()
+        if isinstance(arg1, str):
+            return needle in arg1.lower()
+        return any(True for item in arg1 if _to_string(item).lower() == needle)
+    if name == 'startsWith':
+        return _to_string(arg1).lower().startswith(_to_string(arg2).lower())
+    if name == 'endsWith':
+        return _to_string(arg1).lower().endswith(_to_string(arg2).lower())
+    raise ValueError(f'Unknown function {name}(arg1, arg2)')
+
+
+def evaluate_status_function(name: str, contexts) -> bool:
+    """Evaluate job status function."""
+    if name == 'always':
+        return True
+    if name == 'success':
+        return contexts['job']['status'] == 'success'
+    if name == 'failure':
+        return contexts['job']['status'] == 'failure'
+    if name == 'cancelled':
+        return contexts['job']['status'] == 'cancelled'
+    raise ValueError(f'Unknown function {name}')
+
+
 def evaluate(expr: str, contexts):
     """Perform expression evaluation, using contexts.
 
     # Required parameters
 
     - expr: a string
     - contexts: a dictionary
@@ -449,27 +535,14 @@
         elif isinstance(value, list):
             result[item] = [evaluate_item(entry, contexts) for entry in value]
         else:
             result[item] = value
     return result
 
 
-def evaluate_status_function(name: str, contexts) -> bool:
-    """Evaluate job status function."""
-    if name == 'always':
-        return True
-    if name == 'success':
-        return contexts['job']['status'] == 'success'
-    if name == 'failure':
-        return contexts['job']['status'] == 'failure'
-    if name == 'cancelled':
-        return contexts['job']['status'] == 'cancelled'
-    raise ValueError(f'Unknown function {name}')
-
-
 def evaluate_bool(expr: str, contexts) -> bool:
     """Evaluate expression in context.
 
     `expr` may be surrounded by `${{` and `}}`.
 
     # Required parameters
```

## opentf/toolkit/__init__.py

```diff
@@ -15,15 +15,15 @@
 """A toolkit for creating OpenTestFactory plugins."""
 
 from typing import Any, Callable, Dict, Optional
 
 import inspect
 import os
 import sys
-import time
+import threading
 
 from collections import defaultdict
 
 from flask import request, g
 
 import yaml
 
@@ -47,14 +47,15 @@
 ########################################################################
 
 SUBSCRIPTION_KEY = '__subscription uuid__'
 MANIFEST_KEY = '__manifest key__'
 KIND_KEY = '__kind key__'
 INPUTS_KEY = '__inputs key__'
 WATCHEDFILES_KEY = '__watched files__'
+WATCHEDFILES_EVENT_KEY = '__watched files event__'
 
 WATCHDOG_POLLING_DELAY_SECONDS = 30
 WATCHDOG_POLLING_DELAY_KEY = 'watchdog_polling_delay_seconds'
 
 Handler = Callable[[Dict[str, Any]], Any]
 
 
@@ -298,34 +299,34 @@
             )
 
 
 def _watchdog(plugin, polling_delay):
     """Watch changes and call handlers when appropriate."""
     files_stat = defaultdict(float)
     files_handlers = plugin.config[WATCHEDFILES_KEY]
+    first = True
     while True:
         for file in list(files_handlers):
             try:
                 current_modified_time = os.stat(file).st_mtime
             except OSError as err:
                 plugin.logger.debug("Could not stat file '%s': %s.", file, err)
                 current_modified_time = 0
-            if current_modified_time == files_stat[file]:
+            if current_modified_time == files_stat[file] and not first:
                 continue
             plugin.logger.debug("Watched file '%s' has changed.", file)
             files_stat[file] = current_modified_time
             _run_handlers(plugin, file, list(files_handlers[file]))
-
-        time.sleep(polling_delay)
+        first = False
+        plugin.config[WATCHEDFILES_EVENT_KEY].wait(polling_delay)
+        plugin.config[WATCHEDFILES_EVENT_KEY].clear()
 
 
 def _start_watchdog(plugin) -> None:
     """Set up a watchdog that monitors specified files for changes."""
-    import threading
-
     try:
         polling_delay = max(
             WATCHDOG_POLLING_DELAY_SECONDS,
             int(plugin.config['CONTEXT'].get(WATCHDOG_POLLING_DELAY_KEY, 0)),
         )
     except ValueError as err:
         plugin.logger.error(
@@ -366,18 +367,21 @@
 
     The provided extra parameters, if any, are passed to the handler
     whenever it is called.
     """
     need_init = plugin.config.get(WATCHEDFILES_KEY) is None
     if need_init:
         plugin.config[WATCHEDFILES_KEY] = defaultdict(list)
+        plugin.config[WATCHEDFILES_EVENT_KEY] = threading.Event()
     plugin.logger.debug("Adding configuration watcher for '%s'.", path)
     plugin.config[WATCHEDFILES_KEY][path].append((handler, args, kwargs))
     if need_init:
         _start_watchdog(plugin)
+    else:
+        plugin.config[WATCHEDFILES_EVENT_KEY].set()
 
 
 def _subscribe(
     plugin, cat_prefix: str, cat: str, cat_version: str, manifest: Dict[str, Any]
 ) -> str:
     """Subscribe for the relevant event."""
     context = plugin.config['CONTEXT']
```

## opentf/toolkit/channels.py

```diff
@@ -79,25 +79,52 @@
     'macos': '{root}/{job_id}_{step_sequence_id}.sh',
     'windows': '{root}\\{job_id}_{step_sequence_id}.cmd',
 }
 
 LINESEP = {'linux': '\n', 'macos': '\n', 'windows': '\r\n'}
 RUNNER_OS = {'windows', 'macos', 'linux'}
 
-OPENTF_WORKSPACE_TEMPLATE = {
-    'linux': '`pwd`/{job_id}',
-    'macos': '`pwd`/{job_id}',
-    'windows': '%CD%\\{job_id}',
+WORKSPACE_TEMPLATE = {
+    'linux': '`pwd`/{workspace}',
+    'macos': '`pwd`/{workspace}',
+    'windows': '%CD%\\{workspace}',
 }
-OPENTF_VARIABLES_TEMPLATE = {
+VARIABLES_TEMPLATE = {
     'linux': '{root}/{job_id}_dynamic_env.sh',
     'macos': '{root}/{job_id}_dynamic_env.sh',
     'windows': '{root}\\{job_id}_dynamic_env.cmd',
 }
 
+PROLOG_SCRIPTS = {
+    'windows': (
+        'call "%OPENTF_VARIABLES%"',
+        '@del /q "{root}\\{job_id}_*.cmd"',
+        '@if exist "%OPENTF_WORKSPACE%" @rmdir /s/q "%OPENTF_WORKSPACE%"',
+        '@cd "%OPENTF_WORKSPACE%"',
+    ),
+    'linux': (
+        '. "$OPENTF_VARIABLES"',
+        'rm "{root}/{job_id}"_*.sh',
+        'rm -rf "$OPENTF_WORKSPACE"',
+        'cd "$OPENTF_WORKSPACE"',
+    ),
+    'macos': (
+        '. "$OPENTF_VARIABLES"',
+        'rm "{root}/{job_id}"_*.sh',
+        'rm -rf "$OPENTF_WORKSPACE"',
+        'cd "$OPENTF_WORKSPACE"',
+    ),
+}
+
+LOAD_VARIABLES = 0
+REMOVE_SCRIPTS = 1
+REMOVE_WORKSPACE = 2
+MOVE_TO_WORKSPACE = 3
+
+HOOKS_ANNOTATIONS = 'opentestfactory.org/hooks'
 ## os helpers
 
 
 def make_variable_linux(name: str, variable: Union[str, Dict[str, Any]]) -> str:
     """Prepare variable declaration for linux runners."""
 
     def pseudoquote(val):
@@ -119,34 +146,29 @@
 
 
 def make_variable_windows(name: str, variable: Union[str, Dict[str, Any]]) -> str:
     """Prepare variable declaration for windows runners."""
     if isinstance(variable, dict):
         value = variable['value']
         if variable.get('verbatim'):
-            for symbol in '^&<>\\':
+            for symbol in '^&<>':
                 value = value.replace(symbol, f'^{symbol}')
             value = value.replace('%', '%%')
     else:
         value = variable
     return f'@set "{name}={value}"'
 
 
-def add_default_variables(script, job_id, runner_os, root):
+def _add_default_variables(script, job_id, runner_os, root):
     """Prepare default variables."""
-    script.append(
-        VARIABLE_MAKER[runner_os](
-            'OPENTF_WORKSPACE',
-            OPENTF_WORKSPACE_TEMPLATE[runner_os].format(job_id=job_id),
-        )
-    )
+
     script.append(
         VARIABLE_MAKER[runner_os](
             'OPENTF_VARIABLES',
-            OPENTF_VARIABLES_TEMPLATE[runner_os].format(job_id=job_id, root=root),
+            VARIABLES_TEMPLATE[runner_os].format(job_id=job_id, root=root),
         )
     )
     script.append(VARIABLE_MAKER[runner_os]('OPENTF_ACTOR', 'dummy'))
     script.append(VARIABLE_MAKER[runner_os]('CI', 'true'))
 
 
 ## masks helpers
@@ -296,77 +318,135 @@
     if attachments:
         result['attachments'] = attachments
         result['metadata']['attachments'] = attachments_metadata
 
     return result
 
 
+def _export_opentf_workspace(runner_os, workspace, script) -> None:
+    opentf_workspace = WORKSPACE_TEMPLATE[runner_os].format(workspace=workspace)
+    if runner_os == 'windows':
+        script.append('@type nul >>"%OPENTF_VARIABLES%"')
+        script.append(
+            f'@echo set "OPENTF_WORKSPACE={opentf_workspace}" >>"%OPENTF_VARIABLES%"'
+        )
+    else:
+        script.append('touch "$OPENTF_VARIABLES"')
+        script.append(
+            f'echo export OPENTF_WORKSPACE="{opentf_workspace}" >> "$OPENTF_VARIABLES"'
+        )
+
+
+def _create_workspace(runner_os, workspace, script):
+    if runner_os == 'windows':
+        script.append(f'@if not exist {workspace} @mkdir {workspace}')
+    else:
+        script.append(f'mkdir -p {workspace}')
+    _export_opentf_workspace(runner_os, workspace, script)
+
+
+def _must_keep_workspace(metadata) -> bool:
+    hooks_annotations = metadata.get('annotations', {}).get(HOOKS_ANNOTATIONS, {})
+    if hooks_annotations.get('channel') == 'teardown':
+        return hooks_annotations.get('keep-workspace')
+    return False
+
+
+def _maybe_change_directory(command, runner_os, script, prefix: str) -> None:
+    if 'working-directory' not in command:
+        return
+    path = command['working-directory']
+    if runner_os == 'windows':
+        path = path.replace('/', '\\')
+    if ' ' in path:
+        path = '"' + path.strip('"') + '"'
+    script.append(f'{prefix}cd {path}')
+
+
+def _maybe_create_workspace(metadata, runner_os, step_sequence_id, script) -> None:
+    hooks_annotations = metadata.get('annotations', {}).get(HOOKS_ANNOTATIONS, {})
+    if hooks_annotations.get('channel') == 'setup':
+        if workspace := hooks_annotations.get('use-workspace'):
+            _create_workspace(runner_os, workspace, script)
+            if runner_os == 'windows':
+                script.append(
+                    f'@echo Using workspace \'{workspace}\' on execution environment'
+                )
+            else:
+                script.append(
+                    f'echo "Using workspace \'{workspace}\' on execution environment"'
+                )
+        elif step_sequence_id == 0:
+            _export_opentf_workspace(runner_os, '.', script)
+    elif step_sequence_id == 0:
+        _create_workspace(runner_os, metadata['job_id'], script)
+
+
+def _make_prolog(runner_os, job_id, step_sequence_id, root, script, command) -> None:
+    for name, value in command.get('variables', {}).items():
+        script.append(VARIABLE_MAKER[runner_os](name, value))
+
+    script.append(PROLOG_SCRIPTS[runner_os][LOAD_VARIABLES])
+    if step_sequence_id == CHANNEL_RELEASE:
+        # on windows, the script ends if it is removed, so script
+        # removal should be the last operation
+        if not _must_keep_workspace(command['metadata']):
+            script.append(PROLOG_SCRIPTS[runner_os][REMOVE_WORKSPACE])
+        else:
+            if runner_os == 'windows':
+                script.append(
+                    f'@echo Keeping workspace \'%OPENTF_WORKSPACE%\' on execution environment'
+                )
+            else:
+                script.append(
+                    'echo "Keeping workspace \'$OPENTF_WORKSPACE\' on execution environment"'
+                )
+
+        script.append(
+            PROLOG_SCRIPTS[runner_os][REMOVE_SCRIPTS].format(root=root, job_id=job_id)
+        )
+    else:
+        script.append(PROLOG_SCRIPTS[runner_os][MOVE_TO_WORKSPACE])
+
+
 def make_script(command, script_path, runner_os: str) -> Tuple[str, str, str]:
     """Prepare script.
 
     # Required parameters
 
     - command: an ExecutionCommand event
     - script_path: a string or None, where to put script on runner
     - runner_os: a string
 
     # Returned value
 
     script_path, script_content, script_command.
     """
-    job_id = command['metadata']['job_id']
-    step_sequence_id = command['metadata']['step_sequence_id']
+    metadata = command['metadata']
+    job_id = metadata['job_id']
+    step_sequence_id = metadata['step_sequence_id']
     root = script_path or SCRIPTPATH_DEFAULT[runner_os]
     script_path = SCRIPTFILE_DEFAULT[runner_os].format(
         root=root, job_id=job_id, step_sequence_id=step_sequence_id
     )
     script_command = SHELL_TEMPLATE[SHELL_DEFAULT[runner_os]].format(f'"{script_path}"')
 
     script = []
     if runner_os == 'windows':
         script.append('@echo off')
         prefix = '@'
     else:
         script.append('#!/usr/bin/env bash')
         prefix = ''
 
-    add_default_variables(script, job_id, runner_os, root)
-    for name, value in command.get('variables', {}).items():
-        script.append(VARIABLE_MAKER[runner_os](name, value))
-
-    if step_sequence_id == 0:
-        script.append(f'{prefix}mkdir {job_id}')
-        if runner_os != 'windows':
-            script.append('touch "$OPENTF_VARIABLES"')
-        else:
-            script.append('@type nul >>"%OPENTF_VARIABLES%"')
-
-    if step_sequence_id == CHANNEL_RELEASE:
-        script.append(
-            f'rm -rf {job_id}' if runner_os != 'windows' else f'@rmdir /s/q {job_id}'
-        )
-        script.append(
-            f'rm "{root}/{job_id}"_*.sh'
-            if runner_os != 'windows'
-            else f'@del /q "{root}\\{job_id}_*.cmd"'
-        )
-    else:
-        script.append(f'{prefix}cd {job_id}')
-        if runner_os == 'windows':
-            script.append('call "%OPENTF_VARIABLES%"')
-        else:
-            script.append('. "$OPENTF_VARIABLES"')
+    _add_default_variables(script, job_id, runner_os, root)
 
-    if 'working-directory' in command:
-        path = command['working-directory']
-        if runner_os == 'windows':
-            path = path.replace('/', '\\')
-        if ' ' in path:
-            path = '"' + path.strip('"') + '"'
-        script.append(f'{prefix}cd {path}')
+    _maybe_create_workspace(metadata, runner_os, step_sequence_id, script)
+    _make_prolog(runner_os, job_id, step_sequence_id, root, script, command)
+    _maybe_change_directory(command, runner_os, script, prefix)
 
     if (shell := command.get('shell')) in (None, SHELL_DEFAULT[runner_os]):
         script += command['scripts']
     else:
         path = f'{job_id}_shell_script_{step_sequence_id}'
         marker = make_uuid()
         shell_script = command['scripts']
```

## Comparing `opentf_toolkit-0.47.0.dist-info/LICENSE` & `opentf_toolkit-0.48.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `opentf_toolkit-0.47.0.dist-info/METADATA` & `opentf_toolkit-0.48.0.dist-info/METADATA`

 * *Files 11% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 Metadata-Version: 2.1
 Name: opentf-toolkit
-Version: 0.47.0
+Version: 0.48.0
 Summary: OpenTestFactory Orchestrator Toolkit
-Home-page: https://gitlab.com/opentestfactory/python-toolkit
+Home-page: https://gitlab.com/henixdevelopment/open-source/opentestfactory/python-toolkit
 Author: Martin Lafaix
 Author-email: mlafaix@henix.com
+Maintainer: Henix
+Maintainer-email: opentestfactory@henix.com
 License: Apache Software License (https://www.apache.org/licenses/LICENSE-2.0)
 Platform: UNKNOWN
 Classifier: Development Status :: 4 - Beta
 Classifier: Programming Language :: Python :: 3
 Classifier: Operating System :: OS Independent
 Classifier: Topic :: Software Development :: Libraries
 Classifier: License :: OSI Approved :: Apache Software License
@@ -36,15 +38,15 @@
 The package documentation is part of the
 [OpenTestFactory orchestrator](https://opentestfactory.org/impl/index.html)
 documentation, in the "Create plugins" section.
 
 
 ## License
 
-Copyright 2021-2022 Henix, henix.fr
+Copyright 2021-2023 Henix, henix.fr
 
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
 
     http://www.apache.org/licenses/LICENSE-2.0
```

## Comparing `opentf_toolkit-0.47.0.dist-info/RECORD` & `opentf_toolkit-0.48.0.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-opentf/commons/__init__.py,sha256=UOoIU-o9AxN44wlhW-UxLZaJifhm43hA9y2HcDQXzkc,40202
-opentf/commons/expressions.py,sha256=l4x_wH103HYZW2oDFhRnA5HWEX1ja9H4D0VXOnVQ63w,14520
+opentf/commons/__init__.py,sha256=FqDZ5TJWEP_m2wXjS2ofPNrk8x3KJJl6Ve8dzNfD21k,40261
+opentf/commons/expressions.py,sha256=abNQRhyb0wZuUGoLIlSVyHl1QJ87OP4H8geKQU-UXxk,17538
 opentf/commons/selectors.py,sha256=yj7Os7_8osvOssKUxi8d4tpKSMKBAa5hM81TWKjIADI,5521
 opentf/schemas/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 opentf/schemas/abac.opentestfactory.org/v1alpha1/Policy.json,sha256=JXsfNAPSEYggeyaDutSQBeG38o4Bmcr70dPLWWeqIh8,2105
 opentf/schemas/opentestfactory.org/v1alpha1/AgentRegistration.json,sha256=NQykqU-lKE8LtBhBiFUcpVJq00MRG6dZsoM1xedx6uQ,1230
 opentf/schemas/opentestfactory.org/v1alpha1/AllureCollectorOutput.json,sha256=-L9DDWA0A4x54bPMn4m6Qwi2tf2nHvzIPFOElTjaVck,1366
 opentf/schemas/opentestfactory.org/v1alpha1/ChannelHandlerHooks.json,sha256=6K6m9praw_f2biCMHfTsHPYia5z2jq10dciRLqf3ogI,1239
 opentf/schemas/opentestfactory.org/v1alpha1/EventBusConfig.json,sha256=2aIYtA07qRoauKNy-MH25Kzg1l1Q1fjY9_4YIvlyYgw,2174
@@ -13,14 +13,15 @@
 opentf/schemas/opentestfactory.org/v1alpha1/GeneratorCommand.json,sha256=uxbqDhP4newgz-85TnGKbchx448QEQ8WB5PXpcJy2ME,1754
 opentf/schemas/opentestfactory.org/v1alpha1/GeneratorResult.json,sha256=LkHLGt2uam1Q5Ux0zP_O9oFgxBMCjD3Th3BsfsXxd1g,6633
 opentf/schemas/opentestfactory.org/v1alpha1/Notification.json,sha256=XlzvDxg1V1bJJDX__K-lXibDYpqZIjgJHL96OJFaAKo,3790
 opentf/schemas/opentestfactory.org/v1alpha1/PluginMetadata.json,sha256=BLklO7CObT4OpAEsQT60WJ1ttOcG71hIYzgN-e7Ch9k,2803
 opentf/schemas/opentestfactory.org/v1alpha1/ProviderCommand.json,sha256=soe0imdnnq1mfGEpcLJvF3JVUIrF-7FFECc7CzNzobI,2875
 opentf/schemas/opentestfactory.org/v1alpha1/ProviderConfig.json,sha256=HT0bgPJ5fNytQJr-wxU21oApp4RrjogurgRP-zj_eDs,3878
 opentf/schemas/opentestfactory.org/v1alpha1/ProviderResult.json,sha256=o0X0tdHgZkhxZiqd-xvJNaKTRmA1jloTZYrDvVWtkDo,4259
+opentf/schemas/opentestfactory.org/v1alpha1/QualityGate.json,sha256=5el4gDH62647JdlziGCb9xeqDXtnOcZvv-kbQ_RmFWc,2898
 opentf/schemas/opentestfactory.org/v1alpha1/SSHServiceConfig.json,sha256=qqFoI-Ltn6O25YgjSiumhh0KEgm-Ftl3v56AxnCP7Cs,6301
 opentf/schemas/opentestfactory.org/v1alpha1/ServiceConfig.json,sha256=hRhJj4CkvB6p0IKKLMIwyxnbTmJkyEiDJSUxqzv0exI,2835
 opentf/schemas/opentestfactory.org/v1alpha1/Subscription.json,sha256=WwCmyqrhDUWl2Hel2y9cSzqih_VPyjhBaK71-rYyIfA,2810
 opentf/schemas/opentestfactory.org/v1alpha1/Workflow.json,sha256=PKuAGeyQnGjoYNbd3IUng4k8SIecIVelXzzOncewhyw,9899
 opentf/schemas/opentestfactory.org/v1alpha1/WorkflowCanceled.json,sha256=hLGQnrSXjvKZTzegucHrtGjAgS8dZeC7dZZ6mZVvclc,1351
 opentf/schemas/opentestfactory.org/v1alpha1/WorkflowCompleted.json,sha256=O1wpwhSawF9u64RtX38Lv2sptq8w3q8dvdvHxFwG20U,1292
 opentf/schemas/opentestfactory.org/v1alpha1/WorkflowResult.json,sha256=4vdr6YPTEVB_1CN9MW55oZ_Qiljir0SELHhbxSkz2-M,1577
@@ -32,15 +33,15 @@
 opentf/schemas/opentestfactory.org/v1beta1/ProviderConfig.json,sha256=FoA1gIGU1k1MJjptZxhJwRombO_s6zMZEOJ2WS-yMAA,4563
 opentf/schemas/opentestfactory.org/v1beta1/ProviderResult.json,sha256=t6zp8QvfrJ7b5meyQPzKIrZzQjGz064_yebKo5MUY2Y,7494
 opentf/schemas/opentestfactory.org/v1beta1/ServiceConfig.json,sha256=m5ZgWAKbutum7NAa4JtPuy5XbgQ4eH9DgXdoG2DOfnY,2850
 opentf/schemas/opentestfactory.org/v1beta1/Workflow.json,sha256=QZ8mM9PhzsI9gTmwmKTWYNoRn--rtcM3L0PzgnPBfMU,15424
 opentf/schemas/opentestfactory.org/v1beta2/ServiceConfig.json,sha256=rEvK2YWL5lG94_qYgR_GnLWNsaQhaQ-2kuZdWJr5NnY,3517
 opentf/scripts/launch_java_service.sh,sha256=FRYrQD704VWLGXQ3QI-M3m77olXexB0vVEwzyiKLkxc,1579
 opentf/scripts/startup.py,sha256=46UL6uCBXId3z3009bIIOD-inFEKrgg3allNQQYFIZs,18703
-opentf/toolkit/__init__.py,sha256=T_DOnGWLosNpp3S5nCdIOmmMZAaLQCFXQKO3QdCAxlE,18927
-opentf/toolkit/channels.py,sha256=2Zjbakelz9UhL-JMWXHioYH55IE1Bix33VGAKuUY3Pw,13130
+opentf/toolkit/__init__.py,sha256=_cqGImItjz9XO_XHuMR_8d4lz-WpHVkVI3q57jdzWlw,19227
+opentf/toolkit/channels.py,sha256=s7y0VDgKy6XzqnSa_aaYrIhhpHuWuGAB5Uaf1etWKkw,16089
 opentf/toolkit/core.py,sha256=wLu2fvcahExR6MYAwzsLJnG-tdO0wg6_LZ2NxHeUdvA,7314
-opentf_toolkit-0.47.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-opentf_toolkit-0.47.0.dist-info/METADATA,sha256=PisRDOTimyBG--iWdOdtuZ0eueILKddHyqSEUH7S31s,1875
-opentf_toolkit-0.47.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-opentf_toolkit-0.47.0.dist-info/top_level.txt,sha256=_gPuE6GTT6UNXy1DjtmQSfCcZb_qYA2vWmjg7a30AGk,7
-opentf_toolkit-0.47.0.dist-info/RECORD,,
+opentf_toolkit-0.48.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+opentf_toolkit-0.48.0.dist-info/METADATA,sha256=M3ji6whi_wy0s16c3SnvTJg5E_2uAz8PWdmnDz8YPoU,1966
+opentf_toolkit-0.48.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+opentf_toolkit-0.48.0.dist-info/top_level.txt,sha256=_gPuE6GTT6UNXy1DjtmQSfCcZb_qYA2vWmjg7a30AGk,7
+opentf_toolkit-0.48.0.dist-info/RECORD,,
```

