# Comparing `tmp/LbNightlyTools-3.0.9.tar.gz` & `tmp/LbNightlyTools-4.0.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "public/LbNightlyTools-3.0.9.tar", last modified: Thu May 14 12:42:19 2020, max compression
+gzip compressed data, was "LbNightlyTools-4.0.0.tar", last modified: Tue Jul 11 11:19:26 2023, max compression
```

## Comparing `LbNightlyTools-3.0.9.tar` & `LbNightlyTools-4.0.0.tar`

### file list

```diff
@@ -1,461 +1,425 @@
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/
--rw-rw-rw-   0 root         (0) root         (0)    35147 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/COPYING
--rw-r--r--   0 root         (0) root         (0)      896 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/PKG-INFO
--rw-rw-rw-   0 root         (0) root         (0)     4772 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/.cproject
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/cmt/
--rw-rw-rw-   0 root         (0) root         (0)       47 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/cmt/requirements
--rw-rw-rw-   0 root         (0) root         (0)       79 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/cmt/.gitignore
--rw-rw-rw-   0 root         (0) root         (0)       72 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/README.rst
--rw-rw-rw-   0 root         (0) root         (0)      954 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/setup.csh
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/utils/
--rw-rw-rw-   0 root         (0) root         (0)     1698 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/utils/add_ci_webhook.py
--rw-rw-rw-   0 root         (0) root         (0)      985 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/setup.sh
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/cron/
--rwxrwxrwx   0 root         (0) root         (0)     1518 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/cron/cleanup_artifacts.sh
--rwxrwxrwx   0 root         (0) root         (0)     2118 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/cron/preheat_nightly_dashboard.sh
--rw-rw-rw-   0 root         (0) root         (0)      154 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/cron/logrotate.conf
--rwxrwxrwx   0 root         (0) root         (0)     2034 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/cron/clean_up_reduced_db.sh
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/scripts/
--rwxrwxrwx   0 root         (0) root         (0)     1595 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/scripts/lbn-wrapcmd
--rwxrwxrwx   0 root         (0) root         (0)     2340 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/scripts/lbpr-collect
--rwxrwxrwx   0 root         (0) root         (0)     1053 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/scripts/lbn-get-configs
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/admin/
--rwxrwxrwx   0 root         (0) root         (0)     1901 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/admin/RpmHelpers.py
--rwxrwxrwx   0 root         (0) root         (0)     3723 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/admin/createLbScriptsRpm
--rw-rw-rw-   0 root         (0) root         (0)     1670 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/admin/LHCb_LbScripts.spectemplate
--rw-rw-rw-   0 root         (0) root         (0)      368 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/.project
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/jenkins/
--rwxrwxrwx   0 root         (0) root         (0)      943 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/utils.sh
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/jenkins/mock/
--rwxrwxrwx   0 root         (0) root         (0)      936 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/mock/clean_checkout.sh
--rwxrwxrwx   0 root         (0) root         (0)      887 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/mock/clean_build.sh
--rwxrwxrwx   0 root         (0) root         (0)      864 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/mock/clean_preconditions.sh
--rwxrwxrwx   0 root         (0) root         (0)      904 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/mock/clean_enabled_slots.sh
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/jenkins/testrunners/
--rwxrwxrwx   0 root         (0) root         (0)      382 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/testrunners/qmtest.sh
--rwxrwxrwx   0 root         (0) root         (0)      605 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/testrunners/lhcbpr.sh
--rwxrwxrwx   0 root         (0) root         (0)      387 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/testrunners/default.sh
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/jenkins/nightly-builds/
--rwxrwxrwx   0 root         (0) root         (0)      966 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/nightly-builds/tests-poll.sh
--rwxrwxrwx   0 root         (0) root         (0)    15845 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/nightly-builds/gitlab-mr.py
--rwxrwxrwx   0 root         (0) root         (0)     2864 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/nightly-builds/checkout.sh
--rwxrwxrwx   0 root         (0) root         (0)     2571 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/nightly-builds/tests.sh
--rwxrwxrwx   0 root         (0) root         (0)     1403 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/nightly-builds/main.sh
--rwxrwxrwx   0 root         (0) root         (0)     1093 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/nightly-builds/release-poll.sh
--rwxrwxrwx   0 root         (0) root         (0)     2256 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/nightly-builds/gaudi_mr_poll.py
--rwxrwxrwx   0 root         (0) root         (0)      903 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/nightly-builds/preconditions.sh
--rwxrwxrwx   0 root         (0) root         (0)     3176 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/nightly-builds/build.sh
--rwxrwxrwx   0 root         (0) root         (0)      933 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/nightly-builds/release.sh
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/jenkins/periodic-tests/
--rwxrwxrwx   0 root         (0) root         (0)     1219 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/periodic-tests/tests-pollqueue.sh
--rwxrwxrwx   0 root         (0) root         (0)     1170 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/periodic-tests/tests-poll.sh
--rwxrwxrwx   0 root         (0) root         (0)     2276 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/periodic-tests/tests.sh
--rwxrwxrwx   0 root         (0) root         (0)      892 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/periodic-tests/tests-getteststorun.sh
--rwxrwxrwx   0 root         (0) root         (0)     2410 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/mock.sh
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/jenkins/utils.d/
--rw-rw-rw-   0 root         (0) root         (0)     7244 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/utils.d/build_slot.sh
--rw-rw-rw-   0 root         (0) root         (0)     5278 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/utils.d/set_common.sh
--rw-rw-rw-   0 root         (0) root         (0)     2639 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/utils.d/check_preconditions.sh
--rw-rw-rw-   0 root         (0) root         (0)     6055 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/utils.d/checkout_slot.sh
--rw-rw-rw-   0 root         (0) root         (0)     2029 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/utils.d/execute_preconditions.sh
--rwxrwxrwx   0 root         (0) root         (0)     2327 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/docker.sh
--rwxrwxrwx   0 root         (0) root         (0)     2364 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/testMock.sh
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/jenkins/docker-home/
--rw-rw-rw-   0 root         (0) root         (0)      131 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/docker-home/.bashrc
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/jenkins/docker-home/.ssh/
--rw-rw-rw-   0 root         (0) root         (0)      234 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/docker-home/.ssh/config
--rw-rw-rw-   0 root         (0) root         (0)      183 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/jenkins/docker-home/.bash_profile
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/periodic_tests/
--rw-rw-rw-   0 root         (0) root         (0)      883 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/periodic_tests/starter_schedule.xml
--rw-rw-rw-   0 root         (0) root         (0)      402 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/periodic_tests/scheduleIncorrect.xml
--rw-rw-rw-   0 root         (0) root         (0)      486 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/periodic_tests/lhcbpr_schedule.xml
--rw-rw-rw-   0 root         (0) root         (0)      742 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/periodic_tests/schedule.xml
--rw-rw-rw-   0 root         (0) root         (0)    15857 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/periodic_tests/slotbuilds.json
--rw-rw-rw-   0 root         (0) root         (0)      398 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/testing-slot-lbcore-664.json
--rw-rw-rw-   0 root         (0) root         (0)      381 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/testing-slot-2b.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/fix_glimpse/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/fix_glimpse/untouched/
--rw-rw-rw-   0 root         (0) root         (0)       12 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/fix_glimpse/untouched/.glimpse_filenames
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/fix_glimpse/levelA/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/fix_glimpse/levelA/levelB/
--rw-rw-rw-   0 root         (0) root         (0)       10 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/fix_glimpse/levelA/levelB/.glimpse_filenames
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/fix_glimpse/level1/
--rw-rw-rw-   0 root         (0) root         (0)       54 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/fix_glimpse/level1/.glimpse_filenames
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/fix_glimpse/level1/level2/
--rw-rw-rw-   0 root         (0) root         (0)       19 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/fix_glimpse/level1/level2/.glimpse_filenames
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/fix_glimpse/docs/
--rw-rw-rw-   0 root         (0) root         (0)       12 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/fix_glimpse/docs/.glimpse_filenames
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/build.dir/
--rw-rw-rw-   0 root         (0) root         (0)       18 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/build.dir/IgnoredSource.cpp
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/cmake/
--rw-rw-rw-   0 root         (0) root         (0)       23 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/cmake/AProjectConfig.cmake
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/python/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/python/MyPackage/
--rw-rw-rw-   0 root         (0) root         (0)       23 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/python/MyPackage/MyPackage_user_confDb.py
--rw-rw-rw-   0 root         (0) root         (0)       19 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/python/MyPackage/MyPackage_confDb.py
--rw-rw-rw-   0 root         (0) root         (0)       18 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/python/MyPackage/SomeModule.py
--rw-rw-rw-   0 root         (0) root         (0)       16 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/python/MyPackage/SomethingConf.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/python/MyPackage/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)       27 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/python/MyPackage/MyPackageConf.py
--rw-rw-rw-   0 root         (0) root         (0)       26 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/python/AProject_merged_confDb.py
--rw-rw-rw-   0 root         (0) root         (0)       24 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/python/GeneratedPython.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/include/
--rw-rw-rw-   0 root         (0) root         (0)       14 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/include/MyHeader.h
--rw-rw-rw-   0 root         (0) root         (0)       24 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/InstallArea/include/GeneratedHeader.h
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/MyPackage/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/MyPackage/Headers/
--rw-rw-rw-   0 root         (0) root         (0)       14 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/MyPackage/Headers/MyHeader.h
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/MyPackage/scripts/
--rw-rw-rw-   0 root         (0) root         (0)       11 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/MyPackage/scripts/MyScript
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/MyPackage/src/
--rw-rw-rw-   0 root         (0) root         (0)       15 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/MyPackage/src/MySource.cpp
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/MyPackage/python/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/MyPackage/python/MyPackage/
--rw-rw-rw-   0 root         (0) root         (0)       18 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/MyPackage/python/MyPackage/SomeModule.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/indexer/AProject/MyPackage/python/MyPackage/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)      267 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/testing-slot-with-shared.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/coverity/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/coverity/configs/
--rw-rw-rw-   0 root         (0) root         (0)      110 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/coverity/configs/coverity_config.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/coverity/build/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/coverity/build/TEST/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/coverity/build/TEST/TEST_HEAD/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/coverity/build/TEST/TEST_HEAD/InstallArea/
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/coverity/build/TEST/TEST_HEAD/InstallArea/.empty
--rw-rw-rw-   0 root         (0) root         (0)      256 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/coverity/build/TEST/TEST_HEAD/Makefile
--rw-rw-rw-   0 root         (0) root         (0)      310 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/coverity/build/TEST/TEST_HEAD/CMakeLists.txt
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/coverity/bin/
--rwxrwxrwx   0 root         (0) root         (0)     1694 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/coverity/bin/cov-commit-defects
--rwxrwxrwx   0 root         (0) root         (0)     1695 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/coverity/bin/cov-analyze
--rwxrwxrwx   0 root         (0) root         (0)     1545 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/coverity/bin/cov-build
--rw-rw-rw-   0 root         (0) root         (0)      414 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/testing-slot-2.json
--rw-rw-rw-   0 root         (0) root         (0)      279 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/testing-slot-lbcore-192.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/tools/
--rw-rw-rw-   0 root         (0) root         (0)      658 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/tools/manifest.xml
--rw-rw-rw-   0 root         (0) root         (0)      103 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/tools/mini_manifest.xml
--rw-rw-rw-   0 root         (0) root         (0)     1272 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/tools/manifest_do0.xml
--rw-rw-rw-   0 root         (0) root         (0)     1074 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/tools/manifest_with_pkgs.xml
--rw-rw-rw-   0 root         (0) root         (0)      219 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/testing-slot.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/artifacts/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/artifacts/packs/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/artifacts/packs/src/
--rw-rw-rw-   0 root         (0) root         (0)     2387 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/artifacts/packs/src/TestProject.HEAD.testing-slot.src.zip
--rw-rw-rw-   0 root         (0) root         (0)      244 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/data-packs.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Lbcom/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Lbcom/cmt/
--rw-rw-rw-   0 root         (0) root         (0)       19 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Lbcom/cmt/project.cmt
--rw-rw-rw-   0 root         (0) root         (0)      559 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/conf.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Online/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Online/cmt/
--rw-rw-rw-   0 root         (0) root         (0)      115 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Online/cmt/project.cmt
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Brunel/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Brunel/cmt/
--rw-rw-rw-   0 root         (0) root         (0)       41 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Brunel/cmt/project.cmt
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Rec/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Rec/cmt/
--rw-rw-rw-   0 root         (0) root         (0)       22 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Rec/cmt/project.cmt
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Gaudi/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Gaudi/cmt/
--rw-rw-rw-   0 root         (0) root         (0)       26 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/Gaudi/cmt/project.cmt
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/LHCb/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/LHCb/cmt/
--rw-rw-rw-   0 root         (0) root         (0)       50 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/LHCb/cmt/project.cmt
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/NewProj/
--rw-rw-rw-   0 root         (0) root         (0)       40 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmt/NewProj/project.info
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/Lbcom/
--rw-rw-rw-   0 root         (0) root         (0)       54 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/Lbcom/CMakeLists.txt
--rw-rw-rw-   0 root         (0) root         (0)      561 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/conf.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/Online/
--rw-rw-rw-   0 root         (0) root         (0)      117 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/Online/CMakeLists.txt
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/Brunel/
--rw-rw-rw-   0 root         (0) root         (0)      111 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/Brunel/CMakeLists.txt
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/Rec/
--rw-rw-rw-   0 root         (0) root         (0)       52 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/Rec/CMakeLists.txt
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/Gaudi/
--rw-rw-rw-   0 root         (0) root         (0)       29 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/Gaudi/CMakeLists.txt
--rw-rw-rw-   0 root         (0) root         (0)       25 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/Gaudi/toolchain.cmake
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/LHCb/
--rw-rw-rw-   0 root         (0) root         (0)       85 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/LHCb/CMakeLists.txt
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/NewProj/
--rw-rw-rw-   0 root         (0) root         (0)       40 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/cmake/NewProj/project.info
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/broken/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/broken/BadCMake/
--rw-rw-rw-   0 root         (0) root         (0)       14 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/broken/BadCMake/CMakeLists.txt
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/broken/BadCMT/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/broken/BadCMT/cmt/
--rw-rw-rw-   0 root         (0) root         (0)       21 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/broken/BadCMT/cmt/project.cmt
--rw-rw-rw-   0 root         (0) root         (0)      295 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/broken/conf.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/collect_deps/broken/Gaudi/
--rw-rw-rw-   0 root         (0) root         (0)       29 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/broken/Gaudi/CMakeLists.txt
--rw-rw-rw-   0 root         (0) root         (0)       25 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/collect_deps/broken/Gaudi/toolchain.cmake
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/build_tests/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/build_tests/orig/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/build_tests/orig/dummy/
--rw-rw-rw-   0 root         (0) root         (0)      392 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/build_tests/orig/dummy/Makefile
--rw-rw-rw-   0 root         (0) root         (0)      364 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/testing-slot-env.json
--rw-rw-rw-   0 root         (0) root         (0)     6009 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/ci-test-hook-content.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/rpm/
--rw-rw-rw-   0 root         (0) root         (0)     2977 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/PARAM_TMVAWeights.spec
--rw-rw-rw-   0 root         (0) root         (0)      617 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/manifest.xml
--rw-rw-rw-   0 root         (0) root         (0)     1265 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/Brunel_v46r0.spec
--rw-rw-rw-   0 root         (0) root         (0)      961 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/datapkg-slot-config.json
--rw-rw-rw-   0 root         (0) root         (0)      915 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/slot-configdo0.json
--rw-rw-rw-   0 root         (0) root         (0)     7195 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/LCG_68_externalsDict.json
--rw-rw-rw-   0 root         (0) root         (0)     1272 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/manifest_do0.xml
--rw-rw-rw-   0 root         (0) root         (0)     1981 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/glimpse_Brunel_v46r0.spec
--rw-rw-rw-   0 root         (0) root         (0)     1630 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/Brunel_v46r0_x86_64-slc6-gcc48-opt.spec
--rw-rw-rw-   0 root         (0) root         (0)     2476 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/Gaudi_v27r0_x86_64-slc6-gcc49-do0.spec
--rw-rw-rw-   0 root         (0) root         (0)      915 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/slot-config.json
--rw-rw-rw-   0 root         (0) root         (0)     2977 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/PARAM_TMVAWeights_rel5.spec
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/testdata/rpm/rel/
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/rel/PARAM_TMVAWeights_v1r4-1.0.0-toto.noarch.rpm
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/rel/PARAM_TMVAWeights_v1r2-1.0.0-1.noarch.rpm
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/rel/PARAM_TMVAWeights_v1r4-1.0.0-1.noarch.rpm
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/testdata/rpm/rel/PARAM_TMVAWeights_v1r4-1.0.0-4.noarch.rpm
--rw-rw-rw-   0 root         (0) root         (0)      463 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/.pydevproject
--rw-rw-rw-   0 root         (0) root         (0)    11051 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/CHANGELOG.md
--rw-rw-rw-   0 root         (0) root         (0)     2532 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/.gitlab-ci.yml
--rw-rw-rw-   0 root         (0) root         (0)       54 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/.coveragerc
--rw-rw-rw-   0 root         (0) root         (0)      290 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/.gitignore
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/docs/
--rw-rw-rw-   0 root         (0) root         (0)     7965 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/pylint.rc
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/docs/examples/
--rwxrwxrwx   0 root         (0) root         (0)     1247 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/examples/lbpr-example
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/docs/operation/
--rw-rw-rw-   0 root         (0) root         (0)    26491 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/operation/NightlyBuildsOperation.html
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/docs/operation/images/
--rw-rw-rw-   0 root         (0) root         (0)      788 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/operation/images/jenkins-jobs.dot
--rw-rw-rw-   0 root         (0) root         (0)    32492 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/operation/images/jenkins-jobs.dot.png
--rw-rw-rw-   0 root         (0) root         (0)      974 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/operation/Makefile
--rw-rw-rw-   0 root         (0) root         (0)    11284 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/operation/NightlyBuildsOperation.rst
--rw-rw-rw-   0 root         (0) root         (0)    25549 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/Interactive builds of LHCb projects.ipynb
--rw-rw-rw-   0 root         (0) root         (0)     2628 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/jenkins-scripts.dot
--rw-rw-rw-   0 root         (0) root         (0)   142880 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/jenkins-scripts.dot.png
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/docs/note/
--rw-rw-rw-   0 root         (0) root         (0)     2326 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/design.tex
--rw-rw-rw-   0 root         (0) root         (0)     2299 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/introduction.tex
--rw-rw-rw-   0 root         (0) root         (0)    32577 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/cite.sty
--rw-rw-rw-   0 root         (0) root         (0)     3132 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/appendix.tex
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/docs/note/figs/
--rw-rw-rw-   0 root         (0) root         (0)    14116 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/figs/lhcb-logo.pdf
--rw-rw-rw-   0 root         (0) root         (0)   134216 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/figs/old-summary.png
--rw-rw-rw-   0 root         (0) root         (0)   101416 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/figs/cdash-3.png
--rw-rw-rw-   0 root         (0) root         (0)    60108 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/figs/cdash-1.png
--rw-rw-rw-   0 root         (0) root         (0)   173109 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/figs/jenkins-3.png
--rw-rw-rw-   0 root         (0) root         (0)   162025 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/figs/cdash-4.png
--rw-rw-rw-   0 root         (0) root         (0)    81047 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/figs/jenkins-2.png
--rw-rw-rw-   0 root         (0) root         (0)    91381 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/figs/jenkins-1.png
--rw-rw-rw-   0 root         (0) root         (0)    97134 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/figs/cdash-2.png
--rw-rw-rw-   0 root         (0) root         (0)   160146 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/figs/lhcb-logo.eps
--rw-rw-rw-   0 root         (0) root         (0)      185 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/README.txt
--rw-rw-rw-   0 root         (0) root         (0)     2787 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/preamble.tex
--rw-rw-rw-   0 root         (0) root         (0)   946715 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/LHCb-INT-2013-006.pdf
--rw-rw-rw-   0 root         (0) root         (0)      567 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/conclusions.tex
--rwxrwxrwx   0 root         (0) root         (0)     3645 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/listsymbols
--rw-rw-rw-   0 root         (0) root         (0)     5975 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/dashboard.tex
--rw-rw-rw-   0 root         (0) root         (0)     5159 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/bibliography.bib
--rw-rw-rw-   0 root         (0) root         (0)     5596 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/lhcb-int-2013-006.kilepr
--rw-rw-rw-   0 root         (0) root         (0)     1363 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/requirements.tex
--rw-rw-rw-   0 root         (0) root         (0)    24755 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/LHCb.bst
--rw-rw-rw-   0 root         (0) root         (0)    28733 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/unsrturl.bst
--rw-rw-rw-   0 root         (0) root         (0)     1681 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/Makefile
--rw-rw-rw-   0 root         (0) root         (0)     2478 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/title-LHCb-ANA.tex
--rw-rw-rw-   0 root         (0) root         (0)     1586 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/main.tex
--rw-rw-rw-   0 root         (0) root         (0)    33058 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/implementation.tex
--rw-rw-rw-   0 root         (0) root         (0)    61172 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/note/mciteplus.sty
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/docs/configuration/
--rw-rw-rw-   0 root         (0) root         (0)     3047 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/configuration/Example.py
--rw-rw-rw-   0 root         (0) root         (0)     1318 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/docs/LHCbPR2.md
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/merge_requests/
--rw-rw-rw-   0 root         (0) root         (0)       23 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/merge_requests/_id
--rw-rw-rw-   0 root         (0) root         (0)       11 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/merge_requests/language
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/merge_requests/views/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/merge_requests/views/mrs/
--rw-rw-rw-   0 root         (0) root         (0)      756 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/merge_requests/views/mrs/map.js
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/merge_requests/views/mr_slots_by_ref_slot/
--rw-rw-rw-   0 root         (0) root         (0)      307 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/merge_requests/views/mr_slots_by_ref_slot/map.js
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/deployment/
--rw-rw-rw-   0 root         (0) root         (0)       18 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/deployment/_id
--rw-rw-rw-   0 root         (0) root         (0)       10 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/deployment/language
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/deployment/views/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/deployment/views/ready/
--rw-rw-rw-   0 root         (0) root         (0)      920 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/deployment/views/ready/map.js
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/nightlies_summaries/
--rw-rw-rw-   0 root         (0) root         (0)       27 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/nightlies_summaries/_id
--rw-rw-rw-   0 root         (0) root         (0)       10 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/nightlies_summaries/language
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/nightlies_summaries/views/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/nightlies_summaries/views/by_app_version/
--rw-rw-rw-   0 root         (0) root         (0)       97 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/nightlies_summaries/views/by_app_version/map.js
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/frontend-stats/
--rw-rw-rw-   0 root         (0) root         (0)       22 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/frontend-stats/_id
--rw-rw-rw-   0 root         (0) root         (0)       82 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/frontend-stats/couchapp.json
--rw-rw-rw-   0 root         (0) root         (0)       10 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/frontend-stats/language
--rw-rw-rw-   0 root         (0) root         (0)      176 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/frontend-stats/.couchappignore
--rw-rw-rw-   0 root         (0) root         (0)      679 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/frontend-stats/README.md
--rw-rw-rw-   0 root         (0) root         (0)      115 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/frontend-stats/.couchapprc
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/frontend-stats/views/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/frontend-stats/views/byDate/
--rw-rw-rw-   0 root         (0) root         (0)     2489 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/frontend-stats/views/byDate/map.js
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/auth/
--rw-rw-rw-   0 root         (0) root         (0)     1085 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/auth/validate_doc_update.js
--rw-rw-rw-   0 root         (0) root         (0)      982 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/Push CouchDB Nightly Builds.launch
--rwxrwxrwx   0 root         (0) root         (0)     3494 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/webapp_testbench.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/periodic_summaries/
--rw-rw-rw-   0 root         (0) root         (0)       26 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/periodic_summaries/_id
--rw-rw-rw-   0 root         (0) root         (0)       10 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/periodic_summaries/language
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/periodic_summaries/views/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/periodic_summaries/views/byTime/
--rw-rw-rw-   0 root         (0) root         (0)       74 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/periodic_summaries/views/byTime/map.js
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/names/
--rw-rw-rw-   0 root         (0) root         (0)       14 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/names/_id
--rw-rw-rw-   0 root         (0) root         (0)       10 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/names/language
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/names/views/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/names/views/platforms/
--rw-rw-rw-   0 root         (0) root         (0)      149 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/names/views/platforms/reduce.js
--rw-rw-rw-   0 root         (0) root         (0)      140 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/names/views/platforms/map.js
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/names/views/slots/
--rw-rw-rw-   0 root         (0) root         (0)      149 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/names/views/slots/reduce.js
--rw-rw-rw-   0 root         (0) root         (0)       81 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/names/views/slots/map.js
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/names/views/projects/
--rw-rw-rw-   0 root         (0) root         (0)      149 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/names/views/projects/reduce.js
--rw-rw-rw-   0 root         (0) root         (0)      142 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/names/views/projects/map.js
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/old_dashboard/
--rw-rw-rw-   0 root         (0) root         (0)       21 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/old_dashboard/_id
--rw-rw-rw-   0 root         (0) root         (0)       10 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/old_dashboard/language
--rw-rw-rw-   0 root         (0) root         (0)      791 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/old_dashboard/rewrites.json
--rw-rw-rw-   0 root         (0) root         (0)     1744 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/README.md
--rw-rw-rw-   0 root         (0) root         (0)      486 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/build_id_index.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/summaries/
--rw-rw-rw-   0 root         (0) root         (0)       17 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/summaries/_id
--rw-rw-rw-   0 root         (0) root         (0)       10 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/summaries/language
--rw-rw-rw-   0 root         (0) root         (0)      264 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/summaries/rewrites.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/summaries/views/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/summaries/views/lastBuildId/
--rw-rw-rw-   0 root         (0) root         (0)      190 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/summaries/views/lastBuildId/reduce.js
--rw-rw-rw-   0 root         (0) root         (0)       89 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/summaries/views/lastBuildId/map.js
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/summaries/views/byDay/
--rw-rw-rw-   0 root         (0) root         (0)      347 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/summaries/views/byDay/map.js
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/releases/
--rw-rw-rw-   0 root         (0) root         (0)       16 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/releases/_id
--rw-rw-rw-   0 root         (0) root         (0)       10 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/releases/language
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/releases/lists/
--rw-rw-rw-   0 root         (0) root         (0)      153 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/releases/lists/projectBuildIds.js
--rw-rw-rw-   0 root         (0) root         (0)      185 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/releases/rewrites.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/releases/views/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/couchdb/releases/views/projectBuildIds/
--rw-rw-rw-   0 root         (0) root         (0)      165 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/releases/views/projectBuildIds/map.js
--rw-rw-rw-   0 root         (0) root         (0)       12 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/couchdb/.gitignore
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbPeriodicTools/
--rw-rw-rw-   0 root         (0) root         (0)     1600 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPeriodicTools/TestSchedule.xsd
--rw-rw-rw-   0 root         (0) root         (0)     4133 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPeriodicTools/LbPeriodicStarter.py
--rw-rw-rw-   0 root         (0) root         (0)    10843 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPeriodicTools/LbPeriodicTest.py
--rw-rw-rw-   0 root         (0) root         (0)    10085 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPeriodicTools/_entry_points.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPeriodicTools/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     2147 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPeriodicTools/LbPeriodicTestSchedule.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbPeriodicTools/tests/
--rw-rw-rw-   0 root         (0) root         (0)     3611 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPeriodicTools/tests/TestStarter.py
--rw-rw-rw-   0 root         (0) root         (0)     4173 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPeriodicTools/tests/TestXMLParsing.py
--rw-rw-rw-   0 root         (0) root         (0)     2340 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPeriodicTools/tests/TestLHCbPR.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPeriodicTools/tests/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbTools/
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbTools/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     4235 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbTools/Manifest.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbTools/tests/
--rw-rw-rw-   0 root         (0) root         (0)     3869 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbTools/tests/TestXMLParsing.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbNightlyTools.egg-info/
--rw-r--r--   0 root         (0) root         (0)      896 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbNightlyTools.egg-info/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)      123 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbNightlyTools.egg-info/requires.txt
--rw-r--r--   0 root         (0) root         (0)      236 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbNightlyTools.egg-info/dependency_links.txt
--rw-r--r--   0 root         (0) root         (0)    12185 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbNightlyTools.egg-info/SOURCES.txt
--rw-r--r--   0 root         (0) root         (0)     2748 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbNightlyTools.egg-info/entry_points.txt
--rw-r--r--   0 root         (0) root         (0)       61 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbNightlyTools.egg-info/top_level.txt
--rw-r--r--   0 root         (0) root         (0)        1 2020-05-14 12:41:28.000000 LbNightlyTools-3.0.9/python/LbNightlyTools.egg-info/not-zip-safe
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbPR/
--rw-rw-rw-   0 root         (0) root         (0)     3004 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPR/LbPRJobManager.py
--rw-rw-rw-   0 root         (0) root         (0)    13502 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPR/_entry_points.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbPR/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbMsg/
--rwxrwxrwx   0 root         (0) root         (0)     3411 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbMsg/BuildMsg.py
--rw-rw-rw-   0 root         (0) root         (0)     4725 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbMsg/Common.py
--rw-rw-rw-   0 root         (0) root         (0)     3363 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbMsg/TestMsg.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbMsg/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbRPMTools/
--rw-rw-rw-   0 root         (0) root         (0)    22655 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbRPMTools/LHCbExternalsSpecBuilder.py
--rw-rw-rw-   0 root         (0) root         (0)    16260 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbRPMTools/LHCbLbScriptsSpecBuilder.py
--rw-rw-rw-   0 root         (0) root         (0)    49470 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbRPMTools/LHCbRPMSpecBuilder.py
--rw-rw-rw-   0 root         (0) root         (0)    10023 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbRPMTools/LHCbCompatSpecBuilder.py
--rw-rw-rw-   0 root         (0) root         (0)    10051 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbRPMTools/LHCbGenericSpecBuilder.py
--rw-rw-rw-   0 root         (0) root         (0)     8660 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbRPMTools/LHCbMetaSpecBuilder.py
--rw-rw-rw-   0 root         (0) root         (0)    28105 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbRPMTools/PackageSlot.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbRPMTools/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbRPMTools/tests/
--rw-rw-rw-   0 root         (0) root         (0)    13491 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbRPMTools/tests/TestSpec.py
--rw-rw-rw-   0 root         (0) root         (0)    13068 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbRPMTools/tests/TestPackageSlot.py
--rw-rw-rw-   0 root         (0) root         (0)     5904 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbRPMTools/tests/TestExternalSpec.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbRPMTools/tests/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/
--rw-rw-rw-   0 root         (0) root         (0)     6052 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/ProcUtils.py
--rw-rw-rw-   0 root         (0) root         (0)    42586 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Utils.py
--rw-rw-rw-   0 root         (0) root         (0)    18491 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/HTMLUtils.py
--rw-rw-rw-   0 root         (0) root         (0)     4285 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/LbScriptsUtils.py
--rw-rw-rw-   0 root         (0) root         (0)     3649 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/CheckSlotPreconditions.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/
--rw-rw-rw-   0 root         (0) root         (0)    11736 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/EnabledSlots.py
--rw-rw-rw-   0 root         (0) root         (0)    14479 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Test.py
--rw-rw-rw-   0 root         (0) root         (0)     7624 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Index.py
--rw-rw-rw-   0 root         (0) root         (0)    15853 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/CollectBuildLogs.py
--rw-rw-rw-   0 root         (0) root         (0)    23904 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Install.py
--rw-rw-rw-   0 root         (0) root         (0)      999 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/listzip.php
--rwxrwxrwx   0 root         (0) root         (0)    26588 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Common.py
--rw-rw-rw-   0 root         (0) root         (0)     4597 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Preconditions.py
--rw-rw-rw-   0 root         (0) root         (0)    34123 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Build.py
--rw-rw-rw-   0 root         (0) root         (0)     3014 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/extract.php
--rw-rw-rw-   0 root         (0) root         (0)    12214 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/GitlabMR.py
--rw-rw-rw-   0 root         (0) root         (0)    28433 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/_entry_points.py
--rw-rw-rw-   0 root         (0) root         (0)    17630 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Release.py
--rw-rw-rw-   0 root         (0) root         (0)      890 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    14858 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Checkout.py
--rw-rw-rw-   0 root         (0) root         (0)     4373 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/ArtifactsServer.py
--rw-rw-rw-   0 root         (0) root         (0)    12018 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/BuildLogScanner.py
--rw-rw-rw-   0 root         (0) root         (0)    39193 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/CheckoutMethods.py
--rw-rw-rw-   0 root         (0) root         (0)    84038 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/Configuration.py
--rwxrwxrwx   0 root         (0) root         (0)     4987 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/GetNightlyRefs.py
--rw-rw-rw-   0 root         (0) root         (0)    14597 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/MergeRequestBuilds.py
--rw-rw-rw-   0 root         (0) root         (0)    25212 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/BuildMethods.py
--rw-rw-rw-   0 root         (0) root         (0)     6769 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/GitlabUtils.py
--rw-rw-rw-   0 root         (0) root         (0)     1478 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/
--rw-rw-rw-   0 root         (0) root         (0)     2103 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_config_pickle.py
--rw-rw-rw-   0 root         (0) root         (0)     1758 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_jobconfig.py
--rw-rw-rw-   0 root         (0) root         (0)     3573 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_gitlab_mr_script.py
--rw-rw-rw-   0 root         (0) root         (0)     1869 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_indexer.py
--rw-rw-rw-   0 root         (0) root         (0)    25318 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_config_load.py
--rw-rw-rw-   0 root         (0) root         (0)     1539 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_retry.py
--rw-rw-rw-   0 root         (0) root         (0)     4900 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_checkout_script.py
--rw-rw-rw-   0 root         (0) root         (0)     5892 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_coverity_support.py
--rw-rw-rw-   0 root         (0) root         (0)    18039 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_build_script.py
--rw-rw-rw-   0 root         (0) root         (0)     7901 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_release_poll.py
--rw-rw-rw-   0 root         (0) root         (0)     2565 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_install.py
--rw-rw-rw-   0 root         (0) root         (0)     3223 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_copytree.py
--rw-rw-rw-   0 root         (0) root         (0)     1404 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/__main__.py
--rw-rw-rw-   0 root         (0) root         (0)     6722 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_build.py
--rw-rw-rw-   0 root         (0) root         (0)     3204 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/utils.py
--rw-rw-rw-   0 root         (0) root         (0)     1322 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_precond.py
--rw-rw-rw-   0 root         (0) root         (0)    14547 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_enabled_slots_script.py
--rw-rw-rw-   0 root         (0) root         (0)     1098 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_utils.py
--rw-rw-rw-   0 root         (0) root         (0)    20507 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_checkout.py
--rw-rw-rw-   0 root         (0) root         (0)    12665 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_rel_gen_script.py
--rw-rw-rw-   0 root         (0) root         (0)    15015 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_configuration.py
--rw-rw-rw-   0 root         (0) root         (0)     5596 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_pack.py
--rw-rw-rw-   0 root         (0) root         (0)      921 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/python/LbNightlyTools/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)      166 2020-05-14 12:42:19.000000 LbNightlyTools-3.0.9/setup.cfg
--rw-rw-rw-   0 root         (0) root         (0)    11343 2020-05-14 12:41:20.000000 LbNightlyTools-3.0.9/setup.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.544000 LbNightlyTools-4.0.0/
+-rw-r--r--   0 root         (0) root         (0)       54 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/.coveragerc
+-rw-r--r--   0 root         (0) root         (0)      339 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/.gitignore
+-rw-r--r--   0 root         (0) root         (0)     4932 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/.gitlab-ci.yml
+-rw-r--r--   0 root         (0) root         (0)      487 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/.pre-commit-config.yaml
+-rw-r--r--   0 root         (0) root         (0)    15557 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/CHANGELOG.md
+-rw-r--r--   0 root         (0) root         (0)    35147 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/COPYING
+-rw-r--r--   0 root         (0) root         (0)      838 2023-07-11 11:19:26.548000 LbNightlyTools-4.0.0/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)       72 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/README.rst
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.508000 LbNightlyTools-4.0.0/admin/
+-rw-r--r--   0 root         (0) root         (0)     1669 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/admin/LHCb_LbScripts.spectemplate
+-rwxr-xr-x   0 root         (0) root         (0)     1882 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/admin/RpmHelpers.py
+-rwxr-xr-x   0 root         (0) root         (0)     3688 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/admin/createLbScriptsRpm
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.508000 LbNightlyTools-4.0.0/couchdb/
+-rw-r--r--   0 root         (0) root         (0)       12 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/.gitignore
+-rw-r--r--   0 root         (0) root         (0)      982 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/Push CouchDB Nightly Builds.launch
+-rw-r--r--   0 root         (0) root         (0)     1742 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/README.md
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.508000 LbNightlyTools-4.0.0/couchdb/auth/
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/auth/validate_doc_update.js
+-rw-r--r--   0 root         (0) root         (0)      486 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/build_id_index.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.508000 LbNightlyTools-4.0.0/couchdb/deployment/
+-rw-r--r--   0 root         (0) root         (0)       19 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/deployment/_id
+-rw-r--r--   0 root         (0) root         (0)       11 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/deployment/language
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.496000 LbNightlyTools-4.0.0/couchdb/deployment/views/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.508000 LbNightlyTools-4.0.0/couchdb/deployment/views/ready/
+-rw-r--r--   0 root         (0) root         (0)      920 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/deployment/views/ready/map.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.508000 LbNightlyTools-4.0.0/couchdb/frontend-stats/
+-rw-r--r--   0 root         (0) root         (0)      177 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/frontend-stats/.couchappignore
+-rw-r--r--   0 root         (0) root         (0)      116 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/frontend-stats/.couchapprc
+-rw-r--r--   0 root         (0) root         (0)      672 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/frontend-stats/README.md
+-rw-r--r--   0 root         (0) root         (0)       23 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/frontend-stats/_id
+-rw-r--r--   0 root         (0) root         (0)       83 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/frontend-stats/couchapp.json
+-rw-r--r--   0 root         (0) root         (0)       11 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/frontend-stats/language
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.496000 LbNightlyTools-4.0.0/couchdb/frontend-stats/views/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.508000 LbNightlyTools-4.0.0/couchdb/frontend-stats/views/byDate/
+-rw-r--r--   0 root         (0) root         (0)     2483 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/frontend-stats/views/byDate/map.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.508000 LbNightlyTools-4.0.0/couchdb/merge_requests/
+-rw-r--r--   0 root         (0) root         (0)       23 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/merge_requests/_id
+-rw-r--r--   0 root         (0) root         (0)       11 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/merge_requests/language
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.496000 LbNightlyTools-4.0.0/couchdb/merge_requests/views/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.508000 LbNightlyTools-4.0.0/couchdb/merge_requests/views/mr_slots_by_ref_slot/
+-rw-r--r--   0 root         (0) root         (0)      307 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/merge_requests/views/mr_slots_by_ref_slot/map.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.508000 LbNightlyTools-4.0.0/couchdb/merge_requests/views/mrs/
+-rw-r--r--   0 root         (0) root         (0)      756 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/merge_requests/views/mrs/map.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.508000 LbNightlyTools-4.0.0/couchdb/names/
+-rw-r--r--   0 root         (0) root         (0)       14 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/names/_id
+-rw-r--r--   0 root         (0) root         (0)       11 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/names/language
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.496000 LbNightlyTools-4.0.0/couchdb/names/views/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.508000 LbNightlyTools-4.0.0/couchdb/names/views/platforms/
+-rw-r--r--   0 root         (0) root         (0)      140 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/names/views/platforms/map.js
+-rw-r--r--   0 root         (0) root         (0)      149 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/names/views/platforms/reduce.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/names/views/projects/
+-rw-r--r--   0 root         (0) root         (0)      142 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/names/views/projects/map.js
+-rw-r--r--   0 root         (0) root         (0)      149 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/names/views/projects/reduce.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/names/views/slots/
+-rw-r--r--   0 root         (0) root         (0)       81 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/names/views/slots/map.js
+-rw-r--r--   0 root         (0) root         (0)      149 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/names/views/slots/reduce.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/nightlies_summaries/
+-rw-r--r--   0 root         (0) root         (0)       28 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/nightlies_summaries/_id
+-rw-r--r--   0 root         (0) root         (0)       11 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/nightlies_summaries/language
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.496000 LbNightlyTools-4.0.0/couchdb/nightlies_summaries/views/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/nightlies_summaries/views/by_app_version/
+-rw-r--r--   0 root         (0) root         (0)       98 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/nightlies_summaries/views/by_app_version/map.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/old_dashboard/
+-rw-r--r--   0 root         (0) root         (0)       22 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/old_dashboard/_id
+-rw-r--r--   0 root         (0) root         (0)       11 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/old_dashboard/language
+-rw-r--r--   0 root         (0) root         (0)      791 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/old_dashboard/rewrites.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/periodic_summaries/
+-rw-r--r--   0 root         (0) root         (0)       27 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/periodic_summaries/_id
+-rw-r--r--   0 root         (0) root         (0)       11 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/periodic_summaries/language
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.496000 LbNightlyTools-4.0.0/couchdb/periodic_summaries/views/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/periodic_summaries/views/byTime/
+-rw-r--r--   0 root         (0) root         (0)       74 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/periodic_summaries/views/byTime/map.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/releases/
+-rw-r--r--   0 root         (0) root         (0)       17 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/releases/_id
+-rw-r--r--   0 root         (0) root         (0)       11 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/releases/language
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/releases/lists/
+-rw-r--r--   0 root         (0) root         (0)      153 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/releases/lists/projectBuildIds.js
+-rw-r--r--   0 root         (0) root         (0)      185 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/releases/rewrites.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.496000 LbNightlyTools-4.0.0/couchdb/releases/views/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/releases/views/projectBuildIds/
+-rw-r--r--   0 root         (0) root         (0)      165 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/releases/views/projectBuildIds/map.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/summaries/
+-rw-r--r--   0 root         (0) root         (0)       18 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/summaries/_id
+-rw-r--r--   0 root         (0) root         (0)       11 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/summaries/language
+-rw-r--r--   0 root         (0) root         (0)      264 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/summaries/rewrites.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.496000 LbNightlyTools-4.0.0/couchdb/summaries/views/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/summaries/views/byDay/
+-rw-r--r--   0 root         (0) root         (0)      347 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/summaries/views/byDay/map.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/couchdb/summaries/views/lastBuildId/
+-rw-r--r--   0 root         (0) root         (0)       89 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/summaries/views/lastBuildId/map.js
+-rw-r--r--   0 root         (0) root         (0)      190 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/summaries/views/lastBuildId/reduce.js
+-rwxr-xr-x   0 root         (0) root         (0)     3600 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/couchdb/webapp_testbench.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.512000 LbNightlyTools-4.0.0/cron/
+-rwxr-xr-x   0 root         (0) root         (0)     1863 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/cron/cleanup_artifacts.sh
+-rw-r--r--   0 root         (0) root         (0)      433 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/cron/logrotate.conf
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.516000 LbNightlyTools-4.0.0/docs/
+-rw-r--r--   0 root         (0) root         (0)    25550 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/Interactive builds of LHCb projects.ipynb
+-rw-r--r--   0 root         (0) root         (0)     1318 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/LHCbPR2.md
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.516000 LbNightlyTools-4.0.0/docs/configuration/
+-rw-r--r--   0 root         (0) root         (0)     3017 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/configuration/Example.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.516000 LbNightlyTools-4.0.0/docs/examples/
+-rwxr-xr-x   0 root         (0) root         (0)     1247 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/examples/lbpr-example
+-rw-r--r--   0 root         (0) root         (0)     2628 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/jenkins-scripts.dot
+-rw-r--r--   0 root         (0) root         (0)   142880 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/jenkins-scripts.dot.png
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.516000 LbNightlyTools-4.0.0/docs/note/
+-rw-r--r--   0 root         (0) root         (0)   946715 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/LHCb-INT-2013-006.pdf
+-rw-r--r--   0 root         (0) root         (0)    24731 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/LHCb.bst
+-rw-r--r--   0 root         (0) root         (0)     1679 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/Makefile
+-rw-r--r--   0 root         (0) root         (0)      185 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/README.txt
+-rw-r--r--   0 root         (0) root         (0)     3132 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/appendix.tex
+-rw-r--r--   0 root         (0) root         (0)     5159 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/bibliography.bib
+-rw-r--r--   0 root         (0) root         (0)    32522 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/cite.sty
+-rw-r--r--   0 root         (0) root         (0)      567 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/conclusions.tex
+-rw-r--r--   0 root         (0) root         (0)     5975 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/dashboard.tex
+-rw-r--r--   0 root         (0) root         (0)     2326 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/design.tex
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.520000 LbNightlyTools-4.0.0/docs/note/figs/
+-rw-r--r--   0 root         (0) root         (0)    60108 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/figs/cdash-1.png
+-rw-r--r--   0 root         (0) root         (0)    97134 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/figs/cdash-2.png
+-rw-r--r--   0 root         (0) root         (0)   101416 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/figs/cdash-3.png
+-rw-r--r--   0 root         (0) root         (0)   162025 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/figs/cdash-4.png
+-rw-r--r--   0 root         (0) root         (0)    91381 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/figs/jenkins-1.png
+-rw-r--r--   0 root         (0) root         (0)    81047 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/figs/jenkins-2.png
+-rw-r--r--   0 root         (0) root         (0)   173109 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/figs/jenkins-3.png
+-rw-r--r--   0 root         (0) root         (0)   160146 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/figs/lhcb-logo.eps
+-rw-r--r--   0 root         (0) root         (0)    14116 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/figs/lhcb-logo.pdf
+-rw-r--r--   0 root         (0) root         (0)   134216 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/figs/old-summary.png
+-rw-r--r--   0 root         (0) root         (0)    33058 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/implementation.tex
+-rw-r--r--   0 root         (0) root         (0)     2299 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/introduction.tex
+-rw-r--r--   0 root         (0) root         (0)     5596 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/lhcb-int-2013-006.kilepr
+-rwxr-xr-x   0 root         (0) root         (0)     3645 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/listsymbols
+-rw-r--r--   0 root         (0) root         (0)     1586 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/main.tex
+-rw-r--r--   0 root         (0) root         (0)    61167 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/mciteplus.sty
+-rw-r--r--   0 root         (0) root         (0)     2787 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/preamble.tex
+-rw-r--r--   0 root         (0) root         (0)     1363 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/requirements.tex
+-rw-r--r--   0 root         (0) root         (0)     2478 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/title-LHCb-ANA.tex
+-rw-r--r--   0 root         (0) root         (0)    28723 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/note/unsrturl.bst
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.520000 LbNightlyTools-4.0.0/docs/operation/
+-rw-r--r--   0 root         (0) root         (0)      974 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/operation/Makefile
+-rw-r--r--   0 root         (0) root         (0)    26499 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/operation/NightlyBuildsOperation.html
+-rw-r--r--   0 root         (0) root         (0)    11288 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/operation/NightlyBuildsOperation.rst
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.520000 LbNightlyTools-4.0.0/docs/operation/images/
+-rw-r--r--   0 root         (0) root         (0)      788 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/operation/images/jenkins-jobs.dot
+-rw-r--r--   0 root         (0) root         (0)    32492 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/operation/images/jenkins-jobs.dot.png
+-rw-r--r--   0 root         (0) root         (0)     7965 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/docs/pylint.rc
+-rw-r--r--   0 root         (0) root         (0)      181 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/pyproject.toml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/python/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.520000 LbNightlyTools-4.0.0/python/LbMsg/
+-rwxr-xr-x   0 root         (0) root         (0)     3452 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbMsg/BuildMsg.py
+-rw-r--r--   0 root         (0) root         (0)     4609 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbMsg/Common.py
+-rw-r--r--   0 root         (0) root         (0)     3478 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbMsg/TestMsg.py
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbMsg/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.524000 LbNightlyTools-4.0.0/python/LbNightlyTools/
+-rw-r--r--   0 root         (0) root         (0)     4457 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/ArtifactsServer.py
+-rw-r--r--   0 root         (0) root         (0)    12315 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/BuildLogScanner.py
+-rw-r--r--   0 root         (0) root         (0)    32491 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/BuildMethods.py
+-rw-r--r--   0 root         (0) root         (0)     3715 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/CheckSlotPreconditions.py
+-rw-r--r--   0 root         (0) root         (0)    35063 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/CheckoutMethods.py
+-rw-r--r--   0 root         (0) root         (0)    81350 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Configuration.py
+-rwxr-xr-x   0 root         (0) root         (0)     5166 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/GetNightlyRefs.py
+-rw-r--r--   0 root         (0) root         (0)     7547 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/GitlabUtils.py
+-rw-r--r--   0 root         (0) root         (0)    18542 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/HTMLUtils.py
+-rw-r--r--   0 root         (0) root         (0)     4305 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/LbScriptsUtils.py
+-rw-r--r--   0 root         (0) root         (0)    17730 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/MergeRequestBuilds.py
+-rw-r--r--   0 root         (0) root         (0)     6152 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/ProcUtils.py
+-rw-r--r--   0 root         (0) root         (0)     6339 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Repository.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.528000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/
+-rw-r--r--   0 root         (0) root         (0)    36766 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Build.py
+-rw-r--r--   0 root         (0) root         (0)    15160 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Checkout.py
+-rw-r--r--   0 root         (0) root         (0)    15846 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/CollectBuildLogs.py
+-rwxr-xr-x   0 root         (0) root         (0)    28229 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Common.py
+-rw-r--r--   0 root         (0) root         (0)    13855 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/EnabledSlots.py
+-rw-r--r--   0 root         (0) root         (0)    13783 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/GitlabMR.py
+-rw-r--r--   0 root         (0) root         (0)     7665 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Index.py
+-rw-r--r--   0 root         (0) root         (0)    27932 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Install.py
+-rw-r--r--   0 root         (0) root         (0)     4861 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Preconditions.py
+-rw-r--r--   0 root         (0) root         (0)    17852 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Release.py
+-rw-r--r--   0 root         (0) root         (0)    14262 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Test.py
+-rw-r--r--   0 root         (0) root         (0)      890 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    26838 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/_entry_points.py
+-rw-r--r--   0 root         (0) root         (0)     3002 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/extract.php
+-rw-r--r--   0 root         (0) root         (0)      999 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/listzip.php
+-rw-r--r--   0 root         (0) root         (0)    45291 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/Utils.py
+-rw-r--r--   0 root         (0) root         (0)     1479 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.532000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/
+-rw-r--r--   0 root         (0) root         (0)      921 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8920 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_build.py
+-rw-r--r--   0 root         (0) root         (0)    19337 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_build_script.py
+-rw-r--r--   0 root         (0) root         (0)    12989 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_checkout.py
+-rw-r--r--   0 root         (0) root         (0)     4202 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_checkout_script.py
+-rw-r--r--   0 root         (0) root         (0)     9317 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_config_load.py
+-rw-r--r--   0 root         (0) root         (0)     2140 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_config_pickle.py
+-rw-r--r--   0 root         (0) root         (0)    15153 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_configuration.py
+-rw-r--r--   0 root         (0) root         (0)     2967 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_configuration_check.py
+-rw-r--r--   0 root         (0) root         (0)     3233 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_copytree.py
+-rw-r--r--   0 root         (0) root         (0)     5953 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_coverity_support.py
+-rw-r--r--   0 root         (0) root         (0)    14609 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_enabled_slots_script.py
+-rw-r--r--   0 root         (0) root         (0)     6253 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_gitlab_mr_script.py
+-rw-r--r--   0 root         (0) root         (0)     1872 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_indexer.py
+-rw-r--r--   0 root         (0) root         (0)     2597 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_install.py
+-rw-r--r--   0 root         (0) root         (0)     1759 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_jobconfig.py
+-rw-r--r--   0 root         (0) root         (0)     3655 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_merge_request_builds.py
+-rw-r--r--   0 root         (0) root         (0)     8088 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_pack.py
+-rw-r--r--   0 root         (0) root         (0)     1308 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_precond.py
+-rw-r--r--   0 root         (0) root         (0)    10940 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_rel_gen_script.py
+-rw-r--r--   0 root         (0) root         (0)     8064 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_release_poll.py
+-rw-r--r--   0 root         (0) root         (0)     1302 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_repository.py
+-rw-r--r--   0 root         (0) root         (0)     1571 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_retry.py
+-rw-r--r--   0 root         (0) root         (0)     2457 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_utils.py
+-rw-r--r--   0 root         (0) root         (0)     3338 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbNightlyTools/tests/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.524000 LbNightlyTools-4.0.0/python/LbNightlyTools.egg-info/
+-rw-r--r--   0 root         (0) root         (0)      838 2023-07-11 11:19:26.000000 LbNightlyTools-4.0.0/python/LbNightlyTools.egg-info/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)    11506 2023-07-11 11:19:26.000000 LbNightlyTools-4.0.0/python/LbNightlyTools.egg-info/SOURCES.txt
+-rw-r--r--   0 root         (0) root         (0)        1 2023-07-11 11:19:26.000000 LbNightlyTools-4.0.0/python/LbNightlyTools.egg-info/dependency_links.txt
+-rw-r--r--   0 root         (0) root         (0)     2664 2023-07-11 11:19:26.000000 LbNightlyTools-4.0.0/python/LbNightlyTools.egg-info/entry_points.txt
+-rw-r--r--   0 root         (0) root         (0)        1 2023-07-11 11:19:26.000000 LbNightlyTools-4.0.0/python/LbNightlyTools.egg-info/not-zip-safe
+-rw-r--r--   0 root         (0) root         (0)      143 2023-07-11 11:19:26.000000 LbNightlyTools-4.0.0/python/LbNightlyTools.egg-info/requires.txt
+-rw-r--r--   0 root         (0) root         (0)       61 2023-07-11 11:19:26.000000 LbNightlyTools-4.0.0/python/LbNightlyTools.egg-info/top_level.txt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.532000 LbNightlyTools-4.0.0/python/LbPR/
+-rw-r--r--   0 root         (0) root         (0)     3093 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPR/LbPRJobManager.py
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPR/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    14057 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPR/_entry_points.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.532000 LbNightlyTools-4.0.0/python/LbPeriodicTools/
+-rw-r--r--   0 root         (0) root         (0)     4171 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPeriodicTools/LbPeriodicStarter.py
+-rw-r--r--   0 root         (0) root         (0)    11731 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPeriodicTools/LbPeriodicTest.py
+-rw-r--r--   0 root         (0) root         (0)     2178 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPeriodicTools/LbPeriodicTestSchedule.py
+-rw-r--r--   0 root         (0) root         (0)     1600 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPeriodicTools/TestSchedule.xsd
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPeriodicTools/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    10067 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPeriodicTools/_entry_points.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.532000 LbNightlyTools-4.0.0/python/LbPeriodicTools/tests/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPeriodicTools/tests/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2619 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPeriodicTools/tests/test_LHCbPR.py
+-rw-r--r--   0 root         (0) root         (0)     3561 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPeriodicTools/tests/test_Starter.py
+-rw-r--r--   0 root         (0) root         (0)     4012 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbPeriodicTools/tests/test_XMLParsing.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/python/LbRPMTools/
+-rw-r--r--   0 root         (0) root         (0)    10184 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbRPMTools/LHCbCompatSpecBuilder.py
+-rw-r--r--   0 root         (0) root         (0)    22912 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbRPMTools/LHCbExternalsSpecBuilder.py
+-rw-r--r--   0 root         (0) root         (0)    10040 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbRPMTools/LHCbGenericSpecBuilder.py
+-rw-r--r--   0 root         (0) root         (0)    16527 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbRPMTools/LHCbLbScriptsSpecBuilder.py
+-rw-r--r--   0 root         (0) root         (0)     8700 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbRPMTools/LHCbMetaSpecBuilder.py
+-rw-r--r--   0 root         (0) root         (0)    54217 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbRPMTools/LHCbRPMSpecBuilder.py
+-rw-r--r--   0 root         (0) root         (0)    29932 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbRPMTools/PackageSlot.py
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbRPMTools/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/python/LbRPMTools/tests/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbRPMTools/tests/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6060 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbRPMTools/tests/test_ExternalSpec.py
+-rw-r--r--   0 root         (0) root         (0)    14756 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbRPMTools/tests/test_PackageSlot.py
+-rw-r--r--   0 root         (0) root         (0)    18876 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbRPMTools/tests/test_Spec.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/python/LbTools/
+-rw-r--r--   0 root         (0) root         (0)     5602 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbTools/Manifest.py
+-rw-r--r--   0 root         (0) root         (0)     1676 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbTools/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/python/LbTools/tests/
+-rw-r--r--   0 root         (0) root         (0)     3811 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbTools/tests/test_XMLParsing.py
+-rw-r--r--   0 root         (0) root         (0)     1653 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/python/LbTools/tests/test_toolchain_info.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/scripts/
+-rwxr-xr-x   0 root         (0) root         (0)     1053 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/scripts/lbn-get-configs
+-rwxr-xr-x   0 root         (0) root         (0)     1595 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/scripts/lbn-wrapcmd
+-rwxr-xr-x   0 root         (0) root         (0)     2703 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/scripts/lbpr-collect
+-rw-r--r--   0 root         (0) root         (0)      197 2023-07-11 11:19:26.548000 LbNightlyTools-4.0.0/setup.cfg
+-rw-r--r--   0 root         (0) root         (0)    10837 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/setup.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/testdata/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/testdata/artifacts/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/testdata/artifacts/packs/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/testdata/artifacts/packs/src/
+-rw-r--r--   0 root         (0) root         (0)     2387 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/artifacts/packs/src/TestProject.HEAD.testing-slot.src.zip
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/testdata/build_tests/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/testdata/build_tests/orig/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/testdata/build_tests/orig/dummy/
+-rw-r--r--   0 root         (0) root         (0)      392 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/build_tests/orig/dummy/Makefile
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/testdata/build_tests/test_project/
+-rw-r--r--   0 root         (0) root         (0)      258 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/build_tests/test_project/CMakeLists.txt
+-rw-r--r--   0 root         (0) root         (0)       60 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/build_tests/test_project/lhcbproject.yml
+-rw-r--r--   0 root         (0) root         (0)       14 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/build_tests/test_project/main.cpp
+-rw-r--r--   0 root         (0) root         (0)     6010 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/ci-test-hook-content.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/testdata/collect_deps/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/testdata/collect_deps/broken/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/testdata/collect_deps/broken/BadCMT/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/testdata/collect_deps/broken/BadCMT/cmt/
+-rw-r--r--   0 root         (0) root         (0)       21 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/broken/BadCMT/cmt/project.cmt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/testdata/collect_deps/broken/BadCMake/
+-rw-r--r--   0 root         (0) root         (0)       15 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/broken/BadCMake/CMakeLists.txt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/testdata/collect_deps/broken/Gaudi/
+-rw-r--r--   0 root         (0) root         (0)       28 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/broken/Gaudi/CMakeLists.txt
+-rw-r--r--   0 root         (0) root         (0)       25 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/broken/Gaudi/toolchain.cmake
+-rw-r--r--   0 root         (0) root         (0)      295 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/broken/conf.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.536000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/Brunel/
+-rw-r--r--   0 root         (0) root         (0)      111 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/Brunel/CMakeLists.txt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/Gaudi/
+-rw-r--r--   0 root         (0) root         (0)       28 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/Gaudi/CMakeLists.txt
+-rw-r--r--   0 root         (0) root         (0)       25 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/Gaudi/toolchain.cmake
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/LHCb/
+-rw-r--r--   0 root         (0) root         (0)       85 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/LHCb/CMakeLists.txt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/Lbcom/
+-rw-r--r--   0 root         (0) root         (0)       54 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/Lbcom/CMakeLists.txt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/NewLHCbProj/
+-rw-r--r--   0 root         (0) root         (0)       52 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/NewLHCbProj/lhcbproject.yml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/NewProj/
+-rw-r--r--   0 root         (0) root         (0)       40 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/NewProj/project.info
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/Online/
+-rw-r--r--   0 root         (0) root         (0)      117 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/Online/CMakeLists.txt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/Rec/
+-rw-r--r--   0 root         (0) root         (0)       52 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/Rec/CMakeLists.txt
+-rw-r--r--   0 root         (0) root         (0)      634 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmake/conf.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Brunel/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Brunel/cmt/
+-rw-r--r--   0 root         (0) root         (0)       41 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Brunel/cmt/project.cmt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Gaudi/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Gaudi/cmt/
+-rw-r--r--   0 root         (0) root         (0)       26 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Gaudi/cmt/project.cmt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/LHCb/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/LHCb/cmt/
+-rw-r--r--   0 root         (0) root         (0)       50 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/LHCb/cmt/project.cmt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Lbcom/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Lbcom/cmt/
+-rw-r--r--   0 root         (0) root         (0)       19 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Lbcom/cmt/project.cmt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/NewLHCbProj/
+-rw-r--r--   0 root         (0) root         (0)       52 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/NewLHCbProj/lhcbproject.yml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/NewProj/
+-rw-r--r--   0 root         (0) root         (0)       40 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/NewProj/project.info
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Online/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Online/cmt/
+-rw-r--r--   0 root         (0) root         (0)      115 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Online/cmt/project.cmt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.500000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Rec/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Rec/cmt/
+-rw-r--r--   0 root         (0) root         (0)       21 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/Rec/cmt/project.cmt
+-rw-r--r--   0 root         (0) root         (0)      632 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/collect_deps/cmt/conf.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.504000 LbNightlyTools-4.0.0/testdata/coverity/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/coverity/bin/
+-rwxr-xr-x   0 root         (0) root         (0)     1722 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/coverity/bin/cov-analyze
+-rwxr-xr-x   0 root         (0) root         (0)     1630 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/coverity/bin/cov-build
+-rwxr-xr-x   0 root         (0) root         (0)     1787 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/coverity/bin/cov-commit-defects
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.504000 LbNightlyTools-4.0.0/testdata/coverity/build/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.504000 LbNightlyTools-4.0.0/testdata/coverity/build/TEST/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/coverity/build/TEST/TEST_HEAD/
+-rw-r--r--   0 root         (0) root         (0)      310 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/coverity/build/TEST/TEST_HEAD/CMakeLists.txt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/coverity/build/TEST/TEST_HEAD/InstallArea/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/coverity/build/TEST/TEST_HEAD/InstallArea/.empty
+-rw-r--r--   0 root         (0) root         (0)      256 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/coverity/build/TEST/TEST_HEAD/Makefile
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/coverity/configs/
+-rw-r--r--   0 root         (0) root         (0)      110 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/coverity/configs/coverity_config.py
+-rw-r--r--   0 root         (0) root         (0)      244 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/data-packs.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.504000 LbNightlyTools-4.0.0/testdata/fix_glimpse/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/fix_glimpse/docs/
+-rw-r--r--   0 root         (0) root         (0)       12 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/fix_glimpse/docs/.glimpse_filenames
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/fix_glimpse/level1/
+-rw-r--r--   0 root         (0) root         (0)       54 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/fix_glimpse/level1/.glimpse_filenames
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/fix_glimpse/level1/level2/
+-rw-r--r--   0 root         (0) root         (0)       19 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/fix_glimpse/level1/level2/.glimpse_filenames
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.504000 LbNightlyTools-4.0.0/testdata/fix_glimpse/levelA/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/fix_glimpse/levelA/levelB/
+-rw-r--r--   0 root         (0) root         (0)       10 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/fix_glimpse/levelA/levelB/.glimpse_filenames
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/fix_glimpse/untouched/
+-rw-r--r--   0 root         (0) root         (0)       12 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/fix_glimpse/untouched/.glimpse_filenames
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.504000 LbNightlyTools-4.0.0/testdata/indexer/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.504000 LbNightlyTools-4.0.0/testdata/indexer/AProject/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.504000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/cmake/
+-rw-r--r--   0 root         (0) root         (0)       23 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/cmake/AProjectConfig.cmake
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/include/
+-rw-r--r--   0 root         (0) root         (0)       24 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/include/GeneratedHeader.h
+-rw-r--r--   0 root         (0) root         (0)       14 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/include/MyHeader.h
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.540000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/python/
+-rw-r--r--   0 root         (0) root         (0)       26 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/python/AProject_merged_confDb.py
+-rw-r--r--   0 root         (0) root         (0)       24 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/python/GeneratedPython.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.544000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/python/MyPackage/
+-rw-r--r--   0 root         (0) root         (0)       27 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/python/MyPackage/MyPackageConf.py
+-rw-r--r--   0 root         (0) root         (0)       19 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/python/MyPackage/MyPackage_confDb.py
+-rw-r--r--   0 root         (0) root         (0)       23 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/python/MyPackage/MyPackage_user_confDb.py
+-rw-r--r--   0 root         (0) root         (0)       18 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/python/MyPackage/SomeModule.py
+-rw-r--r--   0 root         (0) root         (0)       16 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/python/MyPackage/SomethingConf.py
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/InstallArea/python/MyPackage/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.504000 LbNightlyTools-4.0.0/testdata/indexer/AProject/MyPackage/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.544000 LbNightlyTools-4.0.0/testdata/indexer/AProject/MyPackage/Headers/
+-rw-r--r--   0 root         (0) root         (0)       14 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/MyPackage/Headers/MyHeader.h
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.504000 LbNightlyTools-4.0.0/testdata/indexer/AProject/MyPackage/python/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.544000 LbNightlyTools-4.0.0/testdata/indexer/AProject/MyPackage/python/MyPackage/
+-rw-r--r--   0 root         (0) root         (0)       18 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/MyPackage/python/MyPackage/SomeModule.py
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/MyPackage/python/MyPackage/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.544000 LbNightlyTools-4.0.0/testdata/indexer/AProject/MyPackage/scripts/
+-rw-r--r--   0 root         (0) root         (0)       11 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/MyPackage/scripts/MyScript
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.544000 LbNightlyTools-4.0.0/testdata/indexer/AProject/MyPackage/src/
+-rw-r--r--   0 root         (0) root         (0)       15 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/MyPackage/src/MySource.cpp
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.544000 LbNightlyTools-4.0.0/testdata/indexer/AProject/build.dir/
+-rw-r--r--   0 root         (0) root         (0)       18 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/indexer/AProject/build.dir/IgnoredSource.cpp
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.544000 LbNightlyTools-4.0.0/testdata/periodic_tests/
+-rw-r--r--   0 root         (0) root         (0)      811 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/periodic_tests/lhcbpr_schedule.xml
+-rw-r--r--   0 root         (0) root         (0)      743 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/periodic_tests/schedule.xml
+-rw-r--r--   0 root         (0) root         (0)      402 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/periodic_tests/scheduleIncorrect.xml
+-rw-r--r--   0 root         (0) root         (0)    15858 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/periodic_tests/slotbuilds.json
+-rw-r--r--   0 root         (0) root         (0)      886 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/periodic_tests/starter_schedule.xml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.544000 LbNightlyTools-4.0.0/testdata/rpm/
+-rw-r--r--   0 root         (0) root         (0)     1265 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/Brunel_v46r0.spec
+-rw-r--r--   0 root         (0) root         (0)     1687 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/Brunel_v46r0_x86_64-slc6-gcc48-opt.spec
+-rw-r--r--   0 root         (0) root         (0)     2533 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/Gaudi_v27r0_x86_64-slc6-gcc49-do0.spec
+-rw-r--r--   0 root         (0) root         (0)     7196 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/LCG_68_externalsDict.json
+-rw-r--r--   0 root         (0) root         (0)     3230 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/PARAM_TMVAWeights.spec
+-rw-r--r--   0 root         (0) root         (0)     3230 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/PARAM_TMVAWeights_rel5.spec
+-rw-r--r--   0 root         (0) root         (0)      938 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/datapkg-slot-config.json
+-rw-r--r--   0 root         (0) root         (0)     1981 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/glimpse_Brunel_v46r0.spec
+-rw-r--r--   0 root         (0) root         (0)      617 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/manifest.xml
+-rw-r--r--   0 root         (0) root         (0)     1273 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/manifest_do0.xml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.544000 LbNightlyTools-4.0.0/testdata/rpm/rel/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/rel/PARAM_TMVAWeights_v1r2-1.0.0-1.noarch.rpm
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/rel/PARAM_TMVAWeights_v1r4-1.0.0-1.noarch.rpm
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/rel/PARAM_TMVAWeights_v1r4-1.0.0-4.noarch.rpm
+-rw-r--r--   0 root         (0) root         (0)        0 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/rel/PARAM_TMVAWeights_v1r4-1.0.0-toto.noarch.rpm
+-rw-r--r--   0 root         (0) root         (0)      893 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/slot-config.json
+-rw-r--r--   0 root         (0) root         (0)      892 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/rpm/slot-configdo0.json
+-rw-r--r--   0 root         (0) root         (0)      414 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/testing-slot-2.json
+-rw-r--r--   0 root         (0) root         (0)      381 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/testing-slot-2b.json
+-rw-r--r--   0 root         (0) root         (0)      364 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/testing-slot-env.json
+-rw-r--r--   0 root         (0) root         (0)      279 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/testing-slot-lbcore-192.json
+-rw-r--r--   0 root         (0) root         (0)      398 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/testing-slot-lbcore-664.json
+-rw-r--r--   0 root         (0) root         (0)      267 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/testing-slot-with-shared.json
+-rw-r--r--   0 root         (0) root         (0)      219 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/testing-slot.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.544000 LbNightlyTools-4.0.0/testdata/tools/
+-rw-r--r--   0 root         (0) root         (0)      658 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/tools/manifest.xml
+-rw-r--r--   0 root         (0) root         (0)     1273 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/tools/manifest_do0.xml
+-rw-r--r--   0 root         (0) root         (0)     1074 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/tools/manifest_with_pkgs.xml
+-rw-r--r--   0 root         (0) root         (0)     1588 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/tools/manifest_with_pkgs_new.xml
+-rw-r--r--   0 root         (0) root         (0)      103 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/testdata/tools/mini_manifest.xml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-11 11:19:26.544000 LbNightlyTools-4.0.0/utils/
+-rw-r--r--   0 root         (0) root         (0)     1742 2023-07-11 11:19:25.000000 LbNightlyTools-4.0.0/utils/add_ci_webhook.py
```

### filetype from file(1)

```diff
@@ -1 +1 @@
-POSIX tar archive (GNU)
+POSIX tar archive
```

### Comparing `LbNightlyTools-3.0.9/COPYING` & `LbNightlyTools-4.0.0/COPYING`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/PKG-INFO` & `LbNightlyTools-4.0.0/PKG-INFO`

 * *Files 14% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-Metadata-Version: 1.1
+Metadata-Version: 2.1
 Name: LbNightlyTools
-Version: 3.0.9
+Version: 4.0.0
 Summary: LHCb Nightly tools
 Home-page: https://gitlab.cern.ch/lhcb-core/LbNightlyTools
 Author: CERN - LHCb Core Software
 Author-email: lhcb-core-soft@cern.ch
-License: UNKNOWN
-Description: LbNightlyTools
-        ===============
-        
-        Scripts to perform LHCb Nightly builds.
-        
-Platform: UNKNOWN
 Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Developers
 Classifier: Topic :: Software Development :: Build Tools
 Classifier: License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)
 Classifier: Programming Language :: Python :: 2
 Classifier: Programming Language :: Python :: 2.7
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.4
 Classifier: Programming Language :: Python :: 3.5
 Classifier: Programming Language :: Python :: 3.6
+License-File: COPYING
+
+LbNightlyTools
+===============
+
+Scripts to perform LHCb Nightly builds.
```

### Comparing `LbNightlyTools-3.0.9/utils/add_ci_webhook.py` & `LbNightlyTools-4.0.0/utils/add_ci_webhook.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,56 +1,60 @@
-import gitlab
+import logging
 import os
 import subprocess
-import logging
+
+import gitlab
 
 logging.basicConfig(level=logging.INFO)
 logger = logging.getLogger()
 
-out = subprocess.check_output(['lb-sdb-query', 'listProjects'])
+out = subprocess.check_output(["lb-sdb-query", "listProjects"])
 PROJECTS = out.splitlines()
-HOOK_URL = 'https://lhcb-nightlies.cern.ch/jenkins/'
-HOOK_TOKEN = os.environ['HOOK_TOKEN']
-GITLAB_TOKEN = os.environ['GITLAB_TOKEN']
+HOOK_URL = "https://lhcb-nightlies.web.cern.ch/jenkins/"
+HOOK_TOKEN = os.environ["HOOK_TOKEN"]
+GITLAB_TOKEN = os.environ["GITLAB_TOKEN"]
 
 
 def find_hook(project, url):
     for hook in project.hooks.list(all=True):
-        if hook.attributes['url'] == url:
+        if hook.attributes["url"] == url:
             return hook
 
 
 def setup_webhook(project):
     # Find or create a webhook for HOOK_URL
     try:
         hook = find_hook(project, url=HOOK_URL)
     except gitlab.exceptions.GitlabListError:
-        logger.warning('Insufficient permissions for {0}, skipping'.format(
-            project.attributes['path_with_namespace']))
+        logger.warning(
+            "Insufficient permissions for {0}, skipping".format(
+                project.attributes["path_with_namespace"]
+            )
+        )
         return
     if not hook:
-        hook = project.hooks.create(data={'url': HOOK_URL})
+        hook = project.hooks.create(data={"url": HOOK_URL})
 
     # Configure the webhook
     data = {}
     # - set all _events attributes to False
     for attr in hook.attributes:
-        if attr.endswith('_events'):
+        if attr.endswith("_events"):
             data[attr] = False
     # - except the note_events (comments)
-    data['note_events'] = True
-    data['push_events_branch_filter'] = ''
+    data["note_events"] = True
+    data["push_events_branch_filter"] = ""
     # - set token and ssl verification
-    data['token'] = HOOK_TOKEN
-    data['enable_ssl_verification'] = True
+    data["token"] = HOOK_TOKEN
+    data["enable_ssl_verification"] = True
     hook.save(**data)
 
 
-gitlab_server = gitlab.Gitlab('https://gitlab.cern.ch/', GITLAB_TOKEN)
+gitlab_server = gitlab.Gitlab("https://gitlab.cern.ch/", GITLAB_TOKEN)
 for project in PROJECTS:
-    path = 'lhcb/' + project
-    logger.info('Setting up {0}...'.format(path))
+    path = "lhcb/" + project
+    logger.info("Setting up {0}...".format(path))
     try:
         p = gitlab_server.projects.get(path)
     except gitlab.exceptions.GitlabGetError:
-        logger.warning('Could not get project {0}'.format(path))
+        logger.warning("Could not get project {0}".format(path))
     setup_webhook(p)
```

### Comparing `LbNightlyTools-3.0.9/cron/cleanup_artifacts.sh` & `LbNightlyTools-4.0.0/cron/cleanup_artifacts.sh`

 * *Files 24% similar despite different names*

```diff
@@ -7,24 +7,33 @@
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 
 # Remove old data from the artifacts archive directory.
+#
+# Typical use in acrontab:
+#
+#   0 22 * * * lxplus.cern.ch curl -sSL https://gitlab.cern.ch/lhcb-core/LbNightlyTools/-/raw/master/cron/cleanup_artifacts.sh | bash
+#
+
 
 # prepare environment
 
 logfile=/eos/user/l/lhcbsoft/logs/cleanup_artifacts.log
 artifacts_dir=/eos/project/l/lhcbwebsites/www/lhcb-nightlies-artifacts
 
 # clean up the artifacts directory (if present)
 if [ -e ${artifacts_dir} ] ; then
     echo "$(date): removing old artifacts from ${artifacts_dir}" >> $logfile 2>&1
     find ${artifacts_dir} -mindepth 2 -maxdepth 3 \
-        -daystart -mtime +8 -and -path '*/lhcb-*' \
+        -daystart -mtime +15 -and -path '*/lhcb-*' \
+        -print -exec rm -rf \{} \; >> $logfile 2>&1
+    find ${artifacts_dir}/nightly/lhcb-master-mr -mindepth 2 -maxdepth 2 \
+        -daystart -mtime +3 -and -name 'packs' \
         -print -exec rm -rf \{} \; >> $logfile 2>&1
     find ${artifacts_dir} \
         -daystart -mtime +1 -type f -and -name 'ccache_dir.*.zip' \
         -print -delete >> $logfile 2>&1
 fi
 echo "$(date): done" >> $logfile 2>&1
```

### Comparing `LbNightlyTools-3.0.9/scripts/lbn-wrapcmd` & `LbNightlyTools-4.0.0/scripts/lbn-wrapcmd`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/scripts/lbpr-collect` & `LbNightlyTools-4.0.0/scripts/lbpr-collect`

 * *Files 23% similar despite different names*

```diff
@@ -26,30 +26,31 @@
          git fetch --all
          git reset --hard origin/master
         )
     else
         echo "Clone LHCbPR2HD"
         git clone --quiet --depth=1 https://gitlab.cern.ch/lhcb-core/LHCbPR2HD.git
     fi
-    export LHCBPR_HANDLERS_PATH="LHCbPR2HD"
 fi
 
-# Get conda environment
-xrdcp -f root://eosuser.cern.ch//eos/lhcb/storage/lhcbpr/conda/handlers-env.tar.gz handlers-env.tar.gz
-rm -rf handlers-env
-mkdir handlers-env
-tar -xf handlers-env.tar.gz -C handlers-env
-source handlers-env/bin/activate
-
-# Hack to prevent ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1108)
-export SSL_CERT_DIR=/etc/pki/tls/certs/ 
-
-# Collect the run results...
-echo "Run" $LHCBPR_HANDLERS_PATH/collectRunResults.py "$@"
-$LHCBPR_HANDLERS_PATH/collectRunResults.py "$@"
-
-# Deactivating conda environment
-source handlers-env/bin/deactivate
+# Collecting results
+# default env of lb-conda has most of the packages needed to run handlers (ROOT, numpy, matplotlib, pyparsing, requests, pytest)
+# we need to add few packages defined in nightlies-jenkins-scripts (e.g. LbNightlyTools, lxml)
+[[ -e hd-env/run ]] || env -i bash -c "source /cvmfs/lhcb.cern.ch/lib/LbEnv ; lb-conda-dev virtual-env default hd-env"
+curl -o handlers-requirements.txt https://gitlab.cern.ch/lhcb-core/nightlies-jenkins-scripts/raw/master/lhcbpr2hd-reqs/requirements.txt
+./hd-env/run pip install --index-url https://lhcb-repository.web.cern.ch/repository/pypi/simple --use-feature=2020-resolver -r handlers-requirements.txt
+echo "Run" ./LHCbPR2HD/collectRunResults.py "$@"
+./hd-env/run env \
+SSL_CERT_DIR=/etc/pki/tls/certs/ \
+REQUESTS_CA_BUNDLE=/etc/pki/tls/cert.pem \
+SSL_CERT_FILE=/etc/pki/tls/cert.pem \
+BUILD_ID=$BUILD_ID \
+BUILD_URL=$BUILD_URL \
+GITLAB_TOKEN=$GITLAB_TOKEN \
+MATTERMOST_HOOK=$MATTERMOST_HOOK \
+EFFICIENCY_PLOTS_PRCHECKER_REFERENCE=$EFFICIENCY_PLOTS_PRCHECKER_REFERENCE \
+LHCBPR_WWW=$LHCBPR_WWW \
+LHCBPR_WWW_EOS=$LHCBPR_WWW_EOS \
+./hd-env/bin/python ./LHCbPR2HD/collectRunResults.py "$@"
 
 # Send results to Dirac SE
-env -i bash -c "source /cvmfs/lhcb.cern.ch/lib/LbEnv; lb-run -i -s X509_CERT_DIR=/etc/grid-security/certificates -c best LHCbDirac/prod $LHCBPR_HANDLERS_PATH/sendToDB.py -s `cat unique_re\
-sults_id_zip`"
+/cvmfs/lhcb.cern.ch/lib/var/lib/LbEnv/stable/linux-64/bin/lb-dirac ./LHCbPR2HD/sendToDB.py -d -s `cat unique_results_id_zip`
```

### Comparing `LbNightlyTools-3.0.9/scripts/lbn-get-configs` & `LbNightlyTools-4.0.0/scripts/lbn-get-configs`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/admin/RpmHelpers.py` & `LbNightlyTools-4.0.0/admin/RpmHelpers.py`

 * *Files 5% similar despite different names*

```diff
@@ -5,38 +5,36 @@
 import os
 import re
 
 
 # Util method to prepare the build area
 ################################################################################
 def checkBuildArea(ba):
-
     if not os.path.exists(ba):
         os.makedirs(ba)
 
-    basdirs = ['rpmbuild', 'tmpbuild', 'tmp']
+    basdirs = ["rpmbuild", "tmpbuild", "tmp"]
     for s in basdirs:
         tmp = os.path.join(ba, s)
         if not os.path.exists(tmp):
             os.makedirs(tmp)
 
-    rpmbuild = os.path.join(ba, 'rpmbuild')
-    sdirs = ['SOURCES', 'RPMS', 'BUILD', 'SRPMS']
+    rpmbuild = os.path.join(ba, "rpmbuild")
+    sdirs = ["SOURCES", "RPMS", "BUILD", "SRPMS"]
     for s in sdirs:
         tmp = os.path.join(rpmbuild, s)
         if not os.path.exists(tmp):
             os.makedirs(tmp)
 
 
 # Check if the version matches the LHCb standard
 ################################################################################
 
 
 def checkVersion(version):
-
     m = re.match("v([\d]+)r([\d]+)$", version)
     if m != None:
         return True
     else:
         # Checking whetehr the version matches vXrYpZ in that case
         m = re.match("v([\d]+)r([\d]+)p([\d]+)$", version)
         if m != None:
@@ -60,11 +58,10 @@
         # Checking whether the version matches vXrYpZ in that case
         m = re.match("v([\d]+)r([\d]+)p([\d]+)", version)
         if m != None:
             maj_version = m.group(1)
             min_version = m.group(2)
             patch_version = m.group(3)
         else:
-            raise Exception(
-                "Version %s does not match format vXrY or vXrYpZ" % version)
+            raise Exception("Version %s does not match format vXrY or vXrYpZ" % version)
 
     return (maj_version, min_version, patch_version)
```

### Comparing `LbNightlyTools-3.0.9/admin/createLbScriptsRpm` & `LbNightlyTools-4.0.0/admin/createLbScriptsRpm`

 * *Files 5% similar despite different names*

```diff
@@ -9,68 +9,71 @@
 """
 
 import logging
 import os
 import re
 import subprocess
 import sys
+
 from RpmHelpers import checkBuildArea
 
 log = logging.getLogger()
 log.addHandler(logging.StreamHandler())
 log.setLevel(logging.INFO)
 
 local_directory = os.path.dirname(__file__).strip()
-os.environ['PATH'] = os.pathsep.join([os.environ['PATH'], local_directory])
+os.environ["PATH"] = os.pathsep.join([os.environ["PATH"], local_directory])
 
 
 # Checking arguments
 ################################################################################
 def usage():
     print >> sys.stderr, "Usage: %s version" % sys.argv[0]
     sys.exit(2)
 
 
 from optparse import OptionParser
+
 parser = OptionParser()
 parser.add_option(
     "--versioned",
     dest="useVersion",
     action="store_true",
     help="Parse version and set it in the RPM instead of using it in the name",
     metavar="VERSION",
-    default=False)
+    default=False,
+)
 parser.add_option(
     "--buildarea",
     dest="buildarea",
     action="store",
     help="Location where the RPM is build",
-    default="/tmp/buildarea")
+    default="/tmp/buildarea",
+)
 parser.add_option(
-    "--release",
-    dest="release",
-    action="store",
-    help="Release number",
-    default="0")
+    "--release", dest="release", action="store", help="Release number", default="0"
+)
 
 (options, args) = parser.parse_args()
 
 maxarg = len(args)
 if maxarg < 1:
     print >> sys.stderr, "Missing arguments!"
     usage()
 
 orig_project = "LbScripts"
 project = orig_project.upper()
 version = args[0]
-cmtconfig = ''
+cmtconfig = ""
 
 useVersion = True
-log.info("Creating RPM for <%s> <%s> <%s>  - use version: %s" %
-         (project, version, cmtconfig, useVersion))
+log.info(
+    "Creating RPM for <%s> <%s> <%s>  - use version: %s"
+    % (project, version, cmtconfig, useVersion)
+)
 
 buildarea = options.buildarea
 release = options.release
 checkBuildArea(buildarea)
 log.info("Using build area: %s" % buildarea)
 
 # Parsing version
@@ -89,47 +92,49 @@
         # Checking whether the version matches vXrYpZ in that case
         m = re.match("v([\d]+)r([\d]+)p([\d]+)", version)
         if m != None:
             maj_version = m.group(1)
             min_version = m.group(2)
             patch_version = m.group(3)
         else:
-            log.error(
-                "Version %s does not match format vXrY pr vXryPZ" % version)
+            log.error("Version %s does not match format vXrY pr vXryPZ" % version)
 
 # Checking dependencies
 ################################################################################
 
-p = subprocess.Popen("generateRPMDeps %s %s %s" % (project, version, cmtconfig), \
-                     stdout=subprocess.PIPE, shell = "True")
+p = subprocess.Popen(
+    "generateRPMDeps %s %s %s" % (project, version, cmtconfig),
+    stdout=subprocess.PIPE,
+    shell="True",
+)
 deps = p.communicate()[0]
 
 if deps != None and len(deps) > 0:
     log.info("The RPM will have the following dependencies:")
     for l in deps.splitlines():
         log.info(l)
 else:
     log.info("RPM Without dependencies")
 
 
 # Now preparing rpmbuild command
 ################################################################################
 def addDefine(param, val):
-    if val == None or val == '':
+    if val == None or val == "":
         val = '""'
     return " --define '%s %s' " % (param, val)
 
 
 cmd = "rpmbuild -v"
 cmd += addDefine("build_area", buildarea)
 cmd += addDefine("project", project)
 cmd += addDefine("orig_project", orig_project)
 cmd += addDefine("lbversion", version)
 cmd += addDefine("release", release)
-if cmtconfig != '':
+if cmtconfig != "":
     cmd += addDefine("config", "_" + cmtconfig)
 else:
     cmd += addDefine("config", cmtconfig)
 cmd += addDefine("maj_version", maj_version)
 cmd += addDefine("min_version", min_version)
 cmd += addDefine("patch_version", patch_version)
 cmd += addDefine("packarch", "noarch")
```

### Comparing `LbNightlyTools-3.0.9/admin/LHCb_LbScripts.spectemplate` & `LbNightlyTools-4.0.0/admin/LHCb_LbScripts.spectemplate`

 * *Files 0% similar despite different names*

```diff
@@ -77,8 +77,7 @@
 
 %define date    %(echo `LC_ALL="C" date +"%a %b %d %Y"`)
 
 %changelog
 
 * %{date} User <ben.couturier..rcern.ch>
 - first Version
-
```

### Comparing `LbNightlyTools-3.0.9/jenkins/mock/clean_build.sh` & `LbNightlyTools-4.0.0/docs/operation/Makefile`

 * *Files 23% similar despite different names*

```diff
@@ -1,17 +1,24 @@
-#!/bin/bash
 ###############################################################################
-# (c) Copyright 2013 CERN                                                     #
+# (c) Copyright 2014 CERN                                                     #
 #                                                                             #
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 
+SRCS=$(wildcard *.rst)
+TARGETS=$(SRCS:.rst=.html)
 
-rm expected_builds.json
-rm -f build.sh.*.env
-rm -rf artifacts build tmp
+all: $(TARGETS)
 
+# Generic rule for rst2html
+%.html: %.rst
+	rst2html $^ > $@
+
+clean:
+	$(RM) $(TARGETS)
+
+.PHONY: all clean
```

### Comparing `LbNightlyTools-3.0.9/jenkins/nightly-builds/tests-poll.sh` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,21 +1,14 @@
-#!/bin/bash -e
 ###############################################################################
-# (c) Copyright 2013 CERN                                                     #
+# (c) Copyright 2015 CERN                                                     #
 #                                                                             #
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-
-. $(dirname $0)/../utils.sh
-
-set_common
-
-rm -f test-*.txt
-
-for flavour in ${flavours} ; do
-  lbn-test-poll --debug --submit --flavour ${flavour}
-done
+"""
+Scripts related modules.
+"""
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
```

### Comparing `LbNightlyTools-3.0.9/jenkins/nightly-builds/preconditions.sh` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_precond.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,28 @@
-#!/bin/bash
 ###############################################################################
 # (c) Copyright 2013 CERN                                                     #
 #                                                                             #
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
+import json
 
-. $(dirname $0)/../utils.sh
+from LbNightlyTools.Configuration import findSlot
+from LbNightlyTools.tests.utils import processFile
 
-set_common
+# Uncomment to disable the tests.
+# __test__ = False
 
-execute_preconditions "${slot}.${slot_build_id}"
+
+def test_parseConfigFile():
+    "Preconditions parsing"
+    expected = [{"name": "waitForFile", "args": {"path": "path/to/file"}}]
+
+    found = processFile(json.dumps({"preconditions": expected}), findSlot).preconditions
+    assert found == expected
+
+    found = processFile(json.dumps({}), findSlot).preconditions
+    assert found == []
```

### Comparing `LbNightlyTools-3.0.9/testdata/periodic_tests/starter_schedule.xml` & `LbNightlyTools-4.0.0/testdata/periodic_tests/starter_schedule.xml`

 * *Files 11% similar despite different names*

#### Comparing `LbNightlyTools-3.0.9/testdata/periodic_tests/starter_schedule.xml` & `LbNightlyTools-4.0.0/testdata/periodic_tests/starter_schedule.xml`

```diff
@@ -14,14 +14,14 @@
     <project>Brunel</project>
     <platform>x86_64-slc6-gcc46-*</platform>
     <test group="Weekly"/>
     <os_label>slc6</os_label>
   </periodictest>
   <periodictest>
     <schedule type="month" time="13:00">2,11,23</schedule>
-    <slot>lhcb-trigger*</slot>
-    <project>Moo*</project>
-    <platform>x86_64-slc5-gcc*-opt</platform>
+    <slot>lhcb-trigger.*</slot>
+    <project>Moore</project>
+    <platform>x86_64-slc5-gcc.*-opt</platform>
     <test group="MooreTest"/>
     <os_label>slc5</os_label>
   </periodictest>
 </periodictests>
```

### Comparing `LbNightlyTools-3.0.9/testdata/periodic_tests/schedule.xml` & `LbNightlyTools-4.0.0/testdata/periodic_tests/schedule.xml`

 * *Files 2% similar despite different names*

#### Comparing `LbNightlyTools-3.0.9/testdata/periodic_tests/schedule.xml` & `LbNightlyTools-4.0.0/testdata/periodic_tests/schedule.xml`

```diff
@@ -8,13 +8,13 @@
     <test type="qmtest" group="testname"/>
     <os_label>os_label</os_label>
   </periodictest>
   <periodictest>
     <schedule type="month" time="12:00">1,15,20</schedule>
     <slot>lhcb-head</slot>
     <project>Brunel</project>
-    <platform>x86_64-slc6-gcc46-*</platform>
+    <platform>x86_64-slc6-gcc46-.*</platform>
     <test runner="lhcbpr" group="PRTEST-COLLISION12-1000" env="UsePRConfig"/>
     <os_label>slc6</os_label>
     <count>30</count>
   </periodictest>
 </periodictests>
```

### Comparing `LbNightlyTools-3.0.9/testdata/periodic_tests/slotbuilds.json` & `LbNightlyTools-4.0.0/testdata/periodic_tests/slotbuilds.json`

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

 * *Files 0% similar despite different names*

```diff
@@ -985,8 +985,8 @@
 00003d80: 3970 3622 2c20 226e 616d 6522 3a20 224d  9p6", "name": "M
 00003d90: 6f6f 7265 227d 5d2c 2022 706c 6174 666f  oore"}], "platfo
 00003da0: 726d 7322 3a20 5b22 7838 365f 3634 2d73  rms": ["x86_64-s
 00003db0: 6c63 352d 6763 6334 332d 6f70 7422 2c20  lc5-gcc43-opt", 
 00003dc0: 2278 3836 5f36 342d 736c 6335 2d67 6363  "x86_64-slc5-gcc
 00003dd0: 3433 2d64 6267 222c 2022 6936 3836 2d73  43-dbg", "i686-s
 00003de0: 6c63 352d 6763 6334 332d 6f70 7422 5d7d  lc5-gcc43-opt"]}
-00003df0: 5d                                       ]
+00003df0: 5d0a                                     ].
```

### Comparing `LbNightlyTools-3.0.9/testdata/coverity/bin/cov-commit-defects` & `LbNightlyTools-4.0.0/testdata/coverity/bin/cov-analyze`

 * *Files 12% similar despite different names*

```diff
@@ -5,45 +5,45 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
+from __future__ import print_function
 
 import os
 import sys
-
-from os.path import join
 from json import dump
-
 from optparse import OptionParser
+from os.path import join
 
 parser = OptionParser()
 
 parser.allow_interspersed_args = False
-parser.add_option('--dir', action='store')
-parser.add_option('--strip-path', action='append')
-for opt in ['--host', '--port', '--user', '--stream']:
-    parser.add_option(opt, action='store')
+parser.add_option("--dir", action="store")
+parser.add_option("--strip-path", action="append")
+for opt in [
+    "--all",
+    "--enable-constraint-fpp",
+    "--enable-fnptr",
+    "--enable-single-virtual",
+    "--force",
+]:
+    parser.add_option(opt, action="store_true")
 
 prog = os.path.basename(sys.argv[0])
-print prog, 'args:', sys.argv
+print(prog, "args:", sys.argv)
 
 opts, args = parser.parse_args()
 
-rc = int(os.environ.get('COV_TEST_COMMIT_RC', 0))
+rc = int(os.environ.get("COV_TEST_ANALYZE_RC", 0))
 
 if not os.path.exists(opts.dir):
     os.makedirs(opts.dir)
-with open(join(opts.dir, '{0}.report.json'.format(prog)), 'w') as report:
-    dump({
-        prog: sys.argv,
-        'dir': opts.dir,
-        'host': opts.host,
-        'port': opts.port,
-        'user': opts.user,
-        'stream': opts.stream,
-        'retcode': rc
-    }, report)
+with open(join(opts.dir, "{0}.report.json".format(prog)), "w") as report:
+    dump(
+        {prog: sys.argv, "dir": opts.dir, "strip_path": opts.strip_path, "retcode": rc},
+        report,
+    )
 
 sys.exit(rc)
```

### Comparing `LbNightlyTools-3.0.9/testdata/coverity/bin/cov-build` & `LbNightlyTools-4.0.0/testdata/coverity/bin/cov-commit-defects`

 * *Files 21% similar despite different names*

```diff
@@ -5,42 +5,47 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
+from __future__ import print_function
 
 import os
 import sys
-
-from os.path import join
 from json import dump
-
-from subprocess import call
 from optparse import OptionParser
+from os.path import join
 
 parser = OptionParser()
 
 parser.allow_interspersed_args = False
-parser.add_option('--dir', action='store')
-parser.add_option('--build-description', action='store')
+parser.add_option("--dir", action="store")
+parser.add_option("--strip-path", action="append")
+for opt in ["--host", "--port", "--user", "--stream"]:
+    parser.add_option(opt, action="store")
 
 prog = os.path.basename(sys.argv[0])
-print prog, 'args:', sys.argv
+print(prog, "args:", sys.argv)
 
 opts, args = parser.parse_args()
 
-rc = call(args)
+rc = int(os.environ.get("COV_TEST_COMMIT_RC", 0))
 
 if not os.path.exists(opts.dir):
     os.makedirs(opts.dir)
-with open(join(opts.dir, '{0}.report.json'.format(prog)), 'w') as report:
-    dump({
-        prog: sys.argv,
-        'cmd': args,
-        'dir': opts.dir,
-        'desc': opts.build_description,
-        'retcode': rc
-    }, report)
+with open(join(opts.dir, "{0}.report.json".format(prog)), "w") as report:
+    dump(
+        {
+            prog: sys.argv,
+            "dir": opts.dir,
+            "host": opts.host,
+            "port": opts.port,
+            "user": opts.user,
+            "stream": opts.stream,
+            "retcode": rc,
+        },
+        report,
+    )
 
 sys.exit(rc)
```

### Comparing `LbNightlyTools-3.0.9/testdata/tools/manifest.xml` & `LbNightlyTools-4.0.0/testdata/tools/manifest.xml`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/testdata/tools/manifest_do0.xml` & `LbNightlyTools-4.0.0/testdata/rpm/manifest_do0.xml`

 * *Files 1% similar despite different names*

#### Comparing `LbNightlyTools-3.0.9/testdata/tools/manifest_do0.xml` & `LbNightlyTools-4.0.0/testdata/rpm/manifest_do0.xml`

```diff
@@ -1,10 +1,10 @@
 <?xml version="1.0" encoding="utf-8"?>
 <manifest>
-  <project name="Gaudi" version="HEAD"/>
+  <project name="Gaudi" version="v27r0"/>
   <heptools>
     <version>83</version>
     <binary_tag>x86_64-slc6-gcc49-do0</binary_tag>
     <lcg_platform>x86_64-slc6-gcc49-dbg</lcg_platform>
     <lcg_system>x86_64-slc6-gcc49</lcg_system>
     <packages>
       <package name="AIDA" version="3.2.1"/>
```

### Comparing `LbNightlyTools-3.0.9/testdata/tools/manifest_with_pkgs.xml` & `LbNightlyTools-4.0.0/testdata/tools/manifest_with_pkgs.xml`

 * *Files 8% similar despite different names*

#### Comparing `LbNightlyTools-3.0.9/testdata/tools/manifest_with_pkgs.xml` & `LbNightlyTools-4.0.0/testdata/tools/manifest_with_pkgs.xml`

```diff
@@ -1,10 +1,10 @@
 <?xml version="1.0" encoding="utf-8"?>
 <manifest>
-  <project name="Brunel" version="HEAD"/>
+  <project name="Brunel" version="v0r0"/>
   <heptools>
     <version>70root6</version>
     <binary_tag>x86_64-slc6-gcc48-opt</binary_tag>
     <lcg_system>x86_64-slc6-gcc48</lcg_system>
     <packages>
       <package name="RELAX" version="RELAX_1_4_1"/>
       <package name="Boost" version="1.55.0_python2.7"/>
```

### Comparing `LbNightlyTools-3.0.9/testdata/artifacts/packs/src/TestProject.HEAD.testing-slot.src.zip` & `LbNightlyTools-4.0.0/testdata/artifacts/packs/src/TestProject.HEAD.testing-slot.src.zip`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/testdata/collect_deps/cmt/conf.json` & `LbNightlyTools-4.0.0/testdata/collect_deps/cmt/conf.json`

 * *Files 22% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9722222222222222%*

 * *Differences: {"'projects'": "{insert: [(8, OrderedDict([('name', 'NewLHCbProj'), ('version', 'HEAD')]))]}"}*

```diff
@@ -27,11 +27,15 @@
         {
             "name": "Brunel",
             "version": "HEAD"
         },
         {
             "name": "NewProj",
             "version": "HEAD"
+        },
+        {
+            "name": "NewLHCbProj",
+            "version": "HEAD"
         }
     ],
     "slot": "cmt"
 }
```

### Comparing `LbNightlyTools-3.0.9/testdata/collect_deps/cmake/conf.json` & `LbNightlyTools-4.0.0/testdata/collect_deps/cmake/conf.json`

 * *Files 22% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9722222222222222%*

 * *Differences: {"'projects'": "{insert: [(8, OrderedDict([('name', 'NewLHCbProj'), ('version', 'HEAD')]))]}"}*

```diff
@@ -27,11 +27,15 @@
         {
             "name": "Brunel",
             "version": "HEAD"
         },
         {
             "name": "NewProj",
             "version": "HEAD"
+        },
+        {
+            "name": "NewLHCbProj",
+            "version": "HEAD"
         }
     ],
     "slot": "cmake"
 }
```

### Comparing `LbNightlyTools-3.0.9/testdata/ci-test-hook-content.json` & `LbNightlyTools-4.0.0/testdata/ci-test-hook-content.json`

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

 * *Files 0% similar despite different names*

```diff
@@ -369,8 +369,8 @@
 00001700: 656e 222c 0a20 2020 2020 2020 2022 6176  en",.        "av
 00001710: 6174 6172 5f75 726c 223a 206e 756c 6c2c  atar_url": null,
 00001720: 0a20 2020 2020 2020 2022 6e61 6d65 223a  .        "name":
 00001730: 2022 4765 7268 6172 6420 5261 7665 6e22   "Gerhard Raven"
 00001740: 0a20 2020 207d 2c0a 2020 2020 2270 726f  .    },.    "pro
 00001750: 6a65 6374 5f69 6422 3a20 3430 312c 0a20  ject_id": 401,. 
 00001760: 2020 2022 6576 656e 745f 7479 7065 223a     "event_type":
-00001770: 2022 6e6f 7465 220a 7d                    "note".}
+00001770: 2022 6e6f 7465 220a 7d0a                  "note".}.
```

### Comparing `LbNightlyTools-3.0.9/testdata/rpm/PARAM_TMVAWeights.spec` & `LbNightlyTools-4.0.0/testdata/rpm/PARAM_TMVAWeights.spec`

 * *Files 8% similar despite different names*

```diff
@@ -36,14 +36,16 @@
 Provides: /bin/sh
 Provides: /bin/bash
 
 Provides: %{package} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Provides: %{fullname} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Provides: %{package}_v%{lhcb_maj_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Provides: %{fullname}_v%{lhcb_maj_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
+Provides: %{package}_v%{lhcb_maj_version}r%{lhcb_min_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
+Provides: %{fullname}_v%{lhcb_maj_version}r%{lhcb_min_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Requires: %{projectUp}_common
 Requires(post): LBSCRIPTS
 
 %description
 %{fullname} %{version}
 
 %install
```

### Comparing `LbNightlyTools-3.0.9/testdata/rpm/manifest.xml` & `LbNightlyTools-4.0.0/testdata/rpm/manifest.xml`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/testdata/rpm/Brunel_v46r0.spec` & `LbNightlyTools-4.0.0/testdata/rpm/Brunel_v46r0.spec`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/testdata/rpm/datapkg-slot-config.json` & `LbNightlyTools-4.0.0/testdata/rpm/slot-config.json`

 * *Files 22% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.875%*

 * *Differences: {"'projects'": "[OrderedDict([('version', 'v46r0'), ('name', 'Brunel'), ('dependencies', [])])]",*

 * * 'delete': "['packages']"}*

```diff
@@ -9,25 +9,21 @@
     "description": "Slot used for releasing projects.",
     "error_exceptions": [
         "distcc\\[",
         "::error::",
         "^ *Error *$"
     ],
     "no_patch": true,
-    "packages": [
+    "projects": [
         {
-            "checkout_opts": {
-                "export": true
-            },
-            "container": "PARAM",
-            "name": "TMVAWeights",
-            "version": "v1r4"
+            "dependencies": [],
+            "name": "Brunel",
+            "version": "v46r0"
         }
     ],
-    "projects": [],
     "slot": "lhcb-release",
     "type": "slot-config",
     "warning_exceptions": [
         ".*/boost/.*",
         "^--->> genreflex: WARNING:.*",
         " note:",
         "distcc\\[",
```

### Comparing `LbNightlyTools-3.0.9/testdata/rpm/LCG_68_externalsDict.json` & `LbNightlyTools-4.0.0/testdata/rpm/LCG_68_externalsDict.json`

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

 * *Files 0% similar despite different names*

```diff
@@ -443,8 +443,8 @@
 00001ba0: 6572 6e2e 6368 2f73 772f 6c63 672f 7265  ern.ch/sw/lcg/re
 00001bb0: 6c65 6173 6573 2f4c 4347 434d 542f 4c43  leases/LCGCMT/LC
 00001bc0: 4743 4d54 5f36 382f 4c43 475f 5365 7474  GCMT_68/LCG_Sett
 00001bd0: 696e 6773 2f2e 2e2f 2e2e 2f2e 2e2f 4c43  ings/../../../LC
 00001be0: 475f 3638 2f6f 7261 636c 652f 3131 2e32  G_68/oracle/11.2
 00001bf0: 2e30 2e33 2e30 2f78 3836 5f36 342d 736c  .0.3.0/x86_64-sl
 00001c00: 6336 2d67 6363 3438 2d6f 7074 222c 2022  c6-gcc48-opt", "
-00001c10: 6578 7465 726e 616c 225d 7d              external"]}
+00001c10: 6578 7465 726e 616c 225d 7d0a            external"]}.
```

### Comparing `LbNightlyTools-3.0.9/testdata/rpm/manifest_do0.xml` & `LbNightlyTools-4.0.0/testdata/tools/manifest_do0.xml`

 * *Files 1% similar despite different names*

#### Comparing `LbNightlyTools-3.0.9/testdata/rpm/manifest_do0.xml` & `LbNightlyTools-4.0.0/testdata/tools/manifest_do0.xml`

```diff
@@ -1,10 +1,10 @@
 <?xml version="1.0" encoding="utf-8"?>
 <manifest>
-  <project name="Gaudi" version="HEAD"/>
+  <project name="Gaudi" version="v27r0"/>
   <heptools>
     <version>83</version>
     <binary_tag>x86_64-slc6-gcc49-do0</binary_tag>
     <lcg_platform>x86_64-slc6-gcc49-dbg</lcg_platform>
     <lcg_system>x86_64-slc6-gcc49</lcg_system>
     <packages>
       <package name="AIDA" version="3.2.1"/>
```

### Comparing `LbNightlyTools-3.0.9/testdata/rpm/glimpse_Brunel_v46r0.spec` & `LbNightlyTools-4.0.0/testdata/rpm/glimpse_Brunel_v46r0.spec`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/testdata/rpm/Brunel_v46r0_x86_64-slc6-gcc48-opt.spec` & `LbNightlyTools-4.0.0/testdata/rpm/Brunel_v46r0_x86_64-slc6-gcc48-opt.spec`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 
+%define _binaries_in_noarch_packages_terminate_build   0
 %define lhcb_maj_version 1
 %define lhcb_min_version 0
 %define lhcb_patch_version 0
 %define lhcb_release_version 1
 %define buildarea /tmp/rpmjjQtGe
 %define buildlocation None
 %define project Brunel
```

### Comparing `LbNightlyTools-3.0.9/testdata/rpm/Gaudi_v27r0_x86_64-slc6-gcc49-do0.spec` & `LbNightlyTools-4.0.0/testdata/rpm/Gaudi_v27r0_x86_64-slc6-gcc49-do0.spec`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 
+%define _binaries_in_noarch_packages_terminate_build   0
 %define lhcb_maj_version 1
 %define lhcb_min_version 0
 %define lhcb_patch_version 0
 %define lhcb_release_version 1
 %define buildarea /tmp/rpm3xWw5p
 %define buildlocation None
 %define project Gaudi
```

### Comparing `LbNightlyTools-3.0.9/testdata/rpm/PARAM_TMVAWeights_rel5.spec` & `LbNightlyTools-4.0.0/testdata/rpm/PARAM_TMVAWeights_rel5.spec`

 * *Files 5% similar despite different names*

```diff
@@ -36,14 +36,16 @@
 Provides: /bin/sh
 Provides: /bin/bash
 
 Provides: %{package} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Provides: %{fullname} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Provides: %{package}_v%{lhcb_maj_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Provides: %{fullname}_v%{lhcb_maj_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
+Provides: %{package}_v%{lhcb_maj_version}r%{lhcb_min_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
+Provides: %{fullname}_v%{lhcb_maj_version}r%{lhcb_min_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Requires: %{projectUp}_common
 Requires(post): LBSCRIPTS
 
 %description
 %{fullname} %{version}
 
 %install
```

### Comparing `LbNightlyTools-3.0.9/CHANGELOG.md` & `LbNightlyTools-4.0.0/CHANGELOG.md`

 * *Files 20% similar despite different names*

```diff
@@ -8,14 +8,137 @@
 
 ### Removed
  - Drop support for legacy configuration formats #49
 
 ### Added
  - Add semantics checks for nightly slots configurations #50
 
+## [3.0.26] - 2021-02-24
+
+### Changed
+- Drop support for `getpack` (!338)
+
+### Added
+- Add support for new software stack definitions from https://gitlab.cern.ch/lhcb-core/lhcbstacks/ (!335)
+- Add support for project metadata in lhcbproject.yml (!333, !334)
+
+### Fixed
+- Fix from parallel execution of tests (!337)
+- Match correctly dev and deprecation warnings in CMake output (!336)
+- Fix checkout of data packages when the method was explicitly set to `git` (#82)
+
+## [3.0.25] - 2021-01-05
+
+### Fixed
+ - Do not ignore --jobs option in CMT and old-style CMake tests (!332)
+
+## [3.0.24] - 2020-12-08
+
+### Added
+ - Add lbn-install --jobs option (!331)
+
+## [3.0.23] - 2020-12-08
+
+### Added
+ - Use XRootD also for listing in lbn-install (!330)
+
+## [3.0.22] - 2020-12-01
+
+### Added
+ - Use XRootD if possible and process files in parallel (!298)
+
+## [3.0.21] - 2020-11-03
+
+### Fixed
+- Add support for LCG nightly builds for projects with the new cmake configuration (!327)
+
+## [3.0.20] - 2020-10-15
+
+### Fixed
+- Fix disabling of projects with ci-test (!325)
+- Fix regex matching in LHCbPR test schedule definitions (!326)
+
+## [3.0.19] - 2020-09-29
+
+### Fixed
+- Fixes and improvements in /ci-test hook script (!323)
+- Use lb-dirac instead of lb-run LHCbDirac while sending LHCbPR test results (!324)
+
+## [3.0.18] - 2020-09-16
+
+### Added
+- Set `<project>_INSTALL_VERSION` in CMake cache for all projects (!322)
+
+## [3.0.17] - 2020-09-14
+
+### Fixed
+- Fix Python 3 compatibility in lbn-get-new-refs (!321)
+
+## [3.0.16] - 2020-09-04
+
+### Added
+- Send build ready notification to lbtaskweb (!320)
+
+## [3.0.15] - 2020-07-21
+
+### Fixed
+ - Make clean_slot_dict function also delete ci_test trigger info (!318)
+ - Add SSL variables to conda environment (!319)
+
+## [3.0.14] - 2020-07-16
+
+### Added
+- Add ci-test trigger source to ref_slot (!317)
+
+## [3.0.13] - 2020-07-14
+
+### Added
+ - Add "trigger" information to a test_slot created from a Gitlab MR (!316)
+
+## [3.0.12] - 2020-07-08
+
+### Added
+ - Allow compiler extension in platform strings (like gcc9+py3) (!315)
+
+## [3.0.11] - 2020-06-26
+
+### Fixed
+ - Never trust output to be UTF8, always ignore errors !314
+
+## [3.0.10] - 2020-06-17
+
+### Added
+ - Added artifacts repository !306
+ - Allow regex for slot/platform in periodic test definition !310
+ - Show exception before fallback to legacy configuration !311
+ - Added support for data packages in ci-test #59
+ - Support mixing commits and MRs in ci-test !313
+ - Added tests for the most common cases in ci-test !313
+
+### Changed
+ - Prefer lhcb-nightlies.web.cern.ch over lhcb-nightlies.cern.ch !312
+
+### Fixed
+ - Fixed support for multiple MRs per project in ci-test #43
+ - Do not ignore project target version in ci-test #68
+
+### Removed
+ - Removed wrapper script to run nosetests !313
+
+## [3.0.9] - 2020-05-14
+
+### Added
+ - Added command line option to specify platform in lbn-get-new-refs #69
+
+### Removed
+ - Removed clone of lhcb-benchmark-scripts in lhcbpr throughput testing setup !307
+
+### Fixed
+ - Fixed Python 3 str/bytes issues !304
+
 ## [3.0.8] - 2020-04-22
 
 ### Changed
  - Do not create symlinks for ".cvmfscatalog" in DataProjects checkouts !300
 
 ### Fixed
  - Fixed test after LbEnv 2.0.0 05de0767
@@ -323,15 +446,33 @@
 ## LbScripts-v8r6p3 - 2016-06-20
 version used in LbScripts v8r6p3
 accd05c8  Merge branch 'NoLHCbExternals' into 'master'
 
 ## old-style-dirac - 2016-04-06
 15267618  fixed problem with changes in git merge
 
-[Unreleased]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.8...master
+[Unreleased]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.26...master
+[3.0.26]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.25...3.0.26
+[3.0.25]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.24...3.0.25
+[3.0.24]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.23...3.0.24
+[3.0.23]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.22...3.0.23
+[3.0.22]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.21...3.0.22
+[3.0.21]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.20...3.0.21
+[3.0.20]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.19...3.0.20
+[3.0.19]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.18...3.0.19
+[3.0.18]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.17...3.0.18
+[3.0.17]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.16...3.0.17
+[3.0.16]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.15...3.0.16
+[3.0.15]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.14...3.0.15
+[3.0.14]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.13...3.0.14
+[3.0.13]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.12...3.0.13
+[3.0.12]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.11...3.0.12
+[3.0.11]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.10...3.0.11
+[3.0.10]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.9...3.0.10
+[3.0.9]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.8...3.0.9
 [3.0.8]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.7...3.0.8
 [3.0.7]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.6...3.0.7
 [3.0.6]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.5...3.0.6
 [3.0.5]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.4...3.0.5
 [3.0.4]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.3...3.0.4
 [3.0.3]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.2...3.0.3
 [3.0.2]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/3.0.1...3.0.2
@@ -358,9 +499,7 @@
 [0.4.2]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/0.4.1...0.4.2
 [0.4.1]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/0.4.0...0.4.1
 [0.4.0]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/0.3.0...0.4.0
 [0.3.0]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/0.2.0...0.3.0
 [0.2.0]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/0.1.1...0.2.0
 [0.1.1]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/0.1.0...0.1.1
 [0.1.0]: https://gitlab.cern.ch/lhcb-core/LbNightlyTools/compare/LbScripts-v8r6p8...0.1.0
-
-
```

### Comparing `LbNightlyTools-3.0.9/docs/pylint.rc` & `LbNightlyTools-4.0.0/docs/pylint.rc`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/examples/lbpr-example` & `LbNightlyTools-4.0.0/docs/examples/lbpr-example`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/operation/NightlyBuildsOperation.html` & `LbNightlyTools-4.0.0/docs/operation/NightlyBuildsOperation.html`

 * *Files 0% similar despite different names*

#### Comparing `LbNightlyTools-3.0.9/docs/operation/NightlyBuildsOperation.html` & `LbNightlyTools-4.0.0/docs/operation/NightlyBuildsOperation.html`

```diff
@@ -632,15 +632,15 @@
               <a class="toc-backref" href="#id10">Stop One Platform</a>
             </h3>
             <p>If there are pathologic problems with the build of a slot on one platform, or
 before triggering its rebuild, we can stop it following these steps:</p>
             <ol class="arabic simple">
               <li>
                 go to the
-                <a class="reference external" href="https://lhcb-nightlies.cern.ch/">Nightly Builds Dashboard</a>
+                <a class="reference external" href="https://lhcb-nightlies.web.cern.ch/">Nightly Builds Dashboard</a>
               </li>
               <li>locate on the page the slot/platform to stop</li>
               <li>click on the corresponding Jenkins icon</li>
               <li>
                 click on the small red square icon with an X at the top right, close to the
 text
                 <em>Progress:</em>
@@ -801,15 +801,15 @@
               </li>
             </ol>
             <p>
               Note that you can access the specific build page from the
               <a class="reference external" href="https://lhcb-jenkins.cern.ch/follow-builds-status">Jenkins Jobs Status
 page</a>
               if you cannot find it through the
-              <a class="reference external" href="https://lhcb-nightlies.cern.ch/">Nightly Builds Dashboard</a>
+              <a class="reference external" href="https://lhcb-nightlies.web.cern.ch/">Nightly Builds Dashboard</a>
               .
             </p>
           </div>
         </div>
         <div class="section" id="dashboard-database-manipulation">
           <h2>
             <a class="toc-backref" href="#id16">Dashboard Database Manipulation</a>
```

### Comparing `LbNightlyTools-3.0.9/docs/operation/images/jenkins-jobs.dot` & `LbNightlyTools-4.0.0/docs/operation/images/jenkins-jobs.dot`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/operation/images/jenkins-jobs.dot.png` & `LbNightlyTools-4.0.0/docs/operation/images/jenkins-jobs.dot.png`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/operation/NightlyBuildsOperation.rst` & `LbNightlyTools-4.0.0/docs/operation/NightlyBuildsOperation.rst`

 * *Files 0% similar despite different names*

```diff
@@ -297,10 +297,10 @@
 
 .. _Jenkins: http://jenkins-ci.org/
 .. _CouchDB: http://couchdb.apache.org/
 
 .. _LHCbNightlyConf: https://gitlab.cern.ch/lhcb-core/LHCbNightlyConf/
 
 .. _Nightly Builds View: https://lhcb-jenkins.cern.ch/view/Nightly%20Builds/
-.. _Nightly Builds Dashboard: https://lhcb-nightlies.cern.ch/
+.. _Nightly Builds Dashboard: https://lhcb-nightlies.web.cern.ch/
 
 .. _Jenkins Jobs Status page: https://lhcb-jenkins.cern.ch/follow-builds-status
```

### Comparing `LbNightlyTools-3.0.9/docs/Interactive builds of LHCb projects.ipynb` & `LbNightlyTools-4.0.0/docs/Interactive builds of LHCb projects.ipynb`

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

 * *Files 0% similar despite different names*

```diff
@@ -1590,8 +1590,8 @@
 00006350: 696d 653a 2030 3a30 313a 3331 2e30 3432  ime: 0:01:31.042
 00006360: 3036 365c 6e22 2c0a 2020 2020 2020 2020  066\n",.        
 00006370: 225c 6e22 0a20 2020 2020 2020 5d0a 2020  "\n".       ].  
 00006380: 2020 2020 7d0a 2020 2020 205d 2c0a 2020      }.     ],.  
 00006390: 2020 2022 7072 6f6d 7074 5f6e 756d 6265     "prompt_numbe
 000063a0: 7222 3a20 3130 0a20 2020 207d 0a20 2020  r": 10.    }.   
 000063b0: 5d2c 0a20 2020 226d 6574 6164 6174 6122  ],.   "metadata"
-000063c0: 3a20 7b7d 0a20 207d 0a20 5d0a 7d         : {}.  }. ].}
+000063c0: 3a20 7b7d 0a20 207d 0a20 5d0a 7d0a       : {}.  }. ].}.
```

### Comparing `LbNightlyTools-3.0.9/docs/jenkins-scripts.dot` & `LbNightlyTools-4.0.0/docs/jenkins-scripts.dot`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/jenkins-scripts.dot.png` & `LbNightlyTools-4.0.0/docs/jenkins-scripts.dot.png`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/design.tex` & `LbNightlyTools-4.0.0/docs/note/design.tex`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/introduction.tex` & `LbNightlyTools-4.0.0/docs/note/introduction.tex`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/cite.sty` & `LbNightlyTools-4.0.0/docs/note/cite.sty`

 * *Files 1% similar despite different names*

```diff
@@ -95,20 +95,20 @@
   \let\@celt\@compress@cite \@cite@list % output number list with compression
   \@h@ld % output anything held over
  \endgroup
  \@restore@auxhandle
  }
 
 % For each citation, check if it is defined. If so, then extract plain
-% value to \@B@citeB (without hyperlink info). Then, 
+% value to \@B@citeB (without hyperlink info). Then,
 % If it is a pure number, add it to cite list
 % Otherwise, try extracting prefix and suffix characters.
 %
 \def\@make@cite@list{%
- \expandafter\ifx\csname b@\@citeb\@extra@b@citeb 
+ \expandafter\ifx\csname b@\@citeb\@extra@b@citeb
       \endcsname\relax % undefined: output ? and warning
     \@citea {\bfseries ?}\let\@citea\citepunct \G@refundefinedtrue
     \@warning {Citation `\@citeb' on page \thepage\space undefined}%
  %%   \oc@verbo \global\@namedef{b@\@citeb\@extra@b@citeb}{?}%  ???
  \else %  defined               % remove previous line to repeat warnings
     \@cite@nonhyper@sanitize
     \@addto@cite@list
@@ -119,31 +119,31 @@
     \let\hyper@@link\@nonhyper@@link
     \protected@xdef\@B@citeB{\csname b@\@citeb\@extra@b@citeb \endcsname}%
   \endgroup}
 
 \def\@cite@out#1{\citeform{\csname #1\endcsname}}
 
 % Add entry to the list of citations.  This default definition sorts pure
-% numbers as well as numbers with other single-character tags.  There 
-% is presently no other definition than this default, but features may 
+% numbers as well as numbers with other single-character tags.  There
+% is presently no other definition than this default, but features may
 % be added later.
 %
-\def\@addto@cite@list{% 
+\def\@addto@cite@list{%
  \@cite@posnumtest\@B@citeB
    {\@addnumto@cite@list\@B@citeB}%  a positive number, put in list
    {\@cite@combo@num}% not a pure positive number, test for combo forms
 }
 
 % With this \@cite@combo@num we delve into handling of numbers combined
 % with non-numeric tags.  The specific command name \@cite@combo@num can
-% serve as a hook for redefinition, perhaps to give simple non-sorting 
+% serve as a hook for redefinition, perhaps to give simple non-sorting
 % for anything not a pure number, or to attempt even more complicated
 % sorting, say dictionary sorting of textual citations.  The following
-% definition leads down the road of sorting mostly-numbers but with 
-% optional single-character prefix and/or suffix. 
+% definition leads down the road of sorting mostly-numbers but with
+% optional single-character prefix and/or suffix.
 
 \def\@cite@combo@num{\expandafter\@cite@try@combo\@B@citeB\delimiter}
 
 % First of many stages for sorting numbers with prefix/suffix characters.
 % Test for a leading token of category letter or other (appropriate for
 % all combination types).
 %
@@ -187,15 +187,15 @@
       \ifx\@let@token\delimiter % use number, and remove trailing \delimiter
         \@citeaddcnta \expandafter\@gobble
       \else % non-printable char found, so abandon fancy processing
         \expandafter\@cite@gobbledump@now
       \fi
     }}
 
-%  Have everything up to a suffix or separator character.  Check 
+%  Have everything up to a suffix or separator character.  Check
 %  following to see which. Three possibilites are (1) noting =>
 %  a suffix; (2) number => separator-number; (3) other => garbage.
 %
 \def\@cite@add@letnumF#1#2\delimiter{% #1 = suffix/separator #2=rest
   \advance\@tempcnta`#1\relax
   \@cite@posnumtest{#2}{\@cite@add@numsepnum{#2}}% handle as num sep num
     {% else...
@@ -216,60 +216,60 @@
     \advance\@tempcnta #1 % num,sep,num have maximum numbers:  1023, 255, 4095
     \@citeaddcnta
   \else % out of range, treat as raw string
     \@cite@dump@now
   \fi}
 
 % This is our bail-out when the citation cannot be processed as
-% [prefix]number[suffix] or number[sep]number: it outputs the citation 
-% immediately (unsorted) and consumes tokens to the \delimiter tag used 
+% [prefix]number[suffix] or number[sep]number: it outputs the citation
+% immediately (unsorted) and consumes tokens to the \delimiter tag used
 % as an end-marker
 %
 \def\@cite@gobbledump@now#1\delimiter{\@cite@dump@now}%
 
 \def\@cite@dump@now{%
   \@citea \@cite@out{b@\@citeb\@extra@b@citeb}\let\@citea\citepunct}
 
 % add an entry to the sorted list, using its sort-number \@tempcnta, and
-% also saving the plain-text value \@B@citeB as well as the csname 
-% b@\@citeb\@extra@b@citeb. (The \@B@citeB is actually not used, unless 
+% also saving the plain-text value \@B@citeB as well as the csname
+% b@\@citeb\@extra@b@citeb. (The \@B@citeB is actually not used, unless
 % somebody extends the definitions.)
 \def\@citeaddcnta{%
    \ifnum \@tempcnta>\@tempcntb % new highest, add to end (efficiently)
-      \edef\@cite@list{\@cite@list 
+      \edef\@cite@list{\@cite@list
         \@celt{\number\@tempcnta}{\@B@citeB}{b@\@citeb\@extra@b@citeb}}%
       \@tempcntb\@tempcnta
    \else % other sortable value: insert appropriately
       \edef\@cite@list{\expandafter\@sort@celt\@cite@list \@gobble.\@gobble.}%
    \fi
   }
 
 % add pure numeric entry to cite list, with sorting
 \def\@addnumto@cite@list#1{%
    \@tempcnta#1\relax
    \multiply\@tempcnta\@cclvi
    \@citeaddcnta}
 
-% \@sort@celt inserts number (\@tempcnta) into list of \@celt{num}{text}{tag} 
+% \@sort@celt inserts number (\@tempcnta) into list of \@celt{num}{text}{tag}
 % (#1{#2}{#3}{#4})
-% \@celt must not be expandable, and the arguments must not be fragile. 
+% \@celt must not be expandable, and the arguments must not be fragile.
 % List should end with four vanishing tokens.
 %
 \def\@sort@celt#1#2#3#4{\ifx \@celt #1% parameters are \@celt{num}{text}{tag}
    \ifnum #2<\@tempcnta % number goes later in list
       \@celt{#2}{#3}{#4}%
       \expandafter\expandafter\expandafter\@sort@celt % continue
    \else % number goes here
       \@celt{\number\@tempcnta}{\@B@citeB}{b@\@citeb\@extra@b@citeb}%
       \@celt{#2}{#3}{#4}% stop comparing
 \fi\fi}
 
-% Check if each number follows previous and can be put in a range. 
-% Since there are suffix characters allowed, there are two kinds of 
-% ranges: ranges of consecutive pure numbers with no (or same) 
+% Check if each number follows previous and can be put in a range.
+% Since there are suffix characters allowed, there are two kinds of
+% ranges: ranges of consecutive pure numbers with no (or same)
 % suffix, or ranges of the same number with consecutive suffix
 % characters.
 %
 \def\@compress@cite#1#2#3{%% This is executed for each number
   \ifnum\@cite@incr=\z@   % no consecutives pending. Try both types of sequence
     \advance\@tempcnta\@cclvi % Now \@tempcnta has incremented number
     \ifnum #1=\@tempcnta    % Start a sequence of consecutive numbers
@@ -392,32 +392,32 @@
 
 % \@if@fillglue{glue}{true}{false}
 \begingroup
  \catcode`F=12 \catcode`I=12\catcode`L=12
  \lowercase{\endgroup
  \def\@if@fillglue#1{%
   \begingroup \skip@#1\relax
-  \expandafter\endgroup\expandafter 
+  \expandafter\endgroup\expandafter
   \@is@fil@ \the\skip@ \relax\@firstoftwo FIL\relax\@secondoftwo\@nil}
  \def\@is@fil@ #1FIL#2\relax#3#4\@nil{#3}
 }
 
-% Test if next token is a char of "printable" categories other or letter or 
+% Test if next token is a char of "printable" categories other or letter or
 % active.  Syntax:
 %  \@if@printable@char {do if printable}{do if not printable}<char>
 %
 \def\@if@printable@char#1#2{%
   \def\reserved@a{#1}%
   \def\reserved@b{#2}%
   \futurelet\@let@token\@test@print@char
 }
 
 % Note side-effect of redefining \reserved@a and \reserved@b
 \def\@test@print@char{%
- \ifnum 
+ \ifnum
     \ifcat\noexpand\@let@token A1\fi
     \ifcat\noexpand\@let@token 11\fi
     \ifcat\noexpand\@let@token \noexpand~1\fi%
   0>\z@
     \expandafter\reserved@a \else
     \expandafter\reserved@b \fi
 }
@@ -478,31 +478,31 @@
    \else
       % [sort,nocompress]
       \def\@compress@cite#1#2#3{%  % This is executed for each number
         \@h@ld \@citea \@cite@out{#3}%
         \let\@h@ld\@empty \let\@citea\citepunct
       }
    \fi
-\else %  
+\else %
    \ifx\@citeaddcnta\@empty % [nosort,compress]
      %  nosort: always add to end of list, but still calculate
      %  sort-order number (\@tempcnta) because it may be used for
      %  collapsing consecutive numbers.
      \def\@citeaddcnta{%
-       \edef\@cite@list{\@cite@list 
+       \edef\@cite@list{\@cite@list
         \@celt{\number\@tempcnta}{\@B@citeB}{b@\@citeb\@extra@b@citeb}}%
      }
    \fi
 \fi
 
 %  Compatability with chapterbib (see use of \@extra@b@citeb above and in chapterbib)
 \@ifundefined{@extra@b@citeb}{\def\@extra@b@citeb{}}{}
 
 %  Compatability with multibib (see use of \@newciteauxhandle) (Yes, this is
-%  overly messy, but I asked for it...  I can't have multibib putting junk after 
+%  overly messy, but I asked for it...  I can't have multibib putting junk after
 %  the cite command because it hides following punctuation, but then I have
 %  to restore the ordinary meaning of \@newciteauxhandle = \@auxout.)
 \providecommand\@newciteauxhandle{\@auxout}
 \AtBeginDocument{\@ifundefined{newcites}{\global\let\@restore@auxhandle\relax}{}}
 \def\@restore@auxhandle{\def\@newciteauxhandle{\@auxout}}
 
 %  compatability with backref: prevent it from redefining \@citex
@@ -541,51 +541,51 @@
 
 o Put a comma and a small space between each citation number. The option
   [nospace] removes that space, and the option [space] replaces it with
   an ordinary inter-word space.
 
 o Compress lists of three or more consecutive numbers to one number range
   which can be split, with difficulty, after the dash.  All numbers should
-  be greater than zero.  E.g., if you used to get the (nonsense) list 
+  be greater than zero.  E.g., if you used to get the (nonsense) list
   [7,5,6,?,4,9,8,Einstein,6], then this style will give [?,Einstein,4-6,6-9].
   Compression of ranges is disabled by the [nocompress] package option.
 
 o Sort citations into ascending order (this is the default, but may also
   be declared with the package option [sort]). The [nosort] package option
   turns off sorting.  Sortable citations must fit one of these forms:
     1.  <number>
     2.  <optional-char><number><optional-char>
     3.  <number><separator-char><number>
   Forms 1 and 2 are really the same, and they mix well, but form 3 is
   separate and if used simultaneously with form 1 the citations become,
   ummm, mixed.  Non-sortable forms (those not listed) are printed before
-  all sortable forms.  Here <number> means a positive integer (natural 
+  all sortable forms.  Here <number> means a positive integer (natural
   number) less than some limit (different for each form), <optional-char>
   is a single printable character (or nothing), and <separator-char> is also
   a single printable character.
 
-o Sorting of citations with prefix and/or suffix characters is done so so 
-  different prefixes are grouped separately, and suffixes form sub-lists 
+o Sorting of citations with prefix and/or suffix characters is done so so
+  different prefixes are grouped separately, and suffixes form sub-lists
   for the same number.  Compression knows about suffixes, so you can get
   lists like [18a-18c,19] or [A2,Q1,Q3-Q5].
 
 o Allow, but discourage, line breaks within the group of citations (after
   dashes, and after punctuation). Penalties are \citepunctpenalty and
-  \citemidpenalty. 
+  \citemidpenalty.
 
-o Put a high-penalty breakpoint (value \citeprepenalty) before the citation 
-  (unless there is a different penalty specified there).  Also, adjust the 
-  spacing: if there is no space or if there is extra space due to some 
-  punctuation, then change to one inter-word space. E.g.,   
+o Put a high-penalty breakpoint (value \citeprepenalty) before the citation
+  (unless there is a different penalty specified there).  Also, adjust the
+  spacing: if there is no space or if there is extra space due to some
+  punctuation, then change to one inter-word space. E.g.,
   A space will be inserted here\cite{Larry,Curly,Moe}.
 
-o All breaks can be forbidden with the [nobreak] package option.  They can 
-  be adjusted independently by setting the parameters \citeprepenalty, 
+o All breaks can be forbidden with the [nobreak] package option.  They can
+  be adjusted independently by setting the parameters \citeprepenalty,
   \citemidpenalty, and \citepunctpenalty.  Use \mathchardef to change these
-  penalty values!  E.g.,  \mathchardef\citeprepenalty=9999 (Yes, that is 
+  penalty values!  E.g.,  \mathchardef\citeprepenalty=9999 (Yes, that is
   obscure but I don't want to use up counters or to pretend they are counters.)
 
 o With package option [superscript] (or [super] for short), display citation
   numbers as superscripts (unless they have optional notes, causing them to
   be printed on-line with brackets).  Superscripted citations follow these
   additional rules:
 
@@ -593,33 +593,33 @@
    style will ignore spaces before the citation, and move trailing punctuation
    before the superscript citation.  For example, "information \cite{source};"
    ignores the space before \cite and puts the semicolon before the number,
    just as if you had typed "information;$^{12}$".  You may switch off movement
    with the [nomove] package option (only relevant with [superscript]).
 
 -> The punctuation characters that will migrate before the superscript are
-   listed in the macro \CiteMoveChars, which you can redefine.  The default 
+   listed in the macro \CiteMoveChars, which you can redefine.  The default
    set of characters is ".,;:";  Perhaps ! and ? should be included too, but
-   they weren't listed in the APS style manual I looked at, and I agree with 
-   that design choice because they put too much visual separation between the 
+   they weren't listed in the APS style manual I looked at, and I agree with
+   that design choice because they put too much visual separation between the
    cite and what it applies to.  Feel free to redefine \CiteMoveChars.  Quotes
-   were listed as coming before the cite notation, but they should be typed 
+   were listed as coming before the cite notation, but they should be typed
    before the \cite command in any case because both on-line and superscript
    cites come after what is quoted (when citing a quotation). This gives one
-   difficulty -- punctuation following quotes won't migrate inside the 
+   difficulty -- punctuation following quotes won't migrate inside the
    quotation: e.g., "``Transition State Theory''\cite{Eyring}." gives out
    ``Transition State Theory''.$^8$, but you may want the period inside the
    quotes, thus: ``Transition State Theory.''$^8$.
 
 -> Doubling of periods (.., ?., !.) is checked for and suppressed. The spacing
    after the citation is set according to the final punctuation mark moved.
    There is a problem with double periods after a capitalized abbreviation
    or directly after \@ : Both of "N.A.S.A. \cite{space}." and "et al.\@
    \cite{many}." will give doubled periods.  These can be fixed as follows:
-   "N.S.A\@. \cite{space}." and "et al.\ \cite{many}.". The NSA example 
+   "N.S.A\@. \cite{space}." and "et al.\ \cite{many}.". The NSA example
    gives the wrong spacing when there is no citation.  Sorry.  Use "\ " after
    abbreviations like et al. to get the right spacing within a sentence whether
    or not a citation follows.
 
 -> Remember, these rules regarding punctuation only apply when the [super]
    or [superscript] option was given (or overcite.sty used) and the [nomove]
    option was NOT given.
@@ -639,31 +639,31 @@
 Customization:
 ~~~~~~~~~~~~~~
 There are several options for \usepackage{cite}, some already mentioned.
 
  [superscript] use superscrpts for cites without optional notes
  [super]       alias for [superscript] (like natbib)
  [verbose]     UNUSED NOW! (do repeat duplicate warnings)
- [ref]         uses the format "[Ref.~12, given note]" (useful with 
+ [ref]         uses the format "[Ref.~12, given note]" (useful with
                the superscript option)
  [nospace]     eliminates the spaces after commas in the number list
  [space]       uses a full inter-word space after the commas
  [nobreak]     eliminate all line-breaks
  [nosort]      prevents sorting of the numbers (default is to sort, and the...
  [sort]        option is provided for completeness).
  [nomove]      prevents moving the superscript cite after punctuation.
  [move]        is the default
  [noadjust]    disables `smart' handling of space before a cite
  [adjust]      is the default
  [nocompress]  inhibit compression of consecutive numbers into ranges
  [compress]    is the default
  [biblabel]    define the bibliography label as a superscript
 
-If your citations are not numeric, then you should probably not use 
-cite.sty, but if you must, then at least use the [nosort,nocompress] 
+If your citations are not numeric, then you should probably not use
+cite.sty, but if you must, then at least use the [nosort,nocompress]
 options.
 
 There are several commands that you may redefine (using \renewcommand
 or \def) to change the formatting of citation lists:
 
 command          function                    default
 ----------       -----------------------     ----------------------------
@@ -686,16 +686,16 @@
 3: \renewcommand\citeform{\thechapter.}  % by chapter: ^{2.18-2.21}
 4: \renewcommand\citepunct{,} % no space and no breaks at commas
 5: \renewcommand\citemid{; }  % semicolon before optional note
 6: \renewcommand\citeleft{(}  % parentheses around list with note
    \renewcommand\citeright{)} % parentheses around list with note
 
 The appearance of the whole citation list is governed by \@cite, (for full-
-sized cites) and \@citess (for superscripts).  For more extensive changes 
-to the formatting, redefine these.  For example, to get brackets around the 
+sized cites) and \@citess (for superscripts).  For more extensive changes
+to the formatting, redefine these.  For example, to get brackets around the
 list of superscript numbers you can do:
 
    \def\@citess#1{\textsuperscript{[#1]}}
 
 after \makeatletter.
 
 Related Note:  The superscript option does not affect the numbering format
@@ -704,24 +704,24 @@
 
    \renewcommand\@biblabel[1]{\textsuperscript{#1}}
 
 Aw, OK, for your convenience, there is the [biblabel] package option that
 just performs this definition (sort of).
 
 Line breaking can be turned off using the [nobreak] option.  It can be
-controlled more precisely by changing three numeric values, assigned 
+controlled more precisely by changing three numeric values, assigned
 with \mathchardef, for controlling the line-break penalties:
 
 \citeprepenalty   penalty before cite         default \@highpenalty
 \citemidpenalty   penalty used in \citemid    default \@medpenalty
 \citepunctpenalty penalty used in \citepunct  default 1000
 
 (Use \mathchardef assignments like \mathchardef\citemidpenalty=900.
-These were chosen so as to not waste registers.)  Alternatively, the 
-commands \citemid, \citedash, and \citepunct can be redefined to use 
+These were chosen so as to not waste registers.)  Alternatively, the
+commands \citemid, \citedash, and \citepunct can be redefined to use
 different penalty parameters, or none at all.
 
 
 
 
 % Version 1991: Ignore spaces after commas in the parameter list. Move most of
 % \citen into \@cmpresscites for speed. Give the proper \spacefactor afterwards.
@@ -746,23 +746,23 @@
 %      french.sty; warnings in \nocite.
 % 3.8: \citedash hook, fix token look-ahead (Heiko Selber), noadjust, babel.
 % 3.9: More babel-compatibility hacks. Punctuation move with \frencspacing.
 % 4.0: Combine overcite with cite: [superscript] option.  Also add [nocompress]
 %      option and \CiteMoveChars; multibib hooks.
 % 4.01 \bf -> \bfseries
 % 4.02 Bury undouble action in a separate macro to avoid extra \fi error.
-% 5.0  Hyperref and backref compatability! Penalty parameters and [nobreak]. 
+% 5.0  Hyperref and backref compatability! Penalty parameters and [nobreak].
 %      Letter prefix and suffix sorting. Stop suppressing multiple warnings.
 % 5.1  Fix a missing "b@" (disappearing named cites), fix nosort
 % 5.2  More robust treatment of non-numbers
 % 5.3  Handle sort/compress of compound citation numbers (number by chapter)
 %      such as 3.18 or 5-3.  Note that these compounds cannot have prefix or
 %      suffix letters (not enough bits in the maximum TeX number).
 %
 % TODO: other sorting, like dictionary or roman numeral
 % TODO: create special "final punct" that could be ", and " and likewise
-%       a "single punct" that could be " and " 
+%       a "single punct" that could be " and "
 %
 % Send problem reports to asnd@triumf.ca
 
 Test file integrity:  ASCII 32-57, 58-126:  !"#$%&'()*+,-./0123456789
-:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
+:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
```

### Comparing `LbNightlyTools-3.0.9/docs/note/appendix.tex` & `LbNightlyTools-4.0.0/docs/note/appendix.tex`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/figs/lhcb-logo.pdf` & `LbNightlyTools-4.0.0/docs/note/figs/lhcb-logo.pdf`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/figs/old-summary.png` & `LbNightlyTools-4.0.0/docs/note/figs/old-summary.png`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/figs/cdash-3.png` & `LbNightlyTools-4.0.0/docs/note/figs/cdash-3.png`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/figs/cdash-1.png` & `LbNightlyTools-4.0.0/docs/note/figs/cdash-1.png`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/figs/jenkins-3.png` & `LbNightlyTools-4.0.0/docs/note/figs/jenkins-3.png`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/figs/cdash-4.png` & `LbNightlyTools-4.0.0/docs/note/figs/cdash-4.png`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/figs/jenkins-2.png` & `LbNightlyTools-4.0.0/docs/note/figs/jenkins-2.png`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/figs/jenkins-1.png` & `LbNightlyTools-4.0.0/docs/note/figs/jenkins-1.png`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/figs/cdash-2.png` & `LbNightlyTools-4.0.0/docs/note/figs/cdash-2.png`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/figs/lhcb-logo.eps` & `LbNightlyTools-4.0.0/docs/note/figs/lhcb-logo.eps`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/preamble.tex` & `LbNightlyTools-4.0.0/docs/note/preamble.tex`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/LHCb-INT-2013-006.pdf` & `LbNightlyTools-4.0.0/docs/note/LHCb-INT-2013-006.pdf`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/conclusions.tex` & `LbNightlyTools-4.0.0/docs/note/conclusions.tex`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/listsymbols` & `LbNightlyTools-4.0.0/docs/note/listsymbols`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/dashboard.tex` & `LbNightlyTools-4.0.0/docs/note/dashboard.tex`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/bibliography.bib` & `LbNightlyTools-4.0.0/docs/note/bibliography.bib`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/lhcb-int-2013-006.kilepr` & `LbNightlyTools-4.0.0/docs/note/lhcb-int-2013-006.kilepr`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/requirements.tex` & `LbNightlyTools-4.0.0/docs/note/requirements.tex`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/LHCb.bst` & `LbNightlyTools-4.0.0/docs/note/LHCb.bst`

 * *Files 0% similar despite different names*

```diff
@@ -360,40 +360,40 @@
 
 
 FUNCTION {format.eprint}
 { eprint empty$
     { ""}
         { eprint #1 #6 substring$ "arXiv:" =
           eprint #5 #1 substring$ "." =
-          or  
-              { format.eprint.newarXivid } 
-              { format.eprint.oldarXivid } 
+          or
+              { format.eprint.newarXivid }
+              { format.eprint.oldarXivid }
         if$
       }
   if$
 }
 
 
 FUNCTION {format.eprint.paren}
-{ eprint missing$ { "" } { eprint empty$ { "" } {format.eprint} 
-    			   if$ 
-			  } 
+{ eprint missing$ { "" } { eprint empty$ { "" } {format.eprint}
+    			   if$
+			  }
   if$
 }
 
 FUNCTION {format.lhcbid.internal}
-{ "\href{http://cdsweb.cern.ch/search?p=" number * 
-  "&f=reportnumber&action_search=Search&c=LHCb+Internal+Notes&c=LHCb+Analysis+Notes} {" * 
-  number * "}" * 
+{ "\href{http://cdsweb.cern.ch/search?p=" number *
+  "&f=reportnumber&action_search=Search&c=LHCb+Internal+Notes&c=LHCb+Analysis+Notes} {" *
+  number * "}" *
 }
 
 FUNCTION {format.lhcbid.public}
-{ "\href{http://cdsweb.cern.ch/search?p=" number * 
-  "&f=reportnumber&action_search=Search&c=LHCb+Reports&c=LHCb+Conference+Proceedings&c=LHCb+Conference+Contributions&c=LHCb+Notes&c=LHCb+Theses&c=LHCb+Papers} {" * 
-  number * "}" * 
+{ "\href{http://cdsweb.cern.ch/search?p=" number *
+  "&f=reportnumber&action_search=Search&c=LHCb+Reports&c=LHCb+Conference+Proceedings&c=LHCb+Conference+Contributions&c=LHCb+Notes&c=LHCb+Theses&c=LHCb+Papers} {" *
+  number * "}" *
 }
 
 FUNCTION {format.lhcbid}
 { number #6 #3 substring$ "ANA" =
   number #6 #3 substring$ "INT" =
   or
     { format.lhcbid.internal }
@@ -790,24 +790,24 @@
   format.authors "author" output.check
   format.title "title" output.check
   article.sep
   crossref missing$
   { journal missing$
     { format.eprint output }
     { journal empty$ { format.eprint output } {
-      journal ".\ " "." find.replace 
-      ". " "." find.replace 
-      "." ".\ " find.replace 
+      journal ".\ " "." find.replace
+      ". " "." find.replace
+      "." ".\ " find.replace
       "journal" output.check
       blank.sep
       format.volume output
       blank.sep
       format.date.paren "year" output.check
       month empty$ { format.number output }
-        		  'skip$ if$ 
+        		  'skip$ if$
       blank.sep
       format.pages.norange output }
       if$
       }
     if$
     report missing$
             { journal empty$ {} { format.eprint.paren output} if$ }
@@ -832,28 +832,28 @@
   article.sep
   crossref missing$
   { journal missing$
     { format.eprint output }
     { journal empty$ { format.eprint output } {
       "\href{http://dx.doi.org/" doi * "}{" * "doi" output.check
       article.sep
-      journal ".\ " "." find.replace 
-      ". " "." find.replace 
-      "." ".\ " find.replace 
+      journal ".\ " "." find.replace
+      ". " "." find.replace
+      "." ".\ " find.replace
       "journal" output.check
       blank.sep
       format.volume output
       blank.sep
       format.date.paren "year" output.check
       month empty$ { format.number output }
-        		  'skip$ if$ 
+        		  'skip$ if$
       blank.sep
-      format.pages.norange 
+      format.pages.norange
       "}" *
-      output } 
+      output }
       if$
       }
     if$
     report missing$
             { journal empty$ {} { format.eprint.paren output} if$ }
             {blank.sep format.report output format.eprint.paren output}
             if$
@@ -1250,15 +1250,15 @@
 
 % FUNCTION {begin.bib}
 % { preamble$ empty$
 %     'skip$
 %     { preamble$ write$ newline$ }
 %   if$
 %   "\providecommand{\href}[2]{#2}"
-%   "\begingroup\raggedright\begin{thebibliography}{" * longest.label  * 
+%   "\begingroup\raggedright\begin{thebibliography}{" * longest.label  *
 %   "}" * write$ newline$ }
 
 FUNCTION {begin.bib}
 { preamble$ empty$
     'skip$
     { preamble$ write$ newline$ }
   if$
```

### Comparing `LbNightlyTools-3.0.9/docs/note/unsrturl.bst` & `LbNightlyTools-4.0.0/docs/note/unsrturl.bst`

 * *Files 0% similar despite different names*

```diff
@@ -85,15 +85,15 @@
 
   % The following are internal state variables, not configuration constants,
   % so they shouldn't be fiddled with.
   #0 'makeinlinelink :=     % state variable managed by possibly.setup.inlinelink
   "" 'openinlinelink :=     % ditto
   "" 'closeinlinelink :=    % ditto
 }
-INTEGERS { 
+INTEGERS {
   bracket.state
   outside.brackets
   open.brackets
   within.brackets
   close.brackets
 }
 % ...urlbst to here
@@ -206,22 +206,22 @@
     { % Still in brackets.  Add open-bracket or (continuation) comma, add the
       % new text (in s) to the top of the stack, and move to the close-brackets
       % state, ready for next time (unless inbrackets resets it).  If we come
       % into this branch, then output.state is carefully undisturbed.
       bracket.state open.brackets =
         { " [" * }
         { ", " * } % bracket.state will be within.brackets
-      if$ 
-      s * 
+      if$
+      s *
       close.brackets 'bracket.state :=
     }
   if$
 }
 
-% Call this function just before adding something which should be presented in 
+% Call this function just before adding something which should be presented in
 % brackets.  bracket.state is handled specially within output.nonnull.
 FUNCTION {inbrackets}
 { bracket.state close.brackets =
     { within.brackets 'bracket.state := } % reset the state: not open nor closed
     { open.brackets 'bracket.state := }
   if$
 }
@@ -708,22 +708,22 @@
 % make 'null' specials
 FUNCTION {make.href.null}
 {
   pop$
 }
 % make hypertex specials
 FUNCTION {make.href.hypertex}
-{ 
+{
   "\special {html:<a href=" quote$ *
   swap$ * quote$ * "> }" * swap$ *
   "\special {html:</a>}" *
 }
 % make hyperref specials
 FUNCTION {make.href.hyperref}
-{ 
+{
   "\href {" swap$ * "} {\path{" * swap$ * "}}" *
 }
 FUNCTION {make.href}
 { hrefform #2 =
     'make.href.hyperref      % hrefform = 2
     { hrefform #1 =
         'make.href.hypertex  % hrefform = 1
@@ -771,18 +771,18 @@
 % Output a URL.  We can't use the more normal idiom (something like
 % `format.url output'), because the `inbrackets' within
 % format.lastchecked applies to everything between calls to `output',
 % so that `format.url format.lastchecked * output' ends up with both
 % the URL and the lastchecked in brackets.
 FUNCTION {output.url}
 { url empty$
-    'skip$ 
-    { new.block 
+    'skip$
+    { new.block
       format.url output
-      format.lastchecked output 
+      format.lastchecked output
     }
   if$
 }
 
 FUNCTION {output.web.refs}
 {
   new.block
@@ -832,15 +832,15 @@
   if$
   fin.entry.original
 }
 
 % Webpage entry type.
 % Title and url fields required;
 % author, note, year, month, and lastchecked fields optional
-% See references 
+% See references
 %   ISO 690-2 http://www.nlc-bnc.ca/iso/tc46sc9/standard/690-2e.htm
 %   http://www.classroom.net/classroom/CitingNetResources.html
 %   http://neal.ctstateu.edu/history/cite.html
 %   http://www.cas.usf.edu/english/walker/mla.html
 % for citation formats for web pages.
 FUNCTION {webpage}
 { output.bibitem
```

### Comparing `LbNightlyTools-3.0.9/docs/note/Makefile` & `LbNightlyTools-4.0.0/docs/note/Makefile`

 * *Files 4% similar despite different names*

```diff
@@ -26,22 +26,22 @@
 FIGSOURCES = $(wildcard figs/*$(FIGEXT))
 SOURCES    = $(TEXSOURCES) $(FIGSOURCES)
 
 # define output (could be making .ps instead)
 OUTPUT = $(MAIN)$(MAINEXT)
 
 # prescription how to make output (your favorite commands to process latex)
-# do latex twice to make sure that all cross-references are updated 
+# do latex twice to make sure that all cross-references are updated
 $(OUTPUT): $(SOURCES) Makefile
 	$(BUILDCOMMAND)
 
 # just so we can say "make all" without knowing the output name
 all: $(OUTPUT)
 
 # remove temporary files (good idea to say "make clean" before putting things back into repository)
 .PHONY : clean
 clean:
 	rm -f *~ *.aux *.log *.bbl *.blg *.dvi *.tmp *.out *.blg *.bbl $(MAIN)$(MAINEXT) $(MAIN).ps
 
 # remove output file
-rmout: 
+rmout:
 	rm  $(OUTPUT)
```

### Comparing `LbNightlyTools-3.0.9/docs/note/title-LHCb-ANA.tex` & `LbNightlyTools-4.0.0/docs/note/title-LHCb-ANA.tex`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/main.tex` & `LbNightlyTools-4.0.0/docs/note/main.tex`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/implementation.tex` & `LbNightlyTools-4.0.0/docs/note/implementation.tex`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/docs/note/mciteplus.sty` & `LbNightlyTools-4.0.0/docs/note/mciteplus.sty`

 * *Files 1% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 %% Support site:
 %% http://www.michaelshell.org/tex/mciteplus/
 %%
 %%*************************************************************************
 %% Legal Notice:
 %% This code is offered as-is without any warranty either expressed or
 %% implied; without even the implied warranty of MERCHANTABILITY or
-%% FITNESS FOR A PARTICULAR PURPOSE! 
+%% FITNESS FOR A PARTICULAR PURPOSE!
 %% User assumes all risk.
 %% In no event shall any contributor to this code be liable for any damages
 %% or losses, including, but not limited to, incidental, consequential, or
 %% any other damages, resulting from the use or misuse of any information
 %% contained here.
 %%
 %% All comments are the opinions of their respective authors.
@@ -368,15 +368,15 @@
 \fi}
 
 
 % for debug status messages
 % converts given status number to word description
 \def\@mciteStatusNumToWord#1{\expandafter\ifcase#1\relax
 Unknown\or Tail\or Head with tails\or Head without tails\else Invalid (#1)\fi}
-% form that makes no distinction between status 2 or 3. Used with \cite debug as 
+% form that makes no distinction between status 2 or 3. Used with \cite debug as
 % head status is not finalized till after the entry group
 \def\@mciteStatusNumToWordH#1{\expandafter\ifcase#1\relax
 Unknown\or Tail\or Head\or Head\else Invalid (#1)\fi}
 
 
 
 
@@ -647,15 +647,15 @@
   \fi
   \if@mciteheadredeclared % the current head has been redeclared, OK with some restrictions
     \ifnum\@mcitecurstatus=0\relax % cannot add new tails to previous group definitions
     \PackageError{mciteplus}{New tail citation `\@mcitecurkey' cannot be added to the already existing
                              definition of group of head `\@mcitecurhead'}{You cannot define a group,
                              then reissue the head and add new tail citations.}\relax
     \fi
-    \ifnum\@mcitecurstatus=1\relax % OK to respecify tails as long as they already belong to this group, 
+    \ifnum\@mcitecurstatus=1\relax % OK to respecify tails as long as they already belong to this group,
                                    % this allows for overall (global) bibliographies
       \@mciteGetHeadofTail{\@mcitecurtrackID}{\@mcitecurkey}{\@mciteheadofcurkey}\relax
       \ifx\@mciteheadofcurkey\@mcitecurhead
       % Note: We don't/can't catch the case of repeated tail declarations under a redeclared head.
       % Not a mandatory error anyway.
       \else
         % tail cannot have been declared in definition of another group
@@ -1025,15 +1025,15 @@
 
 % special \if macros needed for PKG hooks
 % we've got to define these here to shield the \ifcontinuouslabels
 % and and \fi from TeX's scanner when multibib is *not* loaded
 % as \ifcontinuouslabels will not be defined and TeX would still
 % see the \fi when skipping over the code.
 %
-% multibib 
+% multibib
 \def\@mciteMULTIBIBcontinuouslabelsWarn{\relax
 \ifmciteResetBibitemCount
    \ifcontinuouslabels
      \typeout{** WARNING: mciteplus is using \string\mciteResetBibitemCounttrue, but multibib was not invoked with `resetlabels' option.}
    \fi
 \else
    \ifcontinuouslabels\else
@@ -1211,15 +1211,15 @@
 }% end ref name do loop
 }% end def \@mcitePKGnewcites
 %
 % setup multibib BIB hooks
 % no need to install bibliography wrapper uaing \@auxoutX as multibbl wrapper alters
 % \@auxout to point to \@auxoutX before starting \mcitethebibliography
 % Thus, the default bibteckID will work.
-% 
+%
 % warn if a mismatch between the settings of mciteplus entry label counter resets and those of multibib
 \expandafter\@mcitetmptoksA\expandafter=\expandafter{\@mcitepkgBIBdecl}
 \addto@hook\@mcitetmptoksA{\@mciteMULTIBIBcontinuouslabelsWarn}
 \edef\@mcitepkgBIBdecl{\the\@mcitetmptoksA}
 % reroute all \newcites calls through \@mciteMULTIBIBnewcites
 \let\newcites\@mciteMULTIBIBnewcites
 \fi% if multibib detected
```

### Comparing `LbNightlyTools-3.0.9/docs/configuration/Example.py` & `LbNightlyTools-4.0.0/docs/configuration/Example.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,80 +1,79 @@
 # Example of how the configuration of the nightly builds could look like.
 
-from LbNightlyTools.Configuration import Slot, Project
+from LbNightlyTools.Configuration import Project, Slot
 
 lhcb_head = Slot(
-    'lhcb-head',
-    projects=[
-        Project('Gaudi', 'head', disabled=True),
-        Project('LHCb', 'head')
-    ],
-    env=['CMTPROJECTPATH=${LHCBDEV}:${CMTPROJECTPATH}'])
+    "lhcb-head",
+    projects=[Project("Gaudi", "head", disabled=True), Project("LHCb", "head")],
+    env=["CMTPROJECTPATH=${LHCBDEV}:${CMTPROJECTPATH}"],
+)
 
 
 class CMakeSlot(Slot):
-    build_tool = 'cmake'
-    env = ['PATH=/opt/CMake/bin:${PATH}']
+    build_tool = "cmake"
+    env = ["PATH=/opt/CMake/bin:${PATH}"]
 
 
 class Gaudi(Project):
-    __url__ = 'http://git.cern.ch/pub/gaudi'
+    __url__ = "http://git.cern.ch/pub/gaudi"
 
     def commitId(self):
         import re
-        if self.version == 'head':
+
+        if self.version == "head":
             return master
-        elif re.match(r'v[0-9]+', self.version):
-            return '{0}/{0}_{1}'.format(self.name.upper(), self.version)
-        return self.version.replace('/', '_')
+        elif re.match(r"v[0-9]+", self.version):
+            return "{0}/{0}_{1}".format(self.name.upper(), self.version)
+        return self.version.replace("/", "_")
 
     def checkout(self, **kwargs):
         from LbNightlyTools.Checkout import git
-        args = {'url': self.__url__, 'commit': self.commitId()}
+
+        args = {"url": self.__url__, "commit": self.commitId()}
         args.update(kwargs)
         return git(self, **args)
 
 
 class LHCb(Project):
     pass
 
 
 class LHCb_head(LHCb):
-    override = {'GaudiObjDesc': 'v4r5', 'Tools/CondDBUI': None}
+    override = {"GaudiObjDesc": "v4r5", "Tools/CondDBUI": None}
 
 
 # note:
 #   Project.__init__(self, name, version, ...)
 #   Gaudi.__init__(self, version, ...)
 #   LHCb_head.__init__(self, version='head', ...)
 
 # lhcb_cmake = CMakeSlot('lhcb-cmake',
 #                        projects=[Gaudi('dev/cmake'),
 #                                  LHCb_head(),
 #                                  Project('Lbcom', 'head')])
 CMakeSlot(
-    'lhcb-cmake',
-    projects=[Gaudi('dev/cmake'),
-              LHCb_head(),
-              Project('Lbcom', 'head')])
+    "lhcb-cmake", projects=[Gaudi("dev/cmake"), LHCb_head(), Project("Lbcom", "head")]
+)
 
 
 class HeadSlot(Slot):
-    projects = [Gaudi('head'), LHCb_head()]
+    projects = [Gaudi("head"), LHCb_head()]
 
 
-HeadSlot('lhcb-head-1')
-HeadSlot('lhcb-head-2').projects.append(Project('Lbcom', 'head'))
+HeadSlot("lhcb-head-1")
+HeadSlot("lhcb-head-2").projects.append(Project("Lbcom", "head"))
 
 # in the scripts:
-#from NightlyConf import lhcb_cmake
+# from NightlyConf import lhcb_cmake
 from LbNightlyTools.Configuration import slots
+
 # this should try to import some default configuration module
 # ... or we import it explicitly
-lhcb_cmake = slots['lhcb-cmake']
+lhcb_cmake = slots["lhcb-cmake"]
 
 # lhcb_cmake.json() -> JSON representation of the configuration for the dashboard
 
 # Either we work in current directory or we override it with something like:
 # lhcb_cmake.rootdir = '/a/b/c'
 lhcb_cmake.checkout(export=True)
 # lhcb_cmake.dependencies() -> {'lhcb': ['gaudi'], 'lbcom': ['lhcb'], 'gaudi': []}
@@ -90,17 +89,19 @@
 # build_results.json() -> JSON summary for the dashboard
 test_results = lhcb_cmake.Gaudi.test()
 # similar to the build_results
 
 # ---------------
 # packages
 # ---------------
-from LbNightlyTools.Configuration import Slot, Project, Package, DBASE
+from LbNightlyTools.Configuration import DBASE, Package, Project, Slot
 
-lh = Slot('lhcb-head', [
-    Project('Gaudi', 'head'),
-    Project('LHCb', 'head'),
-    DBASE([Package('AppConfig', 'v3r199'),
-           Package('WG/CharmConfig', 'v3r16')])
-])
+lh = Slot(
+    "lhcb-head",
+    [
+        Project("Gaudi", "head"),
+        Project("LHCb", "head"),
+        DBASE([Package("AppConfig", "v3r199"), Package("WG/CharmConfig", "v3r16")]),
+    ],
+)
 
 lh.DBASE.WG_CharmConfig.checkout()
```

### Comparing `LbNightlyTools-3.0.9/docs/LHCbPR2.md` & `LbNightlyTools-4.0.0/docs/LHCbPR2.md`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/couchdb/merge_requests/views/mrs/map.js` & `LbNightlyTools-4.0.0/couchdb/merge_requests/views/mrs/map.js`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/couchdb/deployment/views/ready/map.js` & `LbNightlyTools-4.0.0/couchdb/deployment/views/ready/map.js`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/couchdb/frontend-stats/README.md` & `LbNightlyTools-4.0.0/couchdb/frontend-stats/README.md`

 * *Files 2% similar despite different names*

```diff
@@ -3,22 +3,22 @@
 This is meant to be an example CouchApp and to ship with most of the CouchApp goodies.
 
 Clone with git:
 
     git clone git://github.com/couchapp/example.git
     cd example
 
-Install with 
-    
+Install with
+
     couchapp push . http://localhost:5984/example
 
 or (if you have security turned on)
 
     couchapp push . http://adminname:adminpass@localhost:5984/example
-  
+
 You can also create this app by running
 
     couchapp generate example && cd example
     couchapp push . http://localhost:5984/example
 
 Deprecated: *couchapp generate proto && cd proto*
```

### Comparing `LbNightlyTools-3.0.9/couchdb/frontend-stats/views/byDate/map.js` & `LbNightlyTools-4.0.0/couchdb/frontend-stats/views/byDate/map.js`

 * *Format-specific differences are supported for JavaScript files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: ASCII text*

 * *Files 6% similar despite different names*

```diff
@@ -86,71 +86,71 @@
 00000550: 6628 746d 7029 7b0a 2020 2020 2020 2020  f(tmp){.        
 00000560: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00000570: 2020 2020 6966 2874 6d70 5b27 4641 494c      if(tmp['FAIL
 00000580: 275d 297b 0a20 2020 2020 2020 2020 2020  ']){.           
 00000590: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000005a0: 2020 2020 2074 6573 745f 6661 696c 6564       test_failed
 000005b0: 203d 2074 6d70 5b27 4641 494c 275d 2e6c   = tmp['FAIL'].l
-000005c0: 656e 6774 6820 0a20 2020 2020 2020 2020  ength .         
+000005c0: 656e 6774 680a 2020 2020 2020 2020 2020  ength.          
 000005d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000005e0: 2020 207d 0a20 2020 2020 2020 2020 2020     }.           
+000005e0: 2020 7d0a 2020 2020 2020 2020 2020 2020    }.            
 000005f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000600: 2069 6628 746d 705b 2750 4153 5327 5d29   if(tmp['PASS'])
-00000610: 7b0a 2020 2020 2020 2020 2020 2020 2020  {.              
+00000600: 6966 2874 6d70 5b27 5041 5353 275d 297b  if(tmp['PASS']){
+00000610: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
 00000620: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000630: 2020 7465 7374 5f70 6173 7365 6420 3d20    test_passed = 
-00000640: 746d 705b 2750 4153 5327 5d2e 6c65 6e67  tmp['PASS'].leng
-00000650: 7468 200a 2020 2020 2020 2020 2020 2020  th .            
-00000660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000670: 7d0a 2020 2020 2020 2020 2020 2020 2020  }.              
-00000680: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00000690: 2874 6d70 5b27 554e 5445 5354 4544 275d  (tmp['UNTESTED']
-000006a0: 297b 0a20 2020 2020 2020 2020 2020 2020  ){.             
+00000630: 2074 6573 745f 7061 7373 6564 203d 2074   test_passed = t
+00000640: 6d70 5b27 5041 5353 275d 2e6c 656e 6774  mp['PASS'].lengt
+00000650: 680a 2020 2020 2020 2020 2020 2020 2020  h.              
+00000660: 2020 2020 2020 2020 2020 2020 2020 7d0a                }.
+00000670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000680: 2020 2020 2020 2020 2020 2020 6966 2874              if(t
+00000690: 6d70 5b27 554e 5445 5354 4544 275d 297b  mp['UNTESTED']){
+000006a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
 000006b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000006c0: 2020 2074 6573 745f 756e 7465 7374 6564     test_untested
-000006d0: 203d 2074 6d70 5b27 554e 5445 5354 4544   = tmp['UNTESTED
-000006e0: 275d 2e6c 656e 6774 6820 0a20 2020 2020  '].length .     
+000006c0: 2074 6573 745f 756e 7465 7374 6564 203d   test_untested =
+000006d0: 2074 6d70 5b27 554e 5445 5354 4544 275d   tmp['UNTESTED']
+000006e0: 2e6c 656e 6774 680a 2020 2020 2020 2020  .length.        
 000006f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000700: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
+00000700: 2020 2020 7d0a 2020 2020 2020 2020 2020      }.          
 00000710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000720: 2020 2020 2069 6628 746d 705b 2745 5252       if(tmp['ERR
-00000730: 4f52 275d 297b 0a20 2020 2020 2020 2020  OR']){.         
+00000720: 2020 6966 2874 6d70 5b27 4552 524f 5227    if(tmp['ERROR'
+00000730: 5d29 7b0a 2020 2020 2020 2020 2020 2020  ]){.            
 00000740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000750: 2020 2020 2020 2074 6573 745f 6572 726f         test_erro
-00000760: 7273 203d 2074 6d70 5b27 4552 524f 5227  rs = tmp['ERROR'
-00000770: 5d2e 6c65 6e67 7468 200a 2020 2020 2020  ].length .      
+00000750: 2020 2020 7465 7374 5f65 7272 6f72 7320      test_errors 
+00000760: 3d20 746d 705b 2745 5252 4f52 275d 2e6c  = tmp['ERROR'].l
+00000770: 656e 6774 680a 2020 2020 2020 2020 2020  ength.          
 00000780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000790: 2020 2020 2020 7d0a 2020 2020 2020 2020        }.        
-000007a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000007b0: 7d0a 2020 2020 2020 2020 2020 2020 2020  }.              
-000007c0: 2020 2020 2020 7d0a 0a20 2020 2020 2020        }..       
-000007d0: 2020 2020 2020 2020 2020 2020 2074 6f5f               to_
-000007e0: 656d 6974 5b27 706c 6174 666f 726d 7327  emit['platforms'
-000007f0: 5d5b 706c 6174 666f 726d 5d5b 7072 6f6a  ][platform][proj
-00000800: 6563 745d 203d 207b 0a20 2020 2020 2020  ect] = {.       
-00000810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000820: 2027 6275 696c 645f 6572 726f 7273 273a   'build_errors':
-00000830: 2062 7569 6c64 5f65 7272 6f72 732c 0a20   build_errors,. 
+00000790: 2020 7d0a 2020 2020 2020 2020 2020 2020    }.            
+000007a0: 2020 2020 2020 2020 2020 2020 7d0a 2020              }.  
+000007b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000007c0: 2020 7d0a 0a20 2020 2020 2020 2020 2020    }..           
+000007d0: 2020 2020 2020 2020 2074 6f5f 656d 6974           to_emit
+000007e0: 5b27 706c 6174 666f 726d 7327 5d5b 706c  ['platforms'][pl
+000007f0: 6174 666f 726d 5d5b 7072 6f6a 6563 745d  atform][project]
+00000800: 203d 207b 0a20 2020 2020 2020 2020 2020   = {.           
+00000810: 2020 2020 2020 2020 2020 2020 2027 6275               'bu
+00000820: 696c 645f 6572 726f 7273 273a 2062 7569  ild_errors': bui
+00000830: 6c64 5f65 7272 6f72 732c 0a20 2020 2020  ld_errors,.     
 00000840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000850: 2020 2020 2020 2027 6275 696c 645f 7761         'build_wa
-00000860: 726e 696e 6773 273a 2062 7569 6c64 5f77  rnings': build_w
-00000870: 6172 6e69 6e67 732c 0a20 2020 2020 2020  arnings,.       
-00000880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000890: 2027 7465 7374 5f65 7272 6f72 7327 3a20   'test_errors': 
-000008a0: 7465 7374 5f65 7272 6f72 732c 0a20 2020  test_errors,.   
+00000850: 2020 2027 6275 696c 645f 7761 726e 696e     'build_warnin
+00000860: 6773 273a 2062 7569 6c64 5f77 6172 6e69  gs': build_warni
+00000870: 6e67 732c 0a20 2020 2020 2020 2020 2020  ngs,.           
+00000880: 2020 2020 2020 2020 2020 2020 2027 7465               'te
+00000890: 7374 5f65 7272 6f72 7327 3a20 7465 7374  st_errors': test
+000008a0: 5f65 7272 6f72 732c 0a20 2020 2020 2020  _errors,.       
 000008b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000008c0: 2020 2020 2027 7465 7374 5f70 6173 7365       'test_passe
-000008d0: 6427 3a20 7465 7374 5f70 6173 7365 642c  d': test_passed,
-000008e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000008f0: 2020 2020 2020 2020 2027 7465 7374 5f66           'test_f
-00000900: 6169 6c65 6427 3a20 7465 7374 5f66 6169  ailed': test_fai
-00000910: 6c65 642c 0a20 2020 2020 2020 2020 2020  led,.           
-00000920: 2020 2020 2020 2020 2020 2020 2027 7465               'te
-00000930: 7374 5f75 6e74 6573 7465 6427 3a20 7465  st_untested': te
-00000940: 7374 5f75 6e74 6573 7465 640a 2020 2020  st_untested.    
-00000950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000960: 7d0a 2020 2020 2020 2020 2020 2020 2020  }.              
-00000970: 2020 7d0a 2020 2020 2020 2020 2020 207d    }.           }
-00000980: 0a20 2020 2020 2020 2020 2020 656d 6974  .           emit
-00000990: 2864 6f63 2e64 6174 652c 2074 6f5f 656d  (doc.date, to_em
-000009a0: 6974 293b 0a20 2020 2020 2020 207d 2020  it);.        }  
-000009b0: 200a 2020 2020 7d0a 7d                    .    }.}
+000008c0: 2027 7465 7374 5f70 6173 7365 6427 3a20   'test_passed': 
+000008d0: 7465 7374 5f70 6173 7365 642c 0a20 2020  test_passed,.   
+000008e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000008f0: 2020 2020 2027 7465 7374 5f66 6169 6c65       'test_faile
+00000900: 6427 3a20 7465 7374 5f66 6169 6c65 642c  d': test_failed,
+00000910: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00000920: 2020 2020 2020 2020 2027 7465 7374 5f75           'test_u
+00000930: 6e74 6573 7465 6427 3a20 7465 7374 5f75  ntested': test_u
+00000940: 6e74 6573 7465 640a 2020 2020 2020 2020  ntested.        
+00000950: 2020 2020 2020 2020 2020 2020 7d0a 2020              }.  
+00000960: 2020 2020 2020 2020 2020 2020 2020 7d0a                }.
+00000970: 2020 2020 2020 2020 2020 207d 0a20 2020             }.   
+00000980: 2020 2020 2020 2020 656d 6974 2864 6f63          emit(doc
+00000990: 2e64 6174 652c 2074 6f5f 656d 6974 293b  .date, to_emit);
+000009a0: 0a20 2020 2020 2020 207d 0a20 2020 207d  .        }.    }
+000009b0: 0a7d 0a                                  .}.
```

### Comparing `LbNightlyTools-3.0.9/couchdb/auth/validate_doc_update.js` & `LbNightlyTools-4.0.0/couchdb/auth/validate_doc_update.js`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/couchdb/Push CouchDB Nightly Builds.launch` & `LbNightlyTools-4.0.0/couchdb/Push CouchDB Nightly Builds.launch`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/couchdb/webapp_testbench.py` & `LbNightlyTools-4.0.0/couchdb/webapp_testbench.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,18 +1,22 @@
 #!/usr/bin/env python
 # -*- coding: utf-8 -*-
-import SimpleHTTPServer
+from __future__ import print_function
+
+from future import standard_library
+
+standard_library.install_aliases()
+import gzip
+import http.server
 import os
 import shutil
-import gzip
-
 from subprocess import call
 
 
-class ForwardHTTPHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):
+class ForwardHTTPHandler(http.server.SimpleHTTPRequestHandler):
     forward_url = None
 
     def send_head(self):
         """Common code for GET and HEAD commands.
 
         This sends the response code and MIME headers.
 
@@ -21,15 +25,15 @@
         and must be closed by the caller under all circumstances), or
         None, in which case the caller has nothing further to do.
 
         """
         path = self.translate_path(self.path)
         f = None
         if os.path.isdir(path):
-            if not self.path.endswith('/'):
+            if not self.path.endswith("/"):
                 # redirect browser - doing basically what apache does
                 self.send_response(301)
                 self.send_header("Location", self.path + "/")
                 self.end_headers()
                 return None
             for index in "index.html", "index.htm":
                 index = os.path.join(path, index)
@@ -38,65 +42,66 @@
                     break
             else:
                 return self.list_directory(path)
 
         ctype = self.guess_type(path)
 
         if not os.path.exists(path):
-            path = '.cache' + self.path
+            path = ".cache" + self.path
             if not os.path.exists(path):
                 if not os.path.exists(os.path.dirname(path)):
                     os.makedirs(os.path.dirname(path))
-                cmd = ['curl', '-k', self.forward_url + self.path, '-o', path]
-                self.log_message('forward request: %s', cmd)
+                cmd = ["curl", "-k", self.forward_url + self.path, "-o", path]
+                self.log_message("forward request: %s", cmd)
                 call(cmd)
                 try:
                     with gzip.open(path) as f:
                         data = f.read()
-                    with open(path, 'wb') as f:
+                    with open(path, "wb") as f:
                         f.write(data)
                 except IOError:
                     pass
 
         try:
             # Always read in binary mode. Opening files in text mode may cause
             # newline translations, making the actual size of the content
             # transmitted *less* than the content-length!
-            f = open(path, 'rb')
+            f = open(path, "rb")
         except IOError:
             self.send_error(404, "File not found")
             return None
         self.send_response(200)
         self.send_header("Content-type", ctype)
         fs = os.fstat(f.fileno())
         self.send_header("Content-Length", str(fs[6]))
         self.send_header("Last-Modified", self.date_time_string(fs.st_mtime))
         self.end_headers()
         return f
 
 
-if __name__ == '__main__':
-    webapp = os.path.join(os.path.dirname(__file__), 'dashboard')
-    baseurl = 'https://lhcb-nightlies.cern.ch'
+if __name__ == "__main__":
+    webapp = os.path.join(os.path.dirname(__file__), "dashboard")
+    baseurl = "https://lhcb-nightlies.web.cern.ch"
     import sys
-    if '-h' in sys.argv or '--help' in sys.argv:
-        print 'Usage: %s [WebApp-dir [forward-url [port]]' % sys.argv[0]
-        print '\nCalled without arguments is equivalent to'
-        print '\t%s %s %s 8000' % (sys.argv[0], webapp, baseurl)
+
+    if "-h" in sys.argv or "--help" in sys.argv:
+        print("Usage: %s [WebApp-dir [forward-url [port]]" % sys.argv[0])
+        print("\nCalled without arguments is equivalent to")
+        print("\t%s %s %s 8000" % (sys.argv[0], webapp, baseurl))
         sys.exit(0)
 
     if sys.argv[1:]:
         webapp = sys.argv.pop(1)
 
-    print 'Entering', webapp
+    print("Entering", webapp)
     os.chdir(webapp)
 
-    if os.path.isdir('.cache'):
-        print 'Cleaning cache...'
-        shutil.rmtree('.cache')
+    if os.path.isdir(".cache"):
+        print("Cleaning cache...")
+        shutil.rmtree(".cache")
 
     if sys.argv[1:]:
         baseurl = sys.argv.pop(1)
     ForwardHTTPHandler.forward_url = baseurl
-    print 'Set up to forward calls to', ForwardHTTPHandler.forward_url
+    print("Set up to forward calls to", ForwardHTTPHandler.forward_url)
 
-    SimpleHTTPServer.test(HandlerClass=ForwardHTTPHandler)
+    http.server.test(HandlerClass=ForwardHTTPHandler)
```

### Comparing `LbNightlyTools-3.0.9/couchdb/old_dashboard/rewrites.json` & `LbNightlyTools-4.0.0/couchdb/old_dashboard/rewrites.json`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/couchdb/README.md` & `LbNightlyTools-4.0.0/couchdb/README.md`

 * *Files 5% similar despite different names*

```diff
@@ -26,12 +26,12 @@
 * **merge_requests** _(nightly, testing)_
   * `mrs`: list slots by merge request applied
   * `mr_slots_by_ref_slot`: list mr ci-test slots related to each ref slot
 * **auth** _(all flavours)_
   * basic permissions check, to prevent unauthorized changes
 * **build_id_index.json** Mango Query Index _(nightly, testing)_
   * index to list slots by name and id
-  
+
 
 Backward compatibility:
 * **old_dashboard** _(all flavours)_
   * only rewrite rules to help the migrations of other tools
```

### Comparing `LbNightlyTools-3.0.9/python/LbPeriodicTools/TestSchedule.xsd` & `LbNightlyTools-4.0.0/python/LbPeriodicTools/TestSchedule.xsd`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/python/LbPeriodicTools/LbPeriodicStarter.py` & `LbNightlyTools-4.0.0/python/LbPeriodicTools/LbPeriodicStarter.py`

 * *Files 12% similar despite different names*

```diff
@@ -4,75 +4,83 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Class to start the periodic tests for a given Date
 
 Created on Dec 2, 2013
 
 @author: Ben Couturier
-'''
+"""
 import logging
+from builtins import object
 from datetime import datetime, timedelta
+
 from LbPeriodicTools.LbPeriodicTestSchedule import PeriodicTestSchedule
-from LbNightlyTools.Utils import DAY_NAMES
-from LbNightlyTools.Utils import Dashboard
+
+from LbNightlyTools.Utils import DAY_NAMES, Dashboard
 
 __log__ = logging.getLogger(__name__)
 
 
 def getSlotsForDay(datestr):
-    '''
+    """
     Query the test DB to locate the list of slots built
-    '''
+    """
     dashboard = Dashboard()
     return [
-        row.doc['config'] for row in dashboard.db.iterview(
-            'summaries/byDay', batch=100, key=datestr, include_docs=True)
+        row.doc["config"]
+        for row in dashboard.db.iterview(
+            "summaries/byDay", batch=100, key=datestr, include_docs=True
+        )
     ]
 
 
 class PeriodicTestStarter(object):
-    '''
+    """
     Parser to the periodic test scheduling XML file
-    '''
+    """
 
-    def __init__(self,
-                 schedule_filename,
-                 datetimestr=None,
-                 testperiod=60,
-                 get_slot_data=getSlotsForDay):
-        '''
+    def __init__(
+        self,
+        schedule_filename,
+        datetimestr=None,
+        testperiod=60,
+        get_slot_data=getSlotsForDay,
+    ):
+        """
         Constructor that takes the XML filename and the test date
-        '''
+        """
         # Checking date
-        if (datetimestr != None):
+        if datetimestr != None:
             self._testdatetimestr = datetimestr
             try:
-                self._testdatetime = datetime.strptime(datetimestr,
-                                                       '%Y-%m-%d %H:%M:%S')
+                self._testdatetime = datetime.strptime(datetimestr, "%Y-%m-%d %H:%M:%S")
             except ValueError:
-                self._testdatetime = datetime.strptime(datetimestr, '%Y-%m-%d')
+                self._testdatetime = datetime.strptime(datetimestr, "%Y-%m-%d")
         else:
             self._testdatetime = datetime.today()
 
-        self._dashboard_date = self._testdatetime.strftime('%Y-%m-%d')
-        self._testdatetime_end = self._testdatetime \
-                                + timedelta(seconds=testperiod)
+        self._dashboard_date = self._testdatetime.strftime("%Y-%m-%d")
+        self._testdatetime_end = self._testdatetime + timedelta(seconds=testperiod)
 
         self._testdaynum = self._testdatetime.weekday()
         self._testdaystr = DAY_NAMES[self._testdaynum]
 
-        __log__.info("Looking for tests to between %s and %s" %
-                     (self._testdatetime.strftime('%Y-%m-%d %H:%M:%S'),
-                      self._testdatetime_end.strftime('%Y-%m-%d %H:%M:%S')))
+        __log__.info(
+            "Looking for tests to between %s and %s"
+            % (
+                self._testdatetime.strftime("%Y-%m-%d %H:%M:%S"),
+                self._testdatetime_end.strftime("%Y-%m-%d %H:%M:%S"),
+            )
+        )
 
         # Load the XML file
         alltests = PeriodicTestSchedule(schedule_filename)
 
         # Select the tests to be run at the date
         if testperiod < 0:
             to_run = alltests.getTests(None)
@@ -82,30 +90,32 @@
             )
         __log__.info("Found %d tests schedule to be run." % len(to_run))
         for test in to_run:
             __log__.info(str(test))
 
         self._test_schedule = alltests
         self._tests_to_run = to_run
-        self._slot_list = get_slot_data(self._dashboard_date)
+        self._slot_list = get_slot_data(self._dashboard_date) + get_slot_data(
+            (datetime.today() - timedelta(days=1)).strftime("%Y-%m-%d")
+        )
         self._all_tests = []
         self._createAllTest()
 
     def getSlotData(self):
-        ''' Just returns the build information available to the starter'''
+        """Just returns the build information available to the starter"""
         return self._slot_list
 
     def _createAllTest(self):
-        '''
+        """
         Based on the tests templates, performs the globbing on
         the slot-name, project, cmtconfig
-        '''
+        """
         all_tests = []
         for to_run in self._tests_to_run:
             __log__.debug("Preparing tests for " + to_run.shortStr())
             all_tests.append((to_run, to_run.getBuildMatches(self._slot_list)))
 
         self._all_tests = all_tests
 
     def getAllTests(self):
-        ''' Just returns complete list of tests identified'''
+        """Just returns complete list of tests identified"""
         return self._all_tests
```

### Comparing `LbNightlyTools-3.0.9/python/LbPeriodicTools/_entry_points.py` & `LbNightlyTools-4.0.0/python/LbPeriodicTools/_entry_points.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,195 +1,210 @@
+from __future__ import print_function
+
+
 ###############################################################################
 # (c) Copyright 2013-2020 CERN                                                #
 #                                                                             #
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 def check_periodic_tests():
     from LbNightlyTools.Utils import JenkinsTest
-    '''
+
+    """
     Simple script to check which tests should be run for a given date
-    '''
-    __author__ = 'Ben Couturier <ben.couturier@cern.ch>'
+    """
+    __author__ = "Ben Couturier <ben.couturier@cern.ch>"
 
     import datetime
     import json
     import logging
-    import sys
     import re
+    import sys
 
-    from LbNightlyTools.Scripts.Common import PlainScript
     from LbPeriodicTools.LbPeriodicStarter import PeriodicTestStarter
 
+    from LbNightlyTools.Scripts.Common import PlainScript
+
     class Script(PlainScript):
-        '''
+        """
         Script to print the list of tests to run on a given day,
         based on the config specified
-        '''
-        __usage__ = '%prog [options] <config.json>'
-        __version__ = ''
+        """
+
+        __usage__ = "%prog [options] <config.json>"
+        __version__ = ""
 
         def defineOpts(self):
-            '''Define options.'''
+            """Define options."""
             from LbNightlyTools.Scripts.Common import addBasicOptions
+
             self.parser.add_option(
-                '-o',
-                '--output',
-                action='store',
-                help='output file format '
-                '[default: test-params-{0}.txt]',
-                default='test-params-{0}.txt')
+                "-o",
+                "--output",
+                action="store",
+                help="output file format " "[default: test-params-{0}.txt]",
+                default="test-params-{0}.txt",
+            )
             self.parser.add_option(
-                '-d',
-                '--date',
-                action='store',
-                help='Date for the tests '
-                'Format: YYYY-MM-dd HH:MM [default: today]')
+                "-d",
+                "--date",
+                action="store",
+                help="Date for the tests " "Format: YYYY-MM-dd HH:MM [default: today]",
+            )
             self.parser.add_option(
-                '-i',
-                '--interval',
-                action='store',
-                help='Interval for test checks in seconds '
-                '[default: 60s]',
-                default="60")
+                "-i",
+                "--interval",
+                action="store",
+                help="Interval for test checks in seconds " "[default: 60s]",
+                default="60",
+            )
             addBasicOptions(self.parser)
 
         def main(self):
-            '''
+            """
             Main function of the script.
-            '''
+            """
 
             # Checking we did pass an argument
             if len(self.args) != 1:
-                self.parser.error('Please specify config file')
+                self.parser.error("Please specify config file")
 
             config_file = self.args[0]
 
             # Checking the date at which to run
             opts = self.options
             testdate = datetime.datetime.today()
             if opts.date:
-                testdate = datetime.datetime.strptime(opts.date,
-                                                      '%Y-%m-%d %H:%M')
+                testdate = datetime.datetime.strptime(opts.date, "%Y-%m-%d %H:%M")
 
-            testdateend = testdate + datetime.timedelta(
-                seconds=int(opts.interval))
+            testdateend = testdate + datetime.timedelta(seconds=int(opts.interval))
             self.log.warning(
-                "Running tests from %s for the period %s/%s" %
-                (config_file, testdate.strftime('%Y-%m-%d %H:%M:%S'),
-                 testdateend.strftime('%Y-%m-%d %H:%M:%S')))
+                "Running tests from %s for the period %s/%s"
+                % (
+                    config_file,
+                    testdate.strftime("%Y-%m-%d %H:%M:%S"),
+                    testdateend.strftime("%Y-%m-%d %H:%M:%S"),
+                )
+            )
 
             # Checking which jobs to run
             starter = PeriodicTestStarter(
-                config_file, testdate.strftime('%Y-%m-%d %H:%M:%S'),
-                int(opts.interval))
+                config_file, testdate.strftime("%Y-%m-%d %H:%M:%S"), int(opts.interval)
+            )
 
             all_tests = starter.getAllTests()
             tests_to_run = []
-            for (test_template, test_list) in all_tests:
-                self.log.warning("%s: %d actual tests to run" %
-                                 (str(test_template), len(test_list)))
+            for test_template, test_list in all_tests:
+                self.log.warning(
+                    "%s: %d actual tests to run" % (str(test_template), len(test_list))
+                )
                 for test_instance in test_list:
-                    #tests_to_run.append(test_instance.__dict__)
+                    # tests_to_run.append(test_instance.__dict__)
                     tests_to_run.append(test_instance)
 
             for idx, ttr in enumerate(tests_to_run):
                 jenkins_test = JenkinsTest.fromScheduledTest(ttr)
                 tests_node = re.search("os_label=([^/]+)", (str(ttr)))
-                with open(opts.output.format(idx), 'w') as paramfile:
+                with open(opts.output.format(idx), "w") as paramfile:
                     paramfile.writelines(jenkins_test.getParameterLines())
                     if tests_node:
-                        paramfile.writelines("tests_node=" +
-                                             tests_node.group(1))
+                        paramfile.writelines("tests_node=" + tests_node.group(1))
                 self.log.warning(opts.output.format(idx))
 
     return Script().run()
 
 
 def check_periodic_tests_msg():
     from LbNightlyTools.Utils import JenkinsTest
-    '''
+
+    """
     Simple script to check which tests should be run for a given date
-    '''
-    __author__ = 'Ben Couturier <ben.couturier@cern.ch>'
+    """
+    __author__ = "Ben Couturier <ben.couturier@cern.ch>"
 
     import datetime
+    import fnmatch
     import json
     import logging
-    import sys
-    import fnmatch
     import re
-    from LbNightlyTools.Scripts.Common import PlainScript
-    from LbPeriodicTools.LbPeriodicStarter import PeriodicTestStarter
+    import sys
+
     import LbMsg.BuildMsg
+    from LbPeriodicTools.LbPeriodicStarter import PeriodicTestStarter
+
+    from LbNightlyTools.Scripts.Common import PlainScript
 
     class Script(PlainScript):
-        '''
+        """
         Script to print the list of tests to run on a given day,
         based on the config specified
-        '''
-        __usage__ = '%prog [options] <config.json>'
-        __version__ = ''
+        """
+
+        __usage__ = "%prog [options] <config.json>"
+        __version__ = ""
 
         def defineOpts(self):
-            '''Define options.'''
+            """Define options."""
             from LbNightlyTools.Scripts.Common import addBasicOptions
+
             self.parser.add_option(
-                '-o',
-                '--output',
-                action='store',
-                help='output file format '
-                '[default: test-params-{0}.txt]',
-                default='test-params-{0}.txt')
+                "-o",
+                "--output",
+                action="store",
+                help="output file format " "[default: test-params-{0}.txt]",
+                default="test-params-{0}.txt",
+            )
             self.parser.add_option(
-                '-d',
-                '--date',
-                action='store',
-                help='Date for the tests '
-                'Format: YYYY-MM-dd HH:MM [default: today]')
+                "-d",
+                "--date",
+                action="store",
+                help="Date for the tests " "Format: YYYY-MM-dd HH:MM [default: today]",
+            )
             self.parser.add_option(
-                '-i',
-                '--interval',
-                action='store',
-                help='Interval for test checks in seconds '
-                '[default: 60s]',
-                default="60")
+                "-i",
+                "--interval",
+                action="store",
+                help="Interval for test checks in seconds " "[default: 60s]",
+                default="60",
+            )
             self.parser.add_option(
-                '-q',
-                '--queue',
+                "-q",
+                "--queue",
                 default=None,
-                help='Name of the (persistent) queue to '
-                'store the messages')
+                help="Name of the (persistent) queue to " "store the messages",
+            )
             self.parser.add_option(
-                '-b',
-                '--bindings',
+                "-b",
+                "--bindings",
                 default=None,
-                help='Message bindings for this channel')
+                help="Message bindings for this channel",
+            )
             self.parser.add_option(
-                '-c',
-                '--consume',
+                "-c",
+                "--consume",
                 action="store_true",
                 default=False,
-                help='Wait and loop on all messages coming '
-                'from the server')
+                help="Wait and loop on all messages coming " "from the server",
+            )
 
             addBasicOptions(self.parser)
 
         def main(self):
-            '''
+            """
             Main function of the script.
-            '''
+            """
 
             # Checking we did pass an argument
             if len(self.args) < 1:
-                self.parser.error('Please specify config file')
+                self.parser.error("Please specify config file")
 
             config_file = self.args[0]
 
             # # Checking the date at which to run
             opts = self.options
             testdate = datetime.datetime.today()
 
@@ -206,53 +221,56 @@
 
                 def callback(ch, method, properties, body):
                     print(" [x] %r:%r" % (method.routing_key, body))
 
                 msg.consumeBuildsDone(callback, queueName, binds)
             else:
                 if queueName == None:
-                    raise Exception('No point in just getting messages '
-                                    'on a newly created queue. '
-                                    'Name the queue with -q or use -c instead')
+                    raise Exception(
+                        "No point in just getting messages "
+                        "on a newly created queue. "
+                        "Name the queue with -q or use -c instead"
+                    )
                 buildsDone = msg.getBuildsDone(queueName, binds)
 
-            testdate = datetime.datetime.today().replace(
-                hour=00, minute=00, second=00)
-            testdateend = testdate + datetime.timedelta(
-                seconds=int(opts.interval))
+            testdate = datetime.datetime.today().replace(hour=00, minute=00, second=00)
+            testdateend = testdate + datetime.timedelta(seconds=int(opts.interval))
 
             self.log.warning(
-                "Running tests from %s for the period %s/%s" %
-                (config_file, testdate.strftime('%Y-%m-%d %H:%M:%S'),
-                 testdateend.strftime('%Y-%m-%d %H:%M:%S')))
+                "Running tests from %s for the period %s/%s"
+                % (
+                    config_file,
+                    testdate.strftime("%Y-%m-%d %H:%M:%S"),
+                    testdateend.strftime("%Y-%m-%d %H:%M:%S"),
+                )
+            )
 
             # Checking which jobs to run
             starter = PeriodicTestStarter(
-                config_file, testdate.strftime('%Y-%m-%d %H:%M:%S'),
-                int(opts.interval))
+                config_file, testdate.strftime("%Y-%m-%d %H:%M:%S"), int(opts.interval)
+            )
             all_tests = starter.getAllTests()
             tests_to_run = []
             idx = 0
-            for (test_template, test_list) in all_tests:
+            for test_template, test_list in all_tests:
                 for test_tmp in test_list:
                     for build in buildsDone:
-                        if test_tmp.slot == build['slot']\
-                           and test_tmp.project == build['project']\
-                           and fnmatch.fnmatch(build['platform'],
-                                               test_tmp.platform):
-                            test_tmp.build_id = build['build_id']
+                        if (
+                            test_tmp.slot == build["slot"]
+                            and test_tmp.build_id == build["build_id"]
+                            and test_tmp.project == build["project"]
+                            and fnmatch.fnmatch(build["platform"], test_tmp.platform)
+                        ):
                             tests_to_run.append(test_tmp)
-                            print test_tmp
-                            jenkins_test = JenkinsTest.fromScheduledTest(
-                                test_tmp)
-                            tests_node = re.search("os_label=([^/]+)",
-                                                   (str(test_tmp)))
-                            with open(opts.output.format(idx), 'w') as parfile:
-                                parfile.writelines(
-                                    jenkins_test.getParameterLines())
+                            print(test_tmp)
+                            jenkins_test = JenkinsTest.fromScheduledTest(test_tmp)
+                            tests_node = re.search("os_label=([^/]+)", (str(test_tmp)))
+                            with open(opts.output.format(idx), "w") as parfile:
+                                parfile.writelines(jenkins_test.getParameterLines())
                                 if tests_node:
-                                    parfile.writelines("tests_node=" +
-                                                       tests_node.group(1))
+                                    parfile.writelines(
+                                        "tests_node=" + tests_node.group(1)
+                                    )
                             self.log.warning(opts.output.format(idx))
                             idx += 1
 
     return Script().run()
```

### Comparing `LbNightlyTools-3.0.9/python/LbPeriodicTools/LbPeriodicTestSchedule.py` & `LbNightlyTools-4.0.0/python/LbPeriodicTools/LbPeriodicTestSchedule.py`

 * *Files 14% similar despite different names*

```diff
@@ -4,58 +4,60 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Class to parse the test Schedule XML file
 Created on Dec 2, 2013
 
 @author: Ben Couturier
-'''
+"""
 import logging
+from builtins import object
 from xml.etree.ElementTree import ElementTree
+
 from LbPeriodicTools.LbPeriodicTest import PeriodicTest
 
 __log__ = logging.getLogger(__name__)
 
 
 class PeriodicTestSchedule(object):
-    '''
+    """
     Parser to the periodic test scheduling XML file
-    '''
+    """
 
     def __init__(self, filename, rethrow_exceptions=False):
-        '''
+        """
         Constructor that takes the schedule filename as parameter
-        '''
+        """
         self._filename = filename
         self._tests = []
         self._tree = None
         self._parse(rethrow_exceptions)
 
     def _parse(self, rethrow=False):
-        '''
+        """
         Parse the file specified and save the ElementTree
-        '''
+        """
         tree = ElementTree()
         tree.parse(self._filename)
 
         for child in tree.getroot():
             try:
                 ptest = PeriodicTest(child)
                 self._tests.append(ptest)
-            except ValueError, val:
+            except ValueError as val:
                 __log__.error(val)
                 if rethrow:
                     raise val
 
     def getTests(self, predicate=None):
-        '''
+        """
         Parse the file specified and save the ElementTree
-        '''
+        """
         if predicate == None:
             return self._tests
         else:
             return [t for t in self._tests if predicate(t)]
```

### Comparing `LbNightlyTools-3.0.9/python/LbPeriodicTools/tests/TestXMLParsing.py` & `LbNightlyTools-4.0.0/python/LbPeriodicTools/tests/test_XMLParsing.py`

 * *Files 17% similar despite different names*

```diff
@@ -4,98 +4,94 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 
 Test for the PeriodTest Tools
 
 Created on Dec 3, 2013
 
 @author: Ben Couturier
-'''
+"""
 import logging
 import os
 import unittest
-from os.path import normpath, join
+from os.path import join, normpath
+
 from LbPeriodicTools.LbPeriodicTestSchedule import PeriodicTestSchedule
 
 # We first try to import from LbCommon, then revert to the old package (LbUtils)
 # if needed
 try:
     import LbCommon.Log as _lblog
 except:
     import LbUtils.Log as _lblog
 
 
 class Test(unittest.TestCase):
-    ''' Test case of the LbPeriodicTestSchedule class '''
+    """Test case of the LbPeriodicTestSchedule class"""
 
     def setUp(self):
-        ''' Setup the test '''
+        """Setup the test"""
         self._data_dir = normpath(
-            join(*([__file__] + [os.pardir] * 4 +
-                   ['testdata', 'periodic_tests'])))
+            join(*([__file__] + [os.pardir] * 4 + ["testdata", "periodic_tests"]))
+        )
         self._data_file = join(self._data_dir, "schedule.xml")
         self._data_file_nok = join(self._data_dir, "scheduleIncorrect.xml")
         logging.basicConfig()
-        _lblog._default_log_format = '%(asctime)s:' \
-                                            + _lblog._default_log_format
+        _lblog._default_log_format = "%(asctime)s:" + _lblog._default_log_format
 
     def tearDown(self):
-        ''' Tear down the test '''
+        """Tear down the test"""
         pass
 
     def testLoadTestXMLFile(self):
-        ''' test the actual XML loading '''
+        """test the actual XML loading"""
         schedule = PeriodicTestSchedule(self._data_file)
         # Checking the count when loading all
-        self.assertEqual(
-            len(schedule.getTests()), 2, "Number of tests in test file")
+        self.assertEqual(len(schedule.getTests()), 2, "Number of tests in test file")
 
     def testFilterResults(self):
-        ''' test the filtering of the results '''
+        """test the filtering of the results"""
         schedule = PeriodicTestSchedule(self._data_file)
         # looking for Brunel tests
         btests = schedule.getTests(lambda t: t.project.lower() == "brunel")
         self.assertEqual(len(btests), 1, "Number of Brunel tests in test file")
         self.assertEqual(btests[0].project, "Brunel", "Test loaded correctly")
 
     def testSchedCheck(self):
-        ''' Check that an exception is thrown in case of bad date '''
-        self.assertRaises(ValueError, PeriodicTestSchedule,
-                          self._data_file_nok, True)
+        """Check that an exception is thrown in case of bad date"""
+        self.assertRaises(ValueError, PeriodicTestSchedule, self._data_file_nok, True)
 
     def testScheduleType(self):
-        ''' test the filtering of the results '''
+        """test the filtering of the results"""
         schedule = PeriodicTestSchedule(self._data_file)
         # looking for Brunel tests
         btests = schedule.getTests(lambda t: t.project.lower() == "brunel")
-        self.assertEqual(btests[0].scheduletype, "month",
-                         "Monthly Brunel Schedule")
+        self.assertEqual(btests[0].scheduletype, "month", "Monthly Brunel Schedule")
         bproj = schedule.getTests(lambda t: t.project.lower() == "project")
-        self.assertEqual(bproj[0].scheduletype, "week",
-                         "Weekly Brunel Schedule")
+        self.assertEqual(bproj[0].scheduletype, "week", "Weekly Brunel Schedule")
 
     def testScheduleTime(self):
-        ''' test the filtering of the results '''
+        """test the filtering of the results"""
         schedule = PeriodicTestSchedule(self._data_file)
         # looking for Brunel tests
         btests = schedule.getTests(lambda t: t.project.lower() == "brunel")
         self.assertEqual(btests[0].scheduletime, "12:00", "Job time")
 
     def testRunCount(self):
-        ''' test if the count is set '''
+        """test if the count is set"""
         schedule = PeriodicTestSchedule(self._data_file)
         # looking for Brunel tests
         btests = schedule.getTests(lambda t: t.project.lower() == "brunel")
         self.assertEqual(btests[0].count, 30, "Number of runs")
         bproj = schedule.getTests(lambda t: t.project.lower() == "project")
         self.assertEqual(bproj[0].count, 1, "Number of runs")
 
 
 if __name__ == "__main__":
-    #import sys;sys.argv = ['', 'Test.testLoadXML']
+    # import sys;sys.argv = ['', 'Test.testLoadXML']
     unittest.main()
```

### Comparing `LbNightlyTools-3.0.9/python/LbPeriodicTools/tests/TestLHCbPR.py` & `LbNightlyTools-4.0.0/python/LbPeriodicTools/tests/test_LHCbPR.py`

 * *Files 17% similar despite different names*

```diff
@@ -4,62 +4,69 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 
 Test for the PeriodTest Tools
 
 Created on Dec 3, 2013
 
 @author: Ben Couturier
-'''
-import logging
+"""
+from __future__ import print_function
+
 import json
+import logging
 import os
 import unittest
-from os.path import normpath, join
+from os.path import join, normpath
+
 from LbPeriodicTools.LbPeriodicStarter import PeriodicTestStarter
 
 
 class Test(unittest.TestCase):
-    ''' Test case of the PeriodicTestStarter class '''
+    """Test case of the PeriodicTestStarter class"""
 
     def setUp(self):
-        ''' Setup the test '''
+        """Setup the test"""
         self._data_dir = normpath(
-            join(*([__file__] + [os.pardir] * 4 +
-                   ['testdata', 'periodic_tests'])))
+            join(*([__file__] + [os.pardir] * 4 + ["testdata", "periodic_tests"]))
+        )
         self._data_file = join(self._data_dir, "lhcbpr_schedule.xml")
         self._json_file = join(self._data_dir, "slotbuilds.json")
         self._slot_data = None
         with open(self._json_file) as jsonfile:
             self._slot_data = json.load(jsonfile)
 
         logging.basicConfig(level=logging.INFO)
 
     def tearDown(self):
-        ''' tear down the test '''
+        """tear down the test"""
         pass
 
     def testLHCbPR(self):
-        '''
+        """
         Test the PeriodicTestStarter based on the saved JSON file
-        '''
-        starter = PeriodicTestStarter(self._data_file, "2013-12-02", 86400,
-                                      lambda x: self._slot_data)
+        """
+        starter = PeriodicTestStarter(
+            self._data_file, "2013-12-02", 86400, lambda x: self._slot_data
+        )
         all_tests = starter.getAllTests()
         for t in all_tests:
             for tt in t[1]:
-                print tt
+                print(tt)
 
-        self.assertEqual(len(all_tests), 1, "1 Match")
-        self.assertEqual(
-            len(all_tests[0][1]), 2, "Tests matching for 2 configs")
+        self.assertEqual(len(all_tests), 2, "2 Matches")
+        # we should have below 2 and 1 tests matching, respectively
+        # but because of 3cbd9676 we need to take into account that dummy slot data
+        # do not contain info about slot date
+        self.assertEqual(len(all_tests[0][1]), 4, "Tests matching for 4 configs")
+        self.assertEqual(len(all_tests[1][1]), 2, "Tests matching for 2 configs")
 
 
 if __name__ == "__main__":
-    #import sys;sys.argv = ['', 'Test.testLoadXML']
+    # import sys;sys.argv = ['', 'Test.testLoadXML']
     unittest.main()
```

### Comparing `LbNightlyTools-3.0.9/python/LbTools/Manifest.py` & `LbNightlyTools-4.0.0/python/LbTools/Manifest.py`

 * *Files 25% similar despite different names*

```diff
@@ -4,79 +4,116 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Nightlies for manifest.xml parser
 
 Created on Feb 27, 2014
 
 @author: Ben Couturier
-'''
+"""
 
 import logging
+import re
 from xml.etree.ElementTree import ElementTree
 
 __log__ = logging.getLogger(__name__)
 
 
-class Parser(object):
-    '''
+def getLCGInfo(version, platform):
+    """Retrieve LCG packages names and versions from LCG metadata"""
+    import requests
+
+    resp = requests.get(
+        "https://lcgpackages.web.cern.ch/lcg/meta/LCG_{version}_{platform}.txt".format(
+            version=version, platform=platform
+        )
+    )
+    info = {}
+    for l in resp.text.splitlines():
+        try:
+            # note: the `+ " "` is needed to correctly handle the case with
+            # no dependencies
+            pkg = dict(e.split(": ") for e in (l.strip().rstrip(",") + " ").split(", "))
+            info[pkg["NAME"].lower()] = {"name": pkg["NAME"], "version": pkg["VERSION"]}
+        except (ValueError, KeyError):
+            # line not good, ignore it
+            pass
+    return info
+
+
+class Parser:
+    """
     Parser for the manifest.xml file generated at build time
-    '''
+    """
 
     def __init__(self, filename):
-        '''
+        """
         Constructor taking the actual file name
-        '''
+        """
         __log__.debug("Loading %s" % filename)
         tree = ElementTree()
         tree.parse(filename)
         self._tree = tree
 
     def getProject(self):
-        ''' Returns the pair (project, version) '''
+        """Returns the pair (project, version)"""
         projectNode = self._tree.find("./project")
         if projectNode == None:
             raise Exception("project tag not found")
         return (projectNode.attrib["name"], projectNode.attrib["version"])
 
     def getHEPTools(self):
-        ''' Returns the triplet (lcgversion, CMTCONFIG, packages) or None
+        """Returns the triplet (lcgversion, CMTCONFIG, packages) or None
         if there is no heptools tag.
         The 'packages' is a dictionary of names to versions.
-        '''
+        """
         # check if there is a dependency on heptools
-        node = self._tree.find('./heptools')
+        node = self._tree.find("./heptools")
         if node is None:
             return None
 
         tags = ["./heptools/version", "./heptools/binary_tag"]
 
         tagValues = []
         for t in tags:
             node = self._tree.find(t)
             if node == None:
                 raise Exception("%s not found" % t)
             tagValues.append(node.text)
 
-        pkgs = dict(
-            (pkg.attrib['name'], pkg.attrib['version'])
-            for pkg in self._tree.findall('./heptools/packages/package'))
+        if re.match(r"v[0-9]+r[0-9]+", self.getProject()[1]):
+            # old style project (version = vXrY)
+            pkgs = dict(
+                (pkg.attrib["name"], pkg.attrib["version"])
+                for pkg in self._tree.findall("./heptools/packages/package")
+            )
+        else:
+            # new style project (version = X.Y)
+            # - get LCG packages names and versions
+            info = getLCGInfo(tagValues[0], self.getLCGConfig()[0])
+            pkgs = dict(
+                (info[key]["name"], info[key]["version"])
+                for key in [
+                    pkg.attrib["name"].lower()
+                    for pkg in self._tree.findall("./heptools/packages/package")
+                ]
+                if key in info
+            )
         tagValues.append(pkgs)
         return tuple(tagValues)
 
     def getLCGConfig(self):
-        ''' Returns the LCG_platform and LCG_system if specified in the XML, None otherwise
-        '''
+        """Returns the LCG_platform and LCG_system if specified in the XML, None otherwise"""
         # check if there is a dependency on heptools
-        node = self._tree.find('./heptools')
+        node = self._tree.find("./heptools")
         if node is None:
             return None
 
         tags = ["./heptools/lcg_platform", "./heptools/lcg_system"]
 
         tagValues = []
         for t in tags:
@@ -85,39 +122,39 @@
                 tagValues.append(None)
             else:
                 tagValues.append(node.text)
 
         return tuple(tagValues)
 
     def getExtTools(self):
-        ''' Returns a dictionary (name->version) of external packages.
-        '''
+        """Returns a dictionary (name->version) of external packages."""
         try:
-            bin_tag = self._tree.find('./exttools/binary_tag').text.strip()
+            bin_tag = self._tree.find("./exttools/binary_tag").text.strip()
         except AttributeError:
             # exttools/binary_tag not found
-            bin_tag = ''
+            bin_tag = ""
 
         pkgs = dict(
-            (pkg.attrib['name'], pkg.attrib['version'])
-            for pkg in self._tree.findall('./exttools/packages/package'))
+            (pkg.attrib["name"], pkg.attrib["version"])
+            for pkg in self._tree.findall("./exttools/packages/package")
+        )
         return bin_tag, pkgs
 
     def getUsedProjects(self):
-        ''' Returns the list of tuples (project, version) for used projects '''
+        """Returns the list of tuples (project, version) for used projects"""
 
         tag = "./used_projects/project"
         usedProjects = []
         nodes = self._tree.findall(tag)
         for node in nodes:
             usedProjects.append((node.attrib["name"], node.attrib["version"]))
         return usedProjects
 
     def getUsedDataPackages(self):
-        ''' Returns the list of tuples (project, version) for used data packages '''
+        """Returns the list of tuples (project, version) for used data packages"""
 
         tag = "./used_data_pkgs/package"
         used = []
         nodes = self._tree.findall(tag)
         for node in nodes:
             used.append((node.attrib["name"], node.attrib["version"]))
         return used
```

### Comparing `LbNightlyTools-3.0.9/python/LbTools/tests/TestXMLParsing.py` & `LbNightlyTools-4.0.0/python/LbTools/tests/test_XMLParsing.py`

 * *Files 13% similar despite different names*

```diff
@@ -4,96 +4,98 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 
 Test for the Manifest parser
 
 Created on Feb 27, 2014
 
 @author: Ben Couturier
-'''
+"""
 import logging
 import os
 import unittest
-from os.path import normpath, join
+from os.path import join, normpath
+
 from LbTools.Manifest import Parser
 
 # We first try to import from LbCommon, then revert to the old package (LbUtils)
 # if needed
 try:
     import LbCommon.Log as _lblog
 except:
     import LbUtils.Log as _lblog
 
 
 class Test(unittest.TestCase):
-    ''' Test case of the Manifest parser class '''
+    """Test case of the Manifest parser class"""
 
     def setUp(self):
-        ''' Setup the test '''
+        """Setup the test"""
         self._data_dir = normpath(
-            join(*([__file__] + [os.pardir] * 4 + ['testdata', 'tools'])))
+            join(*([__file__] + [os.pardir] * 4 + ["testdata", "tools"]))
+        )
         self._data_file = join(self._data_dir, "manifest.xml")
         logging.basicConfig()
-        _lblog._default_log_format = '%(asctime)s:' \
-                                            + _lblog._default_log_format
+        _lblog._default_log_format = "%(asctime)s:" + _lblog._default_log_format
 
     def tearDown(self):
-        ''' Tear down the test '''
+        """Tear down the test"""
         pass
 
     def testGetProject(self):
-        ''' test  loading of project name/version '''
+        """test  loading of project name/version"""
         parser = Parser(self._data_file)
         (p, v) = parser.getProject()
-        self.assertEqual(p, 'Brunel', "Project name")
-        self.assertEqual(v, 'HEAD', "Project version")
+        self.assertEqual(p, "Brunel", "Project name")
+        self.assertEqual(v, "HEAD", "Project version")
 
     def testGetHEPTools(self):
-        ''' test loading of LCG info '''
+        """test loading of LCG info"""
         parser = Parser(self._data_file)
         (v, b, p) = parser.getHEPTools()
-        self.assertEqual(v, '66', "LCG version")
-        self.assertEqual(b, 'x86_64-slc6-gcc48-opt', "CMTCONFIG")
+        self.assertEqual(v, "66", "LCG version")
+        self.assertEqual(b, "x86_64-slc6-gcc48-opt", "CMTCONFIG")
         self.assertEqual(p, {}, "externals")
 
     def testUsedProjects(self):
-        ''' test the getUsedProjects method '''
+        """test the getUsedProjects method"""
         parser = Parser(self._data_file)
         usedProjects = parser.getUsedProjects()
         self.assertEqual(len(usedProjects), 2, "Number of used projects")
 
     def testUsedDataPackages(self):
-        ''' test the getUsedDataPackages method '''
+        """test the getUsedDataPackages method"""
         parser = Parser(self._data_file)
         used = parser.getUsedDataPackages()
         self.assertEqual(len(used), 5, "Number of used data packages")
 
     def testMinimalManifest(self):
-        ''' test parsing of minimal manifest '''
+        """test parsing of minimal manifest"""
         parser = Parser(join(self._data_dir, "mini_manifest.xml"))
         self.assertEqual(parser.getHEPTools(), None, "Dependency on LCG")
         usedProjects = parser.getUsedProjects()
         self.assertEqual(len(usedProjects), 0, "Number of used projects")
         used = parser.getUsedDataPackages()
         self.assertEqual(len(used), 0, "Number of used data packages")
 
     def testGetLCGSystem(self):
-        ''' test getting the value of the lcg_system tag '''
+        """test getting the value of the lcg_system tag"""
         parser = Parser(join(self._data_dir, "manifest.xml"))
         self.assertEqual(parser.getLCGConfig(), (None, "x86_64-slc6-gcc48"))
 
     def testGetLCGPlatform(self):
-        ''' test getting the value of the lcg_system tag '''
+        """test getting the value of the lcg_system tag"""
         parser = Parser(join(self._data_dir, "manifest_do0.xml"))
-        self.assertEqual(parser.getLCGConfig(),
-                         ("x86_64-slc6-gcc49-dbg", "x86_64-slc6-gcc49"))
+        self.assertEqual(
+            parser.getLCGConfig(), ("x86_64-slc6-gcc49-dbg", "x86_64-slc6-gcc49")
+        )
 
 
 if __name__ == "__main__":
-    #import sys;sys.argv = ['', 'Test.testLoadXML']
+    # import sys;sys.argv = ['', 'Test.testLoadXML']
     unittest.main()
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools.egg-info/PKG-INFO` & `LbNightlyTools-4.0.0/python/LbNightlyTools.egg-info/PKG-INFO`

 * *Files 14% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-Metadata-Version: 1.1
+Metadata-Version: 2.1
 Name: LbNightlyTools
-Version: 3.0.9
+Version: 4.0.0
 Summary: LHCb Nightly tools
 Home-page: https://gitlab.cern.ch/lhcb-core/LbNightlyTools
 Author: CERN - LHCb Core Software
 Author-email: lhcb-core-soft@cern.ch
-License: UNKNOWN
-Description: LbNightlyTools
-        ===============
-        
-        Scripts to perform LHCb Nightly builds.
-        
-Platform: UNKNOWN
 Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Developers
 Classifier: Topic :: Software Development :: Build Tools
 Classifier: License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)
 Classifier: Programming Language :: Python :: 2
 Classifier: Programming Language :: Python :: 2.7
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.4
 Classifier: Programming Language :: Python :: 3.5
 Classifier: Programming Language :: Python :: 3.6
+License-File: COPYING
+
+LbNightlyTools
+===============
+
+Scripts to perform LHCb Nightly builds.
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools.egg-info/SOURCES.txt` & `LbNightlyTools-4.0.0/python/LbNightlyTools.egg-info/SOURCES.txt`

 * *Files 18% similar despite different names*

```diff
@@ -1,25 +1,20 @@
 .coveragerc
-.cproject
 .gitignore
 .gitlab-ci.yml
-.project
-.pydevproject
+.pre-commit-config.yaml
 CHANGELOG.md
 COPYING
 README.rst
+pyproject.toml
 setup.cfg
-setup.csh
 setup.py
-setup.sh
 admin/LHCb_LbScripts.spectemplate
 admin/RpmHelpers.py
 admin/createLbScriptsRpm
-cmt/.gitignore
-cmt/requirements
 couchdb/.gitignore
 couchdb/Push CouchDB Nightly Builds.launch
 couchdb/README.md
 couchdb/build_id_index.json
 couchdb/webapp_testbench.py
 couchdb/auth/validate_doc_update.js
 couchdb/deployment/_id
@@ -60,18 +55,16 @@
 couchdb/releases/views/projectBuildIds/map.js
 couchdb/summaries/_id
 couchdb/summaries/language
 couchdb/summaries/rewrites.json
 couchdb/summaries/views/byDay/map.js
 couchdb/summaries/views/lastBuildId/map.js
 couchdb/summaries/views/lastBuildId/reduce.js
-cron/clean_up_reduced_db.sh
 cron/cleanup_artifacts.sh
 cron/logrotate.conf
-cron/preheat_nightly_dashboard.sh
 docs/Interactive builds of LHCb projects.ipynb
 docs/LHCbPR2.md
 docs/jenkins-scripts.dot
 docs/jenkins-scripts.dot.png
 docs/pylint.rc
 docs/configuration/Example.py
 docs/examples/lbpr-example
@@ -106,47 +99,14 @@
 docs/note/figs/lhcb-logo.pdf
 docs/note/figs/old-summary.png
 docs/operation/Makefile
 docs/operation/NightlyBuildsOperation.html
 docs/operation/NightlyBuildsOperation.rst
 docs/operation/images/jenkins-jobs.dot
 docs/operation/images/jenkins-jobs.dot.png
-jenkins/docker.sh
-jenkins/mock.sh
-jenkins/testMock.sh
-jenkins/utils.sh
-jenkins/docker-home/.bash_profile
-jenkins/docker-home/.bashrc
-jenkins/docker-home/.ssh/config
-jenkins/mock/clean_build.sh
-jenkins/mock/clean_checkout.sh
-jenkins/mock/clean_enabled_slots.sh
-jenkins/mock/clean_preconditions.sh
-jenkins/nightly-builds/build.sh
-jenkins/nightly-builds/checkout.sh
-jenkins/nightly-builds/gaudi_mr_poll.py
-jenkins/nightly-builds/gitlab-mr.py
-jenkins/nightly-builds/main.sh
-jenkins/nightly-builds/preconditions.sh
-jenkins/nightly-builds/release-poll.sh
-jenkins/nightly-builds/release.sh
-jenkins/nightly-builds/tests-poll.sh
-jenkins/nightly-builds/tests.sh
-jenkins/periodic-tests/tests-getteststorun.sh
-jenkins/periodic-tests/tests-poll.sh
-jenkins/periodic-tests/tests-pollqueue.sh
-jenkins/periodic-tests/tests.sh
-jenkins/testrunners/default.sh
-jenkins/testrunners/lhcbpr.sh
-jenkins/testrunners/qmtest.sh
-jenkins/utils.d/build_slot.sh
-jenkins/utils.d/check_preconditions.sh
-jenkins/utils.d/checkout_slot.sh
-jenkins/utils.d/execute_preconditions.sh
-jenkins/utils.d/set_common.sh
 python/LbMsg/BuildMsg.py
 python/LbMsg/Common.py
 python/LbMsg/TestMsg.py
 python/LbMsg/__init__.py
 python/LbNightlyTools/ArtifactsServer.py
 python/LbNightlyTools/BuildLogScanner.py
 python/LbNightlyTools/BuildMethods.py
@@ -155,14 +115,15 @@
 python/LbNightlyTools/Configuration.py
 python/LbNightlyTools/GetNightlyRefs.py
 python/LbNightlyTools/GitlabUtils.py
 python/LbNightlyTools/HTMLUtils.py
 python/LbNightlyTools/LbScriptsUtils.py
 python/LbNightlyTools/MergeRequestBuilds.py
 python/LbNightlyTools/ProcUtils.py
+python/LbNightlyTools/Repository.py
 python/LbNightlyTools/Utils.py
 python/LbNightlyTools/__init__.py
 python/LbNightlyTools.egg-info/PKG-INFO
 python/LbNightlyTools.egg-info/SOURCES.txt
 python/LbNightlyTools.egg-info/dependency_links.txt
 python/LbNightlyTools.egg-info/entry_points.txt
 python/LbNightlyTools.egg-info/not-zip-safe
@@ -180,97 +141,105 @@
 python/LbNightlyTools/Scripts/Release.py
 python/LbNightlyTools/Scripts/Test.py
 python/LbNightlyTools/Scripts/__init__.py
 python/LbNightlyTools/Scripts/_entry_points.py
 python/LbNightlyTools/Scripts/extract.php
 python/LbNightlyTools/Scripts/listzip.php
 python/LbNightlyTools/tests/__init__.py
-python/LbNightlyTools/tests/__main__.py
 python/LbNightlyTools/tests/test_build.py
 python/LbNightlyTools/tests/test_build_script.py
 python/LbNightlyTools/tests/test_checkout.py
 python/LbNightlyTools/tests/test_checkout_script.py
 python/LbNightlyTools/tests/test_config_load.py
 python/LbNightlyTools/tests/test_config_pickle.py
 python/LbNightlyTools/tests/test_configuration.py
+python/LbNightlyTools/tests/test_configuration_check.py
 python/LbNightlyTools/tests/test_copytree.py
 python/LbNightlyTools/tests/test_coverity_support.py
 python/LbNightlyTools/tests/test_enabled_slots_script.py
 python/LbNightlyTools/tests/test_gitlab_mr_script.py
 python/LbNightlyTools/tests/test_indexer.py
 python/LbNightlyTools/tests/test_install.py
 python/LbNightlyTools/tests/test_jobconfig.py
+python/LbNightlyTools/tests/test_merge_request_builds.py
 python/LbNightlyTools/tests/test_pack.py
 python/LbNightlyTools/tests/test_precond.py
 python/LbNightlyTools/tests/test_rel_gen_script.py
 python/LbNightlyTools/tests/test_release_poll.py
+python/LbNightlyTools/tests/test_repository.py
 python/LbNightlyTools/tests/test_retry.py
 python/LbNightlyTools/tests/test_utils.py
 python/LbNightlyTools/tests/utils.py
 python/LbPR/LbPRJobManager.py
 python/LbPR/__init__.py
 python/LbPR/_entry_points.py
 python/LbPeriodicTools/LbPeriodicStarter.py
 python/LbPeriodicTools/LbPeriodicTest.py
 python/LbPeriodicTools/LbPeriodicTestSchedule.py
 python/LbPeriodicTools/TestSchedule.xsd
 python/LbPeriodicTools/__init__.py
 python/LbPeriodicTools/_entry_points.py
-python/LbPeriodicTools/tests/TestLHCbPR.py
-python/LbPeriodicTools/tests/TestStarter.py
-python/LbPeriodicTools/tests/TestXMLParsing.py
 python/LbPeriodicTools/tests/__init__.py
+python/LbPeriodicTools/tests/test_LHCbPR.py
+python/LbPeriodicTools/tests/test_Starter.py
+python/LbPeriodicTools/tests/test_XMLParsing.py
 python/LbRPMTools/LHCbCompatSpecBuilder.py
 python/LbRPMTools/LHCbExternalsSpecBuilder.py
 python/LbRPMTools/LHCbGenericSpecBuilder.py
 python/LbRPMTools/LHCbLbScriptsSpecBuilder.py
 python/LbRPMTools/LHCbMetaSpecBuilder.py
 python/LbRPMTools/LHCbRPMSpecBuilder.py
 python/LbRPMTools/PackageSlot.py
 python/LbRPMTools/__init__.py
-python/LbRPMTools/tests/TestExternalSpec.py
-python/LbRPMTools/tests/TestPackageSlot.py
-python/LbRPMTools/tests/TestSpec.py
 python/LbRPMTools/tests/__init__.py
+python/LbRPMTools/tests/test_ExternalSpec.py
+python/LbRPMTools/tests/test_PackageSlot.py
+python/LbRPMTools/tests/test_Spec.py
 python/LbTools/Manifest.py
 python/LbTools/__init__.py
-python/LbTools/tests/TestXMLParsing.py
+python/LbTools/tests/test_XMLParsing.py
+python/LbTools/tests/test_toolchain_info.py
 scripts/lbn-get-configs
 scripts/lbn-wrapcmd
 scripts/lbpr-collect
 testdata/ci-test-hook-content.json
 testdata/data-packs.json
 testdata/testing-slot-2.json
 testdata/testing-slot-2b.json
 testdata/testing-slot-env.json
 testdata/testing-slot-lbcore-192.json
 testdata/testing-slot-lbcore-664.json
 testdata/testing-slot-with-shared.json
 testdata/testing-slot.json
 testdata/artifacts/packs/src/TestProject.HEAD.testing-slot.src.zip
 testdata/build_tests/orig/dummy/Makefile
+testdata/build_tests/test_project/CMakeLists.txt
+testdata/build_tests/test_project/lhcbproject.yml
+testdata/build_tests/test_project/main.cpp
 testdata/collect_deps/broken/conf.json
 testdata/collect_deps/broken/BadCMT/cmt/project.cmt
 testdata/collect_deps/broken/BadCMake/CMakeLists.txt
 testdata/collect_deps/broken/Gaudi/CMakeLists.txt
 testdata/collect_deps/broken/Gaudi/toolchain.cmake
 testdata/collect_deps/cmake/conf.json
 testdata/collect_deps/cmake/Brunel/CMakeLists.txt
 testdata/collect_deps/cmake/Gaudi/CMakeLists.txt
 testdata/collect_deps/cmake/Gaudi/toolchain.cmake
 testdata/collect_deps/cmake/LHCb/CMakeLists.txt
 testdata/collect_deps/cmake/Lbcom/CMakeLists.txt
+testdata/collect_deps/cmake/NewLHCbProj/lhcbproject.yml
 testdata/collect_deps/cmake/NewProj/project.info
 testdata/collect_deps/cmake/Online/CMakeLists.txt
 testdata/collect_deps/cmake/Rec/CMakeLists.txt
 testdata/collect_deps/cmt/conf.json
 testdata/collect_deps/cmt/Brunel/cmt/project.cmt
 testdata/collect_deps/cmt/Gaudi/cmt/project.cmt
 testdata/collect_deps/cmt/LHCb/cmt/project.cmt
 testdata/collect_deps/cmt/Lbcom/cmt/project.cmt
+testdata/collect_deps/cmt/NewLHCbProj/lhcbproject.yml
 testdata/collect_deps/cmt/NewProj/project.info
 testdata/collect_deps/cmt/Online/cmt/project.cmt
 testdata/collect_deps/cmt/Rec/cmt/project.cmt
 testdata/coverity/bin/cov-analyze
 testdata/coverity/bin/cov-build
 testdata/coverity/bin/cov-commit-defects
 testdata/coverity/build/TEST/TEST_HEAD/CMakeLists.txt
@@ -319,9 +288,10 @@
 testdata/rpm/rel/PARAM_TMVAWeights_v1r2-1.0.0-1.noarch.rpm
 testdata/rpm/rel/PARAM_TMVAWeights_v1r4-1.0.0-1.noarch.rpm
 testdata/rpm/rel/PARAM_TMVAWeights_v1r4-1.0.0-4.noarch.rpm
 testdata/rpm/rel/PARAM_TMVAWeights_v1r4-1.0.0-toto.noarch.rpm
 testdata/tools/manifest.xml
 testdata/tools/manifest_do0.xml
 testdata/tools/manifest_with_pkgs.xml
+testdata/tools/manifest_with_pkgs_new.xml
 testdata/tools/mini_manifest.xml
 utils/add_ci_webhook.py
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools.egg-info/entry_points.txt` & `LbNightlyTools-4.0.0/python/LbNightlyTools.egg-info/entry_points.txt`

 * *Files 1% similar despite different names*

```diff
@@ -24,19 +24,17 @@
 lbn-list-platforms = LbNightlyTools.Scripts._entry_points:list_platforms
 lbn-preconditions = LbNightlyTools.Scripts._entry_points:preconditions
 lbn-release-poll = LbNightlyTools.Scripts._entry_points:release_poll
 lbn-release-trigger = LbNightlyTools.Scripts._entry_points:release_trigger
 lbn-reschedule-tests = LbNightlyTools.Scripts._entry_points:reschedule_tests
 lbn-rpm = LbNightlyTools.Scripts._entry_points:rpm
 lbn-rpm-validator = LbNightlyTools.Scripts._entry_points:rpm_validator
-lbn-slots-by-deployment = LbNightlyTools.Scripts._entry_points:slots_by_deployment
 lbn-test = LbNightlyTools.Scripts.Test:run
 lbn-test-legacy = LbNightlyTools.Scripts.Test:run
 lbn-test-poll = LbNightlyTools.Scripts._entry_points:test_poll
 lbp-check-periodic-tests = LbPeriodicTools._entry_points:check_periodic_tests
 lbp-check-periodic-tests-msg = LbPeriodicTools._entry_points:check_periodic_tests_msg
 lbpr-get-command = LbPR._entry_points:get_command
 lbq-builddone = LbNightlyTools.Scripts._entry_points:lbq_builddone
 lbq-buildnotif = LbNightlyTools.Scripts._entry_points:lbq_buildnotif
 lbq-getteststorun = LbNightlyTools.Scripts._entry_points:lbq_getteststorun
 lbq-requesttest = LbNightlyTools.Scripts._entry_points:lbq_requesttest
-
```

### Comparing `LbNightlyTools-3.0.9/python/LbPR/LbPRJobManager.py` & `LbNightlyTools-4.0.0/python/LbPR/LbPRJobManager.py`

 * *Files 13% similar despite different names*

```diff
@@ -4,79 +4,84 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Created on Jan 15, 2014
 
 Interface to the LHCbPR System.
 
 @author: Ben Couturier
-'''
-import urllib2
+"""
+from future import standard_library
+
+standard_library.install_aliases()
 import json
 import ssl
 import sys
+import urllib.error
+import urllib.parse
+import urllib.request
+from builtins import object
 
-HEADERS = {
-    "Content-type": "application/x-www-form-urlencoded",
-    "Accept": "text/plain"
-}
+HEADERS = {"Content-type": "application/x-www-form-urlencoded", "Accept": "text/plain"}
 
 CHECK_SSL = False
 
 
 def urlopen(url, check_ssl=True):
-    '''
+    """
     Wrapper for urllib2.urlopen to enable or disable SSL verification.
-    '''
+    """
     if not check_ssl and sys.version_info >= (2, 7, 9):
         # with Python >= 2.7.9 SSL certificates are validated by default
         # but we can ignore them
-        from ssl import SSLContext, PROTOCOL_SSLv23
-        return urllib2.urlopen(url, context=ssl._create_unverified_context())
-    return urllib2.urlopen(url)
+        from ssl import PROTOCOL_SSLv23, SSLContext
+
+        return urllib.request.urlopen(url, context=ssl._create_unverified_context())
+    return urllib.request.urlopen(url)
 
 
 class JobManager(object):
-    '''
+    """
     Interface to the LHCbPR system
-    '''
+    """
 
     def __init__(self, lhcbpr_api_url, check_ssl=True):
-        '''
+        """
         Constructor taking the URL for the LHCbPR server
-        '''
+        """
         self._lhcbpr_api_url = lhcbpr_api_url
         self._check_ssl = check_ssl
 
     def getJobOptions(self, options_description):
-        ''' Get the list of options from LHCbPR2 '''
+        """Get the list of options from LHCbPR2"""
         resp = urlopen(
-            '%s/options/?description=%s' % (self._lhcbpr_api_url,
-                                            options_description),
-            self._check_ssl).read()
+            "%s/options/?description=%s" % (self._lhcbpr_api_url, options_description),
+            self._check_ssl,
+        ).read()
         data = json.loads(resp)
         return data["results"][0] if data["count"] else None
 
     def getExecutableOptions(self, executable):
-        ''' Get the list of options from LHCbPR2 '''
+        """Get the list of options from LHCbPR2"""
         resp = urlopen(
-            '%s/executables/?name=%s' % (self._lhcbpr_api_url, executable),
-            self._check_ssl).read()
+            "%s/executables/?name=%s" % (self._lhcbpr_api_url, executable),
+            self._check_ssl,
+        ).read()
         data = json.loads(resp)
         return data["results"][0] if data["count"] else None
 
     def getSetupOptions(self, setup_description):
-        ''' Get the SetupProject options from LHCbPR2 '''
+        """Get the SetupProject options from LHCbPR2"""
         if setup_description:
             resp = urlopen(
-                '%s/setups/?description=%s' % (self._lhcbpr_api_url,
-                                               setup_description),
-                self._check_ssl).read()
+                "%s/setups/?description=%s" % (self._lhcbpr_api_url, setup_description),
+                self._check_ssl,
+            ).read()
             data = json.loads(resp)
             return data["results"][0] if data["count"] else None
         else:
             return None
```

### Comparing `LbNightlyTools-3.0.9/python/LbPR/_entry_points.py` & `LbNightlyTools-4.0.0/python/LbPR/_entry_points.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,123 +1,135 @@
+from __future__ import print_function
+
+
 ###############################################################################
 # (c) Copyright 2013-2020 CERN                                                #
 #                                                                             #
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 def get_command():
-    '''
+    """
     Run a LHCbPR job
-    '''
-    __author__ = 'Ben Couturier <ben.couturier@cern.ch>'
+    """
+    __author__ = "Ben Couturier <ben.couturier@cern.ch>"
 
     # We first try to import from LbCommon, then revert to the old package (LbUtils)
     # if needed
     try:
         from LbCommon.Script import PlainScript as _PlainScript
     except:
         from LbUtils.Script import PlainScript as _PlainScript
 
-    import sys
+    import json
     import os
+    import sys
     from datetime import datetime
+
     from LbPR.LbPRJobManager import JobManager
-    from LbNightlyTools import Configuration
 
     def getProjectVersionFromConfig(config, project):
-        ''' Look up the project version for SetupProject '''
+        """Look up the project version for SetupProject"""
         retval = None
-        for proj in config[u'projects']:
-            if proj['name'].lower() == project.lower():
-                retval = proj['version']
+        for proj in config["projects"]:
+            if proj["name"].lower() == project.lower():
+                retval = proj["version"]
                 break
         return retval
 
     def getSlotDateFromConfig(config):
         completed = config["completed"]
-        return datetime.strptime(completed, '%Y-%m-%dT%H:%M:%S.%f')
+        return datetime.strptime(completed, "%Y-%m-%dT%H:%M:%S.%f")
+
+    def testsDisabled(config, project):
+        """Check if the tests for the project are disabled in config"""
+        for proj in config["projects"]:
+            if proj["name"].lower() == project.lower():
+                return proj.get("no_test", False)
 
     class Script(_PlainScript):
-        '''
+        """
         Script to create the commands to run a LHCbPR Job
-        '''
-        __usage__ = '%prog  <command> <project> <version> <platform>' \
-                    ' <options> <setup-options> <slot config>'
-        __version__ = ''
+        """
+
+        __usage__ = (
+            "%prog  <command> <project> <version> <platform>"
+            " <options> <setup-options> <slot config>"
+        )
+        __version__ = ""
 
         def defineOpts(self):
-            '''Define options.'''
+            """Define options."""
             from LbNightlyTools.Scripts.Common import addBasicOptions
+
             self.parser.add_option(
-                '-u',
-                '--url',
-                action='store',
-                help='URL for the LHCbPR REST service')
+                "-u", "--url", action="store", help="URL for the LHCbPR REST service"
+            )
             self.parser.add_option(
-                '-c',
-                '--check-ssl',
-                action='store_true',
-                help='Check SSL certificate.')
+                "-c", "--check-ssl", action="store_true", help="Check SSL certificate."
+            )
             self.parser.add_option(
-                '-o',
-                '--output',
-                action='store',
-                help='output file name '
-                '[default: runlhcbpr.sh]')
+                "-o",
+                "--output",
+                action="store",
+                help="output file name " "[default: runlhcbpr.sh]",
+            )
             addBasicOptions(self.parser)
 
         @staticmethod
-        def interpretOptions(options, executable, app_name, app_version,
-                             platform):
+        def interpretOptions(options, executable, app_name, app_version, platform):
             if not executable:
                 return options["content"]
 
             return executable["content"].format(
                 app_name=app_name,
                 app_version=app_version,
                 platform=platform,
                 build="$(pwd)/../build",
-                options=options["content"])
+                options=options["content"],
+            )
 
         @staticmethod
         def interpretSetup(setup, app_name, app_version):
             if not setup:
-                return ''
+                return ""
 
-            return setup["content"].format(
-                app_name=app_name, app_version=app_version)
+            return setup["content"].format(app_name=app_name, app_version=app_version)
 
         @staticmethod
         def interpretSetupArgs(setupcontent):
             if setupcontent:
                 return "--setup-name='{setup[description]}' --setup-content='{setup[content]}'".format(
-                    setup=setupcontent)
+                    setup=setupcontent
+                )
             return ""
 
         @staticmethod
         def interpretExecArgs(options):
             if not options:
                 return ""
-            return ("--exec-name='{ex[name]}' --exec-content='{ex[content]}'".
-                    format(ex=options))
+            return "--exec-name='{ex[name]}' --exec-content='{ex[content]}'".format(
+                ex=options
+            )
 
         def main(self):
-            '''
+            """
             Main function of the script.
-            '''
+            """
 
             # Checking the arguments
             if len(self.args) != 6:
                 self.parser.error(
-                    'Please specify <project> <version> <platform> '
-                    '<options> <setup-options> <slot config>')
+                    "Please specify <project> <version> <platform> "
+                    "<options> <setup-options> <slot config>"
+                )
                 exit(1)
 
             application = self.args[0]
             version = self.args[1]
             platform = self.args[2]
             job_options = self.args[3]
 
@@ -128,64 +140,73 @@
             handlers = testenv[1]
             setup_options = None if len(testenv) < 3 else testenv[2]
 
             slot_config = self.args[5]
 
             # Parsing the slot config to extract relevant information
             self.log.info("Parsing config file %s" % slot_config)
-            config = Configuration.load(slot_config)
+            with open(slot_config, "rb") as f:
+                config = json.load(f)
+            if testsDisabled(config, application):
+                self.log.warning("Tests are disabled for this project. Exiting.")
+                exit(1)
             project_version = getProjectVersionFromConfig(config, application)
             slot_completed = getSlotDateFromConfig(config)
             # print("SASHA", slot_completed)
             self.log.info("Using %s %s", application, project_version)
 
             # Now create the interface with LHCbPR
             manager = JobManager(self.options.url, self.options.check_ssl)
             try:
                 # Get the actual options based on description
                 optionscontent = manager.getJobOptions(job_options)
 
                 # Get the actual executable
-                executablecontent = manager.getExecutableOptions(
-                    executuable_options)
+                executablecontent = manager.getExecutableOptions(executuable_options)
 
                 # Get the actual options based on description
                 setupcontent = manager.getSetupOptions(setup_options)
 
             except Exception as exc:
                 self.log.error(
                     "Could not get job description options "
-                    "from LHCbPR service %s: %s", self.options.url, str(exc))
+                    "from LHCbPR service %s: %s",
+                    self.options.url,
+                    str(exc),
+                )
                 raise exc
 
             runfilename = "runlhcbpr.sh"
             if self.options.output != None:
                 runfilename = self.options.output
 
             self.log.warning("Writing file: %s", runfilename)
 
             try:
-                with open(runfilename, 'w') as runfile:
+                with open(runfilename, "w") as runfile:
                     # runfile.write("\n")
                     # lblogin_cmd = ". LbLogin.sh -c %s" % platform
                     setup_cmd = self.interpretSetup(
                         setup=setupcontent,
                         app_name=application,
-                        app_version=project_version)
+                        app_version=project_version,
+                    )
                     run_cmd = self.interpretOptions(
                         options=optionscontent,
                         executable=executablecontent,
                         app_name=application,
                         app_version=project_version,
-                        platform=platform)
-                    print(run_cmd, optionscontent)
+                        platform=platform,
+                    )
+                    print((run_cmd, optionscontent))
                     setup_args = self.interpretSetupArgs(setupcontent)
                     exec_args = self.interpretExecArgs(executablecontent)
 
-                    runfile.write('''
+                    runfile.write(
+                        """
 #!/usr/bin/env bash
 #
 # File generated by lbpr-get-command to run the LHCbPR Job
 #
 
 set -v
 
@@ -207,15 +228,18 @@
 
 # Adding jemalloc for the perf jobs
 if [ -d /opt/dirac/lhcbpr/sw/jemalloc-3.6.0/lib ]; then
     export LD_LIBRARY_PATH=/opt/dirac/lhcbpr/sw/jemalloc-3.6.0/lib:$LD_LIBRARY_PATH
 fi
 
 # Get kerberos ticket
-kinit -k -t /afs/cern.ch/user/l/lhcbpr/private/lhcbpr.keytab lhcbpr@CERN.CH
+kinit -k -t $HOME/private/lhcbpr.keytab lhcbpr@CERN.CH
+
+# we need a grid proxy to upload result to Dirac
+export X509_USER_PROXY=$HOME/private/.shifterCred
 
 echo $LD_LIBRARY_PATH
 # Now running the test itself
 set -o pipefail
 date +"%Y-%m-%d %T %z" > start.txt
 time_start=`cat start.txt`
 if [ -d output ]; then
@@ -247,19 +271,14 @@
 data_dict['opt_name'] = '{options[description]}'
 data_dict['time_start'] = sys.argv[2] + "_" + sys.argv[3] + "_" + sys.argv[4]
 data_dict['status'] = 'running'
 data_dict['app_version_datetime'] = '{app_version_datetime}'
 dash.update(doc_name, data_dict)
 END`
 
-# Set environment for throughput tests
-if [[ '{handlers}' == *"Throughput"* ]] ; then
-    source /cvmfs/projects.cern.ch/intelsw/psxe/linux/19-all-setup.sh
-fi
-
 if [ -z "$LHCBPR_MOCK_OUTPUT_PATH" ]
 then
     {run_cmd} 2>&1 | tee run.log
 else
     OUTPUT_PATH="$LHCBPR_MOCK_OUTPUT_PATH"
 fi
 RETCODE=$?
@@ -320,15 +339,15 @@
 eos_path = os.path.join(os.environ['LHCBPR_EOS_LOGS'], '')
 targetDir = 'root://eoslhcb.cern.ch/' + eos_path + logsDir + '/run.log'
 logCollectName = os.path.join(sys.argv[9],'collect.log')
 targetCollectDir = 'root://eoslhcb.cern.ch/' + eos_path + logsDir + '/collect.log'
 try:
     subprocess.call(['xrdcp', logName, targetDir])
     subprocess.call(['xrdcp', logCollectName, targetCollectDir])
-except Exception, ex:
+except Exception as ex:
     logging.warning('Error copying log to eos: %s', ex)
 data_dict['run_log'] = "https://eoslhcbhttp.cern.ch/" + eos_path + logsDir + "/run.log"
 data_dict['collect_log'] = "https://eoslhcbhttp.cern.ch/" + eos_path + logsDir + "/collect.log"
 cmtconfig_dict = dict()
 host_dict = dict()
 cmtconfig_dict['platform'] = sys.argv[10]
 host_dict['hostname'] =  sys.argv[11]
@@ -336,23 +355,26 @@
 host_dict['memoryinfo'] = sys.argv[13]
 data_dict['CMTCONFIG'] = cmtconfig_dict
 data_dict['HOST'] = host_dict
 dash.update(doc_name, data_dict)
 END`
 
 exit $RETCODE
-                    '''.format(
-                        setup_cmd=setup_cmd,
-                        run_cmd=run_cmd,
-                        options=optionscontent,
-                        setup_args=setup_args,
-                        exec_args=exec_args,
-                        handlers=handlers,
-                        app_name=application,
-                        app_version=version,
-                        app_version_datetime=slot_completed.strftime(
-                            "%Y-%m-%d %H:%M:%S -0400")))
+                    """.format(
+                            setup_cmd=setup_cmd,
+                            run_cmd=run_cmd,
+                            options=optionscontent,
+                            setup_args=setup_args,
+                            exec_args=exec_args,
+                            handlers=handlers,
+                            app_name=application,
+                            app_version=version,
+                            app_version_datetime=slot_completed.strftime(
+                                "%Y-%m-%d %H:%M:%S -0400"
+                            ),
+                        )
+                    )
             except Exception as exc:
                 self.log.error("Error generating runfile: %s", str(exc))
                 raise exc
 
     return Script().run()
```

### Comparing `LbNightlyTools-3.0.9/python/LbMsg/BuildMsg.py` & `LbNightlyTools-4.0.0/python/LbMsg/BuildMsg.py`

 * *Files 12% similar despite different names*

```diff
@@ -4,87 +4,96 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Module grouping the common build functions.
-'''
-__author__ = 'Ben Couturier <ben.couturier@cern.ch>'
+"""
+from __future__ import absolute_import, print_function
+
+__author__ = "Ben Couturier <ben.couturier@cern.ch>"
 
 import datetime
-import os
 import json
-from Common import Messenger
+import os
+
+from .Common import Messenger
 
 
 class NightliesMessenger(Messenger):
-    '''
+    """
     Class used to connect to the NightlyBuilds queue
-    '''
+    """
 
     def __init__(self):
-        '''
+        """
         Initialize props
-        '''
+        """
         Messenger.__init__(self)
         self._topic_name = "topic.build_ready"
 
-    def sendBuildDone(self,
-                      slot,
-                      project,
-                      config,
-                      buildId,
-                      deployment=None,
-                      priority=None,
-                      date=datetime.datetime.now()):
-        '''
+    def sendBuildDone(
+        self,
+        slot,
+        project,
+        config,
+        buildId,
+        priority=None,
+        date=datetime.datetime.now(),
+    ):
+        """
         Sends the message that a particular project has been built
-        '''
+        """
         self._basicPublish(
             ".".join([slot, project, config]),
-            json.dumps([{
-                'slot': slot,
-                'project': project,
-                'platform': config,
-                'build_id': buildId,
-                'deployment': deployment,
-                'priority': priority
-            }]))
+            json.dumps(
+                [
+                    {
+                        "slot": slot,
+                        "project": project,
+                        "platform": config,
+                        "build_id": buildId,
+                        "priority": priority,
+                    }
+                ]
+            ),
+        )
 
     def getBuildsDone(self, queueName=None, bindingKeys=None):
-        '''
+        """
         Get the list of builds done, for whcih messages are queued
-        '''
+        """
 
         def callback(ch, method, properties, body):
             print("%r\t%r" % (method.routing_key, body))
 
         buildsDone = []
         with self._getConnection() as connection:
             (channel, queueName) = self._setupClientChannel(
-                connection.channel(), queueName, bindingKeys)
+                connection.channel(), queueName, bindingKeys
+            )
             while True:
-                method_frame, head_frame, body = channel.basic_get(
-                    queue=queueName)
+                method_frame, head_frame, body = channel.basic_get(queue=queueName)
                 if method_frame == None:
                     break
-                print method_frame.routing_key, json.loads(body)
+                print(method_frame.routing_key, json.loads(body))
                 buildsDone.append(json.loads(body)[0])
                 channel.basic_ack(method_frame.delivery_tag)
         return buildsDone
 
     def consumeBuildsDone(self, callback, queueName=None, bindingKeys=None):
-        '''
+        """
         Get the list of builds done, for which messages are queued
         It takes a callback like so:
         def callback(ch, method, properties, body):
             print(" [x] %r:%r" % (method.routing_key, body))
-        '''
+        """
 
         with self._getConnection() as connection:
             (channel, queueName) = self._setupClientChannel(
-                connection.channel(), queueName, bindingKeys)
+                connection.channel(), queueName, bindingKeys
+            )
             channel.basic_consume(callback, queue=queueName, no_ack=True)
             channel.start_consuming()
```

### Comparing `LbNightlyTools-3.0.9/python/LbMsg/Common.py` & `LbNightlyTools-4.0.0/python/LbMsg/Common.py`

 * *Files 23% similar despite different names*

```diff
@@ -4,40 +4,36 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Module grouping the common build functions.
-'''
-__author__ = 'Ben Couturier <ben.couturier@cern.ch>'
+"""
+__author__ = "Ben Couturier <ben.couturier@cern.ch>"
 
 import datetime
-import os
-import pika
 import json
+import os
 import ssl
 
+import pika
+
 
-class Messenger(object):
-    '''
+class Messenger:
+    """
     Class used to send messages to the build system message broker
-    '''
+    """
 
-    def __init__(self,
-                 host=None,
-                 user=None,
-                 passwd=None,
-                 port=5671,
-                 vhost='/lhcb'):
-        '''
+    def __init__(self, host=None, user=None, passwd=None, port=5671, vhost="/lhcb"):
+        """
         Initialize the messenging class
-        '''
+        """
         # Setup the credential variables
         if host == None:
             host = "lbmessagingbroker.cern.ch"
         self._host = host
         if user == None or passwd == None:
             (username, passwd) = self._getPwdFromSys()
             if user == None:
@@ -48,72 +44,73 @@
         self._port = port
         self._vhost = vhost
 
         context = ssl.create_default_context()
         self._ssl_options = pika.SSLOptions(context, self._host)
 
     def _getConnection(self):
-        '''
+        """
         Creates connection to rabbitMQ ond emand
-        '''
+        """
         params = pika.ConnectionParameters(
             self._host,
             ssl_options=self._ssl_options,
             port=self._port,
             virtual_host=self._vhost,
-            credentials=self._credentials)
+            credentials=self._credentials,
+        )
         return pika.BlockingConnection(params)
 
     def _getPwdFromSys(self):
-        '''
+        """
         Get the RabbitMQ password from the environment of from a file on disk
-        '''
+        """
         # First checing the environment
         res = os.environ.get("RMQPWD", None)
 
         # Checking for the password in $PRIVATE_DIR/rabbitmq.txt or
         # $HOME/private/rabbitmq.txt
         if res == None:
-            if not os.environ.get('PRIVATE_DIR'):
-                os.environ['PRIVATE_DIR'] = os.path.join(
-                    os.environ['HOME'], 'private')
+            if not os.environ.get("PRIVATE_DIR"):
+                os.environ["PRIVATE_DIR"] = os.path.join(os.environ["HOME"], "private")
             fname = os.path.join(os.environ["PRIVATE_DIR"], "rabbitmq.txt")
             if os.path.exists(fname):
                 with open(fname, "r") as f:
                     data = f.readlines()
                     if len(data) > 0:
                         res = data[0].strip()
 
         # Separate the username/password
         (username, password) = res.split("/")
         return (username, password)
 
     def _setupChannel(self, channel):
         channel.exchange_declare(
-            exchange=self._topic_name, durable=True, exchange_type='topic')
+            exchange=self._topic_name, durable=True, exchange_type="topic"
+        )
         return channel
 
     def _basicPublish(self, routingKey, body):
-        '''
+        """
         Send a message to the topic defined for the builds
-        '''
+        """
         with self._getConnection() as connection:
             channel = self._setupChannel(connection.channel())
-            props = pika.BasicProperties(
-                delivery_mode=2)  # make message persistent
+            props = pika.BasicProperties(delivery_mode=2)  # make message persistent
             channel.basic_publish(
                 exchange=self._topic_name,
                 routing_key=routingKey,
                 body=body,
-                properties=props)
+                properties=props,
+            )
 
     def _setupClientChannel(self, channel, queueName=None, bindingKeys=None):
-        '''
+        """
         Setup the client channel to receive the appropriate messages
-        '''
+        """
         channel = self._setupChannel(channel)
         if queueName == None:
             # Anonymous queue is NOT persistent
             result = channel.queue_declare(exclusive=True)
             queueName = result.method.queue
         else:
             # Named queues are persistent...
@@ -121,12 +118,11 @@
 
         if bindingKeys == None:
             bindingKeys = ["#"]
 
         # Now binding the queue to the topic
         for bindingKey in bindingKeys:
             channel.queue_bind(
-                exchange=self._topic_name,
-                queue=queueName,
-                routing_key=bindingKey)
+                exchange=self._topic_name, queue=queueName, routing_key=bindingKey
+            )
 
         return (channel, queueName)
```

### Comparing `LbNightlyTools-3.0.9/python/LbMsg/TestMsg.py` & `LbNightlyTools-4.0.0/python/LbMsg/TestMsg.py`

 * *Files 21% similar despite different names*

```diff
@@ -4,90 +4,96 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Module grouping the common build functions.
-'''
-__author__ = 'Ben Couturier <ben.couturier@cern.ch>'
+"""
+from __future__ import absolute_import
+
+__author__ = "Ben Couturier <ben.couturier@cern.ch>"
 
 import datetime
-import os
 import json
-from Common import Messenger
+import os
+
+from .Common import Messenger
 
 
 class TestMessenger(Messenger):
-    '''
+    """
     Class used to connect to the queue of periodic tests to be run
-    '''
+    """
 
     def __init__(self, *args, **kwargs):
-        '''
+        """
         Initialize props
-        '''
+        """
         super(TestMessenger, self).__init__(*args, **kwargs)
         self._topic_name = "topic.periodic_test"
 
-    def requestTest(self, slot, buildId, project, config, group, env, runner,
-                    os_label):
-        '''
+    def requestTest(self, slot, buildId, project, config, group, env, runner, os_label):
+        """
         Sends the request fot starting a test
-        '''
+        """
         params = [slot, project, config, group, env]
         routingKey = ".".join(params)
-        body = json.dumps([{
-            'slot': slot,
-            'build_id': buildId,
-            'project': project,
-            'platform': config,
-            'group': group,
-            'env': env,
-            'runner': runner,
-            'os_label': os_label
-        }])
+        body = json.dumps(
+            [
+                {
+                    "slot": slot,
+                    "build_id": buildId,
+                    "project": project,
+                    "platform": config,
+                    "group": group,
+                    "env": env,
+                    "runner": runner,
+                    "os_label": os_label,
+                }
+            ]
+        )
         self._basicPublish(routingKey, body)
 
     def getTestToRun(self, queueName=None, bindingKeys=None):
-        '''
+        """
         List the waiting requests for tests to be run
-        '''
+        """
         test_list = []
         with self._getConnection() as connection:
             (channel, queueName) = self._setupClientChannel(
-                connection.channel(), queueName, bindingKeys)
+                connection.channel(), queueName, bindingKeys
+            )
             while True:
-                method_frame, header_frame, body = channel.basic_get(
-                    queue=queueName)
+                method_frame, header_frame, body = channel.basic_get(queue=queueName)
                 if method_frame == None:
                     break
                 t = json.loads(body)
                 test_list.append(t[0])
                 channel.basic_ack(method_frame.delivery_tag)
         return test_list
 
     def processTestToRun(
-            self,
-            callback,
-            queueName=None,
-            bindingKeys=None,
+        self,
+        callback,
+        queueName=None,
+        bindingKeys=None,
     ):
-        '''
+        """
         List the waiting requests for tests to be run
-        '''
+        """
         test_list = []
         with self._getConnection() as connection:
             (channel, queueName) = self._setupClientChannel(
-                connection.channel(), queueName, bindingKeys)
+                connection.channel(), queueName, bindingKeys
+            )
             idx = 0
             while True:
-                method_frame, header_frame, body = channel.basic_get(
-                    queue=queueName)
+                method_frame, header_frame, body = channel.basic_get(queue=queueName)
                 if method_frame == None:
                     break
                 t = json.loads(body)
                 callback(idx, t)
                 idx += 1
                 channel.basic_ack(method_frame.delivery_tag)
```

### Comparing `LbNightlyTools-3.0.9/python/LbRPMTools/LHCbExternalsSpecBuilder.py` & `LbNightlyTools-4.0.0/python/LbRPMTools/LHCbExternalsSpecBuilder.py`

 * *Files 9% similar despite different names*

```diff
@@ -4,31 +4,33 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Class to generate RPM Spec for metadapackages that require all the needed packages from
 externals.
 
 Created on Feb 27, 2014
 
 @author: Ben Couturier
-'''
+"""
+from __future__ import absolute_import, print_function
 
+import logging
 import os
 import re
 import sys
-import logging
 from string import Template
-from subprocess import Popen, PIPE, STDOUT
+from subprocess import PIPE, STDOUT, Popen
+
+from .LHCbRPMSpecBuilder import LHCbBaseRpmSpec
 
-from LHCbRPMSpecBuilder import LHCbBaseRpmSpec
 try:
     from LbCommon.Temporary import TempDir
 except:
     from LbUtils.Temporary import TempDir
 
 tmpdir = TempDir(prefix="LHCbExternalsRpmSpec")
 
@@ -43,56 +45,58 @@
 
 
 #
 # Spec for binary RPMs
 #
 ###############################################################################
 class LHCbExternalsRpmSpec(LHCbBaseRpmSpec):
-    """ Class representing a LHCb project"""
+    """Class representing a LHCb project"""
 
-    def __init__(self, project, version, cmtconfig, buildarea, externalsDict,
-                 lcgVer):
-        """ Constructor taking the actual file name """
+    def __init__(self, project, version, cmtconfig, buildarea, externalsDict, lcgVer):
+        """Constructor taking the actual file name"""
         super(LHCbExternalsRpmSpec, self).__init__(project, version)
-        __log__.debug(
-            "Creating RPM for %s/%s/%s" % (project, version, cmtconfig))
+        __log__.debug("Creating RPM for %s/%s/%s" % (project, version, cmtconfig))
         self._project = project
         self._version = version
         self._cmtconfig = cmtconfig
         self._buildarea = buildarea
         self._externalsDict = externalsDict
         self._lcgVersion = lcgVer
         self._lhcb_maj_version = 1
         self._lhcb_min_version = 0
         self._lhcb_patch_version = 0
         self._lhcb_release_version = 0
 
     def getRPMName(self, norelease=False):
-        ''' Return the architecture, always noarch for our packages'''
-        projname = "_".join([
-            self._project.upper(), self._version,
-            self._cmtconfig.replace('-', '_')
-        ])
-        projver = ".".join([
-            str(n) for n in [
-                self._lhcb_maj_version, self._lhcb_min_version, self.
-                _lhcb_patch_version
+        """Return the architecture, always noarch for our packages"""
+        projname = "_".join(
+            [self._project.upper(), self._version, self._cmtconfig.replace("-", "_")]
+        )
+        projver = ".".join(
+            [
+                str(n)
+                for n in [
+                    self._lhcb_maj_version,
+                    self._lhcb_min_version,
+                    self._lhcb_patch_version,
+                ]
             ]
-        ])
+        )
         if norelease:
             return "-".join([projname, projver])
         full = "-".join([projname, projver, str(self._lhcb_release_version)])
         final = ".".join([full, self._arch, "rpm"])
         return final
 
     def _createHeader(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        header = Template("""
+        """
+        header = Template(
+            """
 %define lhcb_maj_version 1
 %define lhcb_min_version 0
 %define lhcb_patch_version 0
 %define buildarea ${buildarea}
 %define project ${project}
 %define projectUp ${projectUp}
 %define cmtconfig ${config}
@@ -116,268 +120,286 @@
 BuildRoot: %{tmpdir}/%{name}-buildroot
 BuildArch: noarch
 AutoReqProv: no
 Prefix: /opt/LHCbSoft
 Provides: /bin/sh
 Provides: %{project}_%{lcgversion}_%{cmtconfigrpm} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 
-\n""").substitute(
+\n"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
             version=self._version,
             config=self._cmtconfig,
-            configrpm=self._cmtconfig.replace('-', '_'),
-            rpmversion=self._version + "_" + self._cmtconfig.replace('-', '_'),
+            configrpm=self._cmtconfig.replace("-", "_"),
+            rpmversion=self._version + "_" + self._cmtconfig.replace("-", "_"),
             lcgversion=self._lcgVersion,
-            releaseversion=self._lhcb_release_version)
+            releaseversion=self._lhcb_release_version,
+        )
 
         return header
 
     def _createRequireForExt(self, extName, extItems):
-        '''
+        """
         Prepare the Ext line for a specific external
-        '''
+        """
         # Extend list if incomplete (that unfortunately happens)
         extItems += [None] * (4 - len(extItems))
         extVer = extItems[0]
         extVerNoLCG = extItems[1]
         cmtcfgopt = extItems[2]
         extpath = extItems[3]
 
         # Exception for Expat, we need to understand this...
         if extName == "Expat":
             extName = "expat"
 
         # LCGCMT is outside of LCG anyway, we deal with it in a special way
         if extName == "LCGCMT":
-            return "Requires: %s_%s\n" % (extName, extVer.replace('-', '_'))
+            return "Requires: %s_%s\n" % (extName, extVer.replace("-", "_"))
 
         requireline = None
         # Now we need to deal with LCG and non LCG externals...
         if "LCG_%s" % self._lcgVersion in extpath:
             # We have a LCG external !
             requireline = "Requires: LCG_%s_%s_%s_%s\n" % (
-                self._lcgVersion, extName, extVer.replace('-', '_'),
-                cmtcfgopt.replace('-', '_'))
+                self._lcgVersion,
+                extName,
+                extVer.replace("-", "_"),
+                cmtcfgopt.replace("-", "_"),
+            )
         else:
             # We have an old type external
             requireline = "Requires: %s_%s_%s\n" % (
-                extName, extVer.replace('-', '_'), cmtcfgopt.replace('-', '_'))
+                extName,
+                extVer.replace("-", "_"),
+                cmtcfgopt.replace("-", "_"),
+            )
         return requireline
 
     def _createRequires(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
-        tmp = ""
+        """
+        tmp = []
         for k, v in self._externalsDict.items():
-
             # Ignore packages from the system like uuid
             if len(v) > 3 and v[3] != None and v[3].startswith("/usr"):
                 continue
 
             # Actually processing the external
-            tmp += self._createRequireForExt(k, v)
+            tmp.append(self._createRequireForExt(k, v))
 
-        return tmp
+        tmp.sort()
+        return "".join(tmp)
 
     def _createDescription(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = "%description\n"
         tmp += "%{project}\n\n"
         return tmp
 
     def _createInstall(self):
-        '''
+        """
         Prepare the Install section of the RPM
-        '''
+        """
         spec = "%install\n"
         spec += "\n\n"
         return spec
 
     def _createTrailer(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        trailer = Template("""
+        """
+        trailer = Template(
+            """
 %files
 
 %post
 
 %postun
 
 %clean
 
 %define date    %(echo `LC_ALL=\"C\" date +\"%a %b %d %Y\"`)
 
 %changelog
 
 * %{date} User <ben.couturier..rcern.ch>
 - first Version
-""").substitute(
+"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
             version=self._version,
             config=self._cmtconfig,
-            configrpm=self._cmtconfig.replace('-', '_'),
-            rpmversion=self._version + "_" + self._cmtconfig.replace('-', '_'))
+            configrpm=self._cmtconfig.replace("-", "_"),
+            rpmversion=self._version + "_" + self._cmtconfig.replace("-", "_"),
+        )
 
         return trailer
 
 
 #
 # Main Script to generate the spec file
 #
 ###############################################################################
 from LbNightlyTools.Scripts.Common import PlainScript
 
 
 class Script(PlainScript):
-    '''
+    """
     Script to generate the Spec file for an LHCb project.
-    '''
-    __usage__ = '''%prog [options] project version platform
+    """
 
-e.g. %prog LHCbExternals v68r0 x86_64-slc6-gcc48-opt'''
-    __version__ = ''
+    __usage__ = """%prog [options] project version platform
+
+e.g. %prog LHCbExternals v68r0 x86_64-slc6-gcc48-opt"""
+    __version__ = ""
 
     def addBasicOptions(self, parser):
-        '''
+        """
         Add some basic (common) options to the option parser
-        '''
+        """
         parser.add_option(
-            '-v',
-            '--version',
+            "-v",
+            "--version",
             dest="version",
             default=None,
             action="store",
-            help="Force LCG version")
+            help="Force LCG version",
+        )
         parser.add_option(
-            '-p',
-            '--platform',
+            "-p",
+            "--platform",
             dest="platform",
             default=None,
             action="store",
-            help="Force platform")
+            help="Force platform",
+        )
         parser.add_option(
-            '-n',
-            '--name',
+            "-n",
+            "--name",
             dest="name",
             default=None,
             action="store",
-            help="Force the name of the RPM generated")
+            help="Force the name of the RPM generated",
+        )
         parser.add_option(
-            '-b',
-            '--buildarea',
+            "-b",
+            "--buildarea",
             dest="buildarea",
             default="/tmp",
             action="store",
-            help="Force build root")
+            help="Force build root",
+        )
         parser.add_option(
-            '-o',
-            '--output',
+            "-o",
+            "--output",
             dest="output",
             default=None,
             action="store",
-            help=
-            "File name for the generated specfile [default output to stdout]")
+            help="File name for the generated specfile [default output to stdout]",
+        )
         return parser
 
     def defineOpts(self):
-        '''
+        """
         Prepare the option parser.
-        '''
+        """
         self.addBasicOptions(self.parser)
 
     def createBuildDirs(self, buildarea, buildname):
-        '''
+        """
         Create directories necessary to the build
-        '''
+        """
         self.topdir = "%s/rpmbuild" % buildarea
         self.tmpdir = "%s/tmpbuild" % buildarea
         self.rpmtmp = "%s/tmp" % buildarea
         self.srcdir = os.path.join(self.topdir, "SOURCES")
         self.rpmsdir = os.path.join(self.topdir, "RPMS")
         self.srpmsdir = os.path.join(self.topdir, "SRPMS")
         self.builddir = os.path.join(self.topdir, "BUILD")
 
         # And creating them if needed
-        for d in [
-                self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir,
-                self.builddir
-        ]:
+        for d in [self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir, self.builddir]:
             if not os.path.exists(d):
                 os.makedirs(d)
 
         self.buildroot = os.path.join(self.tmpdir, "%s-buildroot" % buildname)
 
         if not os.path.exists(self.buildroot):
             os.makedirs(self.buildroot)
 
     def main(self):
-        '''
+        """
         Main method for the script
-        '''
+        """
         if len(self.args) != 3:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         # Extracting info from filename
         project = self.args[0]
         version = self.args[1]
         cmtconfig = self.args[2]
 
-        self.log.warning("Processing externals for %s %s %s" %
-                         (project, version, cmtconfig))
+        self.log.warning(
+            "Processing externals for %s %s %s" % (project, version, cmtconfig)
+        )
 
         # Setting the environment to the request config
-        os.environ['CMTCONFIG'] = cmtconfig
+        os.environ["CMTCONFIG"] = cmtconfig
 
         buildarea = self.options.buildarea
-        self.createBuildDirs(buildarea,
-                             project + "_" + version + "_" + cmtconfig)
+        self.createBuildDirs(buildarea, project + "_" + version + "_" + cmtconfig)
 
         (lcgVerTmp, externalsDict) = get_native_versions(
-            project.upper() + "_" + version, cmtconfig)
+            project.upper() + "_" + version, cmtconfig
+        )
         lcgVer = lcgVerTmp.split("_")[1]
 
         import json
-        with open('externalsDict.json', 'w') as outfile:
+
+        with open("externalsDict.json", "w") as outfile:
             json.dump(externalsDict, outfile)
 
-        print "%s %s %s %s %s %s" % (project, version, cmtconfig, buildarea,
-                                     externalsDict, lcgVer)
+        print(
+            "%s %s %s %s %s %s"
+            % (project, version, cmtconfig, buildarea, externalsDict, lcgVer)
+        )
 
         specname = project
         if self.options.name != None:
             specname = self.options.name
-        spec = LHCbExternalsRpmSpec(specname, version, cmtconfig, buildarea,
-                                    externalsDict, lcgVer)
+        spec = LHCbExternalsRpmSpec(
+            specname, version, cmtconfig, buildarea, externalsDict, lcgVer
+        )
 
         if self.options.output:
             with open(self.options.output, "w") as outputfile:
                 outputfile.write(spec.getSpec())
         else:
-            print spec.getSpec()
+            print(spec.getSpec())
 
 
 #
 # Utilities imported from mkLCGCMTtar to extract list of native versions
 # from dependencies !
 #
 # BEWARE: This is a copy for code from mkLCGCMtar and it needs a lot of
 #         cleanup before proper production.
 #
 ###############################################################################
 #  Method added to facilitate the lookup of macro values
 def get_macro_value(cmtdir, macro, extratags):
-    """ Returns the value of a macro """
+    """Returns the value of a macro"""
     here = os.getcwd()
     if cmtdir != None:
         os.chdir(cmtdir)
     cmd = ["cmt", extratags, "show", "macro_value", macro]
     __log__.debug("get_macro_value - Running: " + " ".join(cmd))
     # Invoking popen to run the command, result is on stdout first line
     p = Popen(" ".join(cmd), stdout=PIPE, stderr=PIPE, shell=True)
@@ -385,100 +407,96 @@
     __log__.debug("get_macro_value - %s = %s" % (macro, line))
     if cmtdir != None:
         os.chdir(here)
     return line
 
 
 def get_base_project(native_version):
-    NAME = native_version.split('_')[0]
-    version = native_version.split('_')[1]
+    NAME = native_version.split("_")[0]
+    version = native_version.split("_")[1]
     Name = NAME.lower().capitalize()
     if NAME == "LHCBDIRAC":
         Name = "LHCbDirac"
-    if NAME == 'LCGCMT':
-        Name = 'LCG'
-    if NAME == 'LHCBGRID':
-        Name = 'LHCbGrid'
-    if Name == 'Lhcbexternals':
-        Name = 'LHCbExternals'
-    NameSys = Name + 'Sys'
-    if Name == 'Gaudi':
-        NameSys = Name + 'Release'
-    if Name == 'LCG':
-        NameSys = Name + '_Release'
-    release_area = Name + '_release_area'
-    if os.path.isdir(
-            os.path.join(os.environ[release_area], Name + 'Env', version)):
-        os.chdir(
-            os.path.join(os.environ[release_area], Name + 'Env', version,
-                         'cmt'))
-        if Name == 'Gaudi': NameSys = Name
+    if NAME == "LCGCMT":
+        Name = "LCG"
+    if NAME == "LHCBGRID":
+        Name = "LHCbGrid"
+    if Name == "Lhcbexternals":
+        Name = "LHCbExternals"
+    NameSys = Name + "Sys"
+    if Name == "Gaudi":
+        NameSys = Name + "Release"
+    if Name == "LCG":
+        NameSys = Name + "_Release"
+    release_area = Name + "_release_area"
+    if os.path.isdir(os.path.join(os.environ[release_area], Name + "Env", version)):
+        os.chdir(os.path.join(os.environ[release_area], Name + "Env", version, "cmt"))
+        if Name == "Gaudi":
+            NameSys = Name
     else:
-        if not os.environ.has_key('CMTPROJECTPATH'):
-            print 'you should set CMTPROJECTPATH first - STOP '
-            sys.exit('No CMTPROJECTPATH')
-        print 'CMTPROJECTPATH = ', os.environ['CMTPROJECTPATH']
-        os.chdir(
-            os.path.join(os.environ[release_area], NAME, native_version,
-                         'cmt'))
-    print "get_base_project %s %s %s %s %s" % (NAME, version, Name, NameSys,
-                                               release_area)
+        if "CMTPROJECTPATH" not in os.environ:
+            print("you should set CMTPROJECTPATH first - STOP ")
+            sys.exit("No CMTPROJECTPATH")
+        print("CMTPROJECTPATH = ", os.environ["CMTPROJECTPATH"])
+        os.chdir(os.path.join(os.environ[release_area], NAME, native_version, "cmt"))
+    print(
+        "get_base_project %s %s %s %s %s" % (NAME, version, Name, NameSys, release_area)
+    )
     return NAME, version, Name, NameSys, release_area
 
 
 def get_project_dir(native_version):
     here = os.getcwd()
-    NAME, version, Name, NameSys, release_area = get_base_project(
-        native_version)
+    NAME, version, Name, NameSys, release_area = get_base_project(native_version)
     dir = os.path.join(os.environ[release_area], NAME, native_version)
     os.chdir(here)
     return dir
 
 
 def get_projectcmt_file(native_version):
     dir = get_project_dir(native_version)
-    return os.path.join(dir, 'cmt', 'project.cmt')
+    return os.path.join(dir, "cmt", "project.cmt")
 
 
 def get_runtime_deps(filename):
     deps = dict()
-    matchexpr = re.compile("#\s*runtime_use\s+\w+")
+    matchexpr = re.compile(r"#\s*runtime_use\s+\w+")
     for l in open(filename, "r"):
         if matchexpr.search(l[:-1]):
             words = l[:-1].replace("#", "").split()
             if len(words) < 3:
                 deps[words[1]] = ""
             else:
                 deps[words[1]] = words[2]
     return deps
 
 
 def get_runtime_cmtpath(native_version):
     file = get_projectcmt_file(native_version)
     deps = get_runtime_deps(file)
     cmtpath = []
-    for d in deps.keys():
+    for d in list(deps.keys()):
         dir = get_project_dir(deps[d])
         cmtpath.append(dir)
-    return ':'.join(cmtpath)
+    return ":".join(cmtpath)
 
 
 def get_cmtpath(native_version):
-    os.environ['CMTPATH'] = get_runtime_cmtpath(native_version)
-    status, CMTPATH = getStatusOutput('cmt show set_value CMTPATH')
-    if CMTPATH[0] == ':':
+    os.environ["CMTPATH"] = get_runtime_cmtpath(native_version)
+    status, CMTPATH = getStatusOutput("cmt show set_value CMTPATH")
+    if CMTPATH[0] == ":":
         CMTPATH = CMTPATH[1:]
-    os.environ['CMTPATH'] = CMTPATH
-    print 'CMTPATH=%s' % CMTPATH
+    os.environ["CMTPATH"] = CMTPATH
+    print("CMTPATH=%s" % CMTPATH)
     return CMTPATH
 
 
 def get_lcg_version(cmtpath):
-    for p in cmtpath.split(':'):
-        pos = p.find('LCGCMT_')
+    for p in cmtpath.split(":"):
+        pos = p.find("LCGCMT_")
         if pos != -1:
             return p[pos:]
 
 
 def getPackPrefix(pak, packages_versions, with_version=True):
     lcg_ext_loc = os.environ["LCG_external_area"]
     bin_dir = packages_versions[pak][2]
@@ -489,18 +507,18 @@
         if full_pack_path.startswith(lcg_ext_loc + os.sep):
             pack_path = full_pack_path.replace(lcg_ext_loc + os.sep, "")
     else:
         # special case for LCGCMT
         pack_path = os.sep.join([pak, nat_version])
 
     if bin_dir in pack_path:
-        pack_path = pack_path[:pack_path.find(bin_dir)]
+        pack_path = pack_path[: pack_path.find(bin_dir)]
 
     if (not with_version) and nat_version:
-        pack_path = pack_path[:pack_path.find(nat_version)]
+        pack_path = pack_path[: pack_path.find(nat_version)]
 
     if pack_path.endswith(os.sep):
         pack_path = pack_path[:-1]
 
     return pack_path
 
 
@@ -514,170 +532,181 @@
         if binary.find("slc3") != -1:
             cmtargs = "-tag=LHCb,LHCbGrid,slc3"
     return cmtargs
 
 
 def getLCGBinary(workdir, extname, binary):
     ext_home = CMT(
-        getCMTExtraTags(binary),
-        "show",
-        "macro_value",
-        "%s_home" % extname,
-        cwd=workdir)[0][:-1]
+        getCMTExtraTags(binary), "show", "macro_value", "%s_home" % extname, cwd=workdir
+    )[0][:-1]
     nat_version = CMT(
         getCMTExtraTags(binary),
         "show",
         "macro_value",
         "%s_native_version" % extname,
-        cwd=workdir)[0][:-1]
+        cwd=workdir,
+    )[0][:-1]
     cfg_version = CMT(
         getCMTExtraTags(binary),
         "show",
         "macro_value",
         "%s_config_version" % extname,
-        cwd=workdir)[0][:-1]
+        cwd=workdir,
+    )[0][:-1]
     if nat_version:
         ext_bin = None
-        ext_bin_list = ext_home[ext_home.find(nat_version):].split(os.sep)
+        ext_bin_list = ext_home[ext_home.find(nat_version) :].split(os.sep)
         if len(ext_bin_list) > 1:
             ext_bin = ext_bin_list[1]
     else:
         ext_bin = ext_home.split(os.sep)[0]
     return nat_version, cfg_version, ext_bin, ext_home
 
 
 def pkgFilter(NAME, pak, vers, binary):
     keep = True
     if NAME == "GANGA" and binary.find("slc5") != -1:
         if pak == "Qt" and vers.startswith("3."):
             keep = False
         if pak == "pyqt" and vers.startswith("3."):
             keep = False
-    if (binary.startswith("win32")
-            or binary.find("winxp") != -1) and pak == "pyqt_compat":
+    if (
+        binary.startswith("win32") or binary.find("winxp") != -1
+    ) and pak == "pyqt_compat":
         keep = False
     if pak.lower() == "icc":
         keep = False
     if not keep:
-        print "Excluding %s %s for %s" % (pak, vers, binary)
+        print("Excluding %s %s for %s" % (pak, vers, binary))
     return keep
 
 
 def get_native_versions(native_version, binary):
-
     here = os.getcwd()
     packages_versions = {}
     extra_packages_versions = {}
 
-    NAME, version, Name, NameSys, release_area = get_base_project(
-        native_version)
+    NAME, version, Name, NameSys, release_area = get_base_project(native_version)
     CMTPATH = get_cmtpath(native_version)
     lcgv = get_lcg_version(CMTPATH)
-    native_cmt = os.path.join(os.environ[release_area], NAME, native_version,
-                              NameSys, 'cmt')
+    native_cmt = os.path.join(
+        os.environ[release_area], NAME, native_version, NameSys, "cmt"
+    )
     if not os.path.exists(native_cmt):
-        native_cmt = os.path.join(os.environ[release_area], NAME,
-                                  native_version, NameSys, version, 'cmt')
+        native_cmt = os.path.join(
+            os.environ[release_area], NAME, native_version, NameSys, version, "cmt"
+        )
     os.chdir(native_cmt)
-    __log__.debug('get_native_version - %s %s %s %s ' %
-                  (release_area, native_cmt, os.getenv('CMTPATH'), lcgv))
-    if NAME != 'LHCBGRID':
-        packages_versions['LCGCMT'] = [lcgv, lcgv, binary]
+    __log__.debug(
+        "get_native_version - %s %s %s %s "
+        % (release_area, native_cmt, os.getenv("CMTPATH"), lcgv)
+    )
+    if NAME != "LHCBGRID":
+        packages_versions["LCGCMT"] = [lcgv, lcgv, binary]
     cmtshow = "cmt %s show " % getCMTExtraTags(binary)
-    cmtcmd = cmtshow + 'macros native > '
+    cmtcmd = cmtshow + "macros native > "
 
     # run cmtcmd
 
-    natives = os.path.join(tmpdir.getName(), native_version + '.vers')
-    __log__.debug('get_native_version - %s ' % (cmtcmd + natives))
+    natives = os.path.join(tmpdir.getName(), native_version + ".vers")
+    __log__.debug("get_native_version - %s " % (cmtcmd + natives))
 
     os.system(cmtcmd + natives)
 
     # get packages_versions
     fd = open(natives)
     fdlines = fd.readlines()
     for fdline in fdlines:
-        native = fdline.split('=')[0]
-        pack = fdline.split('_native')[0]
+        native = fdline.split("=")[0]
+        pack = fdline.split("_native")[0]
         ext_info = getLCGBinary(native_cmt, pack, binary)
         vers = ext_info[0]
         if pkgFilter(NAME, pack, vers, binary):
             packages_versions[pack] = list(ext_info)
 
     os.remove(natives)
 
-    for pak in packages_versions.keys():
+    for pak in list(packages_versions.keys()):
         if not packages_versions[pak][0]:
-            __log__.warning(
-                "%s has no version. Removing it from the list" % pak)
+            __log__.warning("%s has no version. Removing it from the list" % pak)
             del packages_versions[pak]
 
     # Code added to cope with the relocation of some packages from
     # external to app/releases (2012/06/14)
 
     # We first lookup the releases and external paths to be able to compare
     # this is dirty but we have no netter solution for the moment
     LCG_external = os.path.normpath(
-        get_macro_value(None, "LCG_external", getCMTExtraTags(binary)))
+        get_macro_value(None, "LCG_external", getCMTExtraTags(binary))
+    )
     LCG_releases = os.path.normpath(
-        get_macro_value(None, "LCG_releases", getCMTExtraTags(binary)))
+        get_macro_value(None, "LCG_releases", getCMTExtraTags(binary))
+    )
 
-    print "============================================="
-    print "LCG_external: ", LCG_external
-    print "LCG_releases: ", LCG_releases
-    print "============================================="
+    print("=============================================")
+    print("LCG_external: ", LCG_external)
+    print("LCG_releases: ", LCG_releases)
+    print("=============================================")
 
     # Iterate over package to check whether they should be kept in external
     # or app/releases. We execute a show macro_value on the package home
-    for pak in packages_versions.keys():
-        __log__.info(
-            "get_native_version - Checking home for package: %s" % pak)
+    for pak in list(packages_versions.keys()):
+        __log__.info("get_native_version - Checking home for package: %s" % pak)
         macro = pak + "_home"
-        value = os.path.normpath(
-            get_macro_value(None, macro, getCMTExtraTags(binary)))
+        value = os.path.normpath(get_macro_value(None, macro, getCMTExtraTags(binary)))
         __log__.debug("get_native_version - %s = %s" % (macro, value))
 
         # Performing the actual check between LCG_external and LCG_releases and the home of the
         # package
         # BEWARE: LCGCMT_home is set by CMT itself and can be incorrect !
         pakType = None
         if value.startswith(LCG_external):
             pakType = "external"
         if value.startswith(LCG_releases):
             pakType = "app/releases"
 
         # Compatibility check for OLD packages
         # Force external in this case
         if LCG_external == LCG_releases:
-            print "get_native_version - *** Compatibility mode for OLD packages: setting the type to external ***"
+            print(
+                "get_native_version - *** Compatibility mode for OLD packages: setting the type to external ***"
+            )
             pakType = "external"
 
         if pakType is None:
             # Ignoring packages from the system
             if value.startswith("/usr"):
-                print "get_native_version - %s home is %s, IGNORING package from system" % (
-                    pak, value)
+                print(
+                    "get_native_version - %s home is %s, IGNORING package from system"
+                    % (pak, value)
+                )
                 del packages_versions[pak]
             else:
-                print "get_native_version - %s home is %s, not in external or app/releases, WARNING" % (
-                    pak, value)
+                print(
+                    "get_native_version - %s home is %s, not in external or app/releases, WARNING"
+                    % (pak, value)
+                )
                 # Let's not stop for the moment
-                #sys.exit(1)
+                # sys.exit(1)
         else:
             # Adding the pakType to the attribute of the package in the map
             l = packages_versions[pak]
             l.append(pakType)
-            print "get_native_version - Package %s is %s" % (pak, pakType)
+            print("get_native_version - Package %s is %s" % (pak, pakType))
 
     if binary.startswith("i686"):
-        for pak in packages_versions.keys():
+        for pak in list(packages_versions.keys()):
             content = packages_versions[pak]
             if content[2].startswith("x86_64"):
-                print "Replacing binary for %s" % pak
+                print("Replacing binary for %s" % pak)
                 newbin = content[2].replace("x86_64", "i686")
                 newpath = content[3].replace("x86_64", "i686")
                 packages_versions[pak] = [
-                    content[0], content[1], newbin, newpath, content[4]
+                    content[0],
+                    content[1],
+                    newbin,
+                    newpath,
+                    content[4],
                 ]
 
     os.chdir(here)
     return (lcgv, packages_versions)
```

### Comparing `LbNightlyTools-3.0.9/python/LbRPMTools/LHCbLbScriptsSpecBuilder.py` & `LbNightlyTools-4.0.0/python/LbRPMTools/LHCbLbScriptsSpecBuilder.py`

 * *Files 13% similar despite different names*

```diff
@@ -4,46 +4,48 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Class to generate RPM Spec for metadapackages that require all the needed packages from
 externals.
 
 Created on Feb 27, 2014
 
 @author: Ben Couturier
-'''
+"""
+from __future__ import absolute_import, print_function
 
+import logging
 import os
 import re
 import sys
-import logging
 from string import Template
-from subprocess import Popen, PIPE
+from subprocess import PIPE, Popen
+
+from .LHCbRPMSpecBuilder import LHCbBaseRpmSpec
 
-from LHCbRPMSpecBuilder import LHCbBaseRpmSpec
 try:
     from LbCommon.Temporary import TempDir
 except:
     from LbUtils.Temporary import TempDir
 
 tmpdir = TempDir(prefix="LHCbLbScriptsRpmSpec")
 PREFIX = "/opt/LHCbSoft"
 
 __log__ = logging.getLogger(__name__)
 
 
 def parseVersion(version):
-    '''
+    """
     Parse the version string
-    '''
+    """
     maj_version = 1
     min_version = 0
     patch_version = 0
 
     m = re.match("v([\d]+)r([\d]+)$", version)
     if m != None:
         maj_version = m.group(1)
@@ -52,59 +54,66 @@
         # Checking whether the version matches vXrYpZ in that case
         m = re.match("v([\d]+)r([\d]+)p([\d]+)", version)
         if m != None:
             maj_version = m.group(1)
             min_version = m.group(2)
             patch_version = m.group(3)
         else:
-            raise Exception(
-                "Version %s does not match format vXrY or vXrYpZ" % version)
+            raise Exception("Version %s does not match format vXrY or vXrYpZ" % version)
 
     return (maj_version, min_version, patch_version)
 
 
 #
 # Spec for binary RPMs
 #
 ###############################################################################
 class LHCbLbScriptsRpmSpec(LHCbBaseRpmSpec):
-    """ Class representing a LHCb project"""
+    """Class representing a LHCb project"""
 
     def __init__(self, project, version, buildarea, releasedir):
-        """ Constructor taking the actual file name """
+        """Constructor taking the actual file name"""
         super(LHCbLbScriptsRpmSpec, self).__init__(project, version)
         __log__.debug("Creating RPM for %s/%s" % (project, version))
         self._project = project
         self._version = version
         self._buildarea = buildarea
-        (self._lhcb_maj_version, self._lhcb_min_version,
-         self._lhcb_patch_version) = (1, 0, 0)
+        (self._lhcb_maj_version, self._lhcb_min_version, self._lhcb_patch_version) = (
+            1,
+            0,
+            0,
+        )
         self._lhcb_release_version = 0
         self._releasedir = releasedir
 
     def getRPMName(self, norelease=False):
-        ''' Return the architecture, always noarch for our packages'''
+        """Return the architecture, always noarch for our packages"""
         projname = "_".join([self._project.upper(), self._version])
-        projver = ".".join([
-            str(n) for n in [
-                self._lhcb_maj_version, self._lhcb_min_version, self.
-                _lhcb_patch_version
+        projver = ".".join(
+            [
+                str(n)
+                for n in [
+                    self._lhcb_maj_version,
+                    self._lhcb_min_version,
+                    self._lhcb_patch_version,
+                ]
             ]
-        ])
+        )
         if norelease:
             return "-".join([projname, projver])
         full = "-".join([projname, projver, str(self._lhcb_release_version)])
         final = ".".join([full, self._arch, "rpm"])
         return final
 
     def _createHeader(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        header = Template("""
+        """
+        header = Template(
+            """
 %define lhcb_maj_version ${lhcb_maj_version}
 %define lhcb_min_version ${lhcb_min_version}
 %define lhcb_patch_version ${lhcb_patch_version}
 %define lhcb_release_version ${lhcb_release_version}
 %define buildarea ${buildarea}
 %define project ${project}
 %define projectUp ${projectUp}
@@ -132,48 +141,50 @@
 Prefix: %{prefix}
 Provides: /bin/sh
 Provides: /bin/bash
 
 Requires(post): CMT
 Requires: COMPAT
 
-        \n""").substitute(
+        \n"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
             version=self._version,
             lhcb_maj_version=self._lhcb_maj_version,
             lhcb_min_version=self._lhcb_min_version,
             lhcb_patch_version=self._lhcb_patch_version,
             lhcb_release_version=self._lhcb_release_version,
             prefix=PREFIX,
-            releasedir=self._releasedir)
+            releasedir=self._releasedir,
+        )
 
         return header
 
     def _createRequires(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         return ""
 
     def _createDescription(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = "%description\n"
         tmp += "%{project} %{lbversion}\n\n"
         return tmp
 
     def _createInstall(self):
-        '''
+        """
         Prepare the Install section of the RPM
-        '''
+        """
         spec = "%install\n"
-        spec += '''
+        spec += """
 
 [ -d ${RPM_BUILD_ROOT} ] && rm -rf ${RPM_BUILD_ROOT}
 
 mkdir -p ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}/%{projectUp}_%{lbversion}
 
 if [ $? -ne 0 ]; then
   exit $?
@@ -182,22 +193,22 @@
 rsync -avrz %{releasedir}/%{projectUp}/%{projectUp}_%{lbversion}/* ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}/%{projectUp}_%{lbversion}
 
 if [ $? -ne 0 ]; then
   exit $?
 fi
 
 
-        '''
+        """
         return spec
 
     def _createTrailer(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        trailer = '''
+        """
+        trailer = """
 %clean
 
 %post -p /bin/bash
 
 if [ "$MYSITEROOT" ]; then
 PREFIX=$MYSITEROOT
 else
@@ -238,61 +249,68 @@
 %define date    %(echo `LC_ALL=\"C\" date +\"%a %b %d %Y\"`)
 
 %changelog
 
 * %{date} User <ben.couturier..rcern.ch>
 - first Version
 
-        '''
+        """
 
         return trailer
 
 
 #
 # Spec for the LHCb holder package
 #
 ###############################################################################
 class LHCbLbScriptsLinkRpmSpec(LHCbBaseRpmSpec):
-    """ Class representing a LHCb project"""
+    """Class representing a LHCb project"""
 
-    def __init__(self, project, version, linkname, rpmname, buildarea,
-                 releasedir):
-        """ Constructor taking the actual file name """
+    def __init__(self, project, version, linkname, rpmname, buildarea, releasedir):
+        """Constructor taking the actual file name"""
         super(LHCbLbScriptsLinkRpmSpec, self).__init__(project, version)
         __log__.debug("Creating RPM for %s/%s" % (project, version))
         self._project = project
         self._version = version
         self._buildarea = buildarea
         self._linkname = linkname
-        (self._lhcb_maj_version, self._lhcb_min_version,
-         self._lhcb_patch_version) = parseVersion(version)
+        (
+            self._lhcb_maj_version,
+            self._lhcb_min_version,
+            self._lhcb_patch_version,
+        ) = parseVersion(version)
         self._lhcb_release_version = 0
         self._releasedir = releasedir
         self._rpmname = rpmname
 
     def getRPMName(self, norelease=False):
-        ''' Return the architecture, always noarch for our packages'''
+        """Return the architecture, always noarch for our packages"""
         projname = self._rpmname
-        projver = ".".join([
-            str(n) for n in [
-                self._lhcb_maj_version, self._lhcb_min_version, self.
-                _lhcb_patch_version
+        projver = ".".join(
+            [
+                str(n)
+                for n in [
+                    self._lhcb_maj_version,
+                    self._lhcb_min_version,
+                    self._lhcb_patch_version,
+                ]
             ]
-        ])
+        )
         if norelease:
             return "-".join([projname, projver])
         full = "-".join([projname, projver, str(self._lhcb_release_version)])
         final = ".".join([full, self._arch, "rpm"])
         return final
 
     def _createHeader(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        header = Template("""
+        """
+        header = Template(
+            """
 %define lhcb_maj_version ${lhcb_maj_version}
 %define lhcb_min_version ${lhcb_min_version}
 %define lhcb_patch_version ${lhcb_patch_version}
 %define lhcb_release_version ${lhcb_release_version}
 %define buildarea ${buildarea}
 %define project ${project}
 %define projectUp ${projectUp}
@@ -321,229 +339,234 @@
 AutoReqProv: no
 Prefix: %{prefix}
 Provides: /bin/sh
 Provides: /bin/bash
 
 Requires:  %{projectUp}_%{lbversion}
 
-        \n""").substitute(
+        \n"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
             version=self._version,
             lhcb_maj_version=self._lhcb_maj_version,
             lhcb_min_version=self._lhcb_min_version,
             lhcb_patch_version=self._lhcb_patch_version,
             lhcb_release_version=self._lhcb_release_version,
             prefix=PREFIX,
             releasedir=self._releasedir,
             linkname=self._linkname,
-            rpmname=self._rpmname)
+            rpmname=self._rpmname,
+        )
 
         return header
 
     def _createRequires(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         return ""
 
     def _createDescription(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = "%description\n"
         tmp += "%{project} %{lbversion}\n\n"
         return tmp
 
     def _createInstall(self):
-        '''
+        """
         Prepare the Install section of the RPM
-        '''
+        """
         spec = "%install\n"
-        spec += '''
+        spec += """
 
 [ -d ${RPM_BUILD_ROOT} ] && rm -rf ${RPM_BUILD_ROOT}
 
 mkdir -p ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}/%{projectUp}_%{lbversion}
 cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}
 ln -s %{projectUp}_%{lbversion} %{linkname}
 
-        '''
+        """
 
         # HACK ALERT XXX
         # Need to find a better way to do this
         if self._linkname == "prod" and self._project.upper() == "LBSCRIPTS":
-            spec += '''
+            spec += """
 cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/
 ln -s lhcb/%{projectUp}/%{linkname}/InstallArea/scripts/LbLogin.sh
 ln -s lhcb/%{projectUp}/%{linkname}/InstallArea/scripts/LbLogin.csh
-        '''
+        """
         elif self._linkname == "dev" and self._project.upper() == "LBSCRIPTS":
-            spec += '''
+            spec += """
 cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/
 ln -s lhcb/%{projectUp}/%{linkname}/InstallArea/scripts/LbLogin.sh LbLoginDev.sh
 ln -s lhcb/%{projectUp}/%{linkname}/InstallArea/scripts/LbLogin.csh LbLoginDev.csh
-'''
+"""
 
         return spec
 
     def _createTrailer(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        trailer = '''
+        """
+        trailer = """
 %clean
 
 %post
 
 %postun
 
 %files
 %defattr(-,root,root)
 %{prefix}/lhcb/%{projectUp}/%{linkname}
-'''
+"""
         # Same hack as above XXX
         if self._linkname == "prod" and self._project.upper() == "LBSCRIPTS":
-            trailer += '''
+            trailer += """
 %{prefix}/LbLogin.csh
 %{prefix}/LbLogin.sh
-'''
+"""
         if self._linkname == "dev" and self._project.upper() == "LBSCRIPTS":
-            trailer += '''
+            trailer += """
 %{prefix}/LbLoginDev.csh
 %{prefix}/LbLoginDev.sh
-'''
+"""
 
-        trailer += '''
+        trailer += """
 %define date    %(echo `LC_ALL=\"C\" date +\"%a %b %d %Y\"`)
 
 %changelog
 
 * %{date} User <ben.couturier..rcern.ch>
 - first Version
 
-        '''
+        """
 
         return trailer
 
 
 #
 # Main Script to generate the spec file
 #
 ###############################################################################
 from LbNightlyTools.Scripts.Common import PlainScript
 
 
 class Script(PlainScript):
-    '''
+    """
     Script to generate the Spec file for an LHCb project.
-    '''
-    __usage__ = '''%prog [options] project version platform
+    """
+
+    __usage__ = """%prog [options] project version platform
 
-e.g. %prog LHCbExternals v68r0 x86_64-slc6-gcc48-opt'''
-    __version__ = ''
+e.g. %prog LHCbExternals v68r0 x86_64-slc6-gcc48-opt"""
+    __version__ = ""
 
     def addBasicOptions(self, parser):
-        '''
+        """
         Add some basic (common) options to the option parser
-        '''
+        """
         parser.add_option(
-            '-b',
-            '--buildarea',
+            "-b",
+            "--buildarea",
             dest="buildarea",
             default="/tmp",
             action="store",
-            help="Force build root")
+            help="Force build root",
+        )
         parser.add_option(
-            '-o',
-            '--output',
+            "-o",
+            "--output",
             dest="output",
             default=None,
             action="store",
-            help=
-            "File name for the generated specfile [default output to stdout]")
+            help="File name for the generated specfile [default output to stdout]",
+        )
         parser.add_option(
-            '-e',
-            '--releasedir',
+            "-e",
+            "--releasedir",
             dest="releasedir",
             default=os.environ["LHCBRELEASES"],
             action="store",
-            help="LHCb Releases area")
+            help="LHCb Releases area",
+        )
         parser.add_option(
-            '--prod',
+            "--prod",
             dest="buildprodrpm",
             default=False,
             action="store_true",
-            help="Build package with links")
+            help="Build package with links",
+        )
         parser.add_option(
-            '--dev',
+            "--dev",
             dest="builddevrpm",
             default=False,
             action="store_true",
-            help="Build package with links for dev")
+            help="Build package with links for dev",
+        )
 
         return parser
 
     def defineOpts(self):
-        '''
+        """
         Prepare the option parser.
-        '''
+        """
         self.addBasicOptions(self.parser)
 
     def createBuildDirs(self, buildarea, buildname):
-        '''
+        """
         Create directories necessary to the build
-        '''
+        """
         self.topdir = "%s/rpmbuild" % buildarea
         self.tmpdir = "%s/tmpbuild" % buildarea
         self.rpmtmp = "%s/tmp" % buildarea
         self.srcdir = os.path.join(self.topdir, "SOURCES")
         self.rpmsdir = os.path.join(self.topdir, "RPMS")
         self.srpmsdir = os.path.join(self.topdir, "SRPMS")
         self.builddir = os.path.join(self.topdir, "BUILD")
 
         # And creating them if needed
-        for d in [
-                self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir,
-                self.builddir
-        ]:
+        for d in [self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir, self.builddir]:
             if not os.path.exists(d):
                 os.makedirs(d)
 
         self.buildroot = os.path.join(self.tmpdir, "%s-buildroot" % buildname)
 
         if not os.path.exists(self.buildroot):
             os.makedirs(self.buildroot)
 
     def main(self):
-        '''
+        """
         Main method for the script
-        '''
+        """
         if len(self.args) != 1:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         # Extracting info from filename
         project = "LbScripts"
         version = self.args[0]
 
         self.log.warning("Packaging LbScripts %s" % version)
 
         buildarea = self.options.buildarea
         self.createBuildDirs(buildarea, project + "_" + version)
         releasedir = self.options.releasedir
 
         if self.options.buildprodrpm:
-            spec = LHCbLbScriptsLinkRpmSpec(project, version, "prod",
-                                            "LBSCRIPTS", buildarea, releasedir)
+            spec = LHCbLbScriptsLinkRpmSpec(
+                project, version, "prod", "LBSCRIPTS", buildarea, releasedir
+            )
         elif self.options.builddevrpm:
             spec = LHCbLbScriptsLinkRpmSpec(
-                project, version, "dev", "LBSCRIPTSDEV", buildarea, releasedir)
+                project, version, "dev", "LBSCRIPTSDEV", buildarea, releasedir
+            )
         else:
-            spec = LHCbLbScriptsRpmSpec(project, version, buildarea,
-                                        releasedir)
+            spec = LHCbLbScriptsRpmSpec(project, version, buildarea, releasedir)
 
         if self.options.output:
             with open(self.options.output, "w") as outputfile:
                 outputfile.write(spec.getSpec())
         else:
-            print spec.getSpec()
+            print(spec.getSpec())
```

### Comparing `LbNightlyTools-3.0.9/python/LbRPMTools/LHCbRPMSpecBuilder.py` & `LbNightlyTools-4.0.0/python/LbRPMTools/LHCbRPMSpecBuilder.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,231 +1,295 @@
 ###############################################################################
-# (c) Copyright 2014-2016 CERN                                                     #
+# (c) Copyright 2014-2022 CERN                                                #
 #                                                                             #
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Class to generate RPM Specfile
 
 Created on Feb 27, 2014
 
 @author: Ben Couturier
-'''
+"""
+from __future__ import print_function
 
+import logging
 import os
 import re
-import logging
+from builtins import object
 from string import Template
+
+from lbinstall.Installer import Installer
+
+from LbNightlyTools.Utils import TemporaryDir
+
 try:
-    from LbEnv.ProjectEnv.lookup import findProject, MissingProjectError
+    from LbEnv.ProjectEnv.lookup import MissingProjectError, findProject
 except ImportError:
-    from LbConfiguration.SP2.lookup import findProject, MissingProjectError
+    from LbConfiguration.SP2.lookup import MissingProjectError, findProject
 
 __log__ = logging.getLogger(__name__)
 
 PREFIX = "/opt/LHCbSoft"
 
 # FIXME: we need better way to manage this list... util we drop PARAM
-PARAM_PKGS = set([
-    'BcVegPyData',
-    'ChargedProtoANNPIDParam',
-    'Geant4Files',
-    'GenXiccData',
-    'InstallAreaPatch',
-    'LHCbBkg',
-    'MCatNLOData',
-    'MIBData',
-    'ParamFiles',
-    'QMTestFiles',
-    'TMVAWeights',
-])
+PARAM_PKGS = set(
+    [
+        "BcVegPyData",
+        "ChargedProtoANNPIDParam",
+        "Geant4Files",
+        "GenXiccData",
+        "InstallAreaPatch",
+        "LHCbBkg",
+        "MCatNLOData",
+        "MIBData",
+        "ParamFiles",
+        "QMTestFiles",
+        "TMVAWeights",
+    ]
+)
 
 
 # FIXME: we should drop this functionality
 def is_platform_independent(project, version):
     try:
         return os.path.exists(
-            os.path.join(
-                findProject(project, version, 'dummy'), 'manifest.xml'))
+            os.path.join(findProject(project, version, "dummy"), "manifest.xml")
+        )
     except MissingProjectError:
         return False
 
 
-def cmpLCGVersion(x, y):
-    ''' Comparison function that ignores the strings appened to the LCG version
-    e.g. this is useful to check that 86 > 85swan1.
-
-    This method only keeps the first part of the string passed'''
-    import itertools
-    sanitize = lambda x:  int("".join(itertools.takewhile(str.isdigit, x))) if isinstance(x, basestring) else x
-    return cmp(sanitize(x), sanitize(y))
+def convertToLHCbClassicVersion(version):
+    """Convert a version of the type X.Y[.Z[.T]] to vXrY[pZ[tT]].
+    Leaves the other strings unaffected
+    """
+
+    # Case when we specify the version as point separated numbers
+    if re.match(r"^\d[\d.]*$", version):
+        # this is a X.Y CMake style version, so we map it to vXr*
+        # - get the first 4 element max (we support vXrYpZtT)
+        parts = version.split(".")[:4]
+        return "".join(a + b for a, b in zip("vrpt", parts))
 
+    return version
 
-class RpmDirConfig:
-    ''' Placeholder for directory config '''
+
+class RpmDirConfig(object):
+    """Placeholder for directory config"""
 
     def __init__(self, buildarea, buildname):
         self.buildarea = buildarea
         self.buildname = buildname
 
         self.topdir = "%s/rpmbuild" % buildarea
         self.tmpdir = "%s/tmpbuild" % buildarea
         self.rpmtmp = "%s/tmp" % buildarea
         self.srcdir = os.path.join(self.topdir, "SOURCES")
         self.rpmsdir = os.path.join(self.topdir, "RPMS")
         self.srpmsdir = os.path.join(self.topdir, "SRPMS")
         self.builddir = os.path.join(self.topdir, "BUILD")
 
         # And creating them if needed
-        for d in [
-                self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir,
-                self.builddir
-        ]:
+        for d in [self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir, self.builddir]:
             if not os.path.exists(d):
                 os.makedirs(d)
 
         self.buildroot = os.path.join(self.tmpdir, "%s-buildroot" % buildname)
         if not os.path.exists(self.buildroot):
             os.makedirs(self.buildroot)
 
     def removeBuildArea(self):
-        ''' Clean up the dirs '''
+        """Clean up the dirs"""
         import shutil
+
         if os.path.exists(self.buildarea):
             shutil.rmtree(self.buildarea)
 
 
 #
 # Base class for spec files
 #
 ###############################################################################
 class LHCbBaseRpmSpec(object):
-    """ Class representing a LHCb project"""
+    """Class representing a LHCb project"""
 
-    def __init__(self,
-                 project,
-                 version,
-                 prodRPMReleaseDir="/eos/project/l/lhcbwebsites/"
-                 "www/lhcb-rpm/lhcb"):
+    def __init__(self, project, version, prodRPMReleaseDir=None):
         self._project = project
         self._version = version
         self._lhcb_release_version = 0
         self._prodRPMReleaseDir = prodRPMReleaseDir
+        self._checkRelease = False
 
     def getSpec(self):
-        """ Build the global spec file """
+        """Build the global spec file"""
 
         # First we make sure we have a correct release number for the RPM
         # It is created at -1 in constructor.
         # At this point, we can check in the release directory if we need to bump up
         # the release number or keep the current one....
         self._setNextReleaseNumberFromRepo()
 
         # Now returning the spec itself...
-        return str(self._createHeader()) \
-               + str(self._createRequires()) \
-               + str(self._createDescription()) \
-               + str(self._createInstall()) \
-               + str(self._createTrailer())
+        return (
+            str(self._createHeader())
+            + str(self._createRequires())
+            + str(self._createDescription())
+            + str(self._createInstall())
+            + str(self._createTrailer())
+        )
 
     def _createHEPToolsRequires(self):
-        """ Creates the dependency on the HepTools (LHCbExternals) RPMs """
+        """Creates the dependency on the HepTools (LHCbExternals) RPMs"""
+
+        # Looking up the heptools version from the manifest.xml
         heptools = self._manifest.getHEPTools()
-        print "HEPTOOLS:", heptools
-        if heptools:
-            (hver, hcmtconfig, packages) = heptools
-            print "(hver, hcmtconfig, packages):", (hver, hcmtconfig, packages)
-            # Checking whether the LCG_platform is defined
-            # if it is the case, e.g. for do0 build, the RPM depends
-            # on RPMs with different CMTCONFIGs
-            # e.g. do0 depends on dbg
-            (lcg_platform, lcg_system) = self._manifest.getLCGConfig()
-            if lcg_platform != None:
-                hcmtconfig = lcg_platform
-
-            print "(lcg_platform, lcg_system):", (lcg_platform, lcg_system)
-            print "(hver, hcmtconfig, packages):", (hver, hcmtconfig, packages)
-            # Now normalizing to avoid "-" in the RPM name, simpler for parsing...
-            hcmtconfig = hcmtconfig.replace("-", "_")
-            requires = []
-            if packages:
-                #
-                # After LCG 84, we not add dependency to LCGCMT any more !
-                #
-                if cmpLCGVersion("84", hver) >= 0:
-                    requires += [
-                        'Requires: LCGCMT_LCGCMT_{hver}\n'.format(hver=hver)
-                    ]
-                requires += [
-                    'Requires: LCG_{hver}_{name}_{vers}_{platf}\n'.format(
-                        hver=hver,
-                        name=name,
-                        vers=vers.replace('-', '_'),
-                        platf=hcmtconfig)
-                    for name, vers in sorted(packages.items())
-                ]
-                return ''.join(requires)
-            else:
-                return ""
-        else:
-            return ""
+        if not heptools:
+            raise Exception("Missing heptools configuration")
+        (heptools_version, heptools_binary_tag, used_packages) = heptools
+
+        # Looking for the LCG platform, i.e. the one used in the
+        # RPM name
+        (lcg_platform, lcg_system) = self._manifest.getLCGConfig()
+
+        # Getting the list of packages for that LCG version from the toolchain
+        from LbTools import get_toolchain_packages
+
+        try:
+            packages_info, missing, version_mimatch = get_toolchain_packages(
+                heptools_version, lcg_platform, used_packages
+            )
+            for p in missing:
+                __log__.warning("Could not find package %s in toolchain" % p)
+            for p in version_mimatch:
+                tp = packages_info[p]
+                v = used_packages[p]
+                __log__.warning(
+                    "Version mismatch for %s, expected %s, got %s", p, v, tp["version"]
+                )
+        except Exception as e:
+            packages_info = {}
+            __log__.warning("Could not look-up toolchain packages: %s", str(e))
+
+        # at this stage "packages_info" contain a list of package we depend on, with info for the toochain
+        # that we need to create the RPM name for the "Requires" statement.
+
+        # a package from the toolchain is a map such as:
+        # {u'directory': u'Catch2', u'platform': u'x86_64-centos9-gcc12-opt', u'version': u'2.13.9',
+        # u'hash': u'7861b', u'dependencies': [u'Python-3.9.12-9a1bc']}
+        def rpm_name(name, package):
+            return "{n}-{c}_{v}_{p}".format(
+                n=name,
+                c=package["hash"],
+                v=package["version"],
+                p=package["platform"].replace("-", "_"),
+            )
+
+        requires = []
+        for n, p in list(packages_info.items()):
+            requires.append("Requires:" + rpm_name(n, p))
+        return "\n".join(requires) + "\n"
 
     def _createExtToolsRequires(self):
-        """ Creates the dependency on the external (middleware) RPMs """
+        """Creates the dependency on the external (middleware) RPMs"""
         binary_tag, exttools = self._manifest.getExtTools()
-        binary_tag = binary_tag.replace('-', '_')
-        return ''.join('Requires: {name}_{vers}_{platf}\n'.format(
-            name=name, vers=vers.replace('-', '_'), platf=binary_tag)
-                       for name, vers in sorted(exttools.items()))
+        binary_tag = binary_tag.replace("-", "_")
+        return "".join(
+            "Requires: {name}_{vers}_{platf}\n".format(
+                name=name, vers=vers.replace("-", "_"), platf=binary_tag
+            )
+            for name, vers in sorted(exttools.items())
+        )
 
     def setRPMReleaseDir(self, rpmRelDir):
-        """ Set the location for the RPM release directory """
+        """Set the location for the RPM release directory"""
         self._prodRPMReleaseDir = rpmRelDir
 
+    def setCheckRelease(self, checkRelease):
+        """Set the flags enabling the check of the release number in the YUM repository"""
+        self._checkRelease = checkRelease
+
+    def _getMatchingRPMFromRepo(self, name, version):
+        """Looking up a package by name in the YUM repo"""
+        with TemporaryDir() as siteroot:
+            return Installer(siteroot=siteroot).remoteFindPackage(name, version=version)
+
     def _setNextReleaseNumberFromRepo(self):
-        """ Checks the RPM release dir (see constructor for the class) to find the
+        """Checks the RPM release dir (see constructor for the class) to find the
         next release number for the package.
         """
         if self._lhcb_release_version <= 0:
-            if self._prodRPMReleaseDir != None and os.path.exists(
-                    self._prodRPMReleaseDir):
-                __log__.warning(
-                    "Looking for releases in %s" % self._prodRPMReleaseDir)
+            if self._checkRelease:
+                projver = ".".join(
+                    [
+                        str(n)
+                        for n in [
+                            self._lhcb_maj_version,
+                            self._lhcb_min_version,
+                            self._lhcb_patch_version,
+                        ]
+                    ]
+                )
+                __log__.debug(
+                    "Looking for releases of %s / %s"
+                    % (self.getRPMName(norpmver=True), projver)
+                )
+                packages = self._getMatchingRPMFromRepo(
+                    self.getRPMName(norpmver=True), projver
+                )
+                __log__.debug("Found package %s" % packages)
+                if not packages:
+                    self._lhcb_release_version = 1
+                else:
+                    prev_releases = [int(p.release) for p in packages]
+                    __log__.debug("Previous versions releases" % prev_releases)
+                    nextver = max(prev_releases) + 1
+                    self._lhcb_release_version = nextver
+                    __log__.warning(
+                        "Release number set to %s" % self._lhcb_release_version
+                    )
+            elif self._prodRPMReleaseDir != None and os.path.exists(
+                self._prodRPMReleaseDir
+            ):
+                __log__.warning("Looking for releases in %s" % self._prodRPMReleaseDir)
                 # Getting the prefix of out RPM
                 prefix = self.getRPMName(norelease=True)
                 # Now getting the list of already released versions
                 allfiles = [
-                    f for f in os.listdir(self._prodRPMReleaseDir)
+                    f
+                    for f in os.listdir(self._prodRPMReleaseDir)
                     if f.startswith(prefix)
                 ]
                 # If the list is empty, release number is "1"...
                 if len(allfiles) == 0:
                     __log__.warning(
                         "Did not find any releases in the directory - Release number is 1"
                     )
                     self._lhcb_release_version = 1
                 else:
                     __log__.warning(
-                        "Found %d files matching checking latest release" %
-                        len(allfiles))
+                        "Found %d files matching checking latest release"
+                        % len(allfiles)
+                    )
                     allrels = []
                     # Getting the releae numbers from the files found
                     for f in allfiles:
-                        m = re.match("-(\d+)\.", f[len(prefix):])
+                        m = re.match("-(\d+)\.", f[len(prefix) :])
                         if m != None:
                             allrels.append(int(m.group(1)))
                         else:
                             __log__.warning(
                                 "Released RPM %s does not abide by naming convention for release"
-                                % f)
+                                % f
+                            )
 
                     # Now checking the latest one and increase number
                     newrel = sorted(allrels)[-1] + 1
                     __log__.warning("New release is %d" % newrel)
                     self._lhcb_release_version = newrel
 
             else:
@@ -234,55 +298,62 @@
 
 
 #
 # Spec for shared RPMs
 #
 ###############################################################################
 class LHCbSharedRpmSpec(LHCbBaseRpmSpec):
-    """ Class representing the Spec file for an RPM containing the shared files for the project """
+    """Class representing the Spec file for an RPM containing the shared files for the project"""
 
     def __init__(self, project, version, sharedTar, buildarea, manifest=None):
-        """ Constructor  """
+        """Constructor"""
         super(LHCbSharedRpmSpec, self).__init__(project, version)
         __log__.debug("Creating Shared RPM for %s/%s" % (project, version))
         self._project = project
         self._version = version
         self._sharedTar = sharedTar
         self._buildarea = buildarea
         self._lhcb_maj_version = 1
         self._lhcb_min_version = 0
         self._lhcb_patch_version = 0
         self._lhcb_release_version = 0
         self._arch = "noarch"
         self._manifest = manifest
 
     def getArch(self):
-        ''' Return the architecture, always noarch for our packages'''
+        """Return the architecture, always noarch for our packages"""
         return self._arch
 
-    def getRPMName(self, norelease=False):
-        ''' Return the architecture, always noarch for our packages'''
+    def getRPMName(self, norelease=False, norpmver=False):
+        """Return the architecture, always noarch for our packages"""
         projname = "_".join([self._project.upper(), self._version])
-        projver = ".".join([
-            str(n) for n in [
-                self._lhcb_maj_version, self._lhcb_min_version, self.
-                _lhcb_patch_version
+        projver = ".".join(
+            [
+                str(n)
+                for n in [
+                    self._lhcb_maj_version,
+                    self._lhcb_min_version,
+                    self._lhcb_patch_version,
+                ]
             ]
-        ])
+        )
+        if norpmver:
+            return projname
         if norelease:
             return "-".join([projname, projver])
         full = "-".join([projname, projver, str(self._lhcb_release_version)])
         final = ".".join([full, self._arch, "rpm"])
         return final
 
     def _createHeader(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        header = Template("""%define lhcb_maj_version ${lhcb_maj_version}
+        """
+        header = Template(
+            """%define lhcb_maj_version ${lhcb_maj_version}
 %define lhcb_min_version ${lhcb_min_version}
 %define lhcb_patch_version ${lhcb_patch_version}
 %define lhcb_release_version ${lhcb_release_version}
 %define buildarea ${buildarea}
 %define project ${project}
 %define projectUp ${projectUp}
 %define lbversion ${version}
@@ -303,72 +374,80 @@
 BuildRoot: %{tmpdir}/%{name}-buildroot
 BuildArch: noarch
 AutoReqProv: no
 Prefix: /opt/LHCbSoft
 Provides: /bin/sh
 Provides: %{projectUp}_%{lbversion} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 
-""").substitute(
+"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
             version=self._version,
             lhcb_maj_version=self._lhcb_maj_version,
             lhcb_min_version=self._lhcb_min_version,
             lhcb_patch_version=self._lhcb_patch_version,
             lhcb_release_version=self._lhcb_release_version,
         )
 
         return header
 
     def _createRequires(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
 
         tmp = ""
         # Dependencies to LHCb projects
         if self._manifest != None:
-            for (dproject, dversion) in self._manifest.getUsedProjects():
+            for dproject, origversion in self._manifest.getUsedProjects():
+                dvcersion = convertToLHCbClassicVersion(origversion)
                 if is_platform_independent(dproject, dversion):
                     tmp += "Requires: %s_%s\n" % (dproject.upper(), dversion)
                 else:
                     raise Exception(
                         "Platform independent project cannot depend on a platform dependent one"
                     )
         return tmp
 
     def _createDescription(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = "%description\n"
         tmp += "%{project}\n\n"
         return tmp
 
     def _createInstall(self):
-        '''
+        """
         Prepare the Install section of the RPM
-        '''
+        """
         spec = "%install\n"
         spec += "mkdir -p ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}/%{projectUp}_%{lbversion}\n"
         if self._sharedTar != None:
-            spec += "cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb && unzip -q -o %s" % self._sharedTar
+            spec += (
+                "cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb && unzip -q -o %s"
+                % self._sharedTar
+            )
         else:
-            spec += "cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb && getpack --no-eclipse-config --no-config -P -r % s %s" % (
-                self._project, self._version)
+            spec += (
+                "cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb && getpack --no-eclipse-config --no-config -P -r % s %s"
+                % (self._project, self._version)
+            )
 
         spec += "\n\n"
         return spec
 
     def _createTrailer(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        trailer = Template("""
+        """
+        trailer = Template(
+            """
 %post
 
 %postun
 
 %clean
 
 %files
@@ -377,68 +456,77 @@
 
 %define date    %(echo `LC_ALL=\"C\" date +\"%a %b %d %Y\"`)
 
 %changelog
 
 * %{date} User <ben.couturier..rcern.ch>
 - first Version
-""").substitute(
+"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
-            version=self._version)
+            version=self._version,
+        )
 
         return trailer
 
 
 #
 # Spec for Extra shared RPMs
 #
 ###############################################################################
 class LHCbExtraSharedRpmSpec(LHCbBaseRpmSpec):
-    """ Class representing the Spec file for an RPM containing the shared files for the project """
+    """Class representing the Spec file for an RPM containing the shared files for the project"""
 
     def __init__(self, project, version, sharedTar, buildarea):
-        """ Constructor  """
+        """Constructor"""
         super(LHCbExtraSharedRpmSpec, self).__init__(project, version)
         __log__.debug("Creating Shared RPM for %s/%s" % (project, version))
         self._project = project
         self._version = version
         self._sharedTar = sharedTar
         self._buildarea = buildarea
         self._lhcb_maj_version = 1
         self._lhcb_min_version = 0
         self._lhcb_patch_version = 0
         self._lhcb_release_version = 0
         self._arch = "noarch"
 
     def getArch(self):
-        ''' Return the architecture, always noarch for our packages'''
+        """Return the architecture, always noarch for our packages"""
         return self._arch
 
-    def getRPMName(self, norelease=False):
-        ''' Return the architecture, always noarch for our packages'''
+    def getRPMName(self, norelease=False, norpmver=False):
+        """Return the architecture, always noarch for our packages"""
         projname = "_".join([self._project.upper(), self._version, "shared"])
-        projver = ".".join([
-            str(n) for n in [
-                self._lhcb_maj_version, self._lhcb_min_version, self.
-                _lhcb_patch_version
+        projver = ".".join(
+            [
+                str(n)
+                for n in [
+                    self._lhcb_maj_version,
+                    self._lhcb_min_version,
+                    self._lhcb_patch_version,
+                ]
             ]
-        ])
+        )
+        if norpmver:
+            return projname
         if norelease:
             return "-".join([projname, projver])
         full = "-".join([projname, projver, str(self._lhcb_release_version)])
         final = ".".join([full, self._arch, "rpm"])
         return final
 
     def _createHeader(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        header = Template("""
+        """
+        header = Template(
+            """
 %define lhcb_maj_version ${lhcb_maj_version}
 %define lhcb_min_version ${lhcb_min_version}
 %define lhcb_patch_version ${lhcb_patch_version}
 %define lhcb_release_version ${lhcb_release_version}
 %define buildarea ${buildarea}
 %define project ${project}
 %define projectUp ${projectUp}
@@ -460,61 +548,68 @@
 BuildRoot: %{tmpdir}/%{name}-buildroot
 BuildArch: noarch
 AutoReqProv: no
 Prefix: /opt/LHCbSoft
 Provides: /bin/sh
 Provides: %{projectUp}_%{lbversion}_shared = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 
-""").substitute(
+"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
             version=self._version,
             lhcb_maj_version=self._lhcb_maj_version,
             lhcb_min_version=self._lhcb_min_version,
             lhcb_patch_version=self._lhcb_patch_version,
             lhcb_release_version=self._lhcb_release_version,
         )
 
         return header
 
     def _createRequires(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         return ""
 
     def _createDescription(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = "%description\n"
         tmp += "%{project}\n\n"
         return tmp
 
     def _createInstall(self):
-        '''
+        """
         Prepare the Install section of the RPM
-        '''
+        """
         spec = "%install\n"
         spec += "mkdir -p ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}/%{projectUp}_%{lbversion}\n"
         if self._sharedTar != None:
-            spec += "cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb && unzip -q -o %s" % self._sharedTar
+            spec += (
+                "cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb && unzip -q -o %s"
+                % self._sharedTar
+            )
         else:
-            spec += "cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb && getpack --no-eclipse-config --no-config -P -r % s %s" % (
-                self._project, self._version)
+            spec += (
+                "cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb && getpack --no-eclipse-config --no-config -P -r % s %s"
+                % (self._project, self._version)
+            )
 
         spec += "\n\n"
         return spec
 
     def _createTrailer(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        trailer = Template("""
+        """
+        trailer = Template(
+            """
 %post
 
 %postun
 
 %clean
 
 %files
@@ -523,36 +618,36 @@
 
 %define date    %(echo `LC_ALL=\"C\" date +\"%a %b %d %Y\"`)
 
 %changelog
 
 * %{date} User <ben.couturier..rcern.ch>
 - first Version
-""").substitute(
+"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
-            version=self._version)
+            version=self._version,
+        )
 
         return trailer
 
 
 #
 # Spec for binary RPMs
 #
 ###############################################################################
 class LHCbBinaryRpmSpec(LHCbBaseRpmSpec):
-    """ Class representing a LHCb project"""
+    """Class representing a LHCb project"""
 
-    def __init__(self, project, version, cmtconfig, buildarea, buildlocation,
-                 manifest):
-        """ Constructor taking the actual file name """
+    def __init__(self, project, version, cmtconfig, buildarea, buildlocation, manifest):
+        """Constructor taking the actual file name"""
         super(LHCbBinaryRpmSpec, self).__init__(project, version)
-        __log__.debug(
-            "Creating RPM for %s/%s/%s" % (project, version, cmtconfig))
+        __log__.debug("Creating RPM for %s/%s/%s" % (project, version, cmtconfig))
         self._project = project
         self._cmtconfig = cmtconfig
         self._buildarea = buildarea
         self._buildlocation = buildlocation
         self._manifest = manifest
         # This is the version in LHCb Format
         self._version = version
@@ -561,48 +656,55 @@
         self._lhcb_min_version = 0
         self._lhcb_patch_version = 0
         self._lhcb_release_version = 0
         self._arch = "noarch"
         self._extraRequires = []
 
     def addExtraRequire(self, req):
-        ''' Add a requirement for another package to the list '''
+        """Add a requirement for another package to the list"""
         self._extraRequires.append(req)
 
     def getExtraRequires(self):
-        ''' Add a requirement for another package to the list '''
+        """Add a requirement for another package to the list"""
         return "\n".join(["Requires: %s" % r for r in self._extraRequires])
 
     def getArch(self):
-        ''' Return the architecture, always noarch for our packages'''
+        """Return the architecture, always noarch for our packages"""
         return self._arch
 
-    def getRPMName(self, norelease=False):
-        ''' Return the architecture, always noarch for our packages'''
-        projname = "_".join([
-            self._project.upper(), self._version,
-            self._cmtconfig.replace('-', '_')
-        ])
-        projver = ".".join([
-            str(n) for n in [
-                self._lhcb_maj_version, self._lhcb_min_version, self.
-                _lhcb_patch_version
+    def getRPMName(self, norelease=False, norpmver=False):
+        """Return the architecture, always noarch for our packages"""
+        projname = "_".join(
+            [self._project.upper(), self._version, self._cmtconfig.replace("-", "_")]
+        )
+        if norpmver:
+            return projname
+        projver = ".".join(
+            [
+                str(n)
+                for n in [
+                    self._lhcb_maj_version,
+                    self._lhcb_min_version,
+                    self._lhcb_patch_version,
+                ]
             ]
-        ])
+        )
         if norelease:
             return "-".join([projname, projver])
         full = "-".join([projname, projver, str(self._lhcb_release_version)])
         final = ".".join([full, self._arch, "rpm"])
         return final
 
     def _createHeader(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        header = Template("""
+        """
+        header = Template(
+            """
+%define _binaries_in_noarch_packages_terminate_build   0
 %define lhcb_maj_version ${lhcb_maj_version}
 %define lhcb_min_version ${lhcb_min_version}
 %define lhcb_patch_version ${lhcb_patch_version}
 %define lhcb_release_version ${lhcb_release_version}
 %define buildarea ${buildarea}
 %define buildlocation ${buildlocation}
 %define project ${project}
@@ -627,115 +729,139 @@
 BuildRoot: %{tmpdir}/%{name}-buildroot
 BuildArch: noarch
 AutoReqProv: no
 Prefix: /opt/LHCbSoft
 Provides: /bin/sh
 Requires: %{projectUp}_%{lbversion}
 ${extraRequires}
-\n""").substitute(
+\n"""
+        ).substitute(
             buildarea=self._buildarea,
             buildlocation=self._buildlocation,
             project=self._project,
             projectUp=self._project.upper(),
             version=self._version,
             config=self._cmtconfig,
-            configrpm=self._cmtconfig.replace('-', '_'),
-            rpmversion=self._version + "_" + self._cmtconfig.replace('-', '_'),
+            configrpm=self._cmtconfig.replace("-", "_"),
+            rpmversion=self._version + "_" + self._cmtconfig.replace("-", "_"),
             lhcb_maj_version=self._lhcb_maj_version,
             lhcb_min_version=self._lhcb_min_version,
             lhcb_patch_version=self._lhcb_patch_version,
             lhcb_release_version=self._lhcb_release_version,
-            extraRequires=self.getExtraRequires())
+            extraRequires=self.getExtraRequires(),
+        )
 
         return header
 
     def _createDataPackageDependency(self, pack, ver):
-        '''
+        """
         Create the correct dependency line for the package
-        '''
-        tarBallName = '{}_{}'.format(
-            'PARAM' if pack in PARAM_PKGS else 'DBASE', pack.replace('/', '_'))
+        """
+        tarBallName = "{}_{}".format(
+            "PARAM" if pack in PARAM_PKGS else "DBASE", pack.replace("/", "_")
+        )
 
         # Now parsing the version, including possible '*' and 'v*'
-        if ver in ('*', 'v*'):
-            (major, minor, patch, gpatch) = ('*', None, None, None)
+        if ver in ("*", "v*"):
+            (major, minor, patch, gpatch) = ("*", None, None, None)
         else:
-            _txt_version_style = r'v([0-9\*]+)r([0-9\*]+)(?:p([0-9\*]+))?(?:g([0-9\*]+))?'
+            _txt_version_style = (
+                r"v([0-9\*]+)r([0-9\*]+)(?:p([0-9\*]+))?(?:g([0-9\*]+))?"
+            )
             m = re.match(_txt_version_style, ver)
-            if m == None:
-                raise Exception("Version '%s' could not be parsed" % ver)
-            (major, minor, patch, gpatch) = m.groups()
+            if m is not None:
+                (major, minor, patch, gpatch) = m.groups()
+            else:
+                # Case when we specify data package versions as point separated numbers
+                _txt_version_point_sep = "(\d+).(\d+)"
+                m = re.match(_txt_version_point_sep, ver)
+                if m is None:
+                    raise Exception(
+                        "Version '%s' for data package %s is not allowed, use *, v*, vXrYpZ or X.Y"
+                        % (ver, pack)
+                    )
+                else:
+                    (major, minor, patch, gpatch) = m.groups() + (None, None)
+                    # Special case for the '0' which is translated to *
+                    if minor == "0":
+                        minor = "*"
 
         if gpatch != None:
-            raise Exception(
-                "Data package version %s not handled by RPM tools" % ver)
+            raise Exception("Data package version %s not handled by RPM tools" % ver)
 
         reqstr = None
-        if major == '*':
+        if major == "*":
             # In this case we do not care about the version at all
             # We omit the version from the RPM req
             reqstr = "Requires: %s" % tarBallName
-        elif minor == '*':
+        elif minor == "*":
             # Classic vXr* for data packages
             # In that case we depend on the Provides with the major version number included
             reqstr = "Requires: %s_v%s" % (tarBallName, major)
+        elif patch == "*":
+            # Classic vXrYp* for data packages
+            # In that case we depend on the Provides with the major and minor version numbers included
+            reqstr = "Requires: %s_v%sr%s" % (tarBallName, major, minor)
         elif patch != None:
-            reqstr = "Requires: %s = %s.%s.%s" % (tarBallName, major, minor,
-                                                  patch)
+            reqstr = "Requires: %s = %s.%s.%s" % (tarBallName, major, minor, patch)
         else:
             reqstr = "Requires: %s = %s.%s" % (tarBallName, major, minor)
 
         return reqstr + "\n"
 
     def _createRequires(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = ""
 
         # Dependencies to LHCb projects
-        for (dproject, dversion) in self._manifest.getUsedProjects():
+        for dproject, origversion in self._manifest.getUsedProjects():
+            dversion = convertToLHCbClassicVersion(origversion)
             if is_platform_independent(dproject, dversion):
                 tmp += "Requires: %s_%s\n" % (dproject.upper(), dversion)
             else:
                 tmp += "Requires: %s_%s_%%{cmtconfigrpm}\n" % (
-                    dproject.upper(), dversion)
+                    dproject.upper(),
+                    dversion,
+                )
         # Dependency to LCGCMT
         tmp += self._createHEPToolsRequires()
         tmp += self._createExtToolsRequires()
 
         # Dependency to data packages
-        for (pack, ver) in self._manifest.getUsedDataPackages():
+        for pack, ver in self._manifest.getUsedDataPackages():
             tmp += self._createDataPackageDependency(pack, ver)
 
         return tmp
 
     def _createDescription(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = "%description\n"
         tmp += "%{project}\n\n"
         return tmp
 
     def _createInstall(self):
-        '''
+        """
         Prepare the Install section of the RPM
-        '''
+        """
         spec = "%install\n"
         spec += "mkdir -p ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}/%{projectUp}_%{lbversion}/InstallArea/%{cmtconfig}\n"
         spec += "rsync -arL %{buildlocation}/%{projectUp}/%{projectUp}_%{lbversion}/InstallArea/%{cmtconfig} ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}/%{projectUp}_%{lbversion}/InstallArea/\n"
         spec += "\n\n"
         return spec
 
     def _createTrailer(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        trailer = Template("""
+        """
+        trailer = Template(
+            """
 %post
 
 %postun
 
 %clean
 
 %files
@@ -744,72 +870,81 @@
 
 %define date    %(echo `LC_ALL=\"C\" date +\"%a %b %d %Y\"`)
 
 %changelog
 
 * %{date} User <ben.couturier..rcern.ch>
 - first Version
-""").substitute(
+"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
             version=self._version,
             config=self._cmtconfig,
-            configrpm=self._cmtconfig.replace('-', '_'),
-            rpmversion=self._version + "_" + self._cmtconfig.replace('-', '_'))
+            configrpm=self._cmtconfig.replace("-", "_"),
+            rpmversion=self._version + "_" + self._cmtconfig.replace("-", "_"),
+        )
 
         return trailer
 
 
 #
 # Spec for the glimpse RPMs
 #
 ###############################################################################
 class LHCbGlimpseRpmSpec(LHCbBaseRpmSpec):
-    """ Class representing the Spec file for an RPM containing the shared files for the project """
+    """Class representing the Spec file for an RPM containing the shared files for the project"""
 
     def __init__(self, project, version, sharedTar, buildarea, manifest):
-        """ Constructor  """
+        """Constructor"""
         super(LHCbGlimpseRpmSpec, self).__init__(project, version)
         __log__.debug("Creating Shared RPM for %s/%s" % (project, version))
         self._project = project
         self._version = version
         self._sharedTar = sharedTar
         self._buildarea = buildarea
         self._lhcb_maj_version = 1
         self._lhcb_min_version = 0
         self._lhcb_patch_version = 0
         self._lhcb_release_version = 0
         self._manifest = manifest
         self._arch = "noarch"
 
     def getArch(self):
-        ''' Return the architecture, always noarch for our packages'''
+        """Return the architecture, always noarch for our packages"""
         return self._arch
 
-    def getRPMName(self, norelease=False):
-        ''' Return the architecture, always noarch for our packages'''
+    def getRPMName(self, norelease=False, norpmver=False):
+        """Return the architecture, always noarch for our packages"""
         projname = "_".join([self._project.upper(), self._version, "index"])
-        projver = ".".join([
-            str(n) for n in [
-                self._lhcb_maj_version, self._lhcb_min_version, self.
-                _lhcb_patch_version
+        if norpmver:
+            return projname
+        projver = ".".join(
+            [
+                str(n)
+                for n in [
+                    self._lhcb_maj_version,
+                    self._lhcb_min_version,
+                    self._lhcb_patch_version,
+                ]
             ]
-        ])
+        )
         if norelease:
             return "-".join([projname, projver])
         full = "-".join([projname, projver, str(self._lhcb_release_version)])
         final = ".".join([full, self._arch, "rpm"])
         return final
 
     def _createHeader(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        header = Template("""
+        """
+        header = Template(
+            """
 %define lhcb_maj_version ${lhcb_maj_version}
 %define lhcb_min_version ${lhcb_min_version}
 %define lhcb_patch_version ${lhcb_patch_version}
 %define lhcb_release_version ${lhcb_release_version}
 %define buildarea ${buildarea}
 %define project ${project}
 %define projectUp ${projectUp}
@@ -832,64 +967,69 @@
 BuildArch: noarch
 AutoReqProv: no
 Prefix: /opt/LHCbSoft
 Provides: /bin/sh
 Provides: %{projectUp}_%{lbversion}_index = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Requires: %{projectUp}_%{lbversion}
 
-""").substitute(
+"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
             version=self._version,
             lhcb_maj_version=self._lhcb_maj_version,
             lhcb_min_version=self._lhcb_min_version,
             lhcb_patch_version=self._lhcb_patch_version,
             lhcb_release_version=self._lhcb_release_version,
         )
 
         return header
 
     def _createRequires(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = ""
 
         # Dependencies to LHCb projects
-        for (dproject, dversion) in self._manifest.getUsedProjects():
+        for dproject, origversion in self._manifest.getUsedProjects():
+            dversion = convertToLHCbClassicVersion(origversion)
             tmp += "Requires: %s_%s_index\n" % (dproject.upper(), dversion)
         return tmp
 
     def _createDescription(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = "%description\n"
         tmp += "%{project} glimpse indices\n\n"
         return tmp
 
     def _createInstall(self):
-        '''
+        """
         Prepare the Install section of the RPM
-        '''
+        """
         spec = "%install\n"
         spec += "mkdir -p ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}/%{projectUp}_%{lbversion}\n"
-        spec += "cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb && unzip -q -o %s\n" % self._sharedTar
+        spec += (
+            "cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb && unzip -q -o %s\n"
+            % self._sharedTar
+        )
         spec += "mv  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}/%{projectUp}_%{lbversion}/.glimpse_filenames ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}/%{projectUp}_%{lbversion}/.glimpse_filenames.config"
 
         spec += "\n\n"
         return spec
 
     def _createTrailer(self):
-        '''
+        """
         Prepare the RPM header
-        '''
+        """
         ###trailer = Template('''
-        trailer = '''
+        trailer = """
 %post
 
 if [ "$MYSITEROOT" ]; then
 PREFIX=$MYSITEROOT
 else
 PREFIX=%{prefix}
 fi
@@ -908,82 +1048,82 @@
 
 %define date    %(echo `LC_ALL=\"C\" date +\"%a %b %d %Y\"`)
 
 %changelog
 
 * %{date} User <ben.couturier..rcern.ch>
 - first Version
-'''
-        #).substitute(buildarea = self._buildarea,
+"""
+        # ).substitute(buildarea = self._buildarea,
         #                project = self._project,
         #                projectUp = self._project.upper(),
         #                version = self._version)
 
         return trailer
 
 
 #
 # Spec for Datapackage RPMs
 #
 ###############################################################################
 class LHCbDatapkgRpmSpec(LHCbBaseRpmSpec):
-    """ Class representing the Spec file for an RPM containing the shared files for the project """
+    """Class representing the Spec file for an RPM containing the shared files for the project"""
 
-    def __init__(self,
-                 project,
-                 fulldatapkg,
-                 version,
-                 sharedTar,
-                 buildarea,
-                 release=0):
-        """ Constructor  """
+    def __init__(self, project, fulldatapkg, version, sharedTar, buildarea, release=0):
+        """Constructor"""
         super(LHCbDatapkgRpmSpec, self).__init__(project, version)
         __log__.debug("Creating Data Pkg RPM for %s/%s" % (project, version))
         self._project = project
         self._fulldatapkg = fulldatapkg
         if "/" in fulldatapkg:
             self._package = fulldatapkg.split("/")[-1]
         else:
             self._package = fulldatapkg
         self._normfulldatapkg = fulldatapkg.replace("/", "_")
-        self._fullname = "_".join(
-            [self._project.upper(), self._normfulldatapkg])
+        self._fullname = "_".join([self._project.upper(), self._normfulldatapkg])
         self._fullnameWithVer = "_".join(
-            [self._project.upper(), self._normfulldatapkg, self._version])
-        self._versiondir = os.path.join(self._project.upper(),
-                                        self._fulldatapkg)
+            [self._project.upper(), self._normfulldatapkg, self._version]
+        )
+        self._versiondir = os.path.join(self._project.upper(), self._fulldatapkg)
         self._version = version
         self._sharedTar = sharedTar
         self._buildarea = buildarea
-        (self._lhcb_maj_version, self._lhcb_min_version,
-         self._lhcb_patch_version) = parseVersion(version)
+        (
+            self._lhcb_maj_version,
+            self._lhcb_min_version,
+            self._lhcb_patch_version,
+        ) = parseVersion(version)
         self._lhcb_release_version = release
         self._arch = "noarch"
 
     def getArch(self):
-        ''' Return the architecture, always noarch for our packages'''
+        """Return the architecture, always noarch for our packages"""
         return self._arch
 
-    def getRPMName(self, norelease=False):
-        ''' Return the architecture, always noarch for our packages'''
+    def getRPMName(self, norelease=False, norpmver=False):
+        """Return the architecture, always noarch for our packages"""
         projname = "_".join(
-            [self._project.upper(), self._normfulldatapkg, self._version])
+            [self._project.upper(), self._normfulldatapkg, self._version]
+        )
+        if norpmver:
+            return projname
         # We keep this package to 1.0.0, but the requirements map the vXrY
         projver = ".".join([str(n) for n in [1, 0, 0]])
         if norelease:
             return "-".join([projname, projver])
         full = "-".join([projname, projver, str(self._lhcb_release_version)])
         final = ".".join([full, self._arch, "rpm"])
         return final
 
     def _createHeader(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        header = Template("""
+        """
+        header = Template(
+            """
 %define lhcb_maj_version ${lhcb_maj_version}
 %define lhcb_min_version ${lhcb_min_version}
 %define lhcb_patch_version ${lhcb_patch_version}
 %define lhcb_release_version ${lhcb_release_version}
 %define buildarea ${buildarea}
 %define project ${project}
 %define projectUp ${projectUp}
@@ -1017,65 +1157,71 @@
 Provides: /bin/sh
 Provides: /bin/bash
 
 Provides: %{package} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Provides: %{fullname} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Provides: %{package}_v%{lhcb_maj_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Provides: %{fullname}_v%{lhcb_maj_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
+Provides: %{package}_v%{lhcb_maj_version}r%{lhcb_min_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
+Provides: %{fullname}_v%{lhcb_maj_version}r%{lhcb_min_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Requires: %{projectUp}_common
 Requires(post): LBSCRIPTS
 
-""").substitute(
+"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
             normfulldatapkg=self._normfulldatapkg,
             fulldatapkg=self._fulldatapkg,
             version=self._version,
             lhcb_maj_version=self._lhcb_maj_version,
             lhcb_min_version=self._lhcb_min_version,
             lhcb_patch_version=self._lhcb_patch_version,
             lhcb_release_version=self._lhcb_release_version,
             fullname=self._fullname,
             fullnameWithVer=self._fullnameWithVer,
             versiondir=self._versiondir,
             package=self._package,
-            prefix=PREFIX)
+            prefix=PREFIX,
+        )
 
         return header
 
     def _createRequires(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         return ""
 
     def _createDescription(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = "%description\n"
         tmp += "%{fullname} %{version}\n\n"
         return tmp
 
     def _createInstall(self):
-        '''
+        """
         Prepare the Install section of the RPM
-        '''
+        """
         spec = "%install\n"
         spec += "mkdir -p ${RPM_BUILD_ROOT}%{prefix}/lhcb/%{versiondir}\n"
-        spec += "cd  ${RPM_BUILD_ROOT}%%{prefix}/lhcb && unzip -q -o %s" % self._sharedTar
+        spec += (
+            "cd  ${RPM_BUILD_ROOT}%%{prefix}/lhcb && unzip -q -o %s" % self._sharedTar
+        )
         spec += "\n\n"
         return spec
 
     def _createTrailer(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        trailer = '''
+        """
+        trailer = """
 
 %clean
 
 %post -p /bin/bash
 
 if [ "$MYSITEROOT" ]; then
 PREFIX=$MYSITEROOT
@@ -1126,64 +1272,71 @@
 
 %define date    %(echo `LC_ALL=\"C\" date +\"%a %b %d %Y\"`)
 
 %changelog
 
 * %{date} User <ben.couturier..rcern.ch>
 - first Version
-'''
+"""
 
         return trailer
 
 
 #
 # Spec for LbScript RPM
 #
 ###############################################################################
 class LHCbLbScriptsRpmSpec(LHCbBaseRpmSpec):
-    """ Class representing the Spec file for an RPM containing the shared files for the project """
+    """Class representing the Spec file for an RPM containing the shared files for the project"""
 
     def __init__(self, project, version, sharedTar, buildarea):
-        """ Constructor  """
+        """Constructor"""
         super(LHCbLbScriptsRpmSpec, self).__init__(project, version)
         __log__.debug("Creating Shared RPM for %s/%s" % (project, version))
         self._project = project
         self._version = version
         self._sharedTar = sharedTar
         self._buildarea = buildarea
         self._lhcb_maj_version = 1
         self._lhcb_min_version = 0
         self._lhcb_patch_version = 0
         self._lhcb_release_version = 0
         self._arch = "noarch"
 
     def getArch(self):
-        ''' Return the architecture, always noarch for our packages'''
+        """Return the architecture, always noarch for our packages"""
         return self._arch
 
-    def getRPMName(self, norelease=False):
-        ''' Return the architecture, always noarch for our packages'''
+    def getRPMName(self, norelease=False, norpmver=False):
+        """Return the architecture, always noarch for our packages"""
         projname = "_".join([self._project.upper(), self._version])
-        projver = ".".join([
-            str(n) for n in [
-                self._lhcb_maj_version, self._lhcb_min_version, self.
-                _lhcb_patch_version
+        if norpmver:
+            return projname
+        projver = ".".join(
+            [
+                str(n)
+                for n in [
+                    self._lhcb_maj_version,
+                    self._lhcb_min_version,
+                    self._lhcb_patch_version,
+                ]
             ]
-        ])
+        )
         if norelease:
             return "-".join([projname, projver])
         full = "-".join([projname, projver, str(self._lhcb_release_version)])
         final = ".".join([full, self._arch, "rpm"])
         return final
 
     def _createHeader(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        header = Template("""
+        """
+        header = Template(
+            """
 %define lhcb_maj_version ${lhcb_maj_version}
 %define lhcb_min_version ${lhcb_min_version}
 %define lhcb_patch_version ${lhcb_patch_version}
 %define lhcb_release_version ${lhcb_release_version}
 %define buildarea ${buildarea}
 %define project ${project}
 %define projectUp ${projectUp}
@@ -1207,57 +1360,62 @@
 BuildRoot: %{tmpdir}/%{name}-buildroot
 BuildArch: noarch
 AutoReqProv: no
 Prefix: %{prefix}
 Provides: /bin/sh
 Provides: /bin/bash
 
-""").substitute(
+"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
             version=self._version,
             lhcb_maj_version=self._lhcb_maj_version,
             lhcb_min_version=self._lhcb_min_version,
             lhcb_patch_version=self._lhcb_patch_version,
             lhcb_release_version=self._lhcb_release_version,
-            prefix=PREFIX)
+            prefix=PREFIX,
+        )
 
         return header
 
     def _createRequires(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         return """
 
 """
 
     def _createDescription(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = "%description\n"
         tmp += "%{project} %{lbversion}\n\n"
         return tmp
 
     def _createInstall(self):
-        '''
+        """
         Prepare the Install section of the RPM
-        '''
+        """
         spec = "%install\n"
         spec += "mkdir -p ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}/%{projectUp}_%{lbversion}\n"
-        spec += "cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb && unzip -q -o %s" % self._sharedTar
+        spec += (
+            "cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb && unzip -q -o %s"
+            % self._sharedTar
+        )
         spec += "\n\n"
         return spec
 
     def _createTrailer(self):
-        '''
+        """
         Prepare the RPM header
-        '''
+        """
         trailer = """
 
 %post -p /bin/bash
 
 if [ "$MYSITEROOT" ]; then
 PREFIX=$MYSITEROOT
 else
@@ -1308,45 +1466,45 @@
 
 
 #
 # Various utilities to extract info about the build
 #
 ###############################################################################
 def splitpath(path):
-    ''' Split a path to all its components '''
+    """Split a path to all its components"""
     spath = []
     while True:
         (head, tail) = os.path.split(path)
         if len(head) == 0 or len(tail) == 0:
             break
         spath.insert(0, tail)
         path = head
     return spath
 
 
 def getBuildInfo(manifestFileName):
-    '''
+    """
     Get info about the build from the manifest filename itself
-    '''
+    """
     realFilename = os.path.realpath(manifestFileName)
     splitPath = splitpath(realFilename)
-    if len(splitPath) < 4 or splitPath[-3] != 'InstallArea':
+    if len(splitPath) < 4 or splitPath[-3] != "InstallArea":
         # The manifest is not in the standard location
         return (realFilename, None, None, None)
     else:
         barea = realFilename
         for _i in range(5):
             barea = os.path.dirname(barea)
         return (realFilename, barea, splitPath[-4], splitPath[-2])
 
 
 def parseVersion(version):
-    '''
+    """
     Parse the version string
-    '''
+    """
     maj_version = 1
     min_version = 0
     patch_version = 0
 
     m = re.match("v([\d]+)r([\d]+)$", version)
     if m != None:
         maj_version = m.group(1)
@@ -1355,152 +1513,157 @@
         # Checking whether the version matches vXrYpZ in that case
         m = re.match("v([\d]+)r([\d]+)p([\d]+)", version)
         if m != None:
             maj_version = m.group(1)
             min_version = m.group(2)
             patch_version = m.group(3)
         else:
-            raise Exception(
-                "Version %s does not match format vXrY or vXrYpZ" % version)
+            raise Exception("Version %s does not match format vXrY or vXrYpZ" % version)
 
     return (maj_version, min_version, patch_version)
 
 
 # Main Script to generate the spec file
 #
 ###############################################################################
 from LbNightlyTools.Scripts.Common import PlainScript
 
 
 class Script(PlainScript):
-    '''
+    """
     Script to generate the Spec file for an LHCb project.
-    '''
-    __usage__ = '%prog [options] <manifest.xml>'
-    __version__ = ''
+    """
+
+    __usage__ = "%prog [options] <manifest.xml>"
+    __version__ = ""
 
     def addBasicOptions(self, parser):
-        '''
+        """
         Add some basic (common) options to the option parser
-        '''
+        """
         parser.add_option(
-            '-v',
-            '--version',
+            "-v",
+            "--version",
             dest="version",
             default=None,
             action="store",
-            help="Force LCG version")
+            help="Force LCG version",
+        )
         parser.add_option(
-            '-p',
-            '--platform',
+            "-p",
+            "--platform",
             dest="platform",
             default=None,
             action="store",
-            help="Force platform")
+            help="Force platform",
+        )
         parser.add_option(
-            '-s',
-            '--shared',
+            "-s",
+            "--shared",
             dest="shared",
             default=False,
             action="store_true",
-            help="Build shared RPM")
+            help="Build shared RPM",
+        )
         parser.add_option(
-            '--shared-tar',
+            "--shared-tar",
             dest="sharedTar",
             default=None,
             action="store",
-            help="Shared tar to be included")
+            help="Shared tar to be included",
+        )
         parser.add_option(
-            '--builddir',
+            "--builddir",
             dest="builddir",
             default=None,
             action="store",
-            help=
-            "Force LCG dir if different from the one containing the config file"
+            help="Force LCG dir if different from the one containing the config file",
         )
         parser.add_option(
-            '-b',
-            '--buildarea',
+            "-b",
+            "--buildarea",
             dest="buildarea",
             default="/tmp",
             action="store",
-            help="Force build root")
+            help="Force build root",
+        )
         parser.add_option(
-            '-o',
-            '--output',
+            "-o",
+            "--output",
             dest="output",
             default=None,
             action="store",
-            help=
-            "File name for the generated specfile [default output to stdout]")
+            help="File name for the generated specfile [default output to stdout]",
+        )
         return parser
 
     def defineOpts(self):
-        '''
+        """
         Prepare the option parser.
-        '''
+        """
         self.addBasicOptions(self.parser)
 
     def createBuildDirs(self, buildarea, buildname):
-        '''
+        """
         Create directories necessary to the build
-        '''
+        """
         self.topdir = "%s/rpmbuild" % buildarea
         self.tmpdir = "%s/tmpbuild" % buildarea
         self.rpmtmp = "%s/tmp" % buildarea
         self.srcdir = os.path.join(self.topdir, "SOURCES")
         self.rpmsdir = os.path.join(self.topdir, "RPMS")
         self.srpmsdir = os.path.join(self.topdir, "SRPMS")
         self.builddir = os.path.join(self.topdir, "BUILD")
 
         # And creating them if needed
-        for d in [
-                self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir,
-                self.builddir
-        ]:
+        for d in [self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir, self.builddir]:
             if not os.path.exists(d):
                 os.makedirs(d)
 
         self.buildroot = os.path.join(self.tmpdir, "%s-buildroot" % buildname)
 
         if not os.path.exists(self.buildroot):
             os.makedirs(self.buildroot)
 
     def main(self):
-        '''
+        """
         Main method for the script
-        '''
+        """
         if len(self.args) != 1:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         # Extracting info from filename
         filename = self.args[0]
         self.log.warning("Processing file %s" % filename)
-        (_absFilename, buildlocation, _fprojectVersion,
-         _fcmtconfig) = getBuildInfo(filename)
+        (_absFilename, buildlocation, _fprojectVersion, _fcmtconfig) = getBuildInfo(
+            filename
+        )
 
         # Parsing the XML itself
         from LbTools.Manifest import Parser
+
         manifest = Parser(filename)
 
         (project, version) = manifest.getProject()
         (_LCGVerson, cmtconfig, _packages) = manifest.getHEPTools()
         (lcg_platform, lcg_system) = manifest.getLCGConfig()
 
         buildarea = self.options.buildarea
-        self.createBuildDirs(buildarea,
-                             project + "_" + version + "_" + cmtconfig)
+        self.createBuildDirs(buildarea, project + "_" + version + "_" + cmtconfig)
         if self.options.shared:
-            spec = LHCbSharedRpmSpec(project, version, self.options.sharedTar,
-                                     buildarea)
+            spec = LHCbSharedRpmSpec(
+                project, version, self.options.sharedTar, buildarea
+            )
         elif self.options.glimpse:
-            spec = LHCbGlimpseRpmSpec(project, version, self.options.sharedTar,
-                                      buildarea, manifest)
+            spec = LHCbGlimpseRpmSpec(
+                project, version, self.options.sharedTar, buildarea, manifest
+            )
         else:
-            spec = LHCbBinaryRpmSpec(project, version, cmtconfig, buildarea,
-                                     buildlocation, manifest)
+            spec = LHCbBinaryRpmSpec(
+                project, version, cmtconfig, buildarea, buildlocation, manifest
+            )
 
         if self.options.output:
             with open(self.options.output, "w") as outputfile:
                 outputfile.write(spec.getSpec())
         else:
-            print spec.getSpec()
+            print(spec.getSpec())
```

### Comparing `LbNightlyTools-3.0.9/python/LbRPMTools/LHCbCompatSpecBuilder.py` & `LbNightlyTools-4.0.0/python/LbRPMTools/LHCbCompatSpecBuilder.py`

 * *Files 7% similar despite different names*

```diff
@@ -4,45 +4,47 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Class to generate RPM Spec for LHCb Compat
 
 Created on Feb 27, 2014
 
 @author: Ben Couturier
-'''
+"""
+from __future__ import absolute_import, print_function
 
+import logging
 import os
 import re
 import sys
-import logging
 from string import Template
-from subprocess import Popen, PIPE
+from subprocess import PIPE, Popen
+
+from .LHCbRPMSpecBuilder import LHCbBaseRpmSpec
 
-from LHCbRPMSpecBuilder import LHCbBaseRpmSpec
 try:
     from LbCommon.Temporary import TempDir
 except:
     from LbUtils.Temporary import TempDir
 
 tmpdir = TempDir(prefix="LHCbCompatRpmSpec")
 PREFIX = "/opt/LHCbSoft"
 
 __log__ = logging.getLogger(__name__)
 
 
 def parseVersion(version):
-    '''
+    """
     Parse the version string
-    '''
+    """
     maj_version = 1
     min_version = 0
     patch_version = 0
 
     m = re.match("v([\d]+)r([\d]+)$", version)
     if m != None:
         maj_version = m.group(1)
@@ -51,59 +53,66 @@
         # Checking whether the version matches vXrYpZ in that case
         m = re.match("v([\d]+)r([\d]+)p([\d]+)", version)
         if m != None:
             maj_version = m.group(1)
             min_version = m.group(2)
             patch_version = m.group(3)
         else:
-            raise Exception(
-                "Version %s does not match format vXrY or vXrYpZ" % version)
+            raise Exception("Version %s does not match format vXrY or vXrYpZ" % version)
 
     return (maj_version, min_version, patch_version)
 
 
 #
 # Spec for binary RPMs
 #
 ###############################################################################
 class LHCbLbScriptsRpmSpec(LHCbBaseRpmSpec):
-    """ Class representing a LHCb project"""
+    """Class representing a LHCb project"""
 
     def __init__(self, project, version, buildarea, releasedir):
-        """ Constructor taking the actual file name """
+        """Constructor taking the actual file name"""
         super(LHCbLbScriptsRpmSpec, self).__init__(project, version)
         __log__.debug("Creating RPM for %s/%s" % (project, version))
         self._project = project
         self._version = version
         self._buildarea = buildarea
-        (self._lhcb_maj_version, self._lhcb_min_version,
-         self._lhcb_patch_version) = parseVersion(version)
+        (
+            self._lhcb_maj_version,
+            self._lhcb_min_version,
+            self._lhcb_patch_version,
+        ) = parseVersion(version)
         self._lhcb_release_version = 0
         self._releasedir = releasedir
 
     def getRPMName(self, norelease=False):
-        ''' Return the architecture, always noarch for our packages'''
+        """Return the architecture, always noarch for our packages"""
         projname = "_".join([self._project.upper(), self._version])
-        projver = ".".join([
-            str(n) for n in [
-                self._lhcb_maj_version, self._lhcb_min_version, self.
-                _lhcb_patch_version
+        projver = ".".join(
+            [
+                str(n)
+                for n in [
+                    self._lhcb_maj_version,
+                    self._lhcb_min_version,
+                    self._lhcb_patch_version,
+                ]
             ]
-        ])
+        )
         if norelease:
             return "-".join([projname, projver])
         full = "-".join([projname, projver, str(self._lhcb_release_version)])
         final = ".".join([full, self._arch, "rpm"])
         return final
 
     def _createHeader(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        header = Template("""
+        """
+        header = Template(
+            """
 %define lhcb_maj_version ${lhcb_maj_version}
 %define lhcb_min_version ${lhcb_min_version}
 %define lhcb_patch_version ${lhcb_patch_version}
 %define lhcb_release_version ${lhcb_release_version}
 %define buildarea ${buildarea}
 %define project ${project}
 %define projectUp ${projectUp}
@@ -130,48 +139,50 @@
 AutoReqProv: no
 Prefix: %{prefix}
 Provides: /bin/sh
 Provides: /bin/bash
 
 Provides: %{projectUp} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 Provides: %{projectUp}_v%{lhcb_maj_version} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
-        \n""").substitute(
+        \n"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             projectUp=self._project.upper(),
             version=self._version,
             lhcb_maj_version=self._lhcb_maj_version,
             lhcb_min_version=self._lhcb_min_version,
             lhcb_patch_version=self._lhcb_patch_version,
             lhcb_release_version=self._lhcb_release_version,
             prefix=PREFIX,
-            releasedir=self._releasedir)
+            releasedir=self._releasedir,
+        )
 
         return header
 
     def _createRequires(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         return ""
 
     def _createDescription(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = "%description\n"
         tmp += "%{fullname} %{version}\n\n"
         return tmp
 
     def _createInstall(self):
-        '''
+        """
         Prepare the Install section of the RPM
-        '''
+        """
         spec = "%install\n"
-        spec += '''
+        spec += """
 
 [ -d ${RPM_BUILD_ROOT} ] && rm -rf ${RPM_BUILD_ROOT}
 
 mkdir -p ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}/%{projectUp}_%{lbversion}
 
 if [ $? -ne 0 ]; then
   exit $?
@@ -180,22 +191,22 @@
 rsync -avrz %{releasedir}/%{projectUp}/%{projectUp}_%{lbversion} ${RPM_BUILD_ROOT}/opt/LHCbSoft/lhcb/%{projectUp}
 
 if [ $? -ne 0 ]; then
   exit $?
 fi
 
 
-        '''
+        """
         return spec
 
     def _createTrailer(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        trailer = '''
+        """
+        trailer = """
 %clean
 
 %post -p /bin/bash
 
 if [ "$MYSITEROOT" ]; then
 PREFIX=$MYSITEROOT
 else
@@ -230,106 +241,106 @@
 %define date    %(echo `LC_ALL=\"C\" date +\"%a %b %d %Y\"`)
 
 %changelog
 
 * %{date} User <ben.couturier..rcern.ch>
 - first Version
 
-        '''
+        """
 
         return trailer
 
 
 #
 # Main Script to generate the spec file
 #
 ###############################################################################
 from LbNightlyTools.Scripts.Common import PlainScript
 
 
 class Script(PlainScript):
-    '''
+    """
     Script to generate the Spec file for the LHCb Compat project.
-    '''
-    __usage__ = '''%prog [options] compat_version
+    """
+
+    __usage__ = """%prog [options] compat_version
 
 e.g. %prog v1r19 -o tmp.spec
 
 The spec can then be built with:
 QA_RPATHS=0x003 rpmbuild -bb tmp.spec
 
-'''
-    __version__ = ''
+"""
+    __version__ = ""
 
     def addBasicOptions(self, parser):
-        '''
+        """
         Add some basic (common) options to the option parser
-        '''
+        """
         parser.add_option(
-            '-b',
-            '--buildarea',
+            "-b",
+            "--buildarea",
             dest="buildarea",
             default="/tmp",
             action="store",
-            help="Force build root")
+            help="Force build root",
+        )
         parser.add_option(
-            '-o',
-            '--output',
+            "-o",
+            "--output",
             dest="output",
             default=None,
             action="store",
-            help=
-            "File name for the generated specfile [default output to stdout]")
+            help="File name for the generated specfile [default output to stdout]",
+        )
         parser.add_option(
-            '-e',
-            '--releasedir',
+            "-e",
+            "--releasedir",
             dest="releasedir",
             default=os.environ["LHCBRELEASES"],
             action="store",
-            help="LHCb Releases area")
+            help="LHCb Releases area",
+        )
 
         return parser
 
     def defineOpts(self):
-        '''
+        """
         Prepare the option parser.
-        '''
+        """
         self.addBasicOptions(self.parser)
 
     def createBuildDirs(self, buildarea, buildname):
-        '''
+        """
         Create directories necessary to the build
-        '''
+        """
         self.topdir = "%s/rpmbuild" % buildarea
         self.tmpdir = "%s/tmpbuild" % buildarea
         self.rpmtmp = "%s/tmp" % buildarea
         self.srcdir = os.path.join(self.topdir, "SOURCES")
         self.rpmsdir = os.path.join(self.topdir, "RPMS")
         self.srpmsdir = os.path.join(self.topdir, "SRPMS")
         self.builddir = os.path.join(self.topdir, "BUILD")
 
         # And creating them if needed
-        for d in [
-                self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir,
-                self.builddir
-        ]:
+        for d in [self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir, self.builddir]:
             if not os.path.exists(d):
                 os.makedirs(d)
 
         self.buildroot = os.path.join(self.tmpdir, "%s-buildroot" % buildname)
 
         if not os.path.exists(self.buildroot):
             os.makedirs(self.buildroot)
 
     def main(self):
-        '''
+        """
         Main method for the script
-        '''
+        """
         if len(self.args) != 1:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         # Extracting info from filename
         project = "Compat"
         version = self.args[0]
 
         self.log.warning("Packaging Compat %s" % version)
 
@@ -339,8 +350,8 @@
 
         spec = LHCbLbScriptsRpmSpec(project, version, buildarea, releasedir)
 
         if self.options.output:
             with open(self.options.output, "w") as outputfile:
                 outputfile.write(spec.getSpec())
         else:
-            print spec.getSpec()
+            print(spec.getSpec())
```

### Comparing `LbNightlyTools-3.0.9/python/LbRPMTools/LHCbGenericSpecBuilder.py` & `LbNightlyTools-4.0.0/python/LbRPMTools/LHCbGenericSpecBuilder.py`

 * *Files 9% similar despite different names*

```diff
@@ -4,30 +4,32 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Class to generate RPM Spec for generic packages
 
 Created on Sep 25, 2015
 
 @author: Ben Couturier
-'''
+"""
+from __future__ import absolute_import, print_function
 
+import logging
 import os
 import re
 import sys
-import logging
 from string import Template
-from subprocess import Popen, PIPE
+from subprocess import PIPE, Popen
+
+from .LHCbRPMSpecBuilder import LHCbBaseRpmSpec
 
-from LHCbRPMSpecBuilder import LHCbBaseRpmSpec
 try:
     from LbCommon.Temporary import TempDir
 except:
     from LbUtils.Temporary import TempDir
 
 tmpdir = TempDir(prefix="LHCbGenericRpmSpec")
 
@@ -35,60 +37,53 @@
 
 
 #
 # Spec for binary RPMs
 #
 ###############################################################################
 class LHCbGenericRpmSpec(LHCbBaseRpmSpec):
-    """ Class representing a LHCb project"""
+    """Class representing a LHCb project"""
 
-    def __init__(self,
-                 project,
-                 version,
-                 giturl,
-                 requires,
-                 buildarea,
-                 release=None):
-        """ Constructor taking the actual file name """
+    def __init__(self, project, version, giturl, requires, buildarea, release=None):
+        """Constructor taking the actual file name"""
         super(LHCbGenericRpmSpec, self).__init__(project, version)
         __log__.debug("Creating RPM for %s/%s" % (project, version))
 
         self._project = project
         self._version = version
         self._giturl = giturl
         self._lhcb_release_version = release
         self._buildarea = buildarea
         self._requires = requires
         self._arch = "noarch"
         self._postinstall = None
         self._srcroot = None
 
     def setsrcroot(self, srcroot):
-        ''' Set the dir to use as top of the rpm content '''
+        """Set the dir to use as top of the rpm content"""
         self._srcroot = srcroot
 
     def setpostinstall(self, postinstall):
-        ''' Set the post install script to call '''
+        """Set the post install script to call"""
         self._postinstall = postinstall
 
     def getRPMName(self, norelease=False):
-        ''' Return the architecture, always noarch for our packages'''
+        """Return the architecture, always noarch for our packages"""
         if norelease:
             return "-".join([self._project, self._version])
-        full = "-".join(
-            [self._project, self._version,
-             str(self._lhcb_release_version)])
+        full = "-".join([self._project, self._version, str(self._lhcb_release_version)])
         final = ".".join([full, self._arch, "rpm"])
         return final
 
     def _createHeader(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        header = Template("""
+        """
+        header = Template(
+            """
 %define buildarea ${buildarea}
 %define project ${project}
 %define version ${version}
 %define release ${release}
 %define arch    ${arch}
 %define giturl  ${giturl}
 
@@ -109,107 +104,114 @@
 BuildArch: %{arch}
 AutoReqProv: no
 Prefix: /opt/LHCbSoft
 Provides: /bin/sh
 Provides: /bin/bash
 Provides: %{project} = %{version}
 
-\n""").substitute(
+\n"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             version=self._version,
             release=self._lhcb_release_version,
             arch=self._arch,
-            giturl=self._giturl)
+            giturl=self._giturl,
+        )
         return header
 
     def _createRequires(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = ""
         for r in self._requires:
-
             tmp += "Requires: %s\n" % r
 
         return tmp
 
     def _createDescription(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = "%description\n"
         tmp += "%{project}\n\n"
         return tmp
 
     def _createInstall(self):
-        '''
+        """
         Prepare the Install section of the RPM
-        '''
+        """
         spec = "%install\n"
         spec += """
 
 [ -d ${RPM_BUILD_ROOT} ] && rm -rf ${RPM_BUILD_ROOT}
 
 mkdir -p ${RPM_BUILD_ROOT}/opt/LHCbSoft
 """
         if self._srcroot != None:
-            spec += Template("""
+            spec += Template(
+                """
 if [ -z $${TMPDIR} ]; then
   cd /tmp
 else
   cd $${TMPDIR}
 fi
 git clone --branch %{version} %{giturl}
 cp -r %{project}/${srcroot}/* $${RPM_BUILD_ROOT}/opt/LHCbSoft
 
-""").substitute(srcroot=self._srcroot)
+"""
+            ).substitute(srcroot=self._srcroot)
         else:
             spec += """
 cd  ${RPM_BUILD_ROOT}/opt/LHCbSoft
 git clone --branch %{version} %{giturl}
 
 """
         spec += "\n\n"
         return spec
 
     def _createTrailer(self):
-        '''
+        """
         Prepare the RPM header
-        '''
+        """
 
         # Prepare the files list
         if self._srcroot != None:
             import os
+
             trailer = """
 %files
 %defattr(-,root,root)
 %{prefix}/*
 """
         else:
             trailer = """
 %files
 %defattr(-,root,root)
 %{prefix}/%{project}
 """
 
         # Adding the post install script if requested
         if self._postinstall != None:
-            trailer += '''
+            trailer += (
+                """
 %%post -p /bin/bash
 
 if [ "${MYSITEROOT}" ]; then
 PREFIX=${MYSITEROOT}
 else
 PREFIX=%%{prefix}
 fi
 
 ${MYSITEROOT}/%s
 
-''' % self._postinstall
+"""
+                % self._postinstall
+            )
         else:
             trailer += """
 %post
 """
 
         trailer += """
 %postun
@@ -231,140 +233,142 @@
 # Main Script to generate the spec file
 #
 ###############################################################################
 from LbNightlyTools.Scripts.Common import PlainScript
 
 
 class GenericScript(PlainScript):
-    '''
+    """
     Script to generate the Spec file for an LHCb project.
-    '''
-    __usage__ = '''%prog [options] rpmname rpmversion requirement1 requirement2 [...]
+    """
+
+    __usage__ = """%prog [options] rpmname rpmversion requirement1 requirement2 [...]
 
-e.g. %prog -o tmp.spec LbEnv 1.0.0 ssh://git@gitlab.cern.ch:7999/lhcb-core/LbEnv.git LBSCRIPTS_v8r4p2'''
-    __version__ = ''
+e.g. %prog -o tmp.spec LbEnv 1.0.0 ssh://git@gitlab.cern.ch:7999/lhcb-core/LbEnv.git LBSCRIPTS_v8r4p2"""
+    __version__ = ""
 
     def addBasicOptions(self, parser):
-        '''
+        """
         Add some basic (common) options to the option parser
-        '''
+        """
         parser.add_option(
-            '-v',
-            '--version',
+            "-v",
+            "--version",
             dest="version",
             default=None,
             action="store",
-            help="Force LCG version")
+            help="Force LCG version",
+        )
         parser.add_option(
-            '-p',
-            '--platform',
+            "-p",
+            "--platform",
             dest="platform",
             default=None,
             action="store",
-            help="Force platform")
+            help="Force platform",
+        )
         parser.add_option(
-            '-n',
-            '--name',
+            "-n",
+            "--name",
             dest="name",
             default=None,
             action="store",
-            help="Force the name of the RPM generated")
+            help="Force the name of the RPM generated",
+        )
         parser.add_option(
-            '-b',
-            '--buildarea',
+            "-b",
+            "--buildarea",
             dest="buildarea",
             default="/tmp",
             action="store",
-            help="Force build root")
+            help="Force build root",
+        )
         parser.add_option(
-            '-o',
-            '--output',
+            "-o",
+            "--output",
             dest="output",
             default=None,
             action="store",
-            help=
-            "File name for the generated specfile [default output to stdout]")
+            help="File name for the generated specfile [default output to stdout]",
+        )
         parser.add_option(
-            '--srcroot',
+            "--srcroot",
             dest="srcroot",
             default=None,
             action="store",
-            help=
-            "Subdirectory of the git package to use as a root for the installation"
+            help="Subdirectory of the git package to use as a root for the installation",
         )
         parser.add_option(
-            '--post-install',
+            "--post-install",
             dest="postinstall",
             default=None,
             action="store",
-            help="Script to include as post install for the RPM")
+            help="Script to include as post install for the RPM",
+        )
 
         return parser
 
     def defineOpts(self):
-        '''
+        """
         Prepare the option parser.
-        '''
+        """
         self.addBasicOptions(self.parser)
 
     def createBuildDirs(self, buildarea, buildname):
-        '''
+        """
         Create directories necessary to the build
-        '''
+        """
         self.topdir = "%s/rpmbuild" % buildarea
         self.tmpdir = "%s/tmpbuild" % buildarea
         self.rpmtmp = "%s/tmp" % buildarea
         self.srcdir = os.path.join(self.topdir, "SOURCES")
         self.rpmsdir = os.path.join(self.topdir, "RPMS")
         self.srpmsdir = os.path.join(self.topdir, "SRPMS")
         self.builddir = os.path.join(self.topdir, "BUILD")
 
         # And creating them if needed
-        for d in [
-                self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir,
-                self.builddir
-        ]:
+        for d in [self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir, self.builddir]:
             if not os.path.exists(d):
                 os.makedirs(d)
 
         self.buildroot = os.path.join(self.tmpdir, "%s-buildroot" % buildname)
 
         if not os.path.exists(self.buildroot):
             os.makedirs(self.buildroot)
 
     def main(self):
-        '''
+        """
         Main method for the script
-        '''
+        """
         if len(self.args) < 2:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         # Extracting info from filename
         project = self.args[0]
         version = self.args[1]
         giturl = self.args[2]
 
         requires = self.args[3:]
 
-        self.log.warning("Generating Generic RPM for %s %s - source: %s" %
-                         (project, version, giturl))
+        self.log.warning(
+            "Generating Generic RPM for %s %s - source: %s" % (project, version, giturl)
+        )
 
         buildarea = self.options.buildarea
         self.createBuildDirs(buildarea, project + "_" + version)
 
         specname = project
         if self.options.name != None:
             specname = self.options.name
 
-        spec = LHCbGenericRpmSpec(specname, version, giturl, requires,
-                                  buildarea)
+        spec = LHCbGenericRpmSpec(specname, version, giturl, requires, buildarea)
         if self.options.srcroot != None:
             spec.setsrcroot(self.options.srcroot)
 
         if self.options.postinstall != None:
             spec.setpostinstall(self.options.postinstall)
 
         if self.options.output:
             with open(self.options.output, "w") as outputfile:
                 outputfile.write(spec.getSpec())
         else:
-            print spec.getSpec()
+            print(spec.getSpec())
```

### Comparing `LbNightlyTools-3.0.9/python/LbRPMTools/LHCbMetaSpecBuilder.py` & `LbNightlyTools-4.0.0/python/LbRPMTools/LHCbMetaSpecBuilder.py`

 * *Files 12% similar despite different names*

```diff
@@ -4,31 +4,33 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Class to generate RPM Spec for metadapackages that require all the needed packages from
 externals.
 
 Created on Feb 27, 2014
 
 @author: Ben Couturier
-'''
+"""
+from __future__ import absolute_import, print_function
 
+import logging
 import os
 import re
 import sys
-import logging
 from string import Template
-from subprocess import Popen, PIPE
+from subprocess import PIPE, Popen
+
+from .LHCbRPMSpecBuilder import LHCbBaseRpmSpec
 
-from LHCbRPMSpecBuilder import LHCbBaseRpmSpec
 try:
     from LbCommon.Temporary import TempDir
 except:
     from LbUtils.Temporary import TempDir
 
 tmpdir = TempDir(prefix="LHCbMetaRpmSpec")
 
@@ -36,43 +38,42 @@
 
 
 #
 # Spec for binary RPMs
 #
 ###############################################################################
 class LHCbMetaRpmSpec(LHCbBaseRpmSpec):
-    """ Class representing a LHCb project"""
+    """Class representing a LHCb project"""
 
     def __init__(self, project, version, requires, buildarea, release=None):
-        """ Constructor taking the actual file name """
+        """Constructor taking the actual file name"""
         super(LHCbMetaRpmSpec, self).__init__(project, version)
         __log__.debug("Creating RPM for %s/%s" % (project, version))
 
         self._project = project
         self._version = version
         self._lhcb_release_version = release
         self._buildarea = buildarea
         self._requires = requires
         self._arch = "noarch"
 
     def getRPMName(self, norelease=False):
-        ''' Return the architecture, always noarch for our packages'''
+        """Return the architecture, always noarch for our packages"""
         if norelease:
             return "-".join([self._project, self._version])
-        full = "-".join(
-            [self._project, self._version,
-             str(self._lhcb_release_version)])
+        full = "-".join([self._project, self._version, str(self._lhcb_release_version)])
         final = ".".join([full, self._arch, "rpm"])
         return final
 
     def _createHeader(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        header = Template("""
+        """
+        header = Template(
+            """
 %define buildarea ${buildarea}
 %define project ${project}
 %define version ${version}
 %define release ${release}
 %define arch    ${arch}
 
 %global __os_install_post /usr/lib/rpm/check-buildroot
@@ -91,195 +92,199 @@
 BuildRoot: %{tmpdir}/%{name}-buildroot
 BuildArch: %{arch}
 AutoReqProv: no
 Prefix: /opt/LHCbSoft
 Provides: /bin/sh
 Provides: %{project} = %{version}
 
-\n""").substitute(
+\n"""
+        ).substitute(
             buildarea=self._buildarea,
             project=self._project,
             version=self._version,
             release=self._lhcb_release_version,
-            arch=self._arch)
+            arch=self._arch,
+        )
         return header
 
     def _createRequires(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = ""
         for r in self._requires:
-
             tmp += "Requires: %s\n" % r
 
         return tmp
 
     def _createDescription(self):
-        '''
+        """
         Prepare the Requires section of the RPM
-        '''
+        """
         tmp = "%description\n"
         tmp += "%{project}\n\n"
         return tmp
 
     def _createInstall(self):
-        '''
+        """
         Prepare the Install section of the RPM
-        '''
+        """
         spec = "%install\n"
         spec += "\n\n"
         return spec
 
     def _createTrailer(self):
-        '''
+        """
         Prepare the RPM header
-        '''
-        trailer = Template("""
+        """
+        trailer = Template(
+            """
 %files
 
 %post
 
 %postun
 
 %clean
 
 %define date    %(echo `LC_ALL=\"C\" date +\"%a %b %d %Y\"`)
 
 %changelog
 
 * %{date} User <ben.couturier..rcern.ch>
 - first Version
-""").substitute(buildarea=self._buildarea)
+"""
+        ).substitute(buildarea=self._buildarea)
 
         return trailer
 
 
 #
 # Main Script to generate the spec file
 #
 ###############################################################################
 from LbNightlyTools.Scripts.Common import PlainScript
 
 
 class MetaScript(PlainScript):
-    '''
+    """
     Script to generate the Spec file for an LHCb project.
-    '''
-    __usage__ = '''%prog [options] rpmname rpmversion requirement1 requirement2 [...]
+    """
+
+    __usage__ = """%prog [options] rpmname rpmversion requirement1 requirement2 [...]
 
-e.g. %prog -o tmp.spec OnlineFarmMeta 1.0.0 MOOREONLINE_v23r4_x86_64_slc6_gcc48_opt ALIGNMENTONLINE_v10r2_x86_64_slc6_gcc48_opt'''
-    __version__ = ''
+e.g. %prog -o tmp.spec OnlineFarmMeta 1.0.0 MOOREONLINE_v23r4_x86_64_slc6_gcc48_opt ALIGNMENTONLINE_v10r2_x86_64_slc6_gcc48_opt"""
+    __version__ = ""
 
     def addBasicOptions(self, parser):
-        '''
+        """
         Add some basic (common) options to the option parser
-        '''
+        """
         parser.add_option(
-            '-v',
-            '--version',
+            "-v",
+            "--version",
             dest="version",
             default=None,
             action="store",
-            help="Force LCG version")
+            help="Force LCG version",
+        )
         parser.add_option(
-            '-p',
-            '--platform',
+            "-p",
+            "--platform",
             dest="platform",
             default=None,
             action="store",
-            help="Force platform")
+            help="Force platform",
+        )
         parser.add_option(
-            '-n',
-            '--name',
+            "-n",
+            "--name",
             dest="name",
             default=None,
             action="store",
-            help="Force the name of the RPM generated")
+            help="Force the name of the RPM generated",
+        )
         parser.add_option(
-            '-b',
-            '--buildarea',
+            "-b",
+            "--buildarea",
             dest="buildarea",
             default="/tmp",
             action="store",
-            help="Force build root")
+            help="Force build root",
+        )
         parser.add_option(
-            '-o',
-            '--output',
+            "-o",
+            "--output",
             dest="output",
             default=None,
             action="store",
-            help=
-            "File name for the generated specfile [default output to stdout]")
+            help="File name for the generated specfile [default output to stdout]",
+        )
         parser.add_option(
-            '-t',
-            '--fromtag',
+            "-t",
+            "--fromtag",
             dest="tag",
             default=None,
             action="store",
-            help=
-            "Take the project versions tagged as specified in the conf DB (instead of command line)"
+            help="Take the project versions tagged as specified in the conf DB (instead of command line)",
         )
 
         return parser
 
     def defineOpts(self):
-        '''
+        """
         Prepare the option parser.
-        '''
+        """
         self.addBasicOptions(self.parser)
 
     def createBuildDirs(self, buildarea, buildname):
-        '''
+        """
         Create directories necessary to the build
-        '''
+        """
         self.topdir = "%s/rpmbuild" % buildarea
         self.tmpdir = "%s/tmpbuild" % buildarea
         self.rpmtmp = "%s/tmp" % buildarea
         self.srcdir = os.path.join(self.topdir, "SOURCES")
         self.rpmsdir = os.path.join(self.topdir, "RPMS")
         self.srpmsdir = os.path.join(self.topdir, "SRPMS")
         self.builddir = os.path.join(self.topdir, "BUILD")
 
         # And creating them if needed
-        for d in [
-                self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir,
-                self.builddir
-        ]:
+        for d in [self.rpmtmp, self.srcdir, self.rpmsdir, self.srpmsdir, self.builddir]:
             if not os.path.exists(d):
                 os.makedirs(d)
 
         self.buildroot = os.path.join(self.tmpdir, "%s-buildroot" % buildname)
 
         if not os.path.exists(self.buildroot):
             os.makedirs(self.buildroot)
 
     def main(self):
-        '''
+        """
         Main method for the script
-        '''
+        """
         if len(self.args) < 2:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         # Extracting info from filename
         project = self.args[0]
         version = self.args[1]
 
         if self.options.tag:
             try:
                 from LbSoftConfDb2Clients.GenericClient import LbSoftConfDbBase
+
                 generic_client = LbSoftConfDbBase()
                 db = generic_client.getROInterface()
                 projects = db.listTag(self.options.tag.upper())
                 requires = []
-                for (p, v, f) in projects:
-                    requires.append("_".join(
-                        [p.upper(), v, f.replace("-", "_")]))
+                for p, v, f in projects:
+                    requires.append("_".join([p.upper(), v, f.replace("-", "_")]))
             except:
-                print "Could not access SoftConfDB, exiting"
+                print("Could not access SoftConfDB, exiting")
                 return 2
         else:
             requires = self.args[2:]
 
         self.log.warning("Generating Meta RPM for %s %s" % (project, version))
 
         buildarea = self.options.buildarea
@@ -290,8 +295,8 @@
             specname = self.options.name
         spec = LHCbMetaRpmSpec(specname, version, requires, buildarea)
 
         if self.options.output:
             with open(self.options.output, "w") as outputfile:
                 outputfile.write(spec.getSpec())
         else:
-            print spec.getSpec()
+            print(spec.getSpec())
```

### Comparing `LbNightlyTools-3.0.9/python/LbRPMTools/PackageSlot.py` & `LbNightlyTools-4.0.0/python/LbRPMTools/PackageSlot.py`

 * *Files 15% similar despite different names*

```diff
@@ -4,238 +4,281 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Class to generate RPM packages for a whole slot
 
 Created on Feb 27, 2014
 
 @author: Ben Couturier
-'''
+"""
+from __future__ import absolute_import
 
-import os
 import logging
+import os
 import shutil
 
 __log__ = logging.getLogger(__name__)
 
 # Main Script to generate the RPMs for a build slot
 #
 ###############################################################################
 from LbNightlyTools.Scripts.Common import PlainScript
 
 
 class Script(PlainScript):
-    '''
+    """
     Script to produce the RPM for a LHCb Nightly slot.
-    '''
-    __usage__ = '%prog [options] <slot_config.json>'
-    __version__ = ''
+    """
+
+    __usage__ = "%prog [options] <slot_config.json>"
+    __version__ = ""
 
     def addRpmOptions(self, parser):
-        '''
+        """
         Add some basic (common) options to the option parser
-        '''
+        """
         from optparse import OptionGroup
+
         group = OptionGroup(self.parser, "RPM Options")
         group.add_option(
-            '-p',
-            '--platform',
+            "-p",
+            "--platform",
             dest="platform",
             default=None,
             action="store",
-            help="Force platform")
+            help="Force platform",
+        )
         group.add_option(
-            '-s',
-            '--shared',
+            "-s",
+            "--shared",
             dest="shared",
             default=False,
             action="store_true",
-            help="Build shared RPM")
+            help="Build shared RPM",
+        )
         group.add_option(
-            '-g',
-            '--glimpse',
+            "-g",
+            "--glimpse",
             dest="glimpse",
             default=False,
             action="store_true",
-            help="Build glimpse RPM")
+            help="Build glimpse RPM",
+        )
         group.add_option(
-            '--shared-tar',
+            "--shared-tar",
             dest="sharedTar",
             default=None,
             action="store",
-            help="Shared tar to be included")
+            help="Shared tar to be included",
+        )
         group.add_option(
-            '--builddir',
+            "--builddir",
             dest="builddir",
             default=None,
             action="store",
-            help=
-            "Force LCG dir if different from the one containing the config file"
+            help="Force LCG dir if different from the one containing the config file",
         )
         group.add_option(
-            '-b',
-            '--buildarea',
+            "-b",
+            "--buildarea",
             dest="buildarea",
             default="/tmp",
             action="store",
-            help="Force build root")
+            help="Force build root",
+        )
         group.add_option(
-            '-o',
-            '--output',
+            "-o",
+            "--output",
             dest="output",
             default=None,
             action="store",
-            help=
-            "File name for the generated specfile [default output to stdout]")
+            help="File name for the generated specfile [default output to stdout]",
+        )
         group.add_option(
-            '--keep-rpmdir',
-            dest='keeprpmdir',
+            "--keep-rpmdir",
+            dest="keeprpmdir",
             action="store_true",
             default=False,
-            help="Keep the directories used to build the RPMs")
+            help="Keep the directories used to build the RPMs",
+        )
         group.add_option(
-            '--dry-run',
-            dest='dryrun',
+            "--dry-run",
+            dest="dryrun",
             action="store_true",
             default=False,
-            help="Only prepare the spec, not the RPMs")
+            help="Only prepare the spec, not the RPMs",
+        )
         group.add_option(
-            '--manifest',
+            "--manifest",
             dest="manifestfile",
             default=None,
             action="store",
-            help="Force the manifest file to be used")
+            help="Force the manifest file to be used",
+        )
         group.add_option(
-            '--rpmreldir',
+            "--rpmreldir",
             dest="rpmreldir",
             default=None,
             action="store",
-            help="Specify the RPM release directory")
-
+            help="Specify the RPM release directory",
+        )
+        group.add_option(
+            "--checkrelease",
+            dest="checkrelease",
+            default=False,
+            action="store_true",
+            help="Check the RPM repository to check whether the release number should be incremented",
+        )
         parser.add_option_group(group)
         return parser
 
     def defineOpts(self):
-        '''
+        """
         Prepare the option parser.
-        '''
+        """
         from LbNightlyTools.Scripts.Common import addBasicOptions
 
         addBasicOptions(self.parser)
         self.parser.add_option(
-            '--flavour',
-            default='nightly',
-            help='nightly builds flavour '
-            '[default: %default]')
+            "--flavour",
+            default="nightly",
+            help="nightly builds flavour " "[default: %default]",
+        )
         self.addRpmOptions(self.parser)
 
     def _createRpmDirs(self, buildarea, buildname):
-        '''
+        """
         Create directories necessary to the build
-        '''
-        from LHCbRPMSpecBuilder import RpmDirConfig
+        """
+        from .LHCbRPMSpecBuilder import RpmDirConfig
+
         return RpmDirConfig(buildarea, buildname)
 
     def _callRpmbuild(self, specfilename, fullrpmpath, artifactdir):
-        ''' Call the rpmbuild command itself '''
+        """Call the rpmbuild command itself"""
 
-        rpmsdir = os.path.join(artifactdir, 'rpms')
+        rpmsdir = os.path.join(artifactdir, "rpms")
         if self.options.dryrun:
             self.log.warning(
-                "Dry run mode, not calling RPM build for %s" % specfilename)
+                "Dry run mode, not calling RPM build for %s" % specfilename
+            )
             shutil.copy(specfilename, rpmsdir)
             self.log.warning("Dry run mode, spec file copied to %s" % rpmsdir)
             return
 
         # Now calling the rpmbuild command
-        from subprocess import Popen, PIPE
-        process = Popen(["rpmbuild", "-bb", specfilename],
-                        stdout=PIPE,
-                        stderr=PIPE)
+        from subprocess import PIPE, Popen
+
+        myenv = os.environ.copy()
+        myenv["QA_RPATHS"] = "0x0002"
+        process = Popen(
+            ["rpmbuild", "-bb", specfilename], stdout=PIPE, stderr=PIPE, env=myenv
+        )
 
         (stdout, stderr) = process.communicate()
         # XXX Careful we should not be caching the stdout and stderr
-        self.log.info(stdout)
-        self.log.info(stderr)
+        self.log.info(stdout.decode("utf-8", errors="replace"))
+        self.log.info(stderr.decode("utf-8", errors="replace"))
 
         if not os.path.exists(fullrpmpath):
             self.log.error("Cannot find RPM: %s" % fullrpmpath)
             raise Exception("Cannot find RPM: %s" % fullrpmpath)
         else:
             self.log.info("Copying %s to %s" % (fullrpmpath, rpmsdir))
             shutil.copy(fullrpmpath, rpmsdir)
 
     def _getManifestFilename(self, builddir, project, version, platform):
-
         # Checking if the file was overriden (needed fro tests)
         if self.options.manifestfile != None:
-            self.log.info("Using manifest.xml filename overriden to: %s" %
-                          self.options.manifestfile)
+            self.log.info(
+                "Using manifest.xml filename overriden to: %s"
+                % self.options.manifestfile
+            )
             return self.options.manifestfile
 
         # Checking for the existence of the manifest.xml file
-        projbuilddir = os.path.join(builddir, project.upper(),
-                                    project.upper() + "_" + version)
+        projbuilddir = os.path.join(
+            builddir, project.upper(), project.upper() + "_" + version
+        )
         if platform != None:
-            manifestxmlfile = os.path.join(projbuilddir, 'InstallArea',
-                                           platform, 'manifest.xml')
+            manifestxmlfile = os.path.join(
+                projbuilddir, "InstallArea", platform, "manifest.xml"
+            )
         else:
-            manifestxmlfile = os.path.join(projbuilddir, 'manifest.xml')
+            manifestxmlfile = os.path.join(projbuilddir, "manifest.xml")
 
         if not os.path.exists(manifestxmlfile):
             self.log.error("Missing manifest.xml file: %s" % manifestxmlfile)
             raise Exception("Missing manifest.xml file: %s" % manifestxmlfile)
         else:
             self.log.info("Using manifest.xml file: %s" % manifestxmlfile)
         return manifestxmlfile
 
-    def _buildRpm(self, project, version, platform, rpmbuildarea, builddir,
-                  artifactdir, keeprpmdir):
-        ''' Build the RPM for the project them and copy them to the target area '''
+    def _buildRpm(
+        self,
+        project,
+        version,
+        platform,
+        rpmbuildarea,
+        builddir,
+        artifactdir,
+        keeprpmdir,
+    ):
+        """Build the RPM for the project them and copy them to the target area"""
 
         # First check if there is a shared RPM to build
-        hasShared = self._buildExtraSharedRpm(project, version, rpmbuildarea,
-                                              artifactdir, keeprpmdir)
+        hasShared = self._buildExtraSharedRpm(
+            project, version, rpmbuildarea, artifactdir, keeprpmdir
+        )
 
         rpmbuildname = "_".join([project, version, platform])
 
         # Creating the temp directories to prepare the RPMs
         rpmconf = self._createRpmDirs(rpmbuildarea, rpmbuildname)
 
         # Locating the manifest file
-        manifestxmlfile = self._getManifestFilename(builddir, project, version,
-                                                    platform)
+        manifestxmlfile = self._getManifestFilename(
+            builddir, project, version, platform
+        )
 
         # Parsing the manifest.xml file
         from LbTools.Manifest import Parser
 
         manifest = Parser(manifestxmlfile)
 
         # Now generating the spec
-        from LbRPMTools.LHCbRPMSpecBuilder import getBuildInfo
-        from LbRPMTools.LHCbRPMSpecBuilder import LHCbBinaryRpmSpec
-        (_absFilename, buildlocation, _fprojectVersion,
-         _fcmtconfig) = getBuildInfo(manifestxmlfile)
-        spec = LHCbBinaryRpmSpec(project, version, platform, rpmbuildarea,
-                                 buildlocation, manifest)
+        from LbRPMTools.LHCbRPMSpecBuilder import LHCbBinaryRpmSpec, getBuildInfo
+
+        (_absFilename, buildlocation, _fprojectVersion, _fcmtconfig) = getBuildInfo(
+            manifestxmlfile
+        )
+        spec = LHCbBinaryRpmSpec(
+            project, version, platform, rpmbuildarea, buildlocation, manifest
+        )
         if hasShared:
-            spec.addExtraRequire("_".join([project, version, 'shared']))
+            spec.addExtraRequire("_".join([project, version, "shared"]))
 
         # Check if a non default RPM release dir was specified
         if self.options.rpmreldir != None:
-            self.log.warning("Setting RPM release dir from options: %s" %
-                             self.options.rpmreldir)
+            self.log.warning(
+                "Setting RPM release dir from options: %s" % self.options.rpmreldir
+            )
             spec.setRPMReleaseDir(self.options.rpmreldir)
 
+        if self.options.checkrelease:
+            self.log.warning("Incrementing the release number based on YUM repo")
+            spec.setCheckRelease(self.options.checkrelease)
+
         specfilename = os.path.join(rpmconf.topdir, rpmbuildname + ".spec")
+        self.log.info("Writing spec file to %s" % specfilename)
         with open(specfilename, "w") as outputfile:
             outputfile.write(spec.getSpec())
 
         # Building the name of the expected RPM
         rpmname = spec.getRPMName()
         fullrpmpath = os.path.join(rpmconf.rpmsdir, spec.getArch(), rpmname)
         self._callRpmbuild(specfilename, fullrpmpath, artifactdir)
@@ -243,46 +286,51 @@
         # Remove tmpdirectory
         if not keeprpmdir:
             rpmconf.removeBuildArea()
             self.log.info("Removing: %s " % rpmconf.buildarea)
         else:
             self.log.info("Keeping: %s " % rpmconf.buildarea)
 
-    def _buildExtraSharedRpm(self, project, version, rpmbuildarea, artifactdir,
-                             keeprpmdir):
-        ''' Build the RPM for the extra shared zip filed produced by some projects
-        like geant4 '''
+    def _buildExtraSharedRpm(
+        self, project, version, rpmbuildarea, artifactdir, keeprpmdir
+    ):
+        """Build the RPM for the extra shared zip filed produced by some projects
+        like geant4"""
 
         hasShared = False
-        rpmbuildname = "_".join([project, version, 'shared'])
+        rpmbuildname = "_".join([project, version, "shared"])
 
         # Creating the temp directories to prepare the RPMs
         rpmconf = self._createRpmDirs(rpmbuildarea, rpmbuildname)
 
         # Looking for archive with sources
-        srcArchive = self._findExtraSharedArchive(project, version,
-                                                  artifactdir)
+        srcArchive = self._findExtraSharedArchive(project, version, artifactdir)
         if srcArchive != None:
             self.log.info("Taking sources from %s" % srcArchive)
             hasShared = True
         else:
             # No zip find, no need to do anything...
             hasShared = False
             return hasShared
 
         # Now generating the spec
         from LbRPMTools.LHCbRPMSpecBuilder import LHCbExtraSharedRpmSpec
-        spec = LHCbExtraSharedRpmSpec(project, version, srcArchive,
-                                      rpmbuildarea)
+
+        spec = LHCbExtraSharedRpmSpec(project, version, srcArchive, rpmbuildarea)
         # Check if a non default RPM release dir was specified
         if self.options.rpmreldir != None:
-            self.log.warning("Setting RPM release dir from options: %s" %
-                             self.options.rpmreldir)
+            self.log.warning(
+                "Setting RPM release dir from options: %s" % self.options.rpmreldir
+            )
             spec.setRPMReleaseDir(self.options.rpmreldir)
 
+        if self.options.checkrelease:
+            self.log.warning("Incrementing the release number based on YUM repo")
+            spec.setCheckRelease(self.options.checkrelease)
+
         specfilename = os.path.join(rpmconf.topdir, rpmbuildname + ".spec")
         with open(specfilename, "w") as outputfile:
             outputfile.write(spec.getSpec())
 
         # Building the name of the expected RPM
         rpmname = spec.getRPMName()
 
@@ -292,23 +340,25 @@
         # Remove tmpdirectory
         if not keeprpmdir:
             rpmconf.removeBuildArea()
             self.log.info("Removing: %s " % rpmconf.buildarea)
         else:
             self.log.info("Keeping: %s " % rpmconf.buildarea)
 
-    def _buildSharedRpm(self,
-                        project,
-                        version,
-                        rpmbuildarea,
-                        builddir,
-                        artifactdir,
-                        keeprpmdir,
-                        isPlatformIndependent=False):
-        ''' Build the RPM for the project them and copy them to the target area '''
+    def _buildSharedRpm(
+        self,
+        project,
+        version,
+        rpmbuildarea,
+        builddir,
+        artifactdir,
+        keeprpmdir,
+        isPlatformIndependent=False,
+    ):
+        """Build the RPM for the project them and copy them to the target area"""
 
         rpmbuildname = "_".join([project, version])
 
         # Creating the temp directories to prepare the RPMs
         rpmconf = self._createRpmDirs(rpmbuildarea, rpmbuildname)
 
         # Looking for archive with sources
@@ -322,30 +372,37 @@
         # Only doing the following for platform independent projects: in this case
         # we can have dependencies. In the other case, this is a RPM containing sources
         # that the binary RPM depends on.
         manifest = None
         if isPlatformIndependent:
             # Locating the manifest file
             manifestxmlfile = self._getManifestFilename(
-                builddir, project, version, None)
+                builddir, project, version, None
+            )
 
             # Parsing the manifest.xml file
             from LbTools.Manifest import Parser
+
             manifest = Parser(manifestxmlfile)
 
         # Now generating the spec
         from LbRPMTools.LHCbRPMSpecBuilder import LHCbSharedRpmSpec
-        spec = LHCbSharedRpmSpec(project, version, srcArchive, rpmbuildarea,
-                                 manifest)
+
+        spec = LHCbSharedRpmSpec(project, version, srcArchive, rpmbuildarea, manifest)
         # Check if a non default RPM release dir was specified
         if self.options.rpmreldir != None:
-            self.log.warning("Setting RPM release dir from options: %s" %
-                             self.options.rpmreldir)
+            self.log.warning(
+                "Setting RPM release dir from options: %s" % self.options.rpmreldir
+            )
             spec.setRPMReleaseDir(self.options.rpmreldir)
 
+        if self.options.checkrelease:
+            self.log.warning("Incrementing the release number based on YUM repo")
+            spec.setCheckRelease(self.options.checkrelease)
+
         specfilename = os.path.join(rpmconf.topdir, rpmbuildname + ".spec")
         with open(specfilename, "w") as outputfile:
             outputfile.write(spec.getSpec())
 
         # Building the name of the expected RPM
         rpmname = spec.getRPMName()
         fullrpmpath = os.path.join(rpmconf.rpmsdir, spec.getArch(), rpmname)
@@ -354,17 +411,18 @@
         # Remove tmpdirectory
         if not keeprpmdir:
             rpmconf.removeBuildArea()
             self.log.info("Removing: %s " % rpmconf.buildarea)
         else:
             self.log.info("Keeping: %s " % rpmconf.buildarea)
 
-    def _buildLbScriptsRpm(self, project, version, rpmbuildarea, artifactdir,
-                           keeprpmdir):
-        ''' Build the RPM for the project them and copy them to the target area '''
+    def _buildLbScriptsRpm(
+        self, project, version, rpmbuildarea, artifactdir, keeprpmdir
+    ):
+        """Build the RPM for the project them and copy them to the target area"""
 
         rpmbuildname = "_".join([project, version])
 
         # Creating the temp directories to prepare the RPMs
         rpmconf = self._createRpmDirs(rpmbuildarea, rpmbuildname)
 
         # Looking for archive with sources
@@ -372,21 +430,27 @@
         if srcArchive != None:
             self.log.info("Taking sources from %s" % srcArchive)
         else:
             self.log.warning("Doing clean checkout of the sources")
 
         # Now generating the spec
         from LbRPMTools.LHCbRPMSpecBuilder import LHCbLbScriptsRpmSpec
+
         spec = LHCbLbScriptsRpmSpec(project, version, srcArchive, rpmbuildarea)
         # Check if a non default RPM release dir was specified
         if self.options.rpmreldir != None:
-            self.log.warning("Setting RPM release dir from options: %s" %
-                             self.options.rpmreldir)
+            self.log.warning(
+                "Setting RPM release dir from options: %s" % self.options.rpmreldir
+            )
             spec.setRPMReleaseDir(self.options.rpmreldir)
 
+        if self.options.checkrelease:
+            self.log.warning("Incrementing the release number based on YUM repo")
+            spec.setCheckRelease(self.options.checkrelease)
+
         specfilename = os.path.join(rpmconf.topdir, rpmbuildname + ".spec")
         with open(specfilename, "w") as outputfile:
             outputfile.write(spec.getSpec())
 
         # Building the name of the expected RPM
         rpmname = spec.getRPMName()
         fullrpmpath = os.path.join(rpmconf.rpmsdir, spec.getArch(), rpmname)
@@ -395,45 +459,54 @@
         # Remove tmpdirectory
         if not keeprpmdir:
             rpmconf.removeBuildArea()
             self.log.info("Removing: %s " % rpmconf.buildarea)
         else:
             self.log.info("Keeping: %s " % rpmconf.buildarea)
 
-    def _buildDatapkgRpm(self, project, fulldatapkg, version, rpmbuildarea,
-                         artifactdir, keeprpmdir):
-        ''' Build the RPM for the datapkg and copy them to the target area '''
+    def _buildDatapkgRpm(
+        self, project, fulldatapkg, version, rpmbuildarea, artifactdir, keeprpmdir
+    ):
+        """Build the RPM for the datapkg and copy them to the target area"""
         fulldatapkg
         datapkg = fulldatapkg
         if "/" in datapkg:
             (_hat, datapkg) = fulldatapkg.split("/")
 
         rpmbuildname = "_".join([project, datapkg])
 
         # Creating the temp directories to prepare the RPMs
         rpmconf = self._createRpmDirs(rpmbuildarea, rpmbuildname)
 
         # Looking for archive with sources
-        srcArchive = self._findDatapkgArchive(project, fulldatapkg, version,
-                                              artifactdir)
+        srcArchive = self._findDatapkgArchive(
+            project, fulldatapkg, version, artifactdir
+        )
         if srcArchive != None:
             self.log.info("Taking sources from %s" % srcArchive)
         else:
             self.log.warning("Doing clean checkout of the sources")
 
         # Now generating the spec
         from LbRPMTools.LHCbRPMSpecBuilder import LHCbDatapkgRpmSpec
-        spec = LHCbDatapkgRpmSpec(project, fulldatapkg, version, srcArchive,
-                                  rpmbuildarea)
+
+        spec = LHCbDatapkgRpmSpec(
+            project, fulldatapkg, version, srcArchive, rpmbuildarea
+        )
         # Check if a non default RPM release dir was specified
         if self.options.rpmreldir != None:
-            self.log.warning("Setting RPM release dir from options: %s" %
-                             self.options.rpmreldir)
+            self.log.warning(
+                "Setting RPM release dir from options: %s" % self.options.rpmreldir
+            )
             spec.setRPMReleaseDir(self.options.rpmreldir)
 
+        if self.options.checkrelease:
+            self.log.warning("Incrementing the release number based on YUM repo")
+            spec.setCheckRelease(self.options.checkrelease)
+
         specfilename = os.path.join(rpmconf.topdir, rpmbuildname + ".spec")
         with open(specfilename, "w") as outputfile:
             outputfile.write(spec.getSpec())
 
         # Building the name of the expected RPM
         rpmname = spec.getRPMName()
         fullrpmpath = os.path.join(rpmconf.rpmsdir, spec.getArch(), rpmname)
@@ -442,26 +515,35 @@
         # Remove tmpdirectory
         if not keeprpmdir:
             rpmconf.removeBuildArea()
             self.log.info("Removing: %s " % rpmconf.buildarea)
         else:
             self.log.info("Keeping: %s " % rpmconf.buildarea)
 
-    def _buildGlimpseRpm(self, project, version, platform, rpmbuildarea,
-                         builddir, artifactdir, keeprpmdir):
-        ''' Build the RPM for glimpse index and copy them to the target area '''
+    def _buildGlimpseRpm(
+        self,
+        project,
+        version,
+        platform,
+        rpmbuildarea,
+        builddir,
+        artifactdir,
+        keeprpmdir,
+    ):
+        """Build the RPM for glimpse index and copy them to the target area"""
 
         rpmbuildname = "_".join(["glimpse", project, version])
 
         # Creating the temp directories to prepare the RPMs
         rpmconf = self._createRpmDirs(rpmbuildarea, rpmbuildname)
 
         # Locating the manifest file
-        manifestxmlfile = self._getManifestFilename(builddir, project, version,
-                                                    platform)
+        manifestxmlfile = self._getManifestFilename(
+            builddir, project, version, platform
+        )
 
         # Parsing the manifest.xml file
         from LbTools.Manifest import Parser
 
         manifest = Parser(manifestxmlfile)
 
         # Looking for archive with sources
@@ -469,22 +551,27 @@
         if srcArchive != None:
             self.log.info("Taking sources from %s" % srcArchive)
         else:
             self.log.warning("Doing clean checkout of the sources")
 
         # Now generating the spec
         from LbRPMTools.LHCbRPMSpecBuilder import LHCbGlimpseRpmSpec
-        spec = LHCbGlimpseRpmSpec(project, version, srcArchive, rpmbuildarea,
-                                  manifest)
+
+        spec = LHCbGlimpseRpmSpec(project, version, srcArchive, rpmbuildarea, manifest)
         # Check if a non default RPM release dir was specified
         if self.options.rpmreldir != None:
-            self.log.warning("Setting RPM release dir from options: %s" %
-                             self.options.rpmreldir)
+            self.log.warning(
+                "Setting RPM release dir from options: %s" % self.options.rpmreldir
+            )
             spec.setRPMReleaseDir(self.options.rpmreldir)
 
+        if self.options.checkrelease:
+            self.log.warning("Incrementing the release number based on YUM repo")
+            spec.setCheckRelease(self.options.checkrelease)
+
         specfilename = os.path.join(rpmconf.topdir, rpmbuildname + ".spec")
         with open(specfilename, "w") as outputfile:
             outputfile.write(spec.getSpec())
 
         # Building the name of the expected RPM
         rpmname = spec.getRPMName()
         fullrpmpath = os.path.join(rpmconf.rpmsdir, spec.getArch(), rpmname)
@@ -494,201 +581,241 @@
         if not keeprpmdir:
             rpmconf.removeBuildArea()
             self.log.info("Removing: %s " % rpmconf.buildarea)
         else:
             self.log.info("Keeping: %s " % rpmconf.buildarea)
 
     def _findGlimpseArchive(self, project, version, artifactdir):
-        ''' Locate the source RPM '''
+        """Locate the source RPM"""
         # Checking if we find the src archive
         packname = [project, version]
         if self.options.build_id:
             packname.append(self.options.build_id)
-        packname.append('index')
-        packname.append('zip')
-        archname = '.'.join(packname)
+        packname.append("index")
+        packname.append("zip")
+        archname = ".".join(packname)
 
-        fullarchname = os.path.join(artifactdir, 'packs', 'index', archname)
+        fullarchname = os.path.join(artifactdir, "packs", "index", archname)
         self.log.info("Looking for file: %s" % fullarchname)
         if os.path.exists(fullarchname):
             return os.path.abspath(fullarchname)
         else:
             return None
 
     def _findSrcArchive(self, project, version, artifactdir):
-        ''' Locate the source RPM '''
+        """Locate the source RPM"""
         # Checking if we find the src archive
         packname = [project, version]
         if self.options.build_id:
             packname.append(self.options.build_id)
-        packname.append('src')
-        packname.append('zip')
-        archname = '.'.join(packname)
+        packname.append("src")
+        packname.append("zip")
+        archname = ".".join(packname)
 
-        fullarchname = os.path.join(artifactdir, 'packs', 'src', archname)
+        fullarchname = os.path.join(artifactdir, "packs", "src", archname)
         self.log.info("Looking for file: %s" % fullarchname)
         if os.path.exists(fullarchname):
             return os.path.abspath(fullarchname)
         else:
             return None
 
     def _findExtraSharedArchive(self, project, version, artifactdir):
-        ''' Locate the Extra Shared RPM '''
+        """Locate the Extra Shared RPM"""
         # Checking if we find the src archive
         packname = [project, version]
         if self.options.build_id:
             packname.append(self.options.build_id)
-        packname.append('shared')
-        packname.append('zip')
-        archname = '.'.join(packname)
+        packname.append("shared")
+        packname.append("zip")
+        archname = ".".join(packname)
 
-        fullarchname = os.path.join(artifactdir, 'packs', 'shared', archname)
+        fullarchname = os.path.join(artifactdir, "packs", "shared", archname)
         self.log.info("Looking for file: %s" % fullarchname)
         if os.path.exists(fullarchname):
             return os.path.abspath(fullarchname)
         else:
             return None
 
     def _findDatapkgArchive(self, project, datapkg, version, artifactdir):
-        ''' Locate the source RPM '''
+        """Locate the source RPM"""
         # Checking if we find the src archive
         fixeddatapkg = datapkg.replace("/", "_")
         packname = [fixeddatapkg, version]
 
         if self.options.build_id:
             packname.append(self.options.build_id)
 
-        packname.append('src')
-        packname.append('zip')
-        archname = '.'.join(packname)
+        packname.append("src")
+        packname.append("zip")
+        archname = ".".join(packname)
 
-        fullarchname = os.path.join(artifactdir, 'packs', 'src', archname)
+        fullarchname = os.path.join(artifactdir, "packs", "src", archname)
         self.log.info("Looking for file: %s" % fullarchname)
         if os.path.exists(fullarchname):
             return os.path.abspath(fullarchname)
         else:
             return None
 
     def _isPlatformIndependent(self, project, version, artifactdir):
-        ''' Check if a project is platform independent
+        """Check if a project is platform independent
 
         A project is defined to be platform independent if we can find a
         manifest.xml in the top level directory of the source achive.
 
         Note that this method is slow because it needs to scan the source
         archive, so the result should be cached.
-        '''
+        """
         import zipfile
+
         srcArchive = self._findSrcArchive(project, version, artifactdir)
         if not srcArchive:
-            self.log.warning('assuming platform depdendent project '
-                             '(missing source archive)')
+            self.log.warning(
+                "assuming platform depdendent project " "(missing source archive)"
+            )
             return False
-        manifest = '{P}/{P}_{v}/manifest.xml'.format(
-            P=project.upper(), v=version)
+        manifest = "{P}/{P}_{v}/manifest.xml".format(P=project.upper(), v=version)
         try:
-            for info in zipfile.ZipFile(srcArchive, 'r'):
+            for info in zipfile.ZipFile(srcArchive, "r"):
                 if info.filename == manifest:
                     return True
-        except Exception, exc:
-            self.log.warning('assuming platform dependent project (%s: %s)',
-                             exc.__class__.__name__, exc)
+        except Exception as exc:
+            self.log.warning(
+                "assuming platform dependent project (%s: %s)",
+                exc.__class__.__name__,
+                exc,
+            )
             return False
 
     def main(self):
-        '''
+        """
         Main method for the script
-        '''
+        """
         from LbNightlyTools.Scripts.Common import expandTokensInOptions
 
         if len(self.args) != 1:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         # Same logic as BuildSlot lo locate the builddir
         builddir = self.options.builddir
         if builddir == None:
-            builddir = os.path.join(os.getcwd(), 'build')
+            builddir = os.path.join(os.getcwd(), "build")
 
         # Now loading the slot configuration
         from LbNightlyTools.Configuration import findSlot
+
         self.slot = findSlot(self.args[0], flavour=self.options.flavour)
         # FIXME: to be ported to the new configuration classes
         self.config = self.slot.toDict()
 
         expandTokensInOptions(
-            self.options, ['build_id', 'artifacts_dir'],
-            slot=self.config[u'slot'])
+            self.options, ["build_id", "artifacts_dir"], slot=self.config["slot"]
+        )
 
         # Check the final artifacts dir
         if self.options.artifacts_dir is not None:
             artifactdir = self.options.artifacts_dir
         else:
-            artifactdir = os.path.join(os.getcwd(), 'artifacts')
-        if not os.path.exists(os.path.join(artifactdir, 'rpms')):
-            os.makedirs(os.path.join(artifactdir, 'rpms'))
+            artifactdir = os.path.join(os.getcwd(), "artifacts")
+        if not os.path.exists(os.path.join(artifactdir, "rpms")):
+            os.makedirs(os.path.join(artifactdir, "rpms"))
 
         # Check plaform to package for
-        platform = (self.options.platform or os.environ.get('BINARY_TAG')
-                    or os.environ.get('CMTCONFIG'))
+        platform = (
+            self.options.platform
+            or os.environ.get("BINARY_TAG")
+            or os.environ.get("CMTCONFIG")
+        )
 
         if not platform and not self.options.shared:
             raise Exception("Could not find platform")
 
         # temp area used to build the RPMs
         from tempfile import mkdtemp
+
         rpmbuildarea = mkdtemp(prefix="rpm")
         keeprpmdir = self.options.keeprpmdir
 
         if self.options.shared:
             for p in self.config["packages"]:
                 fulldatapkg = p["name"]
                 project = p.get("container", "DBASE")
                 version = p["version"]
-                self.log.info("Preparing RPM for datapkg %s %s %s" %
-                              (project, fulldatapkg, version))
-                self._buildDatapkgRpm(project, fulldatapkg, version,
-                                      rpmbuildarea, artifactdir, keeprpmdir)
+                self.log.info(
+                    "Preparing RPM for datapkg %s %s %s"
+                    % (project, fulldatapkg, version)
+                )
+                self._buildDatapkgRpm(
+                    project, fulldatapkg, version, rpmbuildarea, artifactdir, keeprpmdir
+                )
 
         for p in self.config["projects"]:
             project = p["name"]
-            if ((self.options.projects
-                 and project.lower() not in self.options.projects)
-                    or project.lower() in ('dbase', 'param', 'lcgcmt')
-                    or p.get('disabled')):
+            if (
+                (self.options.projects and project.lower() not in self.options.projects)
+                or project.lower() in ("dbase", "param", "lcgcmt")
+                or p.get("disabled")
+            ):
                 self.log.warning("Skipping project %s" % project)
                 continue  # project not requested: skip
             version = p["version"]
 
-            platform_independent = (p.get('platform_independent')
-                                    or self._isPlatformIndependent(
-                                        project, version, artifactdir))
+            platform_independent = p.get(
+                "platform_independent"
+            ) or self._isPlatformIndependent(project, version, artifactdir)
             if self.options.shared:
                 if project.lower() == "lbscripts":
                     self.log.info("Preparing RPM for LbScripts %s" % version)
-                    self._buildLbScriptsRpm(project, version, rpmbuildarea,
-                                            artifactdir, keeprpmdir)
+                    self._buildLbScriptsRpm(
+                        project, version, rpmbuildarea, artifactdir, keeprpmdir
+                    )
                 else:
-                    self.log.info("Preparing RPM for project %s %s %s" %
-                                  (project, version, "src"))
-                    self._buildSharedRpm(project, version, rpmbuildarea,
-                                         builddir, artifactdir, keeprpmdir,
-                                         platform_independent)
+                    self.log.info(
+                        "Preparing RPM for project %s %s %s" % (project, version, "src")
+                    )
+                    self._buildSharedRpm(
+                        project,
+                        version,
+                        rpmbuildarea,
+                        builddir,
+                        artifactdir,
+                        keeprpmdir,
+                        platform_independent,
+                    )
             elif self.options.glimpse:
                 if platform_independent:
-                    self.log.info("Platform independent. No glimpse for %s %s",
-                                  project, version)
+                    self.log.info(
+                        "Platform independent. No glimpse for %s %s", project, version
+                    )
                 else:
-                    self.log.info("Preparing Glimpse RPM for project %s %s" %
-                                  (project, version))
-                    self._buildGlimpseRpm(project, version, platform,
-                                          rpmbuildarea, builddir, artifactdir,
-                                          keeprpmdir)
+                    self.log.info(
+                        "Preparing Glimpse RPM for project %s %s" % (project, version)
+                    )
+                    self._buildGlimpseRpm(
+                        project,
+                        version,
+                        platform,
+                        rpmbuildarea,
+                        builddir,
+                        artifactdir,
+                        keeprpmdir,
+                    )
             else:
                 if platform_independent:
                     self.log.info(
                         "No platform specific RPM needed for project %s %s",
-                        project, version)
+                        project,
+                        version,
+                    )
                 else:
-                    self.log.info("Preparing RPM for project %s %s %s" %
-                                  (project, version, platform))
-                    self._buildRpm(project, version, platform, rpmbuildarea,
-                                   builddir, artifactdir, keeprpmdir)
+                    self.log.info(
+                        "Preparing RPM for project %s %s %s"
+                        % (project, version, platform)
+                    )
+                    self._buildRpm(
+                        project,
+                        version,
+                        platform,
+                        rpmbuildarea,
+                        builddir,
+                        artifactdir,
+                        keeprpmdir,
+                    )
```

### Comparing `LbNightlyTools-3.0.9/python/LbRPMTools/tests/TestExternalSpec.py` & `LbNightlyTools-4.0.0/python/LbRPMTools/tests/test_ExternalSpec.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,67 +4,78 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 
 Test for the Tools generating Spec files
 
 Created on Dec 3, 2013
 
 @author: Ben Couturier
-'''
-import logging
+"""
+from __future__ import print_function
+
 import json
+import logging
 import os
 import unittest
-from os.path import normpath, join
+from builtins import range
+from os.path import join, normpath
 
 
 class Test(unittest.TestCase):
-    ''' Test cases for the RPM Spec builder '''
+    """Test cases for the RPM Spec builder"""
 
     def setUp(self):
-        ''' Setup the test '''
+        """Setup the test"""
         self._data_dir = normpath(
-            join(*([__file__] + [os.pardir] * 4 + ['testdata', 'rpm'])))
+            join(*([__file__] + [os.pardir] * 4 + ["testdata", "rpm"]))
+        )
 
         self._externalsDictJSON = normpath(
-            join(*([__file__] + [os.pardir] * 4 +
-                   ['testdata', 'rpm', 'LCG_68_externalsDict.json'])))
+            join(
+                *(
+                    [__file__]
+                    + [os.pardir] * 4
+                    + ["testdata", "rpm", "LCG_68_externalsDict.json"]
+                )
+            )
+        )
 
         logging.basicConfig(level=logging.INFO)
 
     def tearDown(self):
-        ''' tear down the test '''
+        """tear down the test"""
         pass
 
     def testExternalSpecBuilder(self):
-        '''
+        """
         Test the externals package Spec Builder
-        '''
+        """
         from LbRPMTools.LHCbExternalsSpecBuilder import LHCbExternalsRpmSpec
 
         project = "LHCbExternals"
         version = "v68r0"
         lcgVer = "68"
         platform = "x86_64-slc6-gcc48-opt"
         rpmbuildarea = "/tmp"
         externalsDict = None
-        with open(self._externalsDictJSON, 'r') as infile:
+        with open(self._externalsDictJSON, "r") as infile:
             externalsDict = json.load(infile)
 
-        spec = LHCbExternalsRpmSpec(project, version, platform, rpmbuildarea,
-                                    externalsDict, lcgVer)
+        spec = LHCbExternalsRpmSpec(
+            project, version, platform, rpmbuildarea, externalsDict, lcgVer
+        )
         spec.setRPMReleaseDir("/tmptoto")
         newspectxt = spec.getSpec()
-        oldspectxt = '''
+        oldspectxt = """
 %define lhcb_maj_version 1
 %define lhcb_min_version 0
 %define lhcb_patch_version 0
 %define buildarea /tmp
 %define project LHCbExternals
 %define projectUp LHCBEXTERNALS
 %define cmtconfig x86_64-slc6-gcc48-opt
@@ -89,53 +100,53 @@
 BuildArch: noarch
 AutoReqProv: no
 Prefix: /opt/LHCbSoft
 Provides: /bin/sh
 Provides: %{project}_%{lcgversion}_%{cmtconfigrpm} = %{lhcb_maj_version}.%{lhcb_min_version}.%{lhcb_patch_version}
 
 
-Requires: LCG_68_sqlite_3070900_x86_64_slc6_gcc48_opt
-Requires: LCG_68_expat_2.0.1_x86_64_slc6_gcc48_opt
-Requires: LCG_68_Frontier_Client_2.8.10_x86_64_slc6_gcc48_opt
-Requires: LCG_68_blas_20110419_x86_64_slc6_gcc48_opt
-Requires: LCG_68_AIDA_3.2.1_x86_64_slc6_gcc48_opt
-Requires: LCG_68_HepMC_2.06.08_x86_64_slc6_gcc48_opt
-Requires: LCG_68_graphviz_2.28.0_x86_64_slc6_gcc48_opt
-Requires: LCG_68_pyanalysis_1.4_python2.7_x86_64_slc6_gcc48_opt
-Requires: LCG_68_mysql_5.5.27_x86_64_slc6_gcc48_opt
 Requires: LCGCMT_LCGCMT_68
+Requires: LCG_68_AIDA_3.2.1_x86_64_slc6_gcc48_opt
 Requires: LCG_68_Boost_1.55.0_python2.7_x86_64_slc6_gcc48_opt
-Requires: LCG_68_GSL_1.10_x86_64_slc6_gcc48_opt
-Requires: LCG_68_GCCXML_0.9.0_20131026_x86_64_slc6_gcc48_opt
-Requires: LCG_68_pygraphics_1.4_python2.7_x86_64_slc6_gcc48_opt
-Requires: LCG_68_gcc_4.8.1_x86_64_slc6
-Requires: LCG_68_neurobayes_expert_3.7.0_x86_64_slc6_gcc48_opt
+Requires: LCG_68_CASTOR_2.1.13_6_x86_64_slc6_gcc48_opt
 Requires: LCG_68_CLHEP_1.9.4.7_x86_64_slc6_gcc48_opt
-Requires: LCG_68_lapack_3.4.0_x86_64_slc6_gcc48_opt
-Requires: LCG_68_Python_2.7.6_x86_64_slc6_gcc48_opt
-Requires: LCG_68_pytools_1.8_python2.7_x86_64_slc6_gcc48_opt
-Requires: LCG_68_HepPDT_2.06.01_x86_64_slc6_gcc48_opt
-Requires: LCG_68_fastjet_3.0.6_x86_64_slc6_gcc48_opt
 Requires: LCG_68_COOL_COOL_2_9_2_x86_64_slc6_gcc48_opt
+Requires: LCG_68_CORAL_CORAL_2_4_2_x86_64_slc6_gcc48_opt
+Requires: LCG_68_CppUnit_1.12.1_p1_x86_64_slc6_gcc48_opt
+Requires: LCG_68_Frontier_Client_2.8.10_x86_64_slc6_gcc48_opt
+Requires: LCG_68_GCCXML_0.9.0_20131026_x86_64_slc6_gcc48_opt
+Requires: LCG_68_GSL_1.10_x86_64_slc6_gcc48_opt
+Requires: LCG_68_HepMC_2.06.08_x86_64_slc6_gcc48_opt
+Requires: LCG_68_HepPDT_2.06.01_x86_64_slc6_gcc48_opt
+Requires: LCG_68_Python_2.7.6_x86_64_slc6_gcc48_opt
+Requires: LCG_68_QMtest_2.4.1_python2.7_x86_64_slc6_gcc48_opt
+Requires: LCG_68_Qt_4.8.4_x86_64_slc6_gcc48_opt
+Requires: LCG_68_RELAX_RELAX_1_3_0p_x86_64_slc6_gcc48_opt
 Requires: LCG_68_ROOT_5.34.18_x86_64_slc6_gcc48_opt
 Requires: LCG_68_XercesC_3.1.1p1_x86_64_slc6_gcc48_opt
-Requires: LCG_68_Qt_4.8.4_x86_64_slc6_gcc48_opt
-Requires: LCG_68_CORAL_CORAL_2_4_2_x86_64_slc6_gcc48_opt
-Requires: LCG_68_xrootd_3.2.7_x86_64_slc6_gcc48_opt
+Requires: LCG_68_blas_20110419_x86_64_slc6_gcc48_opt
+Requires: LCG_68_expat_2.0.1_x86_64_slc6_gcc48_opt
+Requires: LCG_68_fastjet_3.0.6_x86_64_slc6_gcc48_opt
+Requires: LCG_68_fftw_3.1.2_x86_64_slc6_gcc48_opt
+Requires: LCG_68_gcc_4.8.1_x86_64_slc6
+Requires: LCG_68_graphviz_2.28.0_x86_64_slc6_gcc48_opt
+Requires: LCG_68_lapack_3.4.0_x86_64_slc6_gcc48_opt
 Requires: LCG_68_libunwind_5c2cade_x86_64_slc6_gcc48_opt
+Requires: LCG_68_mysql_5.5.27_x86_64_slc6_gcc48_opt
+Requires: LCG_68_neurobayes_expert_3.7.0_x86_64_slc6_gcc48_opt
+Requires: LCG_68_oracle_11.2.0.3.0_x86_64_slc6_gcc48_opt
+Requires: LCG_68_pyanalysis_1.4_python2.7_x86_64_slc6_gcc48_opt
+Requires: LCG_68_pygraphics_1.4_python2.7_x86_64_slc6_gcc48_opt
+Requires: LCG_68_pytools_1.8_python2.7_x86_64_slc6_gcc48_opt
+Requires: LCG_68_sqlite_3070900_x86_64_slc6_gcc48_opt
 Requires: LCG_68_tbb_42_20131118_x86_64_slc6_gcc48_opt
-Requires: LCG_68_CppUnit_1.12.1_p1_x86_64_slc6_gcc48_opt
 Requires: LCG_68_tcmalloc_1.7p3_x86_64_slc6_gcc48_opt
-Requires: LCG_68_CASTOR_2.1.13_6_x86_64_slc6_gcc48_opt
 Requires: LCG_68_vdt_0.3.6_x86_64_slc6_gcc48_opt
-Requires: LCG_68_RELAX_RELAX_1_3_0p_x86_64_slc6_gcc48_opt
-Requires: LCG_68_QMtest_2.4.1_python2.7_x86_64_slc6_gcc48_opt
-Requires: LCG_68_fftw_3.1.2_x86_64_slc6_gcc48_opt
 Requires: LCG_68_xqilla_2.2.4p1_x86_64_slc6_gcc48_opt
-Requires: LCG_68_oracle_11.2.0.3.0_x86_64_slc6_gcc48_opt
+Requires: LCG_68_xrootd_3.2.7_x86_64_slc6_gcc48_opt
 %description
 %{project}
 
 %install
 
 
 
@@ -149,24 +160,24 @@
 
 %define date    %(echo `LC_ALL="C" date +"%a %b %d %Y"`)
 
 %changelog
 
 * %{date} User <ben.couturier..rcern.ch>
 - first Version
-'''
-        #print newspectxt
+"""
+        # print newspectxt
 
         nl = newspectxt.splitlines()
         ol = oldspectxt.splitlines()
-        self.assertEquals(len(nl), len(ol))
+        self.assertEqual(len(nl), len(ol))
 
         for i in range(len(ol)):
             if ol[i] != nl[i]:
-                print "LINE[%d] REFERENCE:<%s>" % (i, ol[i])
-                print "LINE[%d] GENERATED:<%s>" % (i, nl[i])
+                print("LINE[%d] REFERENCE:<%s>" % (i, ol[i]))
+                print("LINE[%d] GENERATED:<%s>" % (i, nl[i]))
             self.assertEqual(nl[i], ol[i])
 
 
 if __name__ == "__main__":
-    #import sys;sys.argv = ['', 'Test.testLoadXML']
+    # import sys;sys.argv = ['', 'Test.testLoadXML']
     unittest.main()
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/ProcUtils.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/ProcUtils.py`

 * *Files 8% similar despite different names*

```diff
@@ -4,60 +4,63 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Common utility functions.
-'''
-__author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+"""
+from future import standard_library
 
-__all__ = ('call_with_pty', 'call')
+standard_library.install_aliases()
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
+
+__all__ = ("call_with_pty", "call")
 
 import os
 import pty
 import sys
-
-from subprocess import Popen, call as _call, STDOUT
-from threading import Thread
+from queue import Queue
 from select import select
-from Queue import Queue
+from subprocess import STDOUT, Popen
+from subprocess import call as _call
+from threading import Thread
 
 BUF_SIZE = 512
 
 
 class _CollectorThread(Thread):
-    '''
+    """
     Class used to collect the output of a Popen process on a pseudo-terminal
     (pty).
-    '''
+    """
 
     def __init__(self, proc, fdesc, queue, echo=None):
-        '''
+        """
         Initialize the thread.
 
         @param proc: Popen process that was started with a pty slave as output
         descriptor (either stdout or stderr)
         @param fdesc: file descriptor of the pty master
         @param queue: Queue instance used to collect the chunks read from fdesc,
                       recorded as tuples (fdesc, chunk)
         @param echo: file object where the data can be written while collected
-        '''
+        """
         super(_CollectorThread, self).__init__()
         self.proc = proc
         self.fdesc = fdesc
         self.queue = queue
         self.echo = echo
 
     def run(self):
-        '''
+        """
         Core function of the Thread interface.
-        '''
+        """
         proc, fdesc, queue, echo = self.proc, self.fdesc, self.queue, self.echo
         while True:
             if select([fdesc], [], [], 0.1)[0]:
                 chunk = os.read(fdesc, BUF_SIZE)
                 while len(chunk) == BUF_SIZE or select([fdesc], [], [], 0)[0]:
                     queue.put((fdesc, chunk))
                     if echo:
@@ -67,71 +70,70 @@
                     queue.put((fdesc, chunk))
                     if echo:
                         echo.write(chunk)
             elif proc.poll() is not None:
                 break
 
 
-def _collate_chunks(input_data, newline='\r\n'):
-    '''
+def _collate_chunks(input_data, newline="\r\n"):
+    """
     Given an iterable which elements are tuples (fdesc, chunk), merges the chunks
     with the same fdesc such that they always end with a newline ('\\r\\n').
     Returns an iterator over the reorganized chunks.
 
     For example:
 
     >>> list(_collate_chunks([(1, 'a\\r\\n'), (1, 'b'), (2, 'err\\r\\n'),
     ...                       (1, '\\r\\nc\\r\\n')]))
     [(1, 'a\\r\\n'), (2, 'err\\r\\n'), (1, 'b\\r\\nc\\r\\n')]
-    '''
+    """
     newline_size = len(newline)
     from collections import defaultdict
+
     buff = defaultdict(str)
     for fdesc, chunk in input_data:
         curr = buff[fdesc]
         curr += chunk
         idx = curr.rfind(newline)
         if idx >= 0:
-            yield (fdesc, curr[:idx + newline_size])
-            buff[fdesc] = curr[idx + newline_size:]
+            yield (fdesc, curr[: idx + newline_size])
+            buff[fdesc] = curr[idx + newline_size :]
         else:
             buff[fdesc] = curr
-    for item in buff.items():
+    for item in list(buff.items()):
         if item[1]:
             yield item
 
 
 def call_with_pty(*args, **kwargs):
-    '''
+    """
     Similar to subprocess.call, execute a process, but its stdout and stderr are
     bound to a pty and buffered.
 
     Return a tuple where the first element is the return code of the process and
     the second is an iterable of tuples (fdesc, chunk), with fdesc being 1 for
     stdout and 2 for stderr, and chunk is a string that was written on 'fdesc'.
-    '''
+    """
     out_fds = pty.openpty()
     err_fds = pty.openpty()
     queue = Queue()
 
-    echo = kwargs.pop('echo', False)
+    echo = kwargs.pop("echo", False)
 
-    kwargs['stdout'] = out_fds[1]
-    kwargs['stderr'] = err_fds[1]
+    kwargs["stdout"] = out_fds[1]
+    kwargs["stderr"] = err_fds[1]
     proc = Popen(*args, **kwargs)
 
-    out = _CollectorThread(proc, out_fds[0], queue,
-                           sys.stdout if echo else None)
+    out = _CollectorThread(proc, out_fds[0], queue, sys.stdout if echo else None)
     out.start()
-    err = _CollectorThread(proc, err_fds[0], queue,
-                           sys.stderr if echo else None)
+    err = _CollectorThread(proc, err_fds[0], queue, sys.stderr if echo else None)
     err.start()
 
     def data_gen():
-        '''Helper generator function to present the queue as an iterable.'''
+        """Helper generator function to present the queue as an iterable."""
         fds = {out_fds[0]: 1, err_fds[0]: 2}
         while not queue.empty():
             fdesc, chunk = queue.get()
             yield fds[fdesc], chunk
 
     retcode = proc.wait()
 
@@ -140,38 +142,42 @@
     for fdesc in out_fds + err_fds:
         os.close(fdesc)
 
     return retcode, _collate_chunks(data_gen())
 
 
 def call(*args, **kwargs):
-    '''
+    """
     Similar to subprocess.call, but it supports two new arguments:
 
     @param htmlout: if set, take stdout and stderr and produce HTML code with
                     their content
     @param htmlheader: set it to False to produce only the inner HTML and not
                        the headers
-    '''
-    htmlout = kwargs.pop('htmlout')
-    htmlheader = kwargs.pop('htmlheader', True)
+    """
+    htmlout = kwargs.pop("htmlout")
+    htmlheader = kwargs.pop("htmlheader", True)
     if htmlout is None:
         return _call(*args, **kwargs)
     else:
         from LbNightlyTools.HTMLUtils import XTerm2HTML
+
         if htmlout == STDOUT:
             htmlout = sys.stdout
         retcode, data = call_with_pty(*args, **kwargs)
         conv = XTerm2HTML()
         if htmlheader:
-            htmlout.write(conv.head(title=' '.join(args[0])))
-        style = {1: 'stdout', 2: 'stderr'}
+            htmlout.write(conv.head(title=" ".join(args[0])))
+        style = {1: "stdout", 2: "stderr"}
         for fdesc, chunk in data:
-            htmlout.write('<span class="{}">{}</span>'.format(
-                style[fdesc], conv.process(chunk.replace('\r', ''))))
+            htmlout.write(
+                '<span class="{}">{}</span>'.format(
+                    style[fdesc], conv.process(chunk.replace("\r", ""))
+                )
+            )
         if htmlheader:
             htmlout.write(conv.tail())
         return retcode
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     sys.exit(call(sys.argv[1:], htmlout=STDOUT))
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Utils.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Utils.py`

 * *Files 11% similar despite different names*

```diff
@@ -4,73 +4,90 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Common utility functions.
-'''
-__author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+"""
+from __future__ import print_function
+
+import sys
+
+from future import standard_library
+
+standard_library.install_aliases()
+from builtins import next, object
+
+from past.builtins import basestring
+
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
 
-import os
-import logging
-import shutil
-import json
 import codecs
 import contextlib
+import json
+import logging
+import os
+import re
+import shutil
 import subprocess
 import time
-import urllib2
-import re
+import urllib.error
+import urllib.parse
+import urllib.request
 from datetime import datetime
 
 import gitlab
+from LbPlatformUtils import requires
+from LbPlatformUtils.architectures import ARCH_DEFS, get_supported_archs
 
-DAY_NAMES = ('Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun')
+DAY_NAMES = ("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")
 
 
 def setDayNamesEnv(day=None):
-    '''
+    """
     Set the environment variables TODAY and YESTERDAY if not already set.
 
     @param day: weekday number for 'TODAY', if not specified, defaults to
                 today.
-    '''
+    """
     if day is None:
         day = datetime.today().weekday()
-    os.environ['TODAY'] = os.environ.get('TODAY', DAY_NAMES[day])
+    os.environ["TODAY"] = os.environ.get("TODAY", DAY_NAMES[day])
     # Note: it works for day == 0 too
-    os.environ['YESTERDAY'] = os.environ.get('YESTERDAY', DAY_NAMES[day - 1])
+    os.environ["YESTERDAY"] = os.environ.get("YESTERDAY", DAY_NAMES[day - 1])
 
 
 def _timeoutTerminateCB(proc, msg):
-    '''
+    """
     Safely terminate a running Popen object.
-    '''
+    """
     if proc.poll() is None:
         try:
             logging.warning(msg)
             proc.terminate()
         except:  # pylint: disable=W0702
             pass
 
 
 def timeout_call(*popenargs, **kwargs):
     """Reimplementation of subprocess.call with the addition of a timeout
     option.
     """
     from subprocess import Popen
+
     timer = None
     try:
-        timeout = kwargs.pop('timeout')
-        msg = kwargs.pop('timeoutmsg', 'on command ' + repr(popenargs))
-        msg = 'Timeout reached %s (%ds): terminated.' % (msg, timeout)
+        timeout = kwargs.pop("timeout")
+        msg = kwargs.pop("timeoutmsg", "on command " + repr(popenargs))
+        msg = "Timeout reached %s (%ds): terminated." % (msg, timeout)
         from threading import Timer
+
         proc = Popen(*popenargs, **kwargs)
         timer = Timer(timeout, _timeoutTerminateCB, [proc, msg])
         timer.start()
         result = proc.wait()
         timer.cancel()
         return result
     except KeyError:
@@ -78,49 +95,51 @@
     finally:
         # ensure that we do not wait for the timer if there is an abnormal exit
         if timer:
             timer.cancel()
 
 
 def tee_call(*args, **kwargs):
-    '''
+    """
     Wrapper for Popen to run a command and collect the output.
 
     The arguments are those of Popen, with the addition of
     @param verbose: if True, the output and error are printed while the process
                     is running.
 
     @return: tuple with return code, stdout and stderr
 
     Example:
-    >>> tee_call(['echo hello'], shell=True, verbose=True)
+    >>> result = tee_call(['echo hello'], shell=True, verbose=True)
     hello
-    (0, 'hello\\n', '')
-    '''
-    from subprocess import Popen, PIPE
+    >>> result == (0, b'hello\\n', b'')
+    True
+    """
+    import errno
     import select
     import sys
-    import errno
-    verbose = kwargs.pop('verbose', False)
-    if 'stdout' not in kwargs:
-        kwargs['stdout'] = PIPE
-    if 'stderr' not in kwargs:
-        kwargs['stderr'] = PIPE
+    from subprocess import PIPE, Popen
+
+    verbose = kwargs.pop("verbose", False)
+    if "stdout" not in kwargs:
+        kwargs["stdout"] = PIPE
+    if "stderr" not in kwargs:
+        kwargs["stderr"] = PIPE
 
     proc = Popen(*args, **kwargs)
 
     if not verbose:
         out, err = proc.communicate()
         retcode = proc.returncode
     else:
         # code inspired (mostly copied) from subprocess module
         poller = select.poll()
         files = {
             proc.stdout.fileno(): (proc.stdout, sys.stdout),
-            proc.stderr.fileno(): (proc.stderr, sys.stderr)
+            proc.stderr.fileno(): (proc.stderr, sys.stderr),
         }
         out = []
         err = []
         output = {proc.stdout.fileno(): out, proc.stderr.fileno(): err}
 
         select_POLLIN_POLLPRI = select.POLLIN | select.POLLPRI
 
@@ -131,35 +150,35 @@
             poller.unregister(fd)
             files[fd][0].close()
             files.pop(fd)
 
         while files:
             try:
                 ready = poller.poll()
-            except select.error, e:
+            except select.error as e:
                 if e.args[0] == errno.EINTR:
                     continue
                 raise
             for fd, mode in ready:
                 if mode & select_POLLIN_POLLPRI:
                     data = os.read(fd, 4096)
                     if not data:
                         close_unregister_and_remove(fd)
                     output[fd].append(data)
-                    files[fd][1].write(data)
+                    files[fd][1].write(data.decode("utf-8", errors="replace"))
                 else:
                     # Ignore hang up or errors.
                     close_unregister_and_remove(fd)
         retcode = proc.wait()
 
-    return retcode, b''.join(out), b''.join(err)
+    return retcode, b"".join(out), b"".join(err)
 
 
 def log_call(*args, **kwargs):
-    '''
+    """
     Wrapper for Popen to run a command and collect the output.
 
     The arguments are those of Popen, with the addition of
     @param logger: a logging.Logger instance to be used to print messages
                   [default: default logger].
     @param log_level: level the output of the command should use
                       [default: logging.DEBUG]
@@ -168,141 +187,139 @@
 
     Example:
     >>> import logging
     >>> import sys
     >>> logger = logging.getLogger('hi')
     >>> logger.addHandler(logging.StreamHandler(sys.stdout))
     >>> logger.setLevel(logging.INFO)
-    >>> log_call(['echo hello'], shell=True, logger=logging.getLogger('hi'),
+    >>> result = log_call(['echo hello'], shell=True, logger=logging.getLogger('hi'),
     ... log_level=logging.DEBUG)
-    {'retcode': 0, 'stderr': '', 'stdout': 'hello\\n'}
-    >>> log_call(['echo hello'], shell=True, logger=logging.getLogger('hi'),
-    ... log_level=logging.INFO)
+    >>> result == {'retcode': 0, 'stdout': b'hello\\n', 'stderr': b''}
+    True
+    >>> result = log_call(['echo hello'], shell=True, logger=logging.getLogger('hi'),
+    ... log_level=logging.INFO)  # doctest: +SKIP
     hello
-    {'retcode': 0, 'stderr': '', 'stdout': 'hello\\n'}
-    '''
-    from subprocess import Popen, PIPE
-    import select
+    >>> result == {'retcode': 0, 'stdout': b'hello\\n', 'stderr': b''}
+    True
+    """
     import errno
+    import select
+    from subprocess import PIPE, Popen
 
-    log = kwargs.pop('logger', logging).log
-    log_level = kwargs.pop('log_level', logging.DEBUG)
+    log = kwargs.pop("logger", logging).log
+    log_level = kwargs.pop("log_level", logging.DEBUG)
 
-    if 'stdout' not in kwargs:
-        kwargs['stdout'] = PIPE
-    if 'stderr' not in kwargs:
-        kwargs['stderr'] = PIPE
+    if "stdout" not in kwargs:
+        kwargs["stdout"] = PIPE
+    if "stderr" not in kwargs:
+        kwargs["stderr"] = PIPE
 
     proc = Popen(*args, **kwargs)
 
     # code inspired (mostly copied) from subprocess module
     poller = select.poll()
 
     select_POLLIN_POLLPRI = select.POLLIN | select.POLLPRI
     out = []
     err = []
 
     files = dict((x.fileno(), x) for x in (proc.stdout, proc.stderr) if x)
     output = {proc.stdout.fileno(): out}
     if proc.stderr:
         output[proc.stderr.fileno()] = err
-    spilled_output = dict(
-        (x.fileno(), b'') for x in (proc.stdout, proc.stderr) if x)
+    spilled_output = dict((x.fileno(), b"") for x in (proc.stdout, proc.stderr) if x)
 
     poller.register(proc.stdout, select_POLLIN_POLLPRI)
     if proc.stderr:
         poller.register(proc.stderr, select_POLLIN_POLLPRI)
 
     def close_unregister_and_remove(fd):
         poller.unregister(fd)
         files[fd].close()
         files.pop(fd)
 
     while files:
         try:
             ready = poller.poll()
-        except select.error, e:
+        except select.error as e:
             if e.args[0] == errno.EINTR:
                 continue
             raise
         for fd, mode in ready:
             if mode & select_POLLIN_POLLPRI:
                 data = os.read(fd, 4096)
                 if not data:
                     close_unregister_and_remove(fd)
                 output[fd].append(data)
                 data = spilled_output[fd] + data
-                spilled_output[fd] = b''
+                spilled_output[fd] = b""
                 for line in data.splitlines(True):
-                    if line.endswith(b'\n'):
-                        log(log_level, line.decode().rstrip())
+                    if line.endswith(b"\n"):
+                        log(log_level, line.decode("utf-8", errors="replace").rstrip())
                     else:
                         spilled_output[fd] += line
             else:
                 # Ignore hang up or errors.
                 close_unregister_and_remove(fd)
     retcode = proc.wait()
 
-    return {
-        'retcode': retcode,
-        'stdout': b''.join(out),
-        'stderr': b''.join(err)
-    }
+    return {"retcode": retcode, "stdout": b"".join(out), "stderr": b"".join(err)}
 
 
 def _retry_wrapper(func, check=None):
-    '''
+    """
     Decorator to add retrying to functions.
     The optional predicate 'check' can be used to map the output of 'func' to
     success or failure (default: True -> success)
-    '''
+    """
     if check is None:
         check = bool
 
     from functools import wraps
 
     @wraps(func)
     def wrapped(*args, **kwargs):
-        count = retry = kwargs.pop('retry', 0)
-        retry_sleep = kwargs.pop('retry_sleep', 0)
+        count = retry = kwargs.pop("retry", 0)
+        retry_sleep = kwargs.pop("retry_sleep", 0)
         if retry <= 1:
             # no retry
             return func(*args, **kwargs)
         else:
             while retry:
                 retval = func(*args, **kwargs)
                 if check(retval):
                     return retval
                 retry -= 1
                 if retry and retry_sleep:
                     time.sleep(retry_sleep)
-            raise RuntimeError('the command {0} failed {1} times'.format(
-                args[0], count))
+            raise RuntimeError(
+                "the command {0} failed {1} times".format(args[0], count)
+            )
 
     return wrapped
 
 
 retry_call = _retry_wrapper(subprocess.call, lambda rc: rc == 0)
-retry_tee_call = _retry_wrapper(tee_call, lambda rv: rv['retcode'] == 0)
-retry_log_call = _retry_wrapper(log_call, lambda rv: rv['retcode'] == 0)
+retry_tee_call = _retry_wrapper(tee_call, lambda rv: rv["retcode"] == 0)
+retry_log_call = _retry_wrapper(log_call, lambda rv: rv["retcode"] == 0)
 
 
 def ensureDirs(dirs):
-    '''
+    """
     Ensure that the specified directories exist, creating them if needed.
-    '''
+    """
     if isinstance(dirs, basestring):
-        dirs = (dirs, )
+        dirs = (dirs,)
     for path in dirs:
         if not os.path.exists(path):
             os.makedirs(path)
 
 
 def genDocId(data):
-    '''
+    """
     Internal function to generate the document id from the data dictionary.
 
     The data field used to prepare the id are (in order):
 
          ['slot', 'build_id', 'project', 'platform', 'type']
 
     unless the special field '_id' is defined, in which case its value is used
@@ -315,296 +332,323 @@
     'lhcb-head.123.x86_64-slc6-gcc48-opt.start'
     >>> genDocId({'slot': 'lhcb-head', 'build_id': 123,
     ... 'platform': 'x86_64-slc6-gcc48-opt', 'type': 'tests',
     ... 'project': 'Gaudi'})
     'lhcb-head.123.Gaudi.x86_64-slc6-gcc48-opt.tests'
     >>> genDocId({'slot': 'lhcb-head', '_id': 'something'})
     'something'
-    '''
-    if '_id' in data:
-        return data['_id']
-    fields = ['slot', 'build_id', 'project', 'platform', 'type']
-    return '.'.join([str(data[f]) for f in fields if f in data])
+    """
+    if "_id" in data:
+        return data["_id"]
+    fields = ["slot", "build_id", "project", "platform", "type"]
+    return ".".join([str(data[f]) for f in fields if f in data])
 
 
 def wipeDir(path):
-    '''
+    """
     Helper function to remove a directory.
-    '''
+    """
     # FIXME: this can be done asynchronously
-    logging.info('Removing directory %s', path)
+    logging.info("Removing directory %s", path)
     if os.path.exists(path):
         shutil.rmtree(path)
         ensureDirs([path])
 
 
 def recursive_update(dest, data):
-    '''
+    """
     Similar to dict.update, update a dictionary with the entries from
     another one, but do it recursively, if the element in both sides are
     dictionaries.
 
     >>> a = {'a': {'x': 1}, 'b': {'n': 0}, 'c': [1, 2, 3]}
     >>> b = {'a': {'y': 2}, 'b': 'abc', 'c': {}}
-    >>> recursive_update(a, b)
-    {'a': {'y': 2, 'x': 1}, 'c': {}, 'b': 'abc'}
-    >>> a
-    {'a': {'y': 2, 'x': 1}, 'c': {}, 'b': 'abc'}
+    >>> recursive_update(a, b) == {'a': {'x': 1, 'y': 2}, 'b': 'abc', 'c': {}}
+    True
+    >>> a == {'a': {'x': 1, 'y': 2}, 'b': 'abc', 'c': {}}
+    True
 
     It can also be used to deep clone a dictionary:
 
     >>> a = {'a': {'a': {'a': 1}}, 'b': [1, 2, 3]}
     >>> copy = {}
-    >>> recursive_update(copy, a)
-    {'a': {'a': {'a': 1}}, 'b': [1, 2, 3]}
+    >>> _ = recursive_update(copy, a)
     >>> copy == a
     True
     >>> copy is a
     False
     >>> copy['a'] is a['a']
     False
-    '''
-    from collections import MutableMapping, Mapping
+    """
+    try:
+        # Python 3
+        from collections.abc import Mapping, MutableMapping
+    except ImportError:
+        # Python 2
+        from collections import Mapping, MutableMapping
+
     if not isinstance(dest, MutableMapping):
-        raise TypeError('argument 1 must be a mutable mapping')
+        raise TypeError("argument 1 must be a mutable mapping")
     if not isinstance(data, Mapping):  # try to convert to dictionary
         data = dict(data)
     for k in data:
         try:
             if k not in dest:
                 dest[k] = type(data[k])()
             recursive_update(dest[k], data[k])
         except (TypeError, ValueError):
             dest[k] = data[k]
     return dest
 
 
+class SlotAborted(Exception):
+    """
+    Exception raised when a slot was aborted.
+    """
+
+    pass
+
+
 class Dashboard(object):
-    '''
+    """
     Wrapper for the CouchDB-based dashboard.
-    '''
-    if os.environ.get('PRIVATE_DIR'):
-        CRED_FILE = os.path.join(os.environ['PRIVATE_DIR'], 'couchdb-admin')
+    """
+
+    if os.environ.get("PRIVATE_DIR"):
+        CRED_FILE = os.path.join(os.environ["PRIVATE_DIR"], "couchdb-admin")
     else:
-        CRED_FILE = os.path.expanduser(
-            os.path.join('~', 'private', 'couchdb-admin'))
+        CRED_FILE = os.path.expanduser(os.path.join("~", "private", "couchdb-admin"))
 
-    SERVER_URL = os.environ.get('COUCHDB_HOST',
-                                'https://lhcb-couchdb.cern.ch/')
+    SERVER_URL = os.environ.get("COUCHDB_HOST", "https://lhcb-couchdb.cern.ch/")
 
     @classmethod
     def dbName(cls, flavour):
-        '''
+        """
         Return database name for the given flavour.
-        '''
-        return 'nightlies-{0}'.format(flavour)
+        """
+        return "nightlies-{0}".format(flavour)
 
-    def __init__(self,
-                 credentials=None,
-                 flavour='nightly',
-                 server=None,
-                 dbname=None):
-        '''
+    def __init__(self, credentials=None, flavour="nightly", server=None, dbname=None):
+        """
         @param credentials: pair with (username, password) of a valid account
                             on the server
         @param flavour: build flavour, used to select the database to use
         @param server: URL of the server
         @param dbname: database name (overrides flavour)
-        '''
-        import couchdb
+        """
         import socket
 
-        self._log = logging.getLogger('Dashboard')
+        import couchdb
+
+        self._log = logging.getLogger("Dashboard")
 
         if credentials is None:
             cred_data = None
             if os.path.exists(self.CRED_FILE):
-                self._log.debug('taking credentials from %s', self.CRED_FILE)
+                self._log.debug("taking credentials from %s", self.CRED_FILE)
                 cred_data = open(self.CRED_FILE).read()
-            elif os.environ.get('COUCHDB_ADMIN'):
-                self._log.debug('taking credentials from COUCHDB_ADMIN')
-                cred_data = os.environ['COUCHDB_ADMIN']
+            elif os.environ.get("COUCHDB_ADMIN"):
+                self._log.debug("taking credentials from COUCHDB_ADMIN")
+                cred_data = os.environ["COUCHDB_ADMIN"]
 
             if cred_data:
                 # make a tuple with the first two lines of the file
-                credentials = tuple(
-                    [l.strip() for l in cred_data.splitlines()][:2])
+                credentials = tuple([l.strip() for l in cred_data.splitlines()][:2])
             else:
-                self._log.warning('no couchdb credentials found')
+                self._log.warning("no couchdb credentials found")
 
         self.flavour = flavour
 
         if not server:
             server = self.SERVER_URL
-        if not server.endswith('/'):
-            server += '/'
+        if not server.endswith("/"):
+            server += "/"
         if not dbname:
             dbname = self.dbName(flavour)
 
-        self._log.debug('preparing connection to dashboard (%s%s)', server,
-                        dbname)
+        self._log.debug("preparing connection to dashboard (%s%s)", server, dbname)
         self.server = couchdb.Server(server)
         self.server.resource.credentials = credentials
         self.db = self.server[dbname]
-        self._log.debug('connected')
+        self._log.debug("connected")
 
     def lastBuildId(self, slot):
-        '''
+        """
         Return the latest build id recorded for the given slot.
-        '''
+        """
         # the keys in the view are [slot, id] or [slot, id, platform]
         # id is numeric and '.' counts as larger than any number
-        rows = list(
-            self.db.view('summaries/lastBuildId', key=slot, group=True))
+        rows = list(self.db.view("summaries/lastBuildId", key=slot, group=True))
         return rows[0].value if rows else 0
 
     def urlForKey(self, key):
-        '''
+        """
         Return the URL that can be used for retrieveing the data for a given key.
-        '''
-        return '/'.join((self.db.resource.url, key))
+        """
+        return "/".join((self.db.resource.url, key))
 
     def update(self, key, changes):
-        '''
+        """
         Update the content of an object in the database.
 
         @param key: object id in the database
         @param changes: either a dictionary to update the content of the object
                         with or a callable accepting a dict as input and
                         returning the updated object
-        '''
-        from couchdb import ResourceConflict, ServerError
+        """
         from time import sleep
-        self._log.debug('updating %s', self.urlForKey(key))
+
+        from couchdb import ResourceConflict, ServerError
+
+        self._log.debug("updating %s", self.urlForKey(key))
 
         if callable(changes):
             chg = changes
         else:
 
             def chg(d):
                 return recursive_update(d, changes)
 
         allowed_server_errors = 3
         seconds_between_server_retries = 60
         while True:
             # this will be the error message if the changes cannot be applied
-            new = ': cannot apply changes'
+            new = ": cannot apply changes"
             try:
                 old = self.db.get(key, {})
                 # work on a clone of the object to detect actual changes
                 new = chg(json.loads(json.dumps(old)))
                 if new != old:
                     self.db[key] = new
                 else:
-                    self._log.debug('no change')
+                    self._log.debug("no change")
                 break
             except ResourceConflict:
-                self._log.debug('conflict updating %r, retrying', key)
+                self._log.debug("conflict updating %r, retrying", key)
             except ServerError as err:
-                self._log.warning('problems contacting the server: %s', err)
+                self._log.warning("problems contacting the server: %s", err)
                 if allowed_server_errors >= 0:
-                    self._log.debug('retrying in %d s',
-                                    seconds_between_server_retries)
+                    self._log.debug("retrying in %d s", seconds_between_server_retries)
                     sleep(seconds_between_server_retries)
                     allowed_server_errors -= 1
                 else:
-                    self._log.error('failed to connect to %s, giving up',
-                                    self.server.resource.url)
+                    self._log.error(
+                        "failed to connect to %s, giving up", self.server.resource.url
+                    )
                     exit(2)
             except:
-                self._log.debug('failed to store %r', new)
+                self._log.debug("failed to store %r", new)
                 raise
 
     def __getitem__(self, key):
         return self.db[key]
 
+    def assert_not_aborted(self, key):
+        """
+        Raise SlotAborted exception if the slot is flagged as aborted
+        """
+        try:
+            info = self.db[key].get("aborted")
+            if info:
+                raise SlotAborted(key, info)
+        except KeyError:
+            pass
+
 
 class TaskQueue(object):
-    '''
+    """
     Simple class to schedule asynchronous operations.
-    '''
+    """
 
     def __init__(self):
-        '''
+        """
         Initialize the task queue, the worker thread will be started if needed.
-        '''
-        from Queue import Queue
+        """
+        from queue import Queue
+
         self.queue = Queue()
         self._thread = None
 
     @property
     def thread(self):
-        '''
+        """
         Worker thread, created on demand.
-        '''
+        """
         if self._thread is None or not self._thread.is_alive():
 
             def worker(q):
-                'Worker main loop.'
+                "Worker main loop."
                 while True:
                     try:
                         action, args, kwargs = q.get()
                         action(*args, **kwargs)
                     finally:
                         q.task_done()
 
             from threading import Thread
-            self._thread = Thread(target=worker, args=(self.queue, ))
+
+            self._thread = Thread(target=worker, args=(self.queue,))
             # do not wait for the thread when exiting the application
             self._thread.daemon = True
             self._thread.start()
 
         return self._thread
 
     def add(self, task, args=None, kwargs=None):
-        '''
+        """
         Add a new task to the queue.
 
         @param task: callable to be executed
         @param args: positional arguments to pass to the task callable
         @param kwargs: keyword arguments to pass to the task callable
-        '''
-        assert self.thread and self.thread.is_alive(), \
-            'worker thread not available'
+        """
+        assert self.thread and self.thread.is_alive(), "worker thread not available"
         if args is None:
             args = tuple()
         if kwargs is None:
             kwargs = {}
         self.queue.put((task, args, kwargs))
 
     def join(self):
-        '''
+        """
         Waits until all the tasks completed.
-        '''
+        """
         self.queue.join()
 
 
 class JenkinsTest(object):
-    '''
+    """
     Class representing a test ready to be run
-    '''
+    """
 
     SLOT = "slot"
     SBID = "slot_build_id"
     PROJECT = "project"
     PLATFORM = "platform"
     TESTGROUP = "testgroup"
     TESTRUNNER = "testrunner"
     TESTENV = "testenv"
     LABEL = "os_label"
     COUNT = "count"
     JOB_ALLATTRIBUTES = [
-        SLOT, SBID, PROJECT, PLATFORM, LABEL, TESTGROUP, TESTRUNNER, TESTENV,
-        COUNT
+        SLOT,
+        SBID,
+        PROJECT,
+        PLATFORM,
+        LABEL,
+        TESTGROUP,
+        TESTRUNNER,
+        TESTENV,
+        COUNT,
     ]
 
     @classmethod
     def fromJenkinsString(cls, test_string):
-        ''' Build the obkject from the string passed to Jenkins '''
-        test_list = test_string.split('.')
+        """Build the obkject from the string passed to Jenkins"""
+        test_list = test_string.split(".")
         slot = test_list[0]
         slot_build_id = test_list[1]
         project = test_list[2]
         platform = test_list[3]
         os_label = None
         testgroup = None
         testrunner = None
@@ -614,285 +658,315 @@
         # Check it the param nb 5 is specified and if it is != None
         if len(test_list) > 4:
             if test_list[4].lower() != "none":
                 os_label = test_list[4]
 
         # If the label is still None, we take it from teh platform
         if os_label is None:
-            os_label = platform.split('-')[1]
+            os_label = platform.split("-")[1]
 
         # Now check for the test group and runner
         if len(test_list) > 5:
             testgroup = test_list[5]
 
         if len(test_list) > 6:
             testrunner = test_list[6]
 
         if len(test_list) > 7:
             testenv = test_list[7]
 
         if len(test_list) > 8:
             count = test_list[8]
 
-        return JenkinsTest(slot, slot_build_id, project, platform, os_label,
-                           testgroup, testrunner, testenv, count)
+        return JenkinsTest(
+            slot,
+            slot_build_id,
+            project,
+            platform,
+            os_label,
+            testgroup,
+            testrunner,
+            testenv,
+            count,
+        )
 
     @classmethod
     def fromScheduledTest(cls, stest):
-        ''' Build the object from a scheduled test object '''
-        return JenkinsTest(stest.slot, stest.build_id, stest.project,
-                           stest.platform, stest.os_label, stest.testgroup,
-                           stest.testrunner, stest.testenv, stest.count)
-
-    def __init__(self,
-                 slot,
-                 slot_build_id,
-                 project,
-                 platform,
-                 os_label=None,
-                 testgroup=None,
-                 testrunner=None,
-                 testenv=None,
-                 count=1):
-        ''' Basic constructor '''
+        """Build the object from a scheduled test object"""
+        return JenkinsTest(
+            stest.slot,
+            stest.build_id,
+            stest.project,
+            stest.platform,
+            stest.os_label,
+            stest.testgroup,
+            stest.testrunner,
+            stest.testenv,
+            stest.count,
+        )
+
+    def __init__(
+        self,
+        slot,
+        slot_build_id,
+        project,
+        platform,
+        os_label=None,
+        testgroup=None,
+        testrunner=None,
+        testenv=None,
+        count=1,
+    ):
+        """Basic constructor"""
         self.slot_build_id = slot_build_id
         self.slot = slot
         self.project = project
         self.platform = platform
         self.testgroup = testgroup
         self.testrunner = testrunner
         self.os_label = os_label
         self.testenv = testenv
         self.count = count
 
     def getParameterLines(self):
-        ''' Returns a list of key=value lines for each parameter '''
-        return ([
-            '%s=%s\n' % (x, getattr(self, x))
-            for x in JenkinsTest.JOB_ALLATTRIBUTES
-        ])
+        """Returns a list of key=value lines for each parameter"""
+        return [
+            "%s=%s\n" % (x, getattr(self, x)) for x in JenkinsTest.JOB_ALLATTRIBUTES
+        ]
 
     def toJenkinsString(self):
-        ''' Generate the job description for Jenkins '''
-        return '.'.join([
-            self.slot,
-            str(self.slot_build_id), self.project, self.platform,
-            self.os_label if self.os_label else "None", self.testgroup,
-            self.testrunner if self.testrunner else "qmtest",
-            self.testenv if self.testenv else "None",
-            str(self.count)
-        ])
+        """Generate the job description for Jenkins"""
+        return ".".join(
+            [
+                self.slot,
+                str(self.slot_build_id),
+                self.project,
+                self.platform,
+                self.os_label if self.os_label else "None",
+                self.testgroup,
+                self.testrunner if self.testrunner else "qmtest",
+                self.testenv if self.testenv else "None",
+                str(self.count),
+            ]
+        )
 
     def __str__(self):
-        '''
+        """
         Convert to string
-        '''
-        return ".".join([
-            "%s=%s" % (k, getattr(self, k))
-            for k in JenkinsTest.JOB_ALLATTRIBUTES
-        ])
+        """
+        return ".".join(
+            ["%s=%s" % (k, getattr(self, k)) for k in JenkinsTest.JOB_ALLATTRIBUTES]
+        )
 
 
-def _packcmd(srcs, dest, cwd='.', dereference=True, exclude=None):
-    '''
+def _packcmd(srcs, dest, cwd=".", dereference=True, exclude=None):
+    """
     Helper function to call the packing command.
-    '''
+    """
     from subprocess import call
-    cmd = ['zip', '-r', '-q']
+
+    cmd = ["zip", "-r", "-q"]
     if not dereference:
-        cmd.append('-y')
+        cmd.append("-y")
     cmd.append(dest)
-    cmd.append('-@')
+    cmd.append("-@")
     if exclude:
-        for n in exclude:
-            cmd.extend(['-x', n])
+        for n in [tpl.format(x) for x in exclude for tpl in ("{}", "{}/", "{}/**")]:
+            cmd.extend(["-x", n])
 
     from tempfile import TemporaryFile
-    with TemporaryFile() as file_list:
-        file_list.write('\n'.join(srcs))
-        file_list.write('\n')
+
+    with TemporaryFile("w+") as file_list:
+        file_list.write("\n".join(srcs))
+        file_list.write("\n")
         file_list.flush()
         file_list.seek(0)
         try:
             result = call(cmd, cwd=cwd, stdin=file_list)
         except Exception as x:
-            log = logging.getLogger('_packcmd')
-            log.warning('exception while packing: %s: %s', type(x).__name__, x)
+            log = logging.getLogger("_packcmd")
+            log.warning("exception while packing: %s: %s", type(x).__name__, x)
             result = 9
     return result
 
 
-def _packtestcmd(srcs_, dest, cwd='.', dereference=True, exclude=None):
-    '''
+def _packtestcmd(srcs_, dest, cwd=".", dereference=True, exclude=None):
+    """
     Helper function to call the package test command.
-    '''
+    """
     from subprocess import call
-    return call(['unzip', '-t', '-q', dest], cwd=cwd)
+
+    return call(["unzip", "-t", "-q", dest], cwd=cwd)
 
 
 def _find_broken_links(*args, **kwargs):
-    '''
+    """
     Find all broken links in the paths passed as arguments.
 
     Optionally, one can pass the root directory to start from as cwd.
-    '''
-    cwd = kwargs.get('cwd', '.')
+    """
+    cwd = kwargs.get("cwd", ".")
     for rel_src in args:
         src = os.path.join(cwd, rel_src)
         if os.path.isdir(src):
             for brklnk in _find_broken_links(
-                    *[
-                        os.path.join(rel_src, f) for f in os.listdir(src)
-                        if f not in (os.curdir, os.pardir)
-                    ],
-                    cwd=cwd):
+                *[
+                    os.path.join(rel_src, f)
+                    for f in os.listdir(src)
+                    if f not in (os.curdir, os.pardir)
+                ],
+                cwd=cwd
+            ):
                 yield brklnk
         elif os.path.islink(src) and not os.path.exists(src):
             yield rel_src
 
 
-def pack(srcs, dest, cwd='.', checksum=None, dereference=True, exclude=None):
-    '''
+def pack(srcs, dest, cwd=".", checksum=None, dereference=True, exclude=None):
+    """
     Package the directories 'srcs' into the package (tarball) 'dest' working
     from the directory 'cwd'.
     If a string is passed as 'checksum', together with the package a checksum
     file is produced with name <dest>.<checksum>.  The supported checksum types
     are those understood by the hashlib module (e.g. 'md5', 'sha1', etc.).
 
     If the creation of the package fails or the package is not consistent with
     the files to be packed, the packing is retried up to 3 times.
-    '''
-    log = logging.getLogger('pack')
+    """
+    log = logging.getLogger("pack")
 
     if dereference:
         # check that we do not have broken links
         if not exclude:
             exclude = []
 
         def broken_link(path):
-            'helper to report broken links'
-            log.warning('ignore broken link %s', path)
+            "helper to report broken links"
+            log.warning("ignore broken link %s", path)
             return path
 
-        exclude.extend(
-            broken_link(bl) for bl in _find_broken_links(*srcs, cwd=cwd))
+        exclude.extend(broken_link(bl) for bl in _find_broken_links(*srcs, cwd=cwd))
 
     ensureDirs(os.path.dirname(dest))
     ok = False
     retry = 3
     while (not ok) and (retry >= 0):
         retry -= 1
-        srcs_msg = ', '.join(srcs[:4]) + ('...' if len(srcs) > 4 else '')
-        log.debug('packing %s as %s (from %s)', srcs_msg, dest, cwd)
+        srcs_msg = ", ".join(srcs[:4]) + ("..." if len(srcs) > 4 else "")
+        log.debug("packing %s as %s (from %s)", srcs_msg, dest, cwd)
         if _packcmd(srcs, dest, cwd, dereference, exclude) != 0:
-            log.warning('failed to produce %s', dest)
+            log.warning("failed to produce %s", dest)
             continue
 
-        log.debug('checking %s', dest)
+        log.debug("checking %s", dest)
         if _packtestcmd(srcs, dest, cwd, dereference, exclude) != 0:
-            log.warning('invalid package %s', dest)
+            log.warning("invalid package %s", dest)
             continue
 
         if checksum:
             import hashlib
+
             absdest = os.path.join(cwd, dest)
             hashsum = hashlib.new(checksum)
-            log.debug('computing checksum (%s)', checksum)
-            with open(absdest, 'rb') as packfile:
-                for chunk in iter(lambda: packfile.read(8192), ''):
+            log.debug("computing checksum (%s)", checksum)
+            with open(absdest, "rb") as packfile:
+                for chunk in iter(lambda: packfile.read(8192), b""):
                     hashsum.update(chunk)
-            with open(absdest + '.' + checksum, 'w') as checkfile:
-                checkfile.write('%s *%s\n' % (hashsum.hexdigest(),
-                                              os.path.basename(absdest)))
-            log.debug('checksum written to %s', dest + '.' + checksum)
+            with open(absdest + "." + checksum, "w") as checkfile:
+                checkfile.write(
+                    "%s *%s\n" % (hashsum.hexdigest(), os.path.basename(absdest))
+                )
+            log.debug("checksum written to %s", dest + "." + checksum)
         # everything seems correct, stop retrying
         ok = True
     if not ok:
         log.error("failed to pack %s, I'm ignoring it", srcs)
         if os.path.exists(os.path.join(cwd, dest)):
             os.remove(os.path.join(cwd, dest))
 
 
 def shallow_copytree(src, dst, ignore=None):
-    '''Create a shallow (made of symlinks) copy of a directory tree.
+    """Create a shallow (made of symlinks) copy of a directory tree.
 
     The destination directory might exist and in that case it will be
     recursively filled with links pointing to the corresponding entries inside
     the source directory.
     If the destination does not exist, then shallow_copytree is equivalent to
     os.symlink.
 
     The optional argument `ignore` is a callable with the same semantics of
     the equivalent argument of shutil.copytree:
 
        callable(src, names) -> ignored_names
 
-    '''
+    """
     src = os.path.realpath(src)
     if not os.path.exists(dst):
         os.symlink(src, dst)
     elif os.path.isdir(src):
-        names = [name for name in os.listdir(src) if name not in ('.', '..')]
+        names = [name for name in os.listdir(src) if name not in (".", "..")]
         ignored_names = set() if ignore is None else set(ignore(src, names))
         for name in set(names) - ignored_names:
-            shallow_copytree(
-                os.path.join(src, name), os.path.join(dst, name), ignore)
+            shallow_copytree(os.path.join(src, name), os.path.join(dst, name), ignore)
 
 
 def find_path(name, search_path=None):
-    '''
+    """
     Look for a file or directory in a search path.
 
     If the search path is not specified, the concatenation of CMTPROJECTPATH
     and CMAKE_PREFIX_PATH is used.
 
     >>> find_path('true', ['/usr/local/bin', '/bin'])
     '/bin/true'
-    >>> print find_path('cannot_find_me', [])
+    >>> print(find_path('cannot_find_me', []))
     None
-    '''
+    """
     from os import environ, pathsep
-    from os.path import join, exists
+    from os.path import exists, join
+
     if search_path is None:
-        search_path = (environ.get('CMAKE_PREFIX_PATH', '').split(pathsep) +
-                       environ.get('CMTPROJECTPATH', '').split(pathsep))
+        search_path = environ.get("CMAKE_PREFIX_PATH", "").split(pathsep) + environ.get(
+            "CMTPROJECTPATH", ""
+        ).split(pathsep)
 
     try:
         return next(
-            join(path, name) for path in search_path
-            if exists(join(path, name)))
+            join(path, name) for path in search_path if exists(join(path, name))
+        )
     except StopIteration:
-        logging.warning('%s not found in %r', name, search_path)
+        logging.warning("%s not found in %r", name, search_path)
     return None
 
 
 class IgnorePackageVersions(object):
-    '''
+    """
     Helper class which instances can be used as ignore argument of
     shallow_copytree to ignore versions of packages when cloning a container
     project.
-    '''
+    """
 
     def __init__(self, packages):
-        '''
+        """
         @param packages: list of objects describing packages, which must have a
                          property 'name' and a property 'version'
-        '''
+        """
         self._exclusions = dict(
-            (os.path.basename(pack.name), [pack.version]) for pack in packages)
+            (os.path.basename(pack.name), [pack.version]) for pack in packages
+        )
 
     def __call__(self, src, names):
-        '''
+        """
         Implements the semantic of the 'ignore' argument of shallow_copytree.
-        '''
+        """
         return self._exclusions.get(os.path.basename(src), [])
 
 
 def applyenv(envdict, definitions):
-    '''
+    """
     Modify the environment  described by 'envdict' from a list of definitions
     of the type 'name=value', expanding the variables in 'value'.
 
     >>> env = {}
     >>> applyenv(env, ['foo=bar'])
     >>> env['foo']
     'bar'
@@ -902,407 +976,478 @@
 
     If a variable in the value is not known, it is replaces with an empty
     string:
 
     >>> applyenv(env, ['unknown=${var}'])
     >>> env['unknown']
     ''
-    '''
-    from string import Template
+    """
     from collections import defaultdict
+    from string import Template
+
     # use a temporary dictionary where unkown values default to ''
     tmp = defaultdict(str, envdict)
     # keep track of all explicitly set names
     all_names = set(envdict)
     # apply changes
     for item in definitions:
-        name, value = item.split('=', 1)
+        name, value = item.split("=", 1)
         all_names.add(name)
         tmp[name] = Template(value).safe_substitute(tmp)
     # copy changes in the input dictionary excluding the variables
     # created as temporary empty placeholders
-    envdict.update((k, v) for k, v in tmp.items() if k in all_names)
+    envdict.update((k, v) for k, v in list(tmp.items()) if k in all_names)
 
 
 def setenv(definitions):
-    '''
+    """
     Modify the environment from a list of definitions of the type 'name=value',
     expanding the variables in 'value'.
 
     >>> setenv(['foo=bar'])
     >>> os.environ['foo']
     'bar'
 
     @note: it is equivalent to 'applyenv(os.environ, definitions)'
-    '''
+    """
     applyenv(os.environ, definitions)
 
 
 @contextlib.contextmanager
 def chdir(dirname=None, create=False):
-    '''
+    """
     Context manager useful to switch to a directory for a context block and
     back to the previous location once we are out put the block.
 
     See http://www.astropython.org/snippet/2009/10/chdir-context-manager
-    '''
+    """
     curdir = os.getcwd()
     try:
         if dirname is not None:
             if not os.path.isdir(dirname) and create:
                 os.makedirs(dirname)
             os.chdir(dirname)
         yield
     finally:
         os.chdir(curdir)
 
 
 def write_patch(patchfile, olddata, newdata, filename):
-    '''
+    """
     Write the difference between olddata and newdata (of filename) in
     patchfile.
 
     @param patchfile: file object to which write the differences
     @param olddata: old version of the data
     @param newdata: new version of teh data
     @param fileanme: name of the file to be used in the diff headers
-    '''
+    """
     from difflib import context_diff
-    if hasattr(olddata, 'splitlines'):
+
+    if hasattr(olddata, "splitlines"):
         olddata = olddata.splitlines(True)
-    if hasattr(newdata, 'splitlines'):
+    if hasattr(newdata, "splitlines"):
         newdata = newdata.splitlines(True)
     for l in context_diff(
-            olddata,
-            newdata,
-            fromfile=os.path.join('a', filename),
-            tofile=os.path.join('b', filename)):
+        olddata,
+        newdata,
+        fromfile=os.path.join("a", filename),
+        tofile=os.path.join("b", filename),
+    ):
         patchfile.write(l)
 
 
 class JobParams(object):
-    '''
+    """
     Helper class to format job parameters.
 
-    >>> print JobParams(b='x', a=1)
+    >>> print(JobParams(b='x', a=1))
     a=1
     b=x
-    '''
+    """
 
     def __init__(self, **kwargs):
-        '''
+        """
         Initialize the instance
-        '''
+        """
         self.__dict__.update(kwargs)
 
     def __str__(self):
-        '''
+        """
         Convert the instance to parameter file format.
-        '''
+        """
         data = []
         for k in sorted(self.__dict__):
-            if not k.startswith('_'):
-                data.append('{0}={1}'.format(k, getattr(self, k)))
-        return '\n'.join(data)
+            if not k.startswith("_"):
+                data.append("{0}={1}".format(k, getattr(self, k)))
+        return "\n".join(data)
 
 
-def postToMergeRequest(name_or_id,
-                       mreq_iid,
-                       message,
-                       new_comment=False,
-                       token=None):
-    '''
+def postToMergeRequest(name_or_id, mreq_iid, message, new_comment=False, token=None):
+    """
     Add the passed message as comment to a merge request in gitlab.cern.ch.
 
     @param name_or_id: qualified name or id of a project in gitlab
     @param mreq_iid: local id of the merge request
     @param message: what to post to the merge request
     @param new_comment: whether to always post a new comment or edit
     @param token: gitlab API token (default: os.environ['GITLAB_TOKEN'])
-    '''
-    server = gitlab.Gitlab('https://gitlab.cern.ch/', token
-                           or os.environ['GITLAB_TOKEN'])
-    logging.debug('looking for merge request %s in project %s', mreq_iid,
-                  name_or_id)
+    """
+    server = gitlab.Gitlab(
+        "https://gitlab.cern.ch/", token or os.environ["GITLAB_TOKEN"]
+    )
+    logging.debug("looking for merge request %s in project %s", mreq_iid, name_or_id)
     try:
         project = server.projects.get(name_or_id)
         mreq = project.mergerequests.get(mreq_iid)
         if new_comment:
-            mreq.notes.create({'body': message})
+            mreq.notes.create({"body": message})
         else:
             time_tag = datetime.now().strftime("%Y-%m-%d %H:%M")
-            message = '- __[{}]__ {}'.format(time_tag, message)
+            message = "- __[{}]__ {}".format(time_tag, message)
             server.auth()  # sets server.user to the authenticated user
-            all_notes = mreq.notes.list(order_by='created_at', sort='desc')
+            all_notes = mreq.notes.list(order_by="created_at", sort="desc")
             # NB: replying to a plain note makes it a discussion, so next
             # time it won't be found and a new one will be made.
             own_plain_notes = [
-                note for note in all_notes
-                if (note.author['id'] == server.user.id and not note.system
-                    and note.type != 'DiscussionNote')
+                note
+                for note in all_notes
+                if (
+                    note.author["id"] == server.user.id
+                    and not note.system
+                    and note.type != "DiscussionNote"
+                )
             ]
             if own_plain_notes:
                 last_note = own_plain_notes[0]
-                last_note.body = last_note.body + '\n' + message
+                last_note.body = last_note.body + "\n" + message
                 last_note.save()
             else:
-                mreq.notes.create({'body': message})
-    except Exception, err:
+                mreq.notes.create({"body": message})
+    except Exception as err:
         logging.error(str(err))
         raise
 
 
 def getMRTitle(name_or_id, mreq_iid, token=None):
-    '''
+    """
     Return the title of a merge request in gitlab.cern.ch.
 
     @param name_or_id: qualified name or id of a project in gitlab
     @param mreq_iid: local id of the merge request
     @param token: gitlab API token (default: os.environ['GITLAB_TOKEN'])
-    '''
-    token = token or os.environ.get('GITLAB_TOKEN')
+    """
+    token = token or os.environ.get("GITLAB_TOKEN")
     if not token:
         # the MR title is icing on the cake, we do not need to fail
-        return ''
+        return ""
 
-    server = gitlab.Gitlab('https://gitlab.cern.ch/', token)
-    logging.debug('looking for merge request %s in project %s', mreq_iid,
-                  name_or_id)
+    server = gitlab.Gitlab("https://gitlab.cern.ch/", token)
+    logging.debug("looking for merge request %s in project %s", mreq_iid, name_or_id)
     try:
         project = server.projects.get(name_or_id)
         mreq = project.mergerequests.get(mreq_iid)
         return mreq.title
-    except Exception, err:
+    except Exception as err:
         logging.error(str(err))
         raise
 
 
 def getMRTargetBranch(name_or_id, mreq_iid, token=None):
-    '''
+    """
     Return the target branch of a merge request in gitlab.cern.ch.
 
     @param name_or_id: qualified name or id of a project in gitlab
     @param mreq_iid: local id of the merge request
     @param token: gitlab API token (default: os.environ['GITLAB_TOKEN'])
-    '''
-    token = token or os.environ.get('GITLAB_TOKEN')
+    """
+    token = token or os.environ.get("GITLAB_TOKEN")
     if not token:
         # if we cannot interrogate Gitlab, we can assume 'master'
-        return 'master'
+        return "master"
 
-    server = gitlab.Gitlab('https://gitlab.cern.ch/', token)
-    logging.debug('looking for merge request %s in project %s', mreq_iid,
-                  name_or_id)
+    server = gitlab.Gitlab("https://gitlab.cern.ch/", token)
+    logging.debug("looking for merge request %s in project %s", mreq_iid, name_or_id)
     try:
         project = server.projects.get(name_or_id)
         mreq = project.mergerequests.get(mreq_iid)
         return mreq.target_branch
-    except Exception, err:
+    except Exception as err:
         logging.error(str(err))
         raise
 
 
-def getAllMergeRequestIDs(name_or_id,
-                          state='opened',
-                          filters=None,
-                          labels=None,
-                          token=None):
-    '''
+def getAllMergeRequestIDs(
+    name_or_id, state="opened", filters=None, labels=None, token=None
+):
+    """
     Return a list of all the ids of the merge resquests of a project in GitLab.
 
     @param name_or_id:  name or id of the project
     @param state: state of the merge request (usually 'opened')
-    '''
-    server = gitlab.Gitlab('https://gitlab.cern.ch/', token
-                           or os.environ['GITLAB_TOKEN'])
-    logging.debug('looking for %s merge requests in project %s', state,
-                  name_or_id)
+    """
+    server = gitlab.Gitlab(
+        "https://gitlab.cern.ch/", token or os.environ["GITLAB_TOKEN"]
+    )
+    logging.debug("looking for %s merge requests in project %s", state, name_or_id)
     try:
         if filters:
-            filters = [f.split('=', 1) for f in filters if '=' in f]
+            filters = [f.split("=", 1) for f in filters if "=" in f]
         else:
             filters = []
 
         if labels is None:
             labels = []
         elif isinstance(labels, basestring):
             labels = [labels]
         labels = set(labels)
 
         def accepted(mr):
-            '''
+            """
             Helper to keep only mrege requests matching the filters.
-            '''
+            """
             # first apply the filters
             for k, v in filters:
                 if str(getattr(mr, k)) != v:
                     return False
             # of what remains we accept
             #  - those with the right label, if specified
             return labels.intersection(mr.labels)
 
         project = server.projects.get(name_or_id)
         mrs = [
-            mr.iid for mr in project.mergerequests.list(state=state, all=True)
+            mr.iid
+            for mr in project.mergerequests.list(state=state, all=True)
             if accepted(mr)
         ]
         mrs.sort()
         return mrs
     except Exception as err:
         logging.error(str(err))
         raise
 
 
 def gitlabProjectExists(project):
-    '''
+    """
     Quick check to see if a project exists and is public in Gitlab.
-    '''
+    """
     try:
-        logging.debug('probing %s in Gitlab', project)
-        url = ('https://gitlab.cern.ch/{}.git'
-               '/info/refs?service=git-upload-pack').format(project)
-        return urllib2.urlopen(url).getcode() == 200
+        logging.debug("probing %s in Gitlab", project)
+        url = (
+            "https://gitlab.cern.ch/{}.git" "/info/refs?service=git-upload-pack"
+        ).format(project)
+        return urllib.request.urlopen(url).getcode() == 200
     except Exception:
         return False
 
 
 MR_COMMENT_TMPLS = {
-    True: ('Validation started with [{slot}#{id}]('
-           'https://lhcb-nightlies.cern.ch/nightly/{slot}/build/{id}/)'),
-    False: ('Automatic merge failed in [{slot}#{id}]('
-            'https://lhcb-nightlies.cern.ch/logs/checkout/nightly/'
-            '{slot}/{id}/{proj}/)'),
+    True: (
+        "Validation started with [{slot}#{id}]("
+        "https://lhcb-nightlies.web.cern.ch/nightly/{slot}/{id}/)"
+    ),
+    False: (
+        "Automatic merge failed in [{slot}#{id}]("
+        "https://lhcb-nightlies.web.cern.ch/nightly/{slot}/{id}/{proj}/checkout"
+    ),
 }
 
 
 def notifyMergeRequest(proj, name_or_id, mreq_iid, success, token=None):
-    '''
+    """
     Post the link to the slot build as comment to a merge request.
-    '''
-    if (not proj or not proj.slot or not proj.slot.build_id or (os.environ.get(
-            'NO_UPDATE_MR', 'false').lower() not in ('false', '0', ''))):
+    """
+    if (
+        not proj
+        or not proj.slot
+        or not proj.slot.build_id
+        or (os.environ.get("NO_UPDATE_MR", "false").lower() not in ("false", "0", ""))
+    ):
         # noting to notify
         return
-    if not token and 'GITLAB_TOKEN' not in os.environ:
-        logging.warning('cannot post comment to gitlab for project %s, mr %s',
-                        name_or_id, mreq_iid)
+    if not token and "GITLAB_TOKEN" not in os.environ:
+        logging.warning(
+            "cannot post comment to gitlab for project %s, mr %s", name_or_id, mreq_iid
+        )
         return
 
     message = MR_COMMENT_TMPLS[success].format(
-        slot=proj.slot.name, id=proj.slot.build_id, proj=proj.name)
+        slot=proj.slot.name, id=proj.slot.build_id, proj=proj.name
+    )
     postToMergeRequest(name_or_id, mreq_iid, message, token=token)
 
 
 def cpuinfo():
-    '''
+    """
     Return the CPU information of the machine as a list of dictionaries.
 
     Only Linux is supported.
-    '''
+    """
     cpuinfo = []
     try:
         current = {}
-        for l in open('/proc/cpuinfo'):
+        for l in open("/proc/cpuinfo"):
             try:
-                k, v = map(str.strip, l.split(':', 1))
-                if k == 'processor':
+                k, v = [x.strip() for x in l.split(":", 1)]
+                if k == "processor":
                     current = {k: v}
                     cpuinfo.append(current)
-                elif k == 'flags':
+                elif k == "flags":
                     current[k] = v.split()
                 else:
                     current[k] = v
             except ValueError:
                 pass  # ignore lines without a ':'
     except IOError:
         pass  # ignore missing /proc/cpuinfo
     return cpuinfo
 
 
 def write_json(obj, filename, pretty=True):
-    '''
+    """
     Write a JSON serialized object to file.
-    '''
-    with codecs.open(filename, 'w', 'utf-8') as f:
+    """
+    with codecs.open(filename, "w", "utf-8") as f:
         json.dump(obj, f, indent=2 if pretty else None)
 
 
-def natsort_key(v, _nsre=re.compile(r'(\d+)')):
-    '''
+def natsort_key(v, _nsre=re.compile(r"(\d+)")):
+    """
     See https://stackoverflow.com/a/16090640
-    '''
+    """
     return tuple(int(x) if x.isdigit() else x.lower() for x in _nsre.split(v))
 
 
 class TemporaryDir(object):
-    '''
+    """
     Helper class to create a temporary directory and manage its lifetime.
 
     An instance of this class can be used inside the 'with' statement and
     returns the path to the temporary directory.
-    '''
+    """
 
     def __init__(self, chdir=False, keep=False, skel=None):
-        '''Constructor.
+        """Constructor.
 
         @param chdir: change to the temporary directory while inside the
                       context
         @param keep: do not delete the temporary directory once out of context
         @param skel: fill the temporary directory with the content of the
                      provided directory
-        '''
+        """
         import tempfile
         from os.path import join
+
         self.chdir = chdir
         self.keep = keep
         self.path = tempfile.mkdtemp()
         self.old_dir = None
         if skel:
             for src, _dirs, files in os.walk(skel):
                 dst = join(self.path, os.path.relpath(src, skel))
                 if not os.path.exists(dst):
                     os.makedirs(dst)
                     shutil.copymode(src, dst)
                 for f in [join(src, f) for f in files]:
                     shutil.copy(f, dst)
 
     def join(self, *args):
-        '''
+        """
         Equivalent to os.path.join(self.path, *args).
-        '''
+        """
         return os.path.join(self.path, *args)
 
     def __str__(self):
-        '''String representation (path to the temporary directory).'''
+        """String representation (path to the temporary directory)."""
         return self.path
 
     def remove(self):
-        '''
+        """
         Remove the temporary directory.
         After a call to this method, the object is not usable anymore.
-        '''
+        """
         if self.path:  # allow multiple calls to the remove method
             shutil.rmtree(self.path, ignore_errors=True)
             self.path = None
 
     def __enter__(self):
-        '''
+        """
         Context Manager protocol 'enter' function.
-        '''
+        """
         if self.chdir:
             self.old_dir = os.getcwd()
             os.chdir(self.path)
         return self.path
 
     def __exit__(self, exc_type, exc_val, exc_tb):
-        '''
+        """
         Context Manager protocol 'exit' function.
         Remove the temporary directory and let the exceptions propagate.
-        '''
+        """
         if self.old_dir:
             os.chdir(self.old_dir)
             self.old_dir = None
         if not self.keep:
             self.remove()
         else:
-            print "WARNING: not removing temporary directory", self.path
+            print("WARNING: not removing temporary directory", self.path)
         return False
+
+
+def compatible_lcg_external_files(ext_file_name):
+    """
+    Given a filename like `/some/path/LCG_externals_<platform>.txt` return a list of
+    names where `<platform>` is replaced with a compatible architecture.
+    """
+    # we want to always try, at least, the passed name
+    paths = [ext_file_name]
+
+    # split the name in components
+    parts = re.match(r"^(.*/LCG_externals_)([^-]+(?:-[^-]+){3})(\.txt)$", ext_file_name)
+    if not parts:
+        # no need to continue if we do not understand the filename
+        return paths
+    head, platform, tail = parts.groups()
+    _, os_id, comp, opt = platform.split("-")
+
+    # this is a trick to promote "x86_64+avx2" to "x86_64_v3"
+    arch = requires(platform).split("-", 1)[0]
+
+    # if it's a known architecture we extend the list with the
+    # architectures we can use
+    archs = get_supported_archs(ARCH_DEFS[arch]) if arch in ARCH_DEFS else [arch]
+
+    comp_parts = comp.split("+")
+    comps = ["+".join(comp_parts[0:n]) for n in range(len(comp_parts), 0, -1)]
+
+    opt_parts = opt.split("+")
+    opts = ["+".join(opt_parts[0:n]) for n in range(len(opt_parts), 0, -1)]
+
+    # list of externals files we could use
+    paths.extend(
+        "{}{}-{}-{}-{}{}".format(head, arch, os_id, comp, opt, tail)
+        for arch in archs
+        for comp in comps
+        for opt in opts
+    )
+
+    # remove duplicates (preserving the order)
+    unique = []
+    for path in paths:
+        if path not in unique:
+            unique.append(path)
+
+    return unique
+
+
+if sys.version_info < (3, 0):
+
+    def coerce_str(s):
+        return s
+
+else:
+
+    def coerce_str(s):
+        """
+        Get a str out of str or bytes.
+        """
+        return s.decode("utf-8", errors="replace") if isinstance(s, bytes) else s
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/HTMLUtils.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/HTMLUtils.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,26 +4,30 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Common utility functions.
 
 @author Marco Clemencic <marco.clemencic@cern.ch>
-'''
+"""
+from __future__ import print_function
 
-import sys
-import re
-import cgi
 import logging
+import re
+import sys
+from builtins import object
+from html import escape
+
+from past.builtins import basestring
 
-HTML_STYLE = u'''
+HTML_STYLE = """
 .xterm-style-0 {}
 .xterm-style-1 {font-weight: bold}
 .xterm-style-4 {text-decoration: underline}
 .xterm-style-5 {font-weight: blink}
 .xterm-style-7 {} # reverse
 .xterm-color-0 {color: black;}
 .xterm-color-1 {color: red;}
@@ -74,460 +78,481 @@
     white-space: pre-wrap;
     background-color: inherit;
     color: inherit;
     padding: 0;
     margin: 0;
     border: none;
 }
-'''
+"""
 
 # cached regular expression to find ANSI color codes
-COLCODE_RE = re.compile(u'\x1b\\[([0-9;]*m|[012]?K)')
+COLCODE_RE = re.compile("\x1b\\[([0-9;]*m|[012]?K)")
 
 
 class ANSIStyle(object):
-    __slots__ = ('style', 'color', 'bgcolor')
+    __slots__ = ("style", "color", "bgcolor")
 
     def __init__(self, style=0, color=0, bgcolor=0):
         self.style = style
         self.color = color
         self.bgcolor = bgcolor
         if isinstance(style, basestring):
             self.style = 0
             self.apply_code(style)
 
     def apply_code(self, code):
-        '''
+        """
         >>> ANSIStyle(1, 2, 3).apply_code('0')
         ANSIStyle(style=0, color=0, bgcolor=0)
         >>> ANSIStyle().apply_code('1;34')
         ANSIStyle(style=1, color=4, bgcolor=0)
         >>> ANSIStyle().apply_code('45')
         ANSIStyle(style=0, color=0, bgcolor=5)
-        '''
-        if not code or code == '0':
+        """
+        if not code or code == "0":
             self.style = self.color = self.bgcolor = 0
         else:
-            for subcode in [int(x, 10) for x in code.split(';')]:
+            for subcode in [int(x, 10) for x in code.split(";")]:
                 if subcode >= 40:
                     self.bgcolor = subcode - 40
                 elif subcode >= 30:
                     self.color = subcode - 30
                 else:
                     self.style = subcode
         return self
 
     def copy(self):
         return ANSIStyle(self.style, self.color, self.bgcolor)
 
     def code(self, base=None):
         if (self.style, self.color, self.bgcolor) == (0, 0, 0):
-            return ''
+            return ""
         if not base:
             base = ANSIStyle()
         if self == base:
             return self.code()  # prevent a no change to become a reset
         codes = []
         if self.style != base.style:
             codes.append(str(self.style))
         if self.color != base.color:
             codes.append(str(30 + self.color))
         if self.bgcolor != base.bgcolor:
             codes.append(str(40 + self.bgcolor))
-        return ';'.join(codes)
+        return ";".join(codes)
 
     def css(self, base=None):
-        '''
+        """
         CSS class(es) for the current text style.
 
         >>> ANSIStyle().css()
         ''
         >>> ANSIStyle('1;32;43').css()
         'xterm-style-1 xterm-color-2 xterm-bgcolor-3'
-        '''
+        """
         if (self.style, self.color, self.bgcolor) == (0, 0, 0):
-            return ''
+            return ""
         if not base:
             base = ANSIStyle()
         codes = []
         for key in self.__slots__:
             if getattr(self, key) != getattr(base, key):
-                codes.append('xterm-{}-{}'.format(key, getattr(self, key)))
-        return ' '.join(codes)
+                codes.append("xterm-{}-{}".format(key, getattr(self, key)))
+        return " ".join(codes)
 
     def __repr__(self):
-        return 'ANSIStyle({})'.format(', '.join(
-            '{}={!r}'.format(key, getattr(self, key))
-            for key in self.__slots__))
+        return "ANSIStyle({})".format(
+            ", ".join(
+                "{}={!r}".format(key, getattr(self, key)) for key in self.__slots__
+            )
+        )
 
     def __eq__(self, other):
-        return (isinstance(other, ANSIStyle) and
-                (self.style, self.color,
-                 self.bgcolor) == (other.style, other.color, other.bgcolor))
+        return isinstance(other, ANSIStyle) and (
+            self.style,
+            self.color,
+            self.bgcolor,
+        ) == (other.style, other.color, other.bgcolor)
 
 
 class ANSI2HTML(object):
-    '''
+    """
     Class to convert ANSI codes into HTML classes.
-    '''
+    """
 
-    def __init__(self, start_style=''):
-        self.current_style = (start_style if isinstance(
-            start_style, ANSIStyle) else ANSIStyle(start_style))
+    def __init__(self, start_style=""):
+        self.current_style = (
+            start_style
+            if isinstance(start_style, ANSIStyle)
+            else ANSIStyle(start_style)
+        )
 
     def _process(self, line):
         # we record and strip the newline format at end of line not to include
         # it in the formatting
-        if line.endswith('\n'):
-            newline = '\n'
+        if line.endswith("\n"):
+            newline = "\n"
             line = line[:-1]
-        elif line.endswith('\r\n'):
-            newline = '\r\n'
+        elif line.endswith("\r\n"):
+            newline = "\r\n"
             line = line[:-2]
         else:
-            newline = ''
+            newline = ""
 
         # special handling of styles at beginning of line
         m = COLCODE_RE.match(line)
         while m:
-            line = line[m.end():]
-            if m.group(1).endswith('m'):
+            line = line[m.end() :]
+            if m.group(1).endswith("m"):
                 self.current_style.apply_code(m.group(1)[:-1])
             m = COLCODE_RE.match(line)
 
         current_class = self.current_style.css()
         if current_class:
-            yield u'<span class="{}">'.format(current_class)
+            yield '<span class="{}">'.format(current_class)
         else:
-            yield u'<span>'
+            yield "<span>"
 
         pos = 0
         while True:
             # look for a control sequence
             m = COLCODE_RE.search(line, pos)
             if not m:
                 # no more codes to convert
                 break
             # pass the chars so far
             if m.start() != pos:
-                yield line[pos:m.start()]
+                yield line[pos : m.start()]
             # parse the new code
-            if m.group(1).endswith('m'):
+            if m.group(1).endswith("m"):
                 self.current_style.apply_code(m.group(1)[:-1])
                 next_class = self.current_style.css()
             else:
                 next_class = current_class
 
             if next_class != current_class:
                 # we have a change, close previous span, open the new one
-                yield u'</span><span class="{}">'.format(next_class)
+                yield '</span><span class="{}">'.format(next_class)
                 current_class = next_class
             pos = m.end()  # update offset to end of control code
 
         if pos < len(line):  # flush what remains of the line
             yield line[pos:]
-        yield u'</span>' + newline  # close the global <span>
+        yield "</span>" + newline  # close the global <span>
 
     def __call__(self, line):
-        '''
+        """
         Add HTML span tags for ansi colors.
-        '''
-        return u''.join(self._process(line))
+        """
+        return "".join(self._process(line))
 
 
 class TableizeLine(object):
-    '''
+    """
     Add table row tags and optionally line numbers to lines.
-    '''
+    """
 
-    def __init__(self,
-                 first_line_no=1,
-                 line_id_prefix='L',
-                 add_line_nos=False,
-                 row_class=None):
+    def __init__(
+        self, first_line_no=1, line_id_prefix="L", add_line_nos=False, row_class=None
+    ):
         self.line_no = first_line_no
 
-        line_format = u'<tr id="{prefix}{{n}}"{{class_desc}}><td>'
+        line_format = '<tr id="{prefix}{{n}}"{{class_desc}}><td>'
         if add_line_nos:
-            line_format += u'<a href="#{prefix}{{n}}">{{n}}</a></td><td>'
-        line_format += u'{{text}}</td></tr>'
+            line_format += '<a href="#{prefix}{{n}}">{{n}}</a></td><td>'
+        line_format += "{{text}}</td></tr>"
 
         if row_class is None or isinstance(row_class, basestring):
             self.row_class = lambda n: row_class
         else:
             self.row_class = row_class
 
         self._line_format = line_format.format(prefix=line_id_prefix)
 
     def __call__(self, line):
-        '''
+        """
         Add HTML tags.
-        '''
+        """
         # we record and strip the newline format at end of line not to include
         # it in the formatting
-        if line.endswith('\n'):
-            newline = '\n'
+        if line.endswith("\n"):
+            newline = "\n"
             line = line[:-1]
-        elif line.endswith('\r\n'):
-            newline = '\r\n'
+        elif line.endswith("\r\n"):
+            newline = "\r\n"
             line = line[:-2]
         else:
-            newline = ''
+            newline = ""
 
         css = self.row_class(self.line_no)
-        class_desc = u' class="{}"'.format(css) if css else ''
+        class_desc = ' class="{}"'.format(css) if css else ""
 
-        out = self._line_format.format(
-            n=self.line_no, class_desc=class_desc, text=line) + newline
+        out = (
+            self._line_format.format(n=self.line_no, class_desc=class_desc, text=line)
+            + newline
+        )
         self.line_no += 1
         return out
 
 
 class WrapLine(object):
-    '''
+    """
     Wrap a line in HTML tags.
-    '''
+    """
 
     def __init__(self, tag, attrs={}):
-        self._line_format = u'<{tag}{attrs}>{{text}}</{tag}>'.format(
+        self._line_format = "<{tag}{attrs}>{{text}}</{tag}>".format(
             tag=tag,
-            attrs=''
-            if not attrs else ' ' + ' '.join(u'{0}="{1}"'.format(item)
-                                             for item in attrs.items()))
+            attrs=""
+            if not attrs
+            else " "
+            + " ".join('{0}="{1}"'.format(item) for item in list(attrs.items())),
+        )
 
     def __call__(self, line):
-        '''
+        """
         Add HTML tags.
-        '''
+        """
         # we record and strip the newline format at end of line not to include
         # it in the formatting
-        if line.endswith('\n'):
-            newline = '\n'
+        if line.endswith("\n"):
+            newline = "\n"
             line = line[:-1]
-        elif line.endswith('\r\n'):
-            newline = '\r\n'
+        elif line.endswith("\r\n"):
+            newline = "\r\n"
             line = line[:-2]
         else:
-            newline = ''
+            newline = ""
         return self._line_format.format(text=line) + newline
 
 
 class ClassifyByLineNo(object):
-    '''
+    """
     Helper to set specific class for groups of lines in TableizeLine.
-    '''
+    """
 
     def __init__(self, range_classes):
         self.range_classes = list(range_classes)
 
     def __call__(self, line_no):
         for (begin, end), css in self.range_classes:
             if line_no >= begin and line_no < end:
                 return css
         return None
 
 
 class XTerm2HTML(object):
-    '''
+    """
     Class to translate an ASCII string (containing ANSI color codes), into an
     HTML page.
 
     Usage:
 
     >>> input = '\\x1b[31mHello \\x1b[34mcolored \\x1b[32mworld\\x1b[0m!'
     >>> conv = XTerm2HTML()
     >>> html = ''.join([conv.head(title='Hi!'), conv.process(input),
     ...                 conv.tail()])
-    '''
+    """
 
-    def __init__(self,
-                 first_line=1,
-                 show_line_no=False,
-                 line_prefix='L',
-                 is_escaped=False,
-                 plugins_function=None):
-        '''
+    def __init__(
+        self,
+        first_line=1,
+        show_line_no=False,
+        line_prefix="L",
+        is_escaped=False,
+        plugins_function=None,
+    ):
+        """
         Initialize the conversion instance.
         An optional first_line can be provided if the output of the processing
         is meant to be concatenated with the output of another call to this
         class.
-        '''
-        self.actions = [] if is_escaped else [
-            lambda line: cgi.escape(line, quote=True)
-        ]
+        """
+        self.actions = [] if is_escaped else [lambda line: escape(line, quote=True)]
         self.actions.extend(plugins_function or [])
-        self.actions.extend([
-            ANSI2HTML(),
-            WrapLine('pre'),
-            TableizeLine(
-                first_line_no=first_line,
-                line_id_prefix=line_prefix,
-                add_line_nos=show_line_no)
-        ])
+        self.actions.extend(
+            [
+                ANSI2HTML(),
+                WrapLine("pre"),
+                TableizeLine(
+                    first_line_no=first_line,
+                    line_id_prefix=line_prefix,
+                    add_line_nos=show_line_no,
+                ),
+            ]
+        )
         self.log = logging.getLogger(self.__class__.__name__)
         self.is_escaped = is_escaped
 
-    def head(self, title=''):
-        '''
+    def head(self, title=""):
+        """
         Return a string containing the head of the HTML page.
-        '''
-        return (u'<!DOCTYPE html><html><head><meta charset="utf-8">'
-                '<link rel="stylesheet" href="https://maxcdn.bootstrapcdn'
-                '.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="'
-                'sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmS'
-                'Tsz/K68vbdEjh4u" crossorigin="anonymous">'
-                '<link rel="stylesheet" href="https://maxcdn.bootstrapcdn'
-                '.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" '
-                'integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SV'
-                'rLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">'
-                '<style>{}</style><title>{}</title></head><body>\n').format(
-                    HTML_STYLE, title)
+        """
+        return (
+            '<!DOCTYPE html><html><head><meta charset="utf-8">'
+            '<link rel="stylesheet" href="https://maxcdn.bootstrapcdn'
+            '.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="'
+            "sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmS"
+            'Tsz/K68vbdEjh4u" crossorigin="anonymous">'
+            '<link rel="stylesheet" href="https://maxcdn.bootstrapcdn'
+            '.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" '
+            'integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SV'
+            'rLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">'
+            "<style>{}</style><title>{}</title></head><body>\n"
+        ).format(HTML_STYLE, title)
 
     def tail(self):
-        '''
+        """
         Return a string containing the tail of the HTML page.
-        '''
-        return (u'</body>'
-                '<script src="https://ajax.googleapis.com/ajax/libs/jquery'
-                '/1.12.4/jquery.min.js"></script>'
-                '<script src="https://maxcdn.bootstrapcdn.com/bootstrap/'
-                '3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027q'
-                'vyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" '
-                'crossorigin="anonymous"></script>'
-                '</html>\n')
+        """
+        return (
+            "</body>"
+            '<script src="https://ajax.googleapis.com/ajax/libs/jquery'
+            '/1.12.4/jquery.min.js"></script>'
+            '<script src="https://maxcdn.bootstrapcdn.com/bootstrap/'
+            '3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027q'
+            'vyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" '
+            'crossorigin="anonymous"></script>'
+            "</html>\n"
+        )
 
     def process(self, lines):
-        '''
+        """
         Choose the correct function to process the data
-        '''
-        return ''.join(self._process(lines))
+        """
+        return "".join(self._process(lines))
 
     def _process(self, lines):
-        '''
+        """
         Process a chunk of text and return the corresponding HTML code.
-        '''
-        yield u'<table class="table table-striped" style="text-align:left">'
+        """
+        yield '<table class="table table-striped" style="text-align:left">'
 
         if isinstance(lines, basestring):
             lines = lines.splitlines(True)
 
         for line in lines:
             for action in self.actions:
                 line = action(line)
             yield line
 
-        yield u'</table>'
+        yield "</table>"
 
 
-def convertFile(src,
-                dst,
-                show_line_no=False,
-                line_prefix='L',
-                plugins_function=[]):
-    '''
+def convertFile(src, dst, show_line_no=False, line_prefix="L", plugins_function=[]):
+    """
     Small helper to convert a text (ANSI) file to HTML.
-    '''
+    """
     import codecs
     from os.path import basename
+
     conv = XTerm2HTML(
         show_line_no=show_line_no,
         line_prefix=line_prefix,
-        plugins_function=plugins_function)
-    with codecs.open(dst, 'w', 'utf-8') as dst_file, \
-            codecs.open(src, 'r', 'utf-8', 'ignore') as src_file:
+        plugins_function=plugins_function,
+    )
+    with codecs.open(dst, "w", "utf-8") as dst_file, codecs.open(
+        src, "r", "utf-8", "ignore"
+    ) as src_file:
         dst_file.write(conv.head(title=basename(src)))
         dst_file.write(conv.process(src_file))
         dst_file.write(conv.tail())
 
 
 class AddGitlabLinks(object):
-    '''
+    """
     Inject links to gitlab in a string.
-    '''
+    """
 
     def __init__(self):
         self.proj = None
         self._proj_sig = re.compile(
-            ur'checking out .* from '
-            ur'(?:https|ssh)://(?::@|git@)?gitlab.cern.ch(?::7999|:8443)?'
-            ur'/([a-zA-Z0-9-_.]+/[a-zA-Z0-9-_./]+).git', )
-        self._mr_link = re.compile(
-            ur'([a-zA-Z0-9-_.]+/[a-zA-Z0-9-_./]+)!(\d+)')
+            r"checking out .* from "
+            r"(?:https|ssh)://(?::@|git@)?gitlab.cern.ch(?::7999|:8443)?"
+            r"/([a-zA-Z0-9-_.]+/[a-zA-Z0-9-_./]+).git",
+        )
+        self._mr_link = re.compile(r"([a-zA-Z0-9-_.]+/[a-zA-Z0-9-_./]+)!(\d+)")
 
         def mr_link_repl(matchobj):
-            '''
+            """
             re.sub function to add links to MRs
-            '''
-            from LbNightlyTools.Utils import getMRTitle
+            """
             from gitlab import GitlabGetError
+
+            from LbNightlyTools.Utils import getMRTitle
+
             try:
                 title = getMRTitle(matchobj.group(1), int(matchobj.group(2)))
                 if title:
-                    title = cgi.escape(title, quote=True)
-                    if not isinstance(title, unicode):
-                        title = title.decode('utf-8', 'replace')
+                    title = escape(title, quote=True)
+                    if not isinstance(title, str):
+                        title = title.decode("utf-8", errors="replace")
                     return (
-                        u'<a href="https://gitlab.cern.ch/{0}/'
-                        u'merge_requests/{1}" data-toggle="tooltip" '
-                        u'title="{title}" target="_blank">{0}!{1}</a>').format(
-                            *matchobj.groups(), title=title)
+                        '<a href="https://gitlab.cern.ch/{0}/'
+                        'merge_requests/{1}" data-toggle="tooltip" '
+                        'title="{title}" target="_blank">{0}!{1}</a>'
+                    ).format(*matchobj.groups(), title=title)
                 else:
-                    return (u'<a href="https://gitlab.cern.ch/{0}/'
-                            u'merge_requests/{1}" target="_blank">{0}!{1}</a>'
-                            ).format(*matchobj.groups())
+                    return (
+                        '<a href="https://gitlab.cern.ch/{0}/'
+                        'merge_requests/{1}" target="_blank">{0}!{1}</a>'
+                    ).format(*matchobj.groups())
             except GitlabGetError:
                 # the group/project!id match is invalid (e.g. no project found)
                 # do not replace
                 return matchobj.group(0)
 
         self._mr_link_repl = mr_link_repl
 
-        self._commit_link = re.compile(ur'\b([a-f0-9]{7,40})\b')
-        self._commit_link_repl = ur'\1'  # temporary value
+        self._commit_link = re.compile(r"\b([a-f0-9]{7,40})\b")
+        self._commit_link_repl = r"\1"  # temporary value
 
     def __call__(self, line):
         if not self.proj:
             m = self._proj_sig.search(line)
             if m:
                 self.proj = m.group(1)
                 self._commit_link_repl = (
-                    ur'<a href="https://gitlab.cern.ch/{0}/commit/'
-                    ur'\1" target="_blank">\1</a>').format(self.proj)
+                    r'<a href="https://gitlab.cern.ch/{0}/commit/'
+                    r'\1" target="_blank">\1</a>'
+                ).format(self.proj)
         else:
             # replace group/Project!123 with link to merge request
             line = self._mr_link.sub(self._mr_link_repl, line)
             # replace commit ids with links to gitlab
             line = self._commit_link.sub(self._commit_link_repl, line)
         return line
 
 
 # tests for special cases
 def test_special_cases():
-    '''Test for Special Cases'''
-    assert ANSIStyle('') == ANSIStyle(0, 0, 0)
+    """Test for Special Cases"""
+    assert ANSIStyle("") == ANSIStyle(0, 0, 0)
     expected = (
-        u'<table class="table table-striped" style="text-align:left">'
+        '<table class="table table-striped" style="text-align:left">'
         '<tr id="L1"><td><pre><span class="xterm-color-4">test</span>'
         # FIXME: it would be nice to avoid emitting empty tags
         '<span class="xterm-color-4 xterm-bgcolor-3"></span>'
         '<span class="xterm-color-2 xterm-bgcolor-3">blah</span>'
-        '<span class="">blah</span></pre></td></tr></table>')
-    actual = XTerm2HTML().process('\x1b[31m\x1b[34mtest'
-                                  '\x1b[34;43m\x1b[32mblah\x1b[0mblah')
-    print 'actual   ->', repr(actual)
-    print 'expected ->', repr(expected)
+        '<span class="">blah</span></pre></td></tr></table>'
+    )
+    actual = XTerm2HTML().process(
+        "\x1b[31m\x1b[34mtest" "\x1b[34;43m\x1b[32mblah\x1b[0mblah"
+    )
+    print("actual   ->", repr(actual))
+    print("expected ->", repr(expected))
     assert actual == expected
 
 
-if __name__ == '__main__':
-    if '--convertFile' in sys.argv:
-        src = sys.argv[sys.argv.index('--convertFile') + 1]
+if __name__ == "__main__":
+    if "--convertFile" in sys.argv:
+        src = sys.argv[sys.argv.index("--convertFile") + 1]
         plugin = []
-        dest = src + '.html'
-        convertFile(src, dest, show_line_no='--show-line-no' in sys.argv)
+        dest = src + ".html"
+        convertFile(src, dest, show_line_no="--show-line-no" in sys.argv)
     else:
         conv = XTerm2HTML(
-            show_line_no='--show-line-no' in sys.argv,
-            plugins_function=[lambda line: unicode(line, 'utf-8', 'ignore')])
-        sys.stdout.write(conv.head(title='stdin'))
-        sys.stdout.write(conv.process(sys.stdin).encode('utf8'))
+            show_line_no="--show-line-no" in sys.argv,
+            plugins_function=[lambda line: str(line, "utf-8", "ignore")],
+        )
+        sys.stdout.write(conv.head(title="stdin"))
+        sys.stdout.write(conv.process(sys.stdin).encode("utf8"))
         sys.stdout.write(conv.tail())
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/LbScriptsUtils.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/LbScriptsUtils.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,40 +4,39 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Utility functionns to update LbScripts file during the release of the project.
 
 TO BE REMOVED ONCE WE MOVE TO LBENV
-'''
-__author__ = 'Ben Couturier <ben.couturier@cern.ch>'
+"""
+__author__ = "Ben Couturier <ben.couturier@cern.ch>"
 
 import fileinput
-import os
+import json
 import logging
+import os
 import re
 import shutil
-import json
 from datetime import datetime
 
 
 def _checkScriptversion(line):
     """
     Find a line matching
     script_version = '151124'
     and return the updated version
     """
     ret = None
     if re.match("^\s*script_version\s*=\s*['\"]\d+['\"]\s*", line):
-        ret = "script_version = '%s'\n" % datetime.now().strftime(
-            "%y%m%d%H%M%S")
+        ret = "script_version = '%s'\n" % datetime.now().strftime("%y%m%d%H%M%S")
     return ret
 
 
 def _checkLbScriptsversion(line, version):
     """
     Find a line matching
     lbscripts_version = "v8r3p3"
@@ -46,17 +45,17 @@
     ret = None
     if re.match("^\s*lbscripts_version\s*=\s*['\"].+['\"]\s*", line):
         ret = 'lbscripts_version = "%s"\n' % version
     return ret
 
 
 def updateInstallProject(basedir, version):
-    '''
+    """
     Update version and date in install_project
-    '''
+    """
     log = logging.getLogger("updateInstallProject")
 
     # Doing a backup on the original install project
     ipname = "LbLegacy/python/LbLegacy/install_project.py"
     ipbakname = ipname + ".orig"
     ipfullname = os.path.join(basedir, ipname)
     ipbakfullname = os.path.join(basedir, ipbakname)
@@ -84,17 +83,17 @@
     m = re.match("^(.*)\$\(version\)(.*)$", line)
     if m != None:
         ret = "%s%s%s\n" % (m.group(1), version, m.group(2))
     return ret
 
 
 def updateLbConfigurationRequirements(basedir, version):
-    '''
+    """
     Update version and date in install_project
-    '''
+    """
     log = logging.getLogger("updateLbConfReq")
 
     # Doing a backup on the original install project
     ipname = "LbConfiguration/cmt/requirements"
     ipbakname = ipname + ".orig"
     ipfullname = os.path.join(basedir, ipname)
     ipbakfullname = os.path.join(basedir, ipbakname)
@@ -108,27 +107,31 @@
                 if ret != None:
                     fout.write(ret)
                 else:
                     fout.write(line)
 
 
 def _createVersionCmt(basedir, package, version):
-    '''
+    """
     Create the version.cmt file in a specific package
-    '''
+    """
     vfilename = os.path.join(basedir, package, "cmt", "version.cmt")
     with open(vfilename, "w") as f:
         f.write("%s\n" % version)
 
 
 def updateVersionCmt(basedir, version):
-    '''
+    """
     Update version.cmt in all the LbScripts packages
-    '''
+    """
     log = logging.getLogger("updateVersionCmt")
     packages = [
-        "LbConfiguration", "LbLegacy", "LbRelease", "LbScriptsPolicy",
-        "LbScriptsSys", "LbUtils"
+        "LbConfiguration",
+        "LbLegacy",
+        "LbRelease",
+        "LbScriptsPolicy",
+        "LbScriptsSys",
+        "LbUtils",
     ]
 
     for p in packages:
         _createVersionCmt(basedir, p, version)
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/CheckSlotPreconditions.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/CheckSlotPreconditions.py`

 * *Files 12% similar despite different names*

```diff
@@ -4,89 +4,95 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Module containing the classes and functions used to check if a slot have
 preconditions and write files with parameters for next jobs in Jenkins
-'''
-__author__ = 'Colas Pomies <colas.pomies@cern.ch>'
+"""
+__author__ = "Colas Pomies <colas.pomies@cern.ch>"
+
+import os
 
-from LbNightlyTools.Scripts.Common import PlainScript
-from LbNightlyTools.Configuration import findSlot
-from LbNightlyTools.Utils import JobParams
 from LbPlatformUtils import requires
 
-import os
+from LbNightlyTools.Configuration import findSlot
+from LbNightlyTools.Scripts.Common import PlainScript
+from LbNightlyTools.Utils import JobParams
 
 
 class Script(PlainScript):
-    '''
+    """
     Script to check if a slot have preconditions or can be built right away.
-    '''
-    __usage__ = '%prog [options] <slot> <slot_build_id> <flavour>'
-    __version__ = ''
+    """
 
-    def defineOpts(self):
+    __usage__ = "%prog [options] <slot> <slot_build_id> <flavour>"
+    __version__ = ""
 
+    def defineOpts(self):
         self.parser.add_option(
-            '--platforms', action='store', help='Platforms to build the slot')
+            "--platforms", action="store", help="Platforms to build the slot"
+        )
 
         self.parser.set_defaults(platforms="")
 
     def main(self):
-        '''
+        """
         Script main function.
-        '''
+        """
         if len(self.args) != 3:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         opts = self.options
 
         # FIXME: to be ported to the new configuration classes
         slot, slot_build_id, flavour = self.args
-        slot = findSlot('{}.{}'.format(slot, slot_build_id), flavour=flavour)
+        slot = findSlot(
+            "{}.{}".format(slot, slot_build_id), flavour=flavour, raise_if_aborted=True
+        )
 
         preconds = slot.preconditions
         if preconds:
-            self.log.info('Found preconditions for %s', slot.name)
-            output_file = 'slot-precondition-{0}-{1}.txt'
+            self.log.info("Found preconditions for %s", slot.name)
+            output_file = "slot-precondition-{0}-{1}.txt"
         else:
-            self.log.info('No preconditions for %s', slot.name)
-            output_file = 'slot-build-{0}-{1}.txt'
+            self.log.info("No preconditions for %s", slot.name)
+            output_file = "slot-build-{0}-{1}.txt"
 
         platforms = opts.platforms.strip().split() or slot.platforms
 
-        if flavour == 'release':
-            label = '-release'
-        elif os.environ.get('os_label') == 'coverity':
-            label = '-coverity'
+        if flavour == "release":
+            label = "-release"
+        elif os.environ.get("os_label") == "coverity":
+            label = "-coverity"
         else:
-            label = '-build'
+            label = "-build"
 
         for platform in platforms:
-            arch_label, os_label = (item + label
-                                    for item in requires(platform).split('-'))
-            if os.environ.get('os_label') == 'docker':
-                os_label = 'docker' + label
+            arch_label, os_label = (
+                item + label for item in requires(platform).split("-")
+            )
+            if os.environ.get("os_label") == "docker":
+                os_label = "docker" + label
             output_file_name = output_file.format(slot.name, platform)
             jp = JobParams(
                 slot=slot.name,
                 slot_build_id=slot.build_id,
                 platform=platform,
                 os_label=os_label,
             )
             # FIXME: until we have new labels on all hosts we need something special
             #        for x86_64 and avx2
-            if 'avx2' in jp.platform:
-                arch_label = 'avx2' + label  # should become 'broadwell' + label
+            if "avx2" in jp.platform:
+                arch_label = "avx2" + label  # should become 'broadwell' + label
             else:
-                arch_label = arch_label.replace('x86_64-', 'nightly-').replace(
-                    'nehalem-', 'nightly-')
+                arch_label = arch_label.replace("x86_64-", "nightly-").replace(
+                    "nehalem-", "nightly-"
+                )
             jp.build_node = arch_label
-            open(output_file_name, 'w').write(str(jp) + '\n')
-            self.log.debug('%s written', output_file_name)
+            open(output_file_name, "w").write(str(jp) + "\n")
+            self.log.debug("%s written", output_file_name)
 
         return 0
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/EnabledSlots.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/EnabledSlots.py`

 * *Files 18% similar despite different names*

```diff
@@ -4,274 +4,336 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Simple script to extract slot who need to be compile
 Create one file for each slot. Each file contains parameters for the next job.
 Now we only have the slot name in parameter in files
-'''
-__author__ = 'Colas Pomies <colas.pomies@cern.ch>'
+"""
+__author__ = "Colas Pomies <colas.pomies@cern.ch>"
 
 import json
 import os
 import re
-from LbNightlyTools.Utils import JobParams, Dashboard
+
 from LbNightlyTools.Configuration import loadConfig
-from LbNightlyTools.MergeRequestBuilds import (make_mr_slots,
-                                               post_gitlab_feedback)
+from LbNightlyTools.GitlabUtils import getMRLabels
+from LbNightlyTools.MergeRequestBuilds import make_mr_slots, post_gitlab_feedback
 from LbNightlyTools.Scripts.Common import PlainScript, addDashboardOptions
+from LbNightlyTools.Utils import Dashboard, JobParams
 
 
 class Script(PlainScript):
-    '''
+    """
     Script to create one file for all enable slots or for slots in parameters
     This file contain the slot name and the slot build id
     The slot build id is extract with the function get_ids
-    '''
-    __usage__ = '%prog [options] flavour output_file.txt'
-    __version__ = ''
+    """
+
+    __usage__ = "%prog [options] flavour output_file.txt"
+    __version__ = ""
 
     def defineOpts(self):
         from datetime import date
 
         self.parser.add_option(
-            '--config-dir',
-            help='Directory where to find configurations '
-            'files [default: %default]')
+            "--config-dir",
+            help="Directory where to find configurations " "files [default: %default]",
+        )
         self.parser.add_option(
-            '--output',
-            help='template for output file name, it must '
+            "--output",
+            help="template for output file name, it must "
             'contain a "{name}" that will be replaced '
-            'by the slot name '
-            '[default: %default]')
+            "by the slot name "
+            "[default: %default]",
+        )
         self.parser.add_option(
-            '--slots',
-            help='do not look for active slots, but use the '
-            'provided space or comma separated list')
+            "--slots",
+            help="do not look for active slots, but use the "
+            "provided space or comma separated list",
+        )
         self.parser.add_option(
-            '--resolve-mrs',
-            action='store_true',
-            help='resolve symbolic merge requests (all, label=X...) to a list '
-            'pairs (mr_iid, commit_id)')
+            "--resolve-mrs",
+            action="store_true",
+            help="resolve symbolic merge requests (all, label=X...) to a list "
+            "pairs (mr_iid, commit_id)",
+        )
         self.parser.add_option(
-            '--date',
-            help='date to use in the slot document in CouchDB (default: today)'
+            "--date",
+            help="date to use in the slot document in CouchDB (default: today)",
         )
         addDashboardOptions(self.parser)
 
         self.parser.set_defaults(
             config_dir=None,
-            flavour='nightly',
-            output='slot-params-{name}.txt',
+            flavour="nightly",
+            output="slot-params-{name}.txt",
             slots=None,
             resolve_mrs=False,
-            date=date.today().isoformat())
+            date=date.today().isoformat(),
+        )
 
     def write_files(self, slots):
         from couchdb import ResourceConflict
 
         if slots:
-            self.log.info('%s slots to start', len(slots))
+            self.log.info("%s slots to start", len(slots))
         else:
-            self.log.warning('no slots to start')
+            self.log.warning("no slots to start")
             return
 
         d = Dashboard(
             flavour=self.options.flavour,
             server=self.options.db_url,
-            dbname=self.options.db_name)
+            dbname=self.options.db_name,
+        )
 
         for slot in slots:
-            self.log.info(' - %s', slot.name)
+            self.log.info(" - %s", slot.name)
             slot.build_id = d.lastBuildId(slot.name) + 1
             output_file_name = self.options.output.format(name=slot.name)
             while True:
-                key = '{0}.{1}'.format(slot.name, slot.build_id)
+                key = "{0}.{1}".format(slot.name, slot.build_id)
                 value = {
-                    'type': 'slot-info',
-                    'slot': slot.name,
-                    'build_id': slot.build_id,
-                    'config': slot.toDict(),
-                    'date': self.options.date,
+                    "type": "slot-info",
+                    "slot": slot.name,
+                    "build_id": slot.build_id,
+                    "config": slot.toDict(),
+                    "date": self.options.date,
                 }
                 if not self.options.submit:
-                    self.log.debug('   slot info: {}\n{}'.format(
-                        key, json.dumps(value, indent=2)))
+                    self.log.debug(
+                        "   slot info: {}\n{}".format(key, json.dumps(value, indent=2))
+                    )
                     break
                 try:
                     # reserve the build id by creating a place holder in the
                     # dashboard DB
                     d.db[key] = value
-                    self.log.info('updated %s', d.urlForKey(key))
+                    self.log.info("updated %s", d.urlForKey(key))
                     break
                 except ResourceConflict:
                     # if the place holder with that name already exists, bump
                     # the build id
                     slot.build_id += 1
             if self.options.submit:
-                with open(output_file_name, 'w') as f:
+                with open(output_file_name, "w") as f:
                     f.write(
-                        str(
-                            JobParams(
-                                slot=slot.name, slot_build_id=slot.build_id)) +
-                        '\n')
-                self.log.info('%s written for slot %s with build id %s',
-                              output_file_name, slot.name, slot.build_id)
+                        str(JobParams(slot=slot.name, slot_build_id=slot.build_id))
+                        + "\n"
+                    )
+                self.log.info(
+                    "%s written for slot %s with build id %s",
+                    output_file_name,
+                    slot.name,
+                    slot.build_id,
+                )
 
     def main(self):
         if self.args:
-            self.parser.error('unexpected arguments')
+            self.parser.error("unexpected arguments")
 
-        if not re.match(r'^\d{4}-\d{2}-\d{2}$', self.options.date):
+        if not re.match(r"^\d{4}-\d{2}-\d{2}$", self.options.date):
             self.parser.error(
-                'invalid format for --date argument, '
-                'it must be YYYY-MM-DD (got %s)' % self.options.date)
+                "invalid format for --date argument, "
+                "it must be YYYY-MM-DD (got %s)" % self.options.date
+            )
 
-        self.log.info('Loading slot configurations')
-        slots = loadConfig(self.options.config_dir).values()
+        self.log.info("Loading slot configurations")
+        slots = list(loadConfig(self.options.config_dir).values())
 
-        mr_slots_config = os.environ.get('MR_TOKEN')
+        mr_slots_config = os.environ.get("MR_TOKEN")
         ref_slot = mr_slot = None
         if mr_slots_config:
             mr_slots_config = json.loads(mr_slots_config)
             ref_slot, mr_slot = make_mr_slots(mr_slots_config, slots)
-            slots = [ref_slot, mr_slot]
+            slots = (
+                [ref_slot, mr_slot] if mr_slots_config["build_reference"] else [mr_slot]
+            )
 
         if not self.options.slots:
-            self.log.info('get only enabled slots')
+            self.log.info("get only enabled slots")
             slots = [slot for slot in slots if slot.enabled]
         else:
-            self.options.slots = set(
-                self.options.slots.replace(',', ' ').split())
-            self.log.info('get only requested slots')
+            self.options.slots = set(self.options.slots.replace(",", " ").split())
+            self.log.info("get only requested slots")
             slots = [slot for slot in slots if slot.name in self.options.slots]
 
         if self.options.resolve_mrs:
-            self.log.info('resolving merge requests aliases')
+            self.log.info("resolving merge requests aliases")
             from LbNightlyTools.GitlabUtils import resolveMRs
+
             slots = resolveMRs(slots)
 
+        # Collect all labels from all MRs, to be used by LHCbPR,
+        # see LbNightlyTools#109
+        self.log.debug("collect all labels from all MRs")
+        for slot in slots:
+            self.log.debug("  - slot: %s", slot.name)
+            self.log.debug("    projects:")
+            all_labels = set()
+            for project in slot.activeProjects:
+                self.log.debug("      - name: %s", project.name)
+                merges = project.checkout_opts.get("merges", [])
+                if not isinstance(merges, list):
+                    merges = [merges]
+                self.log.debug("        merges: %s", merges)
+                for mr_desc in merges:
+                    if len(mr_desc) > 1:
+                        mr_iid = mr_desc[0]
+                        if isinstance(mr_iid, int):
+                            all_labels.update(getMRLabels(project, mr_iid))
+            slot.metadata["labels"] = sorted(all_labels)
+            self.log.debug("    labels: %s", slot.metadata["labels"])
+
         dropped_slots = []
         if self.options.resolve_mrs and not self.options.slots:
             # we have enough info to tell if a slot has to be rebuilt (--resolve-mrs)
             # and there was no explicit selection of slots (--slots), so we can
             # drop the slots that would be identical to the previous iteration
             d = Dashboard(
                 flavour=self.options.flavour,
                 server=self.options.db_url,
-                dbname=self.options.db_name)
+                dbname=self.options.db_name,
+            )
 
             # get last build id for all slots
-            slot_build_ids = {
-                slot.name: d.lastBuildId(slot.name)
-                for slot in slots
-            }
+            slot_build_ids = {slot.name: d.lastBuildId(slot.name) for slot in slots}
 
             def clean_slot_dict(slot_dict):
-                '''drop elements not to be compared'''
-                if 'build_id' in slot_dict:
-                    del slot_dict['build_id']
-                for p in slot_dict.get('projects', []):
-                    if 'dependencies' in p:  # these are generated during checkout
-                        del p['dependencies']
-                slot_dict.get('projects', []).sort(key=lambda p: p.get('name'))
-                slot_dict.get('packages', []).sort(key=lambda p: p.get('name'))
-                slot_dict.setdefault('metadata', {})
-                if 'config_id' in slot_dict['metadata']:
-                    del slot_dict['metadata']['config_id']
+                """drop elements not to be compared"""
+                if "build_id" in slot_dict:
+                    del slot_dict["build_id"]
+                for p in slot_dict.get("projects", []):
+                    if "dependencies" in p:  # these are generated during checkout
+                        del p["dependencies"]
+                slot_dict.get("projects", []).sort(key=lambda p: p.get("name"))
+                slot_dict.get("packages", []).sort(key=lambda p: p.get("name"))
+                slot_dict.setdefault("metadata", {})
+                if "config_id" in slot_dict["metadata"]:
+                    del slot_dict["metadata"]["config_id"]
+                if (
+                    "ci_test" in slot_dict["metadata"]
+                    and "trigger" in slot_dict["metadata"]["ci_test"]
+                ):
+                    del slot_dict["metadata"]["ci_test"]["trigger"]
 
             def to_build(slot):
-                from datetime import datetime
                 from copy import deepcopy
+                from datetime import datetime
 
-                to_date = lambda s: datetime.strptime(s, '%Y-%m-%d').date()
-                self.log.debug('check if to rebuild %s', slot.name)
+                to_date = lambda s: datetime.strptime(s, "%Y-%m-%d").date()
+                self.log.debug("check if to rebuild %s", slot.name)
 
                 last_slot_info = d.db.get(
-                    '%s.%d' % (slot.name, slot_build_ids[slot.name]), {})
+                    "%s.%d" % (slot.name, slot_build_ids[slot.name]), {}
+                )
+                if last_slot_info.get("aborted"):
+                    self.log.debug("  previous build was aborted")
+                    return True
 
                 # check previous build age
-                age = (to_date(self.options.date) - to_date(
-                    last_slot_info.get('date', '1970-01-01'))).days
-                age_limit = slot.metadata.get('max_build_age', 7)
-                self.log.debug('  age: %d (limit %d)', age, age_limit)
+                age = (
+                    to_date(self.options.date)
+                    - to_date(last_slot_info.get("date", "1970-01-01"))
+                ).days
+                age_limit = slot.metadata.get("max_build_age", 7)
+                self.log.debug("  age: %d (limit %d)", age, age_limit)
                 if age >= age_limit:
                     return True
 
                 slot_dict = deepcopy(slot.toDict())
-                last_dict = last_slot_info.get('config', {})
+                last_dict = last_slot_info.get("config", {})
 
                 # check for differences
                 # (drop elements not to be compared)
                 clean_slot_dict(slot_dict)
                 clean_slot_dict(last_dict)
 
                 # convert to JSON for clean comparison
                 last_json = json.dumps(last_dict, indent=2, sort_keys=True)
                 slot_json = json.dumps(slot_dict, indent=2, sort_keys=True)
                 if last_json != slot_json:
-                    self.log.debug('  changed config:')
+                    self.log.debug("  changed config:")
                     from difflib import context_diff
+
                     for line in context_diff(
-                            last_json.splitlines(True),
-                            slot_json.splitlines(True),
-                            fromfile='before',
-                            tofile='after'):
+                        last_json.splitlines(True),
+                        slot_json.splitlines(True),
+                        fromfile="before",
+                        tofile="after",
+                    ):
                         self.log.debug(line.rstrip())
                     return True
                 else:
-                    self.log.debug('  unchanged config')
+                    self.log.debug("  unchanged config")
                     return False
 
             # remember all names, to report those that have been discarded
             dropped_slots = set(slot.name for slot in slots)
 
             slots = [slot for slot in slots if to_build(slot)]
 
             dropped_slots.difference_update(slot.name for slot in slots)
 
             if dropped_slots:
-                self.log.info('unchanged slots:')
+                self.log.info("unchanged slots:")
                 for name in sorted(dropped_slots):
-                    self.log.info(' - %s', name)
+                    self.log.info(" - %s", name)
             else:
-                self.log.debug('all slots have to be rebuilt')
+                self.log.debug("all slots have to be rebuilt")
 
         # Create a file that contain JobParams for each slot
         self.write_files(slots)
 
         # Use the assigned build_id to give feedback for MR slots
         if mr_slots_config:
             # if one of the two slots was dropped because unchanged,
             # we get the build id of the previous one (that's the only
             # information used to post the gitlab feedback)
             if ref_slot.name in dropped_slots:
                 ref_slot.build_id = slot_build_ids[ref_slot.name]
+
+            # if we don't build a reference the ref should be lhcb-master
+            if not mr_slots_config["build_reference"]:
+                d = Dashboard(
+                    flavour=self.options.flavour,
+                    server=self.options.db_url,
+                    dbname=self.options.db_name,
+                )
+                ref_slot.name = "lhcb-master"
+                ref_slot.build_id = d.lastBuildId(ref_slot.name)
+
             if mr_slot.name in dropped_slots:
                 mr_slot.build_id = slot_build_ids[mr_slot.name]
+
             # if the mr slot is new, and we are sending docs to CouchDB,
             # we can try to add a back link to the matching reference slot
             elif self.options.submit:
                 d = Dashboard(
                     flavour=self.options.flavour,
                     server=self.options.db_url,
-                    dbname=self.options.db_name)
-                key = '{slot.name}.{slot.build_id}'.format(slot=mr_slot)
+                    dbname=self.options.db_name,
+                )
+                key = "{slot.name}.{slot.build_id}".format(slot=mr_slot)
                 data = d[key]
                 try:
-                    data['config']['metadata']['ci_test']['reference'] = (
-                        ref_slot.name, ref_slot.build_id)
+                    data["config"]["metadata"]["ci_test"]["reference"] = (
+                        ref_slot.name,
+                        ref_slot.build_id,
+                    )
                     d.update(key, data)
                 except KeyError:
                     # ignore if the document does not contain the required keys
                     pass
 
-            post_gitlab_feedback(ref_slot, mr_slot, self.options.flavour,
-                                 mr_slots_config)
+            post_gitlab_feedback(
+                ref_slot, mr_slot, self.options.flavour, mr_slots_config
+            )
 
-        self.log.info('End of extraction of all enable slot')
+        self.log.info("End of extraction of all enable slot")
 
         return 0
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Test.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Test.py`

 * *Files 17% similar despite different names*

```diff
@@ -4,364 +4,372 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Module containing the classes and functions used to test a
 "Nightly Build Slot".
 
 @author: Marco Clemencic <marco.clemencic@cern.ch>
-'''
+"""
 
+import codecs
+import json
 import os
 import shutil
-import json
-import codecs
 from datetime import datetime, timedelta
 from subprocess import call
 
-from LbNightlyTools.Utils import chdir, ensureDirs
-from LbNightlyTools.Utils import cpuinfo as get_cpuinfo, write_json
-from LbNightlyTools.Utils import Dashboard, JobParams
-from LbNightlyTools.Scripts.Build import unpackArtifacts, wipeDir
+from LbDevTools import DATA_DIR
 from LbPlatformUtils import requires
+from past.builtins import basestring
 
+from LbNightlyTools.Scripts.Build import unpackArtifacts, wipeDir
 from LbNightlyTools.Scripts.Common import BaseScript
+from LbNightlyTools.Utils import Dashboard, JobParams, chdir
+from LbNightlyTools.Utils import cpuinfo as get_cpuinfo
+from LbNightlyTools.Utils import ensureDirs, write_json
 
-from LbDevTools import DATA_DIR
-CTEST_CONVERTER = os.path.join(DATA_DIR, 'cmake', 'CTestXML2HTML')
+CTEST_CONVERTER = os.path.join(DATA_DIR, "cmake", "CTestXML2HTML")
 if not os.path.exists(CTEST_CONVERTER):
     CTEST_CONVERTER = None
 
 
 def fixFailureCauses(summary_file):
-    '''
+    """
     Process summary.json file to fix missing failure cause.
-    '''
+    """
     import logging
-    from os.path import join, exists
+    from os.path import exists, join
+
     dirname = os.path.dirname(summary_file)
     if not exists(summary_file):
         ensureDirs(dirname)
-        with open(summary_file, 'wb') as summary:
-            summary.write('{}\n')
+        with open(summary_file, "wb") as summary:
+            summary.write(b"{}\n")
         return
-    with open(summary_file, 'rb+') as summary:
+    with open(summary_file, "rb+") as summary:
         touched = False
         try:
             results = json.load(summary)
         except:
             return  # ignore broken files
         for test in results:
-            if (test.get('outcome', 'PASS') != 'PASS'
-                    and 'Causes' in test.get('fields', [])
-                    and not test['cause']):
-                test['cause'] = (open(join(dirname, test['id'],
-                                           'causes')).read().strip().replace(
-                                               '<pre>', '').replace(
-                                                   '</pre>', ''))
+            if (
+                test.get("outcome", "PASS") != "PASS"
+                and "Causes" in test.get("fields", [])
+                and not test["cause"]
+            ):
+                test["cause"] = (
+                    open(join(dirname, test["id"], "causes"))
+                    .read()
+                    .strip()
+                    .replace("<pre>", "")
+                    .replace("</pre>", "")
+                )
                 touched = True
         if touched:
-            logging.info('adding failure causes in %s', summary_file)
+            logging.info("adding failure causes in %s", summary_file)
             summary.seek(0)
             json.dump(results, summary, sort_keys=True, indent=4)
             summary.truncate()
 
 
 class Script(BaseScript):
-    '''
+    """
     Script to test the projects described in a slot configuration.
-    '''
+    """
 
     # unavoidable or fake warnings
     # pylint: disable=E1002,W0201
     def defineTestOptions(self):
-        '''
+        """
         Add build-specific options to the parser.
-        '''
+        """
         from optparse import OptionGroup
+
         group = OptionGroup(self.parser, "Build Options")
 
         group.add_option(
-            '-j',
-            '--jobs',
-            action='store',
-            type='int',
-            help='number of parallel jobs to use during the build '
-            '(default: $LBN_BUILD_JOBS or 1)')
+            "-j",
+            "--jobs",
+            action="store",
+            type="int",
+            help="number of parallel jobs to use during the build "
+            "(default: $LBN_BUILD_JOBS or 1)",
+        )
 
         self.parser.add_option_group(group)
-        self.parser.set_defaults(
-            jobs=int(os.environ.get('LBN_BUILD_JOBS', '1')))
+        self.parser.set_defaults(jobs=int(os.environ.get("LBN_BUILD_JOBS", "1")))
 
     def defineOpts(self):
-        '''
+        """
         Prepare the option parser.
-        '''
+        """
         from LbNightlyTools.Scripts.Common import (
-            addBasicOptions, addBuildDirOptions, addDeploymentOptions,
-            addDashboardOptions)
+            addBasicOptions,
+            addBuildDirOptions,
+            addDashboardOptions,
+            addDeploymentOptions,
+        )
 
         addBasicOptions(self.parser)
         self.defineTestOptions()
         addBuildDirOptions(self.parser)
         addDeploymentOptions(self.parser)
         addDashboardOptions(self.parser)
 
-    def _copy_build_artifacts(self,
-                              proj,
-                              target_dir,
-                              include,
-                              root=None,
-                              exclude_dirs=None):
-        '''
+    def _copy_build_artifacts(
+        self, proj, target_dir, include, root=None, exclude_dirs=None
+    ):
+        """
         Find all files matching the 'include' regexp in the project directory
         and copy them to 'target_dir' in the artifacts directory.
-        '''
+        """
         import re
+
         if isinstance(include, basestring):
             include = re.compile(include)
         if isinstance(exclude_dirs, basestring):
             exclude_dirs = re.compile(exclude_dirs)
 
-        self.log.debug('looking for files matching /%s/', include.pattern)
-        from os.path import join, relpath, dirname, exists
-        from zipfile import ZipFile
+        self.log.debug("looking for files matching /%s/", include.pattern)
+        from os.path import dirname, exists, join, relpath
+        from zipfile import ZIP_DEFLATED, ZipFile
+
         proj_root = root or self._buildDir(proj)
-        zip_name = self._summaryDir(target_dir, proj) + '.zip'
+        zip_name = self._summaryDir(target_dir, proj) + ".zip"
 
         def all_requested_files():
-            '''get all files in the project directory matching the filter'''
+            """get all files in the project directory matching the filter"""
             for root, dirs, files in os.walk(proj_root):
                 if exclude_dirs:
                     dirs[:] = [d for d in dirs if not exclude_dirs.match(d)]
                 for f in files:
                     if include.match(f):
                         yield join(root, f)
 
         # FIXME: it should be better to use a temporary file
         ensureDirs(dirname(zip_name))
         zip_empty = True
-        with ZipFile(zip_name, 'w') as dest_zip:
+        with ZipFile(zip_name, mode="w", compression=ZIP_DEFLATED) as dest_zip:
             for src in all_requested_files():
                 try:
                     dest_zip.write(src, relpath(src, proj_root))
                 except IOError:
                     # ignore failures in the copy (not fatal)
                     pass
             zip_empty = len(dest_zip.infolist()) == 0
         if zip_empty and exists(zip_name):
             os.remove(zip_name)
 
     def copy_new_refs(self, proj):
         return self._copy_build_artifacts(
-            proj, 'newrefs', r'.*\.new$', exclude_dirs=r'^build$')
+            proj, "newrefs", r".*\.new$", exclude_dirs=r"^build$"
+        )
 
     def copy_ctest_xml(self, proj):
-        return self._copy_build_artifacts(proj, 'cdash', r'.*Test\.xml$',
-                                          self._buildDir(proj, 'build'))
+        return self._copy_build_artifacts(
+            proj, "cdash", r".*Test\.xml$", self._buildDir(proj, "build")
+        )
 
     def main(self):
-        '''
+        """
         Script main logic.
-        '''
+        """
 
-        self._setup(json_type='tests-result', summary_base='tests')
+        self._setup(json_type="tests-result", summary_base="tests")
 
         opts = self.options
 
         # prepare build directory
         if opts.clean:
             wipeDir(self.build_dir)
         if not opts.no_unpack:
             unpackArtifacts(
-                os.path.join(self.artifacts_dir, 'packs', 'src'),
-                self.build_dir)
+                os.path.join(self.artifacts_dir, "packs", "src"), self.build_dir
+            )
             unpackArtifacts(
-                os.path.join(self.artifacts_dir, 'packs', self.platform),
-                self.build_dir)
+                os.path.join(self.artifacts_dir, "packs", self.platform), self.build_dir
+            )
 
         cpuinfo = get_cpuinfo()
         # run tests
         with chdir(self.build_dir):
 
             def before(proj):
-                '''callback used before testing a project'''
-                self.send({
-                    'project': proj.name,
-                    'started': datetime.now().isoformat()
-                })
+                """callback used before testing a project"""
+                self.assert_not_aborted()
+                self.send({"project": proj.name, "started": datetime.now().isoformat()})
                 if not os.path.exists(self._summaryDir(proj)):
                     os.makedirs(self._summaryDir(proj))
-                write_json(cpuinfo, self._summaryDir(proj, 'cpuinfo.json'))
+                write_json(cpuinfo, self._summaryDir(proj, "cpuinfo.json"))
 
             for proj, _ in self.slot.testGen(
-                    projects=opts.projects, before=before, jobs=opts.jobs):
-                html_src = self._buildDir(proj, 'build', 'html')
+                projects=opts.projects, before=before, jobs=opts.jobs
+            ):
+                html_src = self._buildDir(proj, "build", "html")
                 # Always use the most recent CTEST_CONVERTER, if available
                 # and we are in a CMake project
-                if os.path.exists(self._buildDir(proj, 'build', 'Testing')):
+                if os.path.exists(self._buildDir(proj, "build", "Testing")):
                     if CTEST_CONVERTER:
                         if os.path.exists(html_src):
                             shutil.rmtree(html_src)
-                        call([CTEST_CONVERTER],
-                             cwd=self._buildDir(proj, 'build'))
-                summary_json = os.path.join(html_src, 'summary.json')
+                        call([CTEST_CONVERTER], cwd=self._buildDir(proj, "build"))
+                summary_json = os.path.join(html_src, "summary.json")
                 fixFailureCauses(summary_json)
 
                 # update annotations with cpuinfo summary
                 try:
-                    annotations_json = os.path.join(html_src,
-                                                    'annotations.json')
-                    with codecs.open(annotations_json, 'rb', 'utf-8') as ann:
+                    annotations_json = os.path.join(html_src, "annotations.json")
+                    with codecs.open(annotations_json, "rb", "utf-8") as ann:
                         annotations = json.load(ann)
 
-                    if 'cpuinfo' not in annotations:
-                        annotations['cpuinfo'] = [
-                            'ncpus: {0}'.format(len(cpuinfo)),
-                            'model name: {0}'.format(cpuinfo[0]['model name']),
-                            'flags: {0}'.format(' '.join(cpuinfo[0]['flags'])),
+                    if "cpuinfo" not in annotations:
+                        annotations["cpuinfo"] = [
+                            "ncpus: {0}".format(len(cpuinfo)),
+                            "model name: {0}".format(cpuinfo[0]["model name"]),
+                            "flags: {0}".format(" ".join(cpuinfo[0]["flags"])),
                         ]
                         write_json(annotations, annotations_json)
-                except Exception, x:  # ignore errors reading summary file
-                    self.log.warning('failed to update annotations.json: %s',
-                                     x)
+                except Exception as x:  # ignore errors reading summary file
+                    self.log.warning("failed to update annotations.json: %s", x)
 
                 self.dumpGitStatus(proj)
 
                 try:
-                    results = json.load(
-                        codecs.open(summary_json, 'rb', 'utf-8'))
+                    results = json.load(codecs.open(summary_json, "rb", "utf-8"))
                 except:  # ignore errors reading summary file
                     results = []
 
-                html_dst = self._summaryDir(proj, 'results')
+                html_dst = self._summaryDir(proj, "results")
                 if os.path.exists(html_dst):
                     shutil.rmtree(html_dst)
                 if os.path.exists(html_src):
                     shutil.copytree(html_src, html_dst)
 
                 self.copy_new_refs(proj)
                 self.copy_ctest_xml(proj)
 
-                self.log.debug('compressing artifacts')
-                call(['zip', '-r', '-m', '-q', proj.name, proj.name],
-                     cwd=self._summaryDir())
-                self.send({
-                    'project': proj.name,
-                    'completed': datetime.now().isoformat(),
-                    'results': results
-                })
-                self.send({
-                    'type': 'artifacts',
-                    'project': proj,
-                    'path': self.artifacts_dir
-                })
+                self.log.debug("compressing artifacts")
+                call(
+                    ["zip", "-r", "-m", "-q", proj.name, proj.name],
+                    cwd=self._summaryDir(),
+                )
+                self.send(
+                    {
+                        "project": proj.name,
+                        "completed": datetime.now().isoformat(),
+                        "results": results,
+                    }
+                )
+                self.send(
+                    {"type": "artifacts", "project": proj, "path": self.artifacts_dir}
+                )
 
         # ensure we do not have pending tasks
         self.tasks.join()
 
         return 0
 
 
 class Poll(BaseScript):
     # number of tests to trigger per iteration
-    BATCH_SIZE = int(os.environ.get('TESTS_BATCH_SIZE') or '20')
-    FILENAME_TPL = 'test-{slot}-{build_id}-{project}-{platform}.txt'
+    BATCH_SIZE = int(os.environ.get("TESTS_BATCH_SIZE") or "20")
+    FILENAME_TPL = "test-{slot}-{build_id}-{project}-{platform}.txt"
 
     def main(self):
-        '''
+        """
         Main logic of the script.
-        '''
+        """
         d = Dashboard(flavour=self.options.flavour)
 
         # builds older than this are considered too old to care about
         expiration_time = str(datetime.now() - timedelta(hours=18))
 
         def test_id(entry):
             try:
-                return '{slot}.{build_id}.{platform}.{project}'.format(**entry)
+                return "{slot}.{build_id}.{platform}.{project}".format(**entry)
             except KeyError:
                 return None
 
-        ready_builds = d.db.get('ready-builds', {'entries': []})
-        entries = list(ready_builds['entries'])
-        entries.sort(
-            key=lambda e: e.get('time', u'0000-00-00 00:00:00'), reverse=True)
+        ready_builds = d.db.get("ready-builds", {"entries": []})
+        entries = list(ready_builds["entries"])
+        entries.sort(key=lambda e: e.get("time", "0000-00-00 00:00:00"), reverse=True)
         triggered = []
         to_drop = []
         used_ids = set()
         for entry in entries:
             # do not run test if disabled
-            do_not_trigger = (entry.get('no_test')
-                              or entry['slot'] == 'lhcb-coverity')
-            if entry.get('time', expiration_time) <= expiration_time:
+            do_not_trigger = entry.get("no_test") or entry["slot"] == "lhcb-coverity"
+            if entry.get("time", expiration_time) <= expiration_time:
                 to_drop.append(entry)
-                self.log.warning('expired entry: %s', entry)
+                self.log.warning("expired entry: %s", entry)
             elif do_not_trigger:
                 # no need to keep entries that do not need to be tested
                 to_drop.append(entry)
             elif test_id(entry) in used_ids:
-                self.log.warning('duplicated entry: %s', entry)
+                self.log.warning("duplicated entry: %s", entry)
                 to_drop.append(entry)
             else:
-                self.log.debug('triggering %s', entry)
-                with open(self.FILENAME_TPL.format(**entry), 'w') as params:
+                self.log.debug("triggering %s", entry)
+                with open(self.FILENAME_TPL.format(**entry), "w") as params:
                     jp = JobParams(
-                        slot=entry['slot'],
-                        slot_build_id=entry['build_id'],
-                        project=entry['project'],
-                        platform=entry['platform'],
-                        os_label=entry.get('os_label',
-                                           entry['platform'].split('-')[1]),
-                        flavour=self.options.flavour)
-                    for k, v in entry.get('scripts', {}).items():
+                        slot=entry["slot"],
+                        slot_build_id=entry["build_id"],
+                        project=entry["project"],
+                        platform=entry["platform"],
+                        os_label=entry.get("os_label", entry["platform"].split("-")[1]),
+                        flavour=self.options.flavour,
+                    )
+                    for k, v in entry.get("scripts", {}).items():
                         if v:
-                            setattr(jp, 'scripts_{0}'.format(k), v)
-                    for k, v in entry.get('venv', {}).items():
+                            setattr(jp, "scripts_{0}".format(k), v)
+                    for k, v in entry.get("venv", {}).items():
                         if v:
                             setattr(jp, k, v)
-                    label = '-tests'
-                    arch_label = requires(jp.platform).split('-')[0] + label
+                    label = "-tests"
+                    arch_label = requires(jp.platform).split("-")[0] + label
                     # FIXME: until we have new labels on all hosts we need something special
                     #        for x86_64 and avx2
-                    if 'avx2' in jp.platform:
-                        arch_label = 'avx2' + label  # should become 'broadwell' + label
+                    if "avx2" in jp.platform:
+                        arch_label = "avx2" + label  # should become 'broadwell' + label
                     else:
-                        arch_label = arch_label.replace(
-                            'x86_64-', 'nightly-').replace(
-                                'nehalem-', 'nightly-')
+                        arch_label = arch_label.replace("x86_64-", "nightly-").replace(
+                            "nehalem-", "nightly-"
+                        )
                     jp.tests_node = arch_label
                     params.write(str(jp))
-                    params.write('\n')
+                    params.write("\n")
                 triggered.append(entry)
                 used_ids.add(test_id(entry))
                 if len(triggered) == self.BATCH_SIZE:
                     break
         to_drop.extend(triggered)
         # drop also all entries that duplicate a test just triggered
         for entry in entries:
             if entry not in to_drop and test_id(entry) in used_ids:
-                self.log.warning('duplicated entry: %s', entry)
+                self.log.warning("duplicated entry: %s", entry)
                 to_drop.append(entry)
 
         if self.options.submit:
 
             def strip_removed_entries(d):
-                '''callback to update the dashboard document'''
-                if 'entries' not in d:
-                    d['entries'] = []
-                d['entries'] = [
-                    entry for entry in d['entries'] if entry not in to_drop
-                ]
+                """callback to update the dashboard document"""
+                if "entries" not in d:
+                    d["entries"] = []
+                d["entries"] = [entry for entry in d["entries"] if entry not in to_drop]
                 return d
 
-            d.update('ready-builds', strip_removed_entries)
-        self.log.info('triggered %d tests, %d pending', len(triggered),
-                      len(entries) - len(to_drop))
+            d.update("ready-builds", strip_removed_entries)
+        self.log.info(
+            "triggered %d tests, %d pending",
+            len(triggered),
+            len(entries) - len(to_drop),
+        )
 
 
 def run():
     return Script().run()
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Index.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Index.py`

 * *Files 16% similar despite different names*

```diff
@@ -4,213 +4,228 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Module supporting the script to index the builds using glimpseindex.
-'''
-__author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+"""
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
 
+import logging
 import os
 import re
-import logging
-from hashlib import sha1  # pylint: disable=E0611
-from subprocess import Popen, PIPE
 from datetime import datetime
+from hashlib import sha1  # pylint: disable=E0611
+from subprocess import PIPE, Popen
 
-from LbNightlyTools.Utils import pack, ensureDirs, wipeDir
+from LbNightlyTools.Utils import ensureDirs, pack, wipeDir
 
 ALLOWED_EXTENSIONS = set(
     [  # official sources (yes, including Python and options)
-        '.h',
-        '.cpp',
-        '.icpp',
-        '.py',
-        '.opts',
+        ".h",
+        ".cpp",
+        ".icpp",
+        ".py",
+        ".opts",
         # special sources
-        '.cxx',
-        '.hpp',
-        '.C',
-        '.cc',
-        '.c',
-        '.F',
-        '.inc',
+        ".cxx",
+        ".hpp",
+        ".C",
+        ".cc",
+        ".c",
+        ".F",
+        ".inc",
         # shell scripts
-        '.sh',
-        '.csh',
+        ".sh",
+        ".csh",
         # extras
-        '.txt',
-        '.cmake',
-    ])
-INCLUSIONS = [r'.*/requirements$', r'.*/scripts/[^.]*$']
+        ".txt",
+        ".cmake",
+    ]
+)
+INCLUSIONS = [r".*/requirements$", r".*/scripts/[^.]*$"]
 
 EXCLUSIONS = [
-    r'.*_confDb\.py$', r'InstallArea.*\.cmake$', r'CTest.*\.cmake',
-    r'SlotConfig\.cmake', r'cache_preload\.cmake',
-    r'(.*/)?(set|clean)up\.c?sh$', r'.*_dict\.cpp$', r'.*/genConf/.*'
+    r".*_confDb\.py$",
+    r"InstallArea.*\.cmake$",
+    r"CTest.*\.cmake",
+    r"SlotConfig\.cmake",
+    r"cache_preload\.cmake",
+    r"(.*/)?(set|clean)up\.c?sh$",
+    r".*_dict\.cpp$",
+    r".*/genConf/.*",
 ]
 
 __log__ = logging.getLogger(__name__)
 
 
 def _isFileWanted(path):
-    '''
+    """
     Tell if a path is required according to the allowed extensions, inclusion
     and exclusion rules.
 
     >>> _isFileWanted('source.cpp')
     True
     >>> _isFileWanted('test.xml')
     False
     >>> _isFileWanted('cmt/requirements')
     True
     >>> _isFileWanted('InstallArea/ProjectConfig.cmake')
     False
-    '''
+    """
 
     # helpers
     def isMatchedByAny(path, regexps):
-        '@return: True if any expression in regexps matches path'
+        "@return: True if any expression in regexps matches path"
         return any(re.match(ex, path) for ex in regexps)
 
     def isIncluded(path):
-        '@return: True if the file is in the inclusions list'
+        "@return: True if the file is in the inclusions list"
         ext = os.path.splitext(path)[1]
         return ext in ALLOWED_EXTENSIONS or isMatchedByAny(path, INCLUSIONS)
 
     def isExcluded(path):
-        '@return: True if the file is in the exclusions list'
+        "@return: True if the file is in the exclusions list"
         return isMatchedByAny(path, EXCLUSIONS)
 
     # we accept files that have the right extension or are matched by one of
     # the INCLUSIONS patterns
     return isIncluded(path) and not isExcluded(path)
 
 
 def filesToIndex(path):
-    '''
+    """
     Given a directory, return an iterator over the files that need to be
     indexed, according to a filename pattern and avoiding duplication.
 
     The returned file names are relative to 'path'.
-    '''
+    """
     hashes = set()  # keep track of the contents indexed
 
     def isNotEmpty(path):
-        '@return: True if the path exist and is not empty'
+        "@return: True if the path exist and is not empty"
         return os.path.exists(path) and os.stat(path).st_size != 0
 
     def isGenConfOutput(path):
-        '@return: True if the file looks like it\'s generated by genconf'
-        return (path.endswith('Conf.py')
-                and 'Automatically generated.' in open(path).readline())
+        "@return: True if the file looks like it's generated by genconf"
+        return (
+            path.endswith("Conf.py")
+            and "Automatically generated." in open(path).readline()
+        )
 
     for root, dirs, files in os.walk(path):
         # ensure that we get a predictable order
         dirs.sort()
         files.sort()
         # move 'InstallArea' to the beginning of the list
-        if 'InstallArea' in dirs:
-            dirs.remove('InstallArea')
-            dirs.insert(0, 'InstallArea')
+        if "InstallArea" in dirs:
+            dirs.remove("InstallArea")
+            dirs.insert(0, "InstallArea")
         # remove directories called 'build.*'
-        for build_dir in [d for d in dirs if d.startswith('build.')]:
+        for build_dir in [d for d in dirs if d.startswith("build.")]:
             dirs.remove(build_dir)
         # loop over the list of files
         for filename in files:
             filename = os.path.join(root, filename)
             relname = os.path.relpath(filename, path)
             # accept only the allowed extensions or no extension for scripts
-            if (_isFileWanted(relname) and isNotEmpty(filename)
-                    and not isGenConfOutput(filename)):
+            if (
+                _isFileWanted(relname)
+                and isNotEmpty(filename)
+                and not isGenConfOutput(filename)
+            ):
                 # return this filename only if the content was not yet
                 # encountered
-                filehash = sha1(open(filename).read()).digest()
+                filehash = sha1(open(filename, "rb").read()).digest()
                 if filehash not in hashes:
                     hashes.add(filehash)
                     yield relname
 
 
 from LbNightlyTools.Scripts.Common import BaseScript
 
 
 class Script(BaseScript):
-    '''
+    """
     Script to produce the index files for all the projects defined in the
     configuration.
-    '''
+    """
 
     def defineOpts(self):
-        '''Options of the script.'''
-        from LbNightlyTools.Scripts.Common import (addBasicOptions,
-                                                   addDashboardOptions)
+        """Options of the script."""
+        from LbNightlyTools.Scripts.Common import addBasicOptions, addDashboardOptions
+
         addBasicOptions(self.parser)
         addDashboardOptions(self.parser, with_submit=False)
 
     def packname(self, proj):
-        '''
+        """
         Return the filename of the archive (package) of the given project.
-        '''
+        """
         packname = [proj.name, proj.version]
         if self.options.build_id:
             packname.append(self.options.build_id)
-        packname.append('index')
-        packname.append('zip')
-        return '.'.join(packname)
+        packname.append("index")
+        packname.append("zip")
+        return ".".join(packname)
 
     def main(self):
-        '''script logic'''
+        """script logic"""
         self._setup()
         from os.path import join
 
         # FIXME: check if the command glimpseindex is available
 
-        indexes_dir = join(os.getcwd(), 'indexes')
+        indexes_dir = join(os.getcwd(), "indexes")
         wipeDir(indexes_dir)
-        ensureDirs([indexes_dir, join(self.artifacts_dir, 'packs', 'index')])
+        ensureDirs([indexes_dir, join(self.artifacts_dir, "packs", "index")])
 
         log_level = self.log.getEffectiveLevel()
         if log_level <= logging.DEBUG:
             glimpse_stdout = None  # this prints to the regular stdout
         else:
-            glimpse_stdout = open(os.devnull, 'w')  # throw away output
+            glimpse_stdout = open(os.devnull, "w")  # throw away output
 
         for proj in self.slot.activeProjects:
             proj_root = self._buildDir(proj)
             # ignore missing directories
             # (the project may not have been checked out)
             if not os.path.exists(proj_root):
-                self.log.warning('%s not found, skip indexing', proj)
+                self.log.warning("%s not found, skip indexing", proj)
                 continue
 
-            self.log.info('Indexing %s', proj)
+            self.log.info("Indexing %s", proj)
 
             index_dir = join(indexes_dir, proj.baseDir)
             ensureDirs([index_dir])
 
-            glimpseindex = Popen(['glimpseindex', '-H', index_dir, '-F'],
-                                 cwd=proj_root,
-                                 stdin=PIPE,
-                                 stdout=glimpse_stdout)
+            glimpseindex = Popen(
+                ["glimpseindex", "-H", index_dir, "-F"],
+                cwd=proj_root,
+                stdin=PIPE,
+                stdout=glimpse_stdout,
+            )
             for f in filesToIndex(proj_root):
-                glimpseindex.stdin.write(f + '\n')
+                glimpseindex.stdin.write((f + "\n").encode("utf-8"))
             glimpseindex.stdin.close()
             glimpseindex.wait()
 
-            self.log.debug('fixing indexes permissions')
+            self.log.debug("fixing indexes permissions")
             for dirpath, _, filenames in os.walk(index_dir):
-                os.chmod(dirpath, 0755)
+                os.chmod(dirpath, 0o755)
                 for filename in filenames:
-                    os.chmod(join(dirpath, filename), 0644)
-            self.log.info('packing indexes for %s...', proj)
-            pack([proj.baseDir],
-                 join(self.artifacts_dir, 'packs', 'index',
-                      self.packname(proj)),
-                 cwd=indexes_dir,
-                 checksum='md5')
-
-        self.log.info('files indexed (time taken: %s).',
-                      datetime.now() - self.starttime)
+                    os.chmod(join(dirpath, filename), 0o644)
+            self.log.info("packing indexes for %s...", proj)
+            pack(
+                [proj.baseDir],
+                join(self.artifacts_dir, "packs", "index", self.packname(proj)),
+                cwd=indexes_dir,
+                checksum="md5",
+            )
+
+        self.log.info(
+            "files indexed (time taken: %s).", datetime.now() - self.starttime
+        )
         return 0
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/CollectBuildLogs.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/CollectBuildLogs.py`

 * *Files 16% similar despite different names*

```diff
@@ -4,279 +4,284 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Collect the build logs produced by lbn-wrapcmd and write the content grouped by
 subdir and target.
-'''
-__author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+"""
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
 
-import cgi
-import os
+import html
 import logging
+import os
+
 from LbNightlyTools.Scripts.Common import PlainScript
 
 
 def collect_cmake_logs(path):
-    '''
+    """
     Looks for files ending in '-build.log' in all the subdirs.
 
     @param path: directory where to start the search from
     @return: dictionary with the subdir as key (relative path) and the list of
              files (full path) as values.
-    '''
-    log = logging.getLogger('collect_cmake_logs')
-    log.info('searching for log files')
+    """
+    log = logging.getLogger("collect_cmake_logs")
+    log.info("searching for log files")
     logs = {}
     for subdir, _dirs, files in os.walk(path):
-        files = [
-            os.path.join(subdir, f) for f in files if f.endswith('-build.log')
-        ]
+        files = [os.path.join(subdir, f) for f in files if f.endswith("-build.log")]
         if files:
-            log.debug('found %d files in %s', len(files), subdir)
+            log.debug("found %d files in %s", len(files), subdir)
             files.sort()
             logs[os.path.relpath(subdir, path)] = files
     return logs
 
 
 def collect_cmt_logs(path, platform):
-    '''
+    """
     Looks for files ending in '-build.log' in all the subdirs.
 
     @param path: directory where to start the search from
     @return: dictionary with the subdir as key (relative path) and the list of
              files (full path) as values.
-    '''
-    logging.getLogger('collect_cmt_logs').info('searching for log files')
+    """
+    logging.getLogger("collect_cmt_logs").info("searching for log files")
     logs = {}
-    filename = 'build.{0}.log'.format(platform)
+    filename = "build.{0}.log".format(platform)
     for subdir, _dirs, files in os.walk(path):
         if filename in files:
-            logs[os.path.relpath(subdir,
-                                 path)] = [os.path.join(subdir, filename)]
+            logs[os.path.relpath(subdir, path)] = [os.path.join(subdir, filename)]
     return logs
 
 
 class CollectLogsError(RuntimeError):
-    '''
+    """
     Exception raised when there are problems collecting the build logs.
-    '''
+    """
+
     pass
 
 
-class RegexExcusion(object):
-    '''
+class RegexExcusion:
+    """
     Small helper class to filter a list excluding entries matching one of the
     provided regular expressions.
-    '''
+    """
 
     def __init__(self, exps):
-        '''
+        """
         Initialize the object with a list of regular expression (strings).
-        '''
+        """
         from re import compile
-        self.exps = map(compile, exps)
+
+        self.exps = [compile(exp) for exp in exps]
 
     def __call__(self, s):
-        '''
+        """
         Check if a string is good (no match) or not (match).
 
         @return: True if there is no match, False if there is a match.
-        '''
+        """
         for x in self.exps:
             if x.match(s):
                 return False
         return True
 
     def filter(self, iterable):
-        '''
+        """
         Generator that returns only the good (not excluded) entries in an
         iterable.
-        '''
+        """
         return (s for s in iterable if self(s))
 
 
 class Script(PlainScript):
-    '''
+    """
     Collect partial build logs from a directory and group them in a single
     file.
-    '''
-    __usage__ = '%prog [options] directory output_file'
+    """
+
+    __usage__ = "%prog [options] directory output_file"
 
     def defineOpts(self):
-        '''
+        """
         Options specific to this script.
-        '''
+        """
         self.parser.add_option(
-            '--append',
+            "--append",
             action="store_true",
-            help='append to the output file instead of '
-            'overwrite it')
+            help="append to the output file instead of " "overwrite it",
+        )
         self.parser.add_option(
-            '-x',
-            '--exclude',
+            "-x",
+            "--exclude",
             action="append",
-            help='regular expression to select files that '
-            'should not be included in the output')
+            help="regular expression to select files that "
+            "should not be included in the output",
+        )
         self.parser.add_option(
-            '--cmt',
-            action='store_const',
-            dest='build_tool',
-            const='cmt',
-            help='expect a CMT build directory')
+            "--cmt",
+            action="store_const",
+            dest="build_tool",
+            const="cmt",
+            help="expect a CMT build directory",
+        )
         self.parser.add_option(
-            '--cmake',
-            action='store_const',
-            dest='build_tool',
-            const='cmake',
-            help='expect a CMake build directory (default)')
+            "--cmake",
+            action="store_const",
+            dest="build_tool",
+            const="cmake",
+            help="expect a CMake build directory (default)",
+        )
         self.parser.add_option(
-            '--platform',
-            action='store',
-            help='platform id (used only with the CMT '
-            'scanner) [default: %default]')
-        platform = os.environ.get('BINARY_TAG', os.environ.get(
-            'CMTCONFIG', ''))
-        self.parser.set_defaults(
-            exclude=[], build_tool='cmake', platform=platform)
+            "--platform",
+            action="store",
+            help="platform id (used only with the CMT " "scanner) [default: %default]",
+        )
+        platform = os.environ.get("BINARY_TAG", os.environ.get("CMTCONFIG", ""))
+        self.parser.set_defaults(exclude=[], build_tool="cmake", platform=platform)
 
     def cmake(self):
-        '''
+        """
         CMake specific logic.
-        '''
+        """
         path, output = self.args
         exclude = RegexExcusion(self.options.exclude)
 
         logs = collect_cmake_logs(path)
         if not logs:
-            raise CollectLogsError(
-                'lbn-wrapcmd did not produce files in %s' % path)
+            raise CollectLogsError("lbn-wrapcmd did not produce files in %s" % path)
 
         # sort the directories by contained filename, so that even if they
         # are built at the same time, the one that completes first wins
         # (note that the list of files in each subdir is sorted)
         from os.path import basename
+
         subdirs = sorted(logs, key=lambda s: (basename(logs[s][-1]), s))
         # copy the content of each log file into the output file, prepending
         # the group of files in a subdir with a separator
-        with open(output, 'a' if self.options.append else 'w') as outfile:
+        with open(output, "a" if self.options.append else "w") as outfile:
             for subdir in subdirs:
                 # we want to show only files that are not excluded
                 files = exclude.filter(logs[subdir])
                 if files:
                     # targets in the '.' directory are "global" targets
-                    if subdir == '.':
+                    if subdir == ".":
                         subdir = "ROOT_DIR"
-                    outfile.write('#### CMake %s ####\n' % subdir)
+                    outfile.write("#### CMake %s ####\n" % subdir)
                     for fname in files:
                         outfile.writelines(open(fname))
 
     def cmt(self):
-        '''
+        """
         CMT specific logic.
-        '''
+        """
         path, output = self.args
         exclude = RegexExcusion(self.options.exclude)
 
         logs = collect_cmt_logs(path, self.options.platform)
         if not logs:
-            raise CollectLogsError(
-                'CMT build did not produce log files in %s' % path)
+            raise CollectLogsError("CMT build did not produce log files in %s" % path)
 
         # sort the directories by contained filename, so that even if they
         # are built at the same time, the one that completes first wins
         # (note that the list of files in each subdir is sorted)
         import re
-        hdr = re.compile(r'Building package[^[]*\[(\d+)/\d+\]')
+
+        hdr = re.compile(r"Building package[^[]*\[(\d+)/\d+\]")
 
         def key(subdir):
             filename = logs[subdir][0]
             # self.log.debug('key for %s', filename)
             with open(filename) as f:
                 m = hdr.search(f.read(1024))
             k = int(m.group(1)) if m else None
             # self.log.debug('key found: %s', k)
             return k
 
         subdirs = sorted(logs, key=key)
         # copy the content of each log file into the output file, prepending
         # the group of files in a subdir with a separator
-        with open(output, 'a' if self.options.append else 'w') as outfile:
+        with open(output, "a" if self.options.append else "w") as outfile:
             for subdir in subdirs:
                 # we want to show only files that are not excluded
                 files = exclude.filter(logs[subdir])
                 for fname in files:
                     outfile.writelines(open(fname))
 
     def main(self):
-        '''
+        """
         Script logic.
-        '''
+        """
         try:
             getattr(self, self.options.build_tool)()
             return 0
-        except CollectLogsError, x:
+        except CollectLogsError as x:
             self.log.error(str(x))
             return 1
 
 
-CHUNK_LOADER = '''<!DOCTYPE html><html><head><meta charset="utf-8">
+CHUNK_LOADER = """<!DOCTYPE html><html><head><meta charset="utf-8">
 <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
 <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">
 <link rel="stylesheet" href="ansi.css"></head>
 <body>Loading...</body>
 <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
 <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
 <script>
 document.title = location.search.slice(1);
 $('body').load(document.title + '.html', function(){
   if (location.hash) location.hash = location.hash;
 });
 </script>
-</html>'''
+</html>"""
 
 TABLE_HEAD = '<table class="table table-striped" style="text-align:left">'
-TABLE_TAIL = '</table>'
+TABLE_TAIL = "</table>"
 
 
 class IssueLinker(object):
     def __init__(self, issues, url_format):
         self.issues = issues
         self.url_format = url_format
         self._count = 0
 
     def __call__(self, line):
         n = self._count
         for issue in self.issues:
             l, h = issue.log_range
             if n >= l and n < h:
-                txt = cgi.escape(issue.linkText(), quote=True)
+                txt = html.escape(issue.linkText(), quote=True)
                 line = line.replace(
-                    txt, '<a href="{url}">{txt}</a>'.format(
-                        url=self.url_format(issue.source), txt=txt))
+                    txt,
+                    '<a href="{url}">{txt}</a>'.format(
+                        url=self.url_format(issue.source), txt=txt
+                    ),
+                )
                 break
         self._count += 1
         return line
 
 
 class GitlabUrlFormat(object):
     def __init__(self, base_url):
-        base_url = base_url.rstrip('/')
-        self.format = base_url + '/{name}#L{line}'
+        base_url = base_url.rstrip("/")
+        self.format = base_url + "/{name}#L{line}"
 
     def __call__(self, source):
         return self.format.format(name=source.name, line=source.line)
 
 
 def report_dict(chunks, reports):
-    '''
+    """
     Convert list of (chunk_id, lines) and a dictionary {chunk_id: issues} into
     a simplified report suitable for conversion to JSON.
 
     The output format is:
 
         {'sections': [{'id': 'section_id',
                        'desc': 'html title of the section',
@@ -286,142 +291,143 @@
                   'section_id': 'id of section it comes from',
                   'anchor': 'html anchor in section content',
                   'desc': 'one line description of the issue',
                   'text': ['full issue', 'report', ...]
              }, ...],
              ...
         }}
-    '''
+    """
     from LbNightlyTools.BuildLogScanner import Issue, remove_colors
 
-    report = {
-        'sections': [],
-        'issues': {severity: []
-                   for severity in Issue.SEVERITIES}
-    }
+    report = {"sections": [], "issues": {severity: [] for severity in Issue.SEVERITIES}}
 
     for chunk_id, chunk in chunks:
-        report['sections'].append({
-            'id': chunk_id,
-            'desc': chunk_id,
-            'url': '{}.html'.format(chunk_id)
-        })
+        report["sections"].append(
+            {"id": chunk_id, "desc": chunk_id, "url": "{}.html".format(chunk_id)}
+        )
         for issue in reports[chunk_id]:
-            report['issues'][issue.severity].append({
-                'section_id':
-                chunk_id,
-                'anchor':
-                '{0}_{1}'.format(chunk_id, issue.log_range[0] + 1),
-                'desc':
-                cgi.escape(str(issue), quote=True),
-                'text': [
-                    cgi.escape(remove_colors(line.rstrip()), quote=True)
-                    for line in chunk[issue.log_range[0]:issue.log_range[1]]
-                ]
-            })
+            report["issues"][issue.severity].append(
+                {
+                    "section_id": chunk_id,
+                    "anchor": "{0}_{1}".format(chunk_id, issue.log_range[0] + 1),
+                    "desc": html.escape(str(issue), quote=True),
+                    "text": [
+                        html.escape(remove_colors(line.rstrip()), quote=True)
+                        for line in chunk[issue.log_range[0] : issue.log_range[1]]
+                    ],
+                }
+            )
     return report
 
 
 def write_report_index(report, output_dir):
-    '''
+    """
     Generate index.html (and accessory files) to allow access to report
     sections.
-    '''
-    from LbNightlyTools.HTMLUtils import HTML_STYLE
+    """
     from LbNightlyTools.BuildLogScanner import Issue
+    from LbNightlyTools.HTMLUtils import HTML_STYLE
     from LbNightlyTools.Utils import natsort_key
 
-    with open(os.path.join(output_dir, 'index.html'), 'w') as h:
-        title = 'Build Log'
-        if 'project' in report:
-            title += ' of ' + cgi.escape(report['project'], quote=True)
-            if 'version' in report:
-                title += '/' + cgi.escape(report['version'], quote=True)
-        h.write('<!DOCTYPE html><html><head><meta charset="utf-8">'
-                '<style>.issue-error {{background-color: pink;}}\n'
-                '.issue-warning {{background-color: lightyellow;}}</style>'
-                '<title>{0}</title></head><body><h1>{0}</h1>\n'.format(title))
+    with open(os.path.join(output_dir, "index.html"), "w") as h:
+        title = "Build Log"
+        if "project" in report:
+            title += " of " + html.escape(report["project"], quote=True)
+            if "version" in report:
+                title += "/" + html.escape(report["version"], quote=True)
+        h.write(
+            '<!DOCTYPE html><html><head><meta charset="utf-8">'
+            "<style>.issue-error {{background-color: pink;}}\n"
+            ".issue-warning {{background-color: lightyellow;}}</style>"
+            "<title>{0}</title></head><body><h1>{0}</h1>\n".format(title)
+        )
 
-        if 'ignored_issues' in report:
+        if "ignored_issues" in report:
             ignored = []
             for severity in Issue.SEVERITIES:
-                counts = report['ignored_issues'].get(severity, {})
+                counts = report["ignored_issues"].get(severity, {})
                 if sum(counts.values()):
-                    ignored.append(
-                        '<li><strong>{}</strong>\n<ul>\n'.format(severity))
-                    ignored.extend('<li>{}: {}</li>\n'.format(
-                        cgi.escape(text, quote=True), count)
-                                   for text, count in counts.items() if count)
-                    ignored.append('</ul></li>\n')
+                    ignored.append("<li><strong>{}</strong>\n<ul>\n".format(severity))
+                    ignored.extend(
+                        "<li>{}: {}</li>\n".format(html.escape(text, quote=True), count)
+                        for text, count in counts.items()
+                        if count
+                    )
+                    ignored.append("</ul></li>\n")
             if ignored:
-                h.write('<h2>Ignored issues</h2>\n<ul>\n')
+                h.write("<h2>Ignored issues</h2>\n<ul>\n")
                 h.writelines(ignored)
-                h.write('</ul>\n')
+                h.write("</ul>\n")
 
-        h.write('<h2>Sections:</h2>\n<ul>\n')
-        for section in report['sections']:
-            h.write('<li><a href="load_section.html?{id}">{id}</a>\n'.format(
-                **section))
+        h.write("<h2>Sections:</h2>\n<ul>\n")
+        for section in report["sections"]:
+            h.write('<li><a href="load_section.html?{id}">{id}</a>\n'.format(**section))
             # add the list only if we do have any issue
-            if sum(len(items) for items in report['issues'].values()):
-                h.write('<ul>')
+            if sum(len(items) for items in report["issues"].values()):
+                h.write("<ul>")
                 for severity in Issue.SEVERITIES:
                     issues = [
-                        issue for issue in report['issues'][severity]
-                        if issue['section_id'] == section['id']
+                        issue
+                        for issue in report["issues"][severity]
+                        if issue["section_id"] == section["id"]
                     ]
                     if issues:
-                        issues.sort(
-                            key=lambda issue: natsort_key(issue['desc']))
+                        issues.sort(key=lambda issue: natsort_key(issue["desc"]))
                         h.write(
                             '<li class="issue-{0}">{0}s ({1})<ul>\n'.format(
-                                severity, len(issues)))
+                                severity, len(issues)
+                            )
+                        )
                         h.writelines(
                             '<li><a href="load_section.html?'
-                            '{section_id}#{anchor}">{desc}</a></li>\n'.format(
-                                **issue) for issue in issues)
-                        h.write('</ul></li>')
-                h.write('</ul>')
-            h.write('</li>\n')
-        h.write('</ul>\n</body>\n')
+                            '{section_id}#{anchor}">{desc}</a></li>\n'.format(**issue)
+                            for issue in issues
+                        )
+                        h.write("</ul></li>")
+                h.write("</ul>")
+            h.write("</li>\n")
+        h.write("</ul>\n</body>\n")
 
-    with open(os.path.join(output_dir, 'ansi.css'), 'w') as h:
+    with open(os.path.join(output_dir, "ansi.css"), "w") as h:
         h.write(HTML_STYLE)
 
-    with open(os.path.join(output_dir, 'load_section.html'), 'w') as h:
+    with open(os.path.join(output_dir, "load_section.html"), "w") as h:
         h.write(CHUNK_LOADER)
 
 
 class LogToHTML(PlainScript):
-    '''
+    """
     Scan a build.log file and produce an HTML report for it.
-    '''
-    __usage__ = '%prog [options] path/to/build.log output_dir'
+    """
+
+    __usage__ = "%prog [options] path/to/build.log output_dir"
 
     def defineOpts(self):
-        '''
+        """
         Options specific to this script.
-        '''
-        self.parser.add_option(
-            '--build-root', help='build root of the project (to strip)')
+        """
         self.parser.add_option(
-            '--slot-build-root', help='build root of the slot (to strip)')
+            "--build-root", help="build root of the project (to strip)"
+        )
         self.parser.add_option(
-            '--base-url', help='base URL to access source files')
+            "--slot-build-root", help="build root of the slot (to strip)"
+        )
+        self.parser.add_option("--base-url", help="base URL to access source files")
         self.parser.set_defaults(strip_string=[])
 
     def main(self):
-        '''
+        """
         Script logic.
-        '''
+        """
         import json
+
         from LbNightlyTools.Scripts.Build import genBuildReport
 
         log_file, output_dir = self.args
 
-        jreport = genBuildReport(log_file, output_dir, self.options.build_root,
-                                 self.options.slot_build_root)
+        jreport = genBuildReport(
+            log_file, output_dir, self.options.build_root, self.options.slot_build_root
+        )
         json.dump(
-            jreport,
-            open(os.path.join(output_dir, 'report.json'), 'wb'),
-            indent=2)
+            jreport, open(os.path.join(output_dir, "report.json"), "wb"), indent=2
+        )
         write_report_index(jreport, output_dir)
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Install.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Install.py`

 * *Files 21% similar despite different names*

```diff
@@ -6,670 +6,819 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Module containing the classes and functions used install in a directory the
 products of a nightly build.
-'''
-__author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+"""
+from future import standard_library
+from past.builtins import execfile
 
+standard_library.install_aliases()
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
+
+import html.parser
+import json
+import logging
 import os
-import HTMLParser
-import urllib2
 import re
-import logging
-import time
 import shutil
-import json
 import sys
-
-from subprocess import Popen, PIPE, call, STDOUT
-from tempfile import mkstemp
+import time
+import urllib.error
+import urllib.parse
+import urllib.request
 from datetime import datetime
 from socket import gethostname
+from subprocess import PIPE, STDOUT, Popen, call
+from tempfile import mkstemp
 
-ARTIFACTS_URL = 'https://lhcb-nightlies-artifacts.web.cern.ch/lhcb-nightlies-artifacts'
+try:
+    from urllib.parse import urlparse, urlunparse
+except ImportError:  # Python2
+    from urllib.parse import urlparse, urlunparse
+
+ARTIFACTS_URL = "https://lhcb-nightlies-artifacts.web.cern.ch/lhcb-nightlies-artifacts"
+ARTIFACTS_URL_XROOTD = (
+    "root://eosproject.cern.ch//eos/project/l/lhcbwebsites/www/lhcb-nightlies-artifacts"
+)
 
 CHECK_SSL = True
 
 
 def urlopen(url):
-    '''
+    """
     Wrapper for urllib2.urlopen to enable or disable SSL verification.
-    '''
+    """
     if not CHECK_SSL and sys.version_info >= (2, 7, 9):
         # with Python >= 2.7.9 SSL certificates are validated by default
         # but we can ignore them
-        from ssl import SSLContext, PROTOCOL_SSLv23
-        return urllib2.urlopen(url, context=SSLContext(PROTOCOL_SSLv23))
-    return urllib2.urlopen(url)
+        from ssl import PROTOCOL_SSLv23, SSLContext
+
+        return urllib.request.urlopen(url, context=SSLContext(PROTOCOL_SSLv23))
+    return urllib.request.urlopen(url)
 
 
 def _list_http(url):
-    '''
+    """
     Implementation of listdir for HTTP.
 
     The HTTP server must allow listing of directories with the typical Apache
     format.
-    '''
+    """
+    if url.startswith(ARTIFACTS_URL):
+        try:
+            return _list_xrootd(url.replace(ARTIFACTS_URL, ARTIFACTS_URL_XROOTD))
+        except Exception:
+            pass
 
-    class ListHTMLParser(HTMLParser.HTMLParser):
-        '''
+    class ListHTMLParser(html.parser.HTMLParser):
+        """
         Specialized HTML parser to extract the list of files from standard
         Apache directory listing.
-        '''
+        """
 
         # pylint: disable=R0904
         def __init__(self):
-            HTMLParser.HTMLParser.__init__(self)
+            html.parser.HTMLParser.__init__(self)
             self.data = []
             self._href = None
-            self._text = ''
+            self._text = ""
 
         def handle_starttag(self, tag, attrs):
-            if tag == 'a':
+            if tag == "a":
                 attrs = dict(attrs)
-                self._href = attrs.get('href')
-                self._text = ''
+                self._href = attrs.get("href")
+                self._text = ""
 
         def handle_data(self, data):
             if self._href:
                 self._text += data
 
         def handle_endtag(self, tag):
-            if tag == 'a':
+            if tag == "a":
                 # ignore special entries like sorting links ("?...") or link to
                 # parent directory
-                if (self._href and '?' not in self._href
-                        and 'parent directory' not in self._text.lower()):
+                if (
+                    self._href
+                    and "?" not in self._href
+                    and "parent directory" not in self._text.lower()
+                ):
                     self.data.append(self._href)
                 self._href = None
-                self._text = ''
+                self._text = ""
 
     parser = ListHTMLParser()
-    parser.feed(urlopen(url).read().decode())
+    parser.feed(urlopen(url).read().decode("utf-8", errors="replace"))
     return parser.data
 
 
 def _list_ssh(url):
-    '''
+    """
     Implementation of listdir for SSH.
-    '''
-    host, path = url.split(':', 1)
-    proc = Popen(['ssh', host, 'ls -a1 %r' % path], stdout=PIPE)
-    return proc.communicate()[0].decode().splitlines()
+    """
+    host, path = url.split(":", 1)
+    proc = Popen(["ssh", host, "ls -a1 %r" % path], stdout=PIPE)
+    return proc.communicate()[0].decode("utf-8", errors="replace").splitlines()
+
+
+def _list_xrootd(url):
+    """
+    List a directory using "xrdfs .. ls ..."
+    """
+    u = urlparse(url)
+    proc = Popen(
+        ["xrdfs", urlunparse((u.scheme, u.netloc, "", "", "", "")), "ls", u.path],
+        stdout=PIPE,
+    )
+    root = u.path if u.path.endswith("/") else (u.path + "/")
+    # "xrdfs ls" always returns full path, so we have to strip that part
+    return [
+        f.replace(root, "")
+        for f in proc.communicate()[0].decode("utf-8", errors="replace").splitlines()
+    ]
 
 
 def _url_protocol(url):
-    '''
+    """
     @return the protocol id of the given URL
-    '''
-    if re.match(r'https?://', url):
-        return 'http'
-    elif re.match(r'([a-z0-9]+@)?[a-z][a-z0-9.]*:', url):
-        return 'ssh'
+    """
+    if re.match(r"https?://", url):
+        return "http"
+    elif url.startswith("root://"):
+        return "root"
+    elif re.match(r"([a-z0-9]+@)?[a-z][a-z0-9.]*:", url):
+        return "ssh"
     else:
-        return 'file'
+        return "file"
 
 
 def listdir(url):
-    '''
+    """
     @return the list of entries in a directory, being it over HTTP, ssh or
             local filesystem.
-    '''
+    """
     protocol = _url_protocol(url)
     listing = {
-        'http': _list_http,
-        'ssh': _list_ssh,
-        'file': os.listdir
+        "http": _list_http,
+        "ssh": _list_ssh,
+        "root": _list_xrootd,
+        "file": os.listdir,
     }[protocol](url)
     return sorted(listing)
 
 
 def getURL(url, dst):
-    '''
+    """
     Generic URL retriever with support for 'http:', 'file:' and 'ssh:'
     protocols.
-    '''
+    """
     protocol = _url_protocol(url)
 
     def getHTTP(url, dst):
-        '''Retrieve from 'http:'.'''
+        """Retrieve from 'http:'."""
         # code copied from shutil.copyfile
         fsrc = None
         fdst = None
+        if url.startswith(ARTIFACTS_URL):
+            try:
+                return getXRootD(url.replace(ARTIFACTS_URL, ARTIFACTS_URL_XROOTD), dst)
+            except Exception:
+                pass
         try:
             fsrc = urlopen(url)
-            fdst = open(dst, 'wb')
-            shutil.copyfileobj(fsrc, fdst)
+            with open(dst, "wb") as fdst:
+                shutil.copyfileobj(fsrc, fdst)
         finally:
-            if fdst:
-                fdst.close()
             if fsrc:
                 fsrc.close()
 
     def getSSH(url, dst):
-        '''Retrieve from 'ssh:'.'''
-        call(['scp', '-q', url, dst])
+        """Retrieve from 'ssh:'."""
+        call(["scp", "-q", url, dst])
+
+    def getXRootD(url, dst):
+        call(["xrdcp", "--force", "--nopbar", url, dst])
 
     return {
-        'http': getHTTP,
-        'ssh': getSSH,
-        'file': shutil.copy2
-    }[protocol](url, dst)
+        "http": getHTTP,
+        "ssh": getSSH,
+        "root": getXRootD,
+        "file": shutil.copy2,
+    }[
+        protocol
+    ](url, dst)
 
 
 def unpack(url, dest, exclude=None):
-    '''
+    """
     Unpack a tarball from 'url' into the directory 'dest'.
-    '''
+    """
     # download on a local file
-    log = logging.getLogger('unpack')
+    log = logging.getLogger("unpack")
     protocol = _url_protocol(url)
     tmpfd = None
     if exclude is None:
         exclude = []
     try:
-        if protocol != 'file':
+        if protocol != "file":
             tmpfd, tmpname = mkstemp()
             os.close(tmpfd)
-            log.info('retrieving %s', url)
-            log.debug('using tempfile %s', tmpname)
+            log.info("retrieving %s", url)
+            log.debug("using tempfile %s", tmpname)
             getURL(url, tmpname)
         else:
             tmpname = os.path.abspath(url)
-        log.info('unpacking %s', url)
-        if url.endswith('.tar.bz2'):
+        log.info("unpacking %s", url)
+        if url.endswith(".tar.bz2"):
             retcode = call(
-                ['tar', '-x', '-f', tmpname] +
-                ['--exclude=%s' % n for n in exclude],
-                cwd=dest)
-        elif url.endswith('.zip'):
-            cmd = ['unzip', '-q', '-o', tmpname]
+                ["tar", "-x", "-f", tmpname] + ["--exclude=%s" % n for n in exclude],
+                cwd=dest,
+            )
+        elif url.endswith(".zip"):
+            cmd = ["unzip", "-q", "-o", tmpname]
             for n in exclude:
-                cmd.extend(['-x', n])
+                cmd.extend(["-x", n])
             retcode = call(cmd, cwd=dest)
 
     finally:
         if tmpfd is not None:
             os.remove(tmpname)
     return retcode
 
 
 def install(url, dest, exclude=None):
-    '''
+    """
     Install the file at 'url' in the directory 'dest'.
 
     If url points to a tarball, it is unpacked, otherwise it is just copied.
-    '''
-    log = logging.getLogger('install')
+    """
+    log = logging.getLogger("install")
     if not os.path.exists(dest):
         log.info('creating directory "%s"', dest)
         os.makedirs(dest)
-    if url.endswith('.tar.bz2') or url.endswith('.zip'):
+    if url.endswith(".tar.bz2") or url.endswith(".zip"):
         return unpack(url, dest, exclude)
     else:
-        log.info('installing %s', url)
-        return getURL(url, os.path.join(dest, url.rsplit('/', 1)[1]))
+        log.info("installing %s", url)
+        return getURL(url, os.path.join(dest, url.rsplit("/", 1)[1]))
 
 
 def getDependencies(projects, slot_configuration):
-    ''' Extract dependencies of a list of projects,
-    using the slot configuration passed '''
+    """Extract dependencies of a list of projects,
+    using the slot configuration passed"""
 
     needed_projects = set()
-    log = logging.getLogger('getDependencies')
+    log = logging.getLogger("getDependencies")
 
     # Iterating over the projects
     for proj in projects:
         # First check the configuration
         proj_lower = proj.lower()
         pdata = None
-        for cp in (slot_configuration.get('projects', []) +
-                   slot_configuration.get('packages', [])):
+        for cp in slot_configuration.get("projects", []) + slot_configuration.get(
+            "packages", []
+        ):
             # Comparing lower case to be sure...
-            if cp['name'].lower() == proj_lower:
+            if cp["name"].lower() == proj_lower:
                 pdata = cp
                 break
 
         # If pdata still None, we have a problem...
         if pdata == None:
             raise Exception("Project %s not in slot metadata" % proj)
 
         # Looking up the project/dependency info
-        pdeps = pdata.get('dependencies', [])
+        pdeps = pdata.get("dependencies", [])
 
         # Adding the direct deps to the set
         for dep in pdeps:
-            log.debug('%s depends on %s' % (proj_lower, dep))
+            log.debug("%s depends on %s" % (proj_lower, dep))
             needed_projects.add(dep)
 
         # check for extra packages in container projects:
         needed_projects |= set(
-            pack['name'] for pack in slot_configuration.get('packages', [])
-            if pack.get('container', '').lower() == proj_lower)
+            pack["name"]
+            for pack in slot_configuration.get("packages", [])
+            if pack.get("container", "").lower() == proj_lower
+        )
 
         # Now looking for transitive deps and adding dependencies
         alldeps = getDependencies(pdeps, slot_configuration)
         needed_projects |= alldeps
 
     return needed_projects
 
 
-def requiredPackages(files,
-                     slot=None,
-                     build_id=None,
-                     projects=None,
-                     platforms=None,
-                     skip=None,
-                     metadataurl=None,
-                     add_dependencies=True):
-    '''
+def requiredPackages(
+    files,
+    slot=None,
+    build_id=None,
+    projects=None,
+    platforms=None,
+    skip=None,
+    metadataurl=None,
+    add_dependencies=True,
+):
+    """
     Extract from the list of tarballs those that need to be installed considering
     the list of requested projects (default: all of them), platforms (default:
     all of them) and what to skip (default: nothing).
-    '''
-    log = logging.getLogger('requiredPackages')
+    """
+    log = logging.getLogger("requiredPackages")
 
     if skip is None:
         skip = set()
     else:
         skip = set(skip)
     if projects:
         # change to lowercase to make the check case-insensitive
-        projects = map(str.lower, projects)
+        projects = [p.lower() for p in projects]
 
     # Checking that we have the right info for the dependencies
     if add_dependencies and metadataurl == None:
         raise Exception("Dependency analysis requires slot configuration URL")
 
     slot_configuration = None
     # Getting the project metadata
     if metadataurl != None:
         try:
             tmpfd, tmpname = mkstemp()
             os.close(tmpfd)
-            log.info('retrieving %s', metadataurl)
-            log.debug('using tempfile %s', tmpname)
+            log.info("retrieving %s", metadataurl)
+            log.debug("using tempfile %s", tmpname)
             getURL(metadataurl, tmpname)
             slot_configuration = json.load(open(tmpname))
         finally:
             os.remove(tmpname)
 
     # Actually getting the dependencies and merging them with the project list
     if add_dependencies and projects is not None:
         allprojects = getDependencies(projects, slot_configuration)
         for proj in allprojects:
             if proj not in projects:
                 log.debug("Adding %s to the list of projects" % proj)
                 projects.append(proj.lower())
 
-    build_id = str(slot_configuration.get('build_id', build_id))
+    build_id = str(slot_configuration.get("build_id", build_id))
 
     if projects:
         # data packages may have '/' in the name, which is converted in '_'
         # in the tarball filename
-        projects = set(p.replace('/', '_') for p in projects)
+        projects = set(p.replace("/", "_") for p in projects)
 
     for filename in files:
         # file names have the format
         #   <project>.<version>.<tag.id>.<platform>{.zip,.tar.bz2}
-        ext = '.zip' if filename.endswith('.zip') else '.tar.bz2'
-        tokens = os.path.basename(filename[:-len(ext)]).split('.')
-        slot_tmp, build_id_tmp, project, platform = tokens[2], tokens[
-            3], tokens[0], tokens[-1]
+        ext = ".zip" if filename.endswith(".zip") else ".tar.bz2"
+        tokens = os.path.basename(filename[: -len(ext)]).split(".", 4)
+        slot_tmp, build_id_tmp, project, platform = (
+            tokens[2],
+            tokens[3],
+            tokens[0],
+            tokens[-1],
+        )
         if len(tokens) > 4 and (slot_tmp != slot or build_id_tmp != build_id):
             continue
         if projects is None or project.lower() in projects:
             if platforms is None or platform in platforms:
                 if filename not in skip:
                     yield filename
 
 
 def findGlimpseFilenames(path):
-    '''
+    """
     Give a top directory, return the iterator over all the .glimpse_filenames
     files that can be found (excluding some special directories).
-    '''
-    excluded_dirs = set([
-        'DOC', 'docs', 'scripts', 'scripts.old', 'DBASE', 'PARAM', 'TOOLS',
-        'XmlEditor'
-    ])
-    log = logging.getLogger('findGlimpseFilenames')
+    """
+    excluded_dirs = set(
+        [
+            "DOC",
+            "docs",
+            "scripts",
+            "scripts.old",
+            "DBASE",
+            "PARAM",
+            "TOOLS",
+            "XmlEditor",
+        ]
+    )
+    log = logging.getLogger("findGlimpseFilenames")
     path = os.path.abspath(path)
-    log.debug('Looking for .glimpse_filenames in %s', path)
+    log.debug("Looking for .glimpse_filenames in %s", path)
     for root, dirs, files in os.walk(path):
-        if '.glimpse_filenames' in files:
-            yield os.path.join(root, '.glimpse_filenames')
+        if ".glimpse_filenames" in files:
+            yield os.path.join(root, ".glimpse_filenames")
             # do not enter subdirectories (we assume no nested indexes)
             dirs[:] = []
-        elif 'Makefile' in files:
+        elif "Makefile" in files:
             # do not descend the projects substructure
             dirs[:] = []
         else:
             # do not descend the known special directories
             dirs[:] = list(set(dirs) - excluded_dirs)
 
 
 def fixGlimpseIndexes(iterable):
-    '''
+    """
     Give a list of of paths to .glimpse_filenames files, replace the relative
     paths with absolute ones.
-    '''
-    log = logging.getLogger('fixGlimpseIndexes')
-    log.debug('Fixing .glimpse_filenames')
+    """
+    log = logging.getLogger("fixGlimpseIndexes")
+    log.debug("Fixing .glimpse_filenames")
     for filename in iterable:
-        log.debug(' - %s', filename)
+        log.debug(" - %s", filename)
         f = open(filename)
         lines = f.readlines()
         f.close()
         root = os.path.dirname(filename)
         # join the file directory on all the lines except the first one
         # (it's a number)
         lines = lines[:1] + [os.path.join(root, l) for l in lines[1:]]
-        f = open(filename, 'w')
+        f = open(filename, "w")
         f.writelines(lines)
         f.close()
 
 
 def createVersionSymlinks(dest, config):
-    from os.path import exists, join
     from os import symlink
-    from re import search, MULTILINE
+    from os.path import exists, join
+    from re import MULTILINE, search
 
     def makeVersionLink(dest, name, version):
-        tgt = join(dest, '{0}_{1}'.format(name, version))
+        tgt = join(dest, "{0}_{1}".format(name, version))
         if not exists(tgt):
-            logging.debug('creating %s', tgt)
+            logging.debug("creating %s", tgt)
             symlink(name, tgt)
 
-    for project in config.get('projects', []):
-        name = project.get('name')
-        version = project.get('version')
-        if name and version != 'None' and exists(join(dest, name)):
+    for project in config.get("projects", []):
+        name = project.get("name")
+        version = project.get("version")
+        if name and version != "None" and exists(join(dest, name)):
             makeVersionLink(dest, name, version)
             # look for the declared project version
             try:
-                with open(join(dest, name, 'CMakeLists.txt')) as cml:
-                    data = ''.join(
-                        l for l in cml if not l.lstrip().startswith('#'))
-                version = search(
-                    r'gaudi_project\(\s*[^\s)]+\s+([^\s)]+)\s*[^)]*\)', data,
-                    MULTILINE)
+                with open(join(dest, name, "CMakeLists.txt")) as cml:
+                    data = "".join(l for l in cml if not l.lstrip().startswith("#"))
+
+                version = None
+                # try old style CMake configuration
+                version_match = search(
+                    r"gaudi_project\(\s*[^\s)]+\s+([^\s)]+)\s*[^)]*\)", data, MULTILINE
+                )
+                if version_match:
+                    version = version_match.group(1)
+                else:  # try new style CMake configuration
+                    version_match = search(
+                        r"project\(\s*[^\s)]+\s+VERSION\s+([\d.]+)\s*[^)]*\)",
+                        data,
+                        MULTILINE,
+                    )
+                    if version_match:  # map X.Y.Z to vXrYpZ
+                        version = "".join(
+                            a + b
+                            for a, b in zip("vrp", version_match.group(1).split("."))
+                        )
+
                 if version:
-                    makeVersionLink(dest, name, version.group(1))
+                    makeVersionLink(dest, name, version)
                 else:
-                    logging.debug('version not found in %s',
-                                  join(dest, name, 'CMakeLists.txt'))
+                    logging.debug(
+                        "version not found in %s", join(dest, name, "CMakeLists.txt")
+                    )
             except IOError:
                 pass  # ignore failures reading the CMakeLists.txt
 
 
 from LbNightlyTools.Scripts.Common import PlainScript
 
 
 class Script(PlainScript):
-    '''
+    """
     Script to install a in a directory a nightly build or a part of it.
-    '''
-    __usage__ = '%prog [options] slot-name[ |.|/]build-id'
-    __version__ = ''
+    """
+
+    __usage__ = "%prog [options] slot-name[ |.|/]build-id"
+    __version__ = ""
 
     def defineOpts(self):
         parser = self.parser
         parser.add_option(
-            '--artifacts-root',
-            action='store',
-            metavar='URI',
-            help='URL or directory where the build artifacts can '
-            'be found [default: %default]')
-        parser.add_option(
-            '--flavour',
-            action='store',
-            help='nightly build flavour to use '
-            '[default: %default]')
-        parser.add_option(
-            '--projects',
-            action='store',
-            help='comma-separated list of projects to install '
-            '[default: all]')
-        parser.add_option(
-            '--platforms',
-            action='store',
-            help='comma-separated list of platforms to install '
+            "--artifacts-root",
+            action="store",
+            metavar="URI",
+            help="URL or directory where the build artifacts can "
+            "be found [default: %default]",
+        )
+        parser.add_option(
+            "--flavour",
+            action="store",
+            help="nightly build flavour to use " "[default: %default]",
+        )
+        parser.add_option(
+            "--projects",
+            action="store",
+            help="comma-separated list of projects to install " "[default: all]",
+        )
+        parser.add_option(
+            "--platforms",
+            action="store",
+            help="comma-separated list of platforms to install "
             '(the special platform "src" is always included '
             'and "shared" is included if "src" is not '
-            'the only specified platform)'
-            ' [default: all]')
+            "the only specified platform)"
+            " [default: all]",
+        )
+        parser.add_option(
+            "--dest",
+            action="store",
+            help="directory where to install the artifacts "
+            "[default: <slot-name>/<build-id>]",
+        )
+
         parser.add_option(
-            '--dest',
-            action='store',
-            help='directory where to install the artifacts '
-            '[default: <slot-name>/<build-id>]')
+            "--nodeps",
+            action="store_true",
+            help="Disable the download of dependencies for a project "
+            "[default: False]",
+            default=False,
+        )
 
         parser.add_option(
-            '--nodeps',
-            action='store_true',
-            help='Disable the download of dependencies for a project '
-            '[default: False]',
-            default=False)
+            "-k",
+            "--insecure",
+            action="store_true",
+            help="skip SSL validation",
+            default=False,
+        )
 
         parser.add_option(
-            '-k',
-            '--insecure',
-            action='store_true',
-            help='skip SSL validation',
-            default=False)
+            "--no-git",
+            action="store_true",
+            help='do not extract ".git" directories from tarfiles',
+        )
 
         parser.add_option(
-            '--no-git',
-            action='store_true',
-            help='do not extract ".git" directories from tarfiles')
+            "--with-git",
+            action="store_false",
+            dest="no_git",
+            help='do extract ".git" directories from tarfiles',
+        )
 
         parser.add_option(
-            '--with-git',
-            action='store_false',
-            dest='no_git',
-            help='do extract ".git" directories from tarfiles')
+            "--no-build-dir",
+            action="store_true",
+            help='do not extract "build" directories from (binary) tarfiles',
+        )
 
         parser.add_option(
-            '--no-build-dir',
-            action='store_true',
-            help='do not extract "build" directories from (binary) tarfiles')
+            "--with-build-dir",
+            action="store_false",
+            dest="no_build_dir",
+            help='do extract "build" directories from (binary) tarfiles',
+        )
 
         parser.add_option(
-            '--with-build-dir',
-            action='store_false',
-            dest='no_build_dir',
-            help='do extract "build" directories from (binary) tarfiles')
+            "-j",
+            "--jobs",
+            help="number of parallel download+unpack jobs to use [default: -1, all CPUs]",
+        )
 
         parser.set_defaults(
             artifacts_root=ARTIFACTS_URL,
-            flavour='nightly',
+            flavour="nightly",
             no_git=False,
-            no_build_dir=True)
+            no_build_dir=True,
+            jobs="-1",
+        )
 
     def main(self):
+        from joblib import Parallel, delayed
+
         # split the 'comma-separated list' options
         opts = self.options
         if opts.projects:
-            opts.projects = map(str.strip, opts.projects.split(','))
+            opts.projects = [v.strip() for v in opts.projects.split(",")]
         if opts.platforms:
-            opts.platforms = map(str.strip, opts.platforms.split(','))
-            if opts.platforms != ['src']:
-                opts.platforms.append(
-                    'shared')  # ensure that 'src' is included
-            opts.platforms.append('src')  # ensure that 'src' is included
+            opts.platforms = [v.strip() for v in opts.platforms.split(",")]
+            if opts.platforms != ["src"]:
+                opts.platforms.append("shared")  # ensure that 'src' is included
+            opts.platforms.append("src")  # ensure that 'src' is included
 
         try:
             if len(self.args) == 1:
-                self.args = self.args[0].split('.' if '.' in self.
-                                               args[0] else '/')
+                self.args = self.args[0].split("." if "." in self.args[0] else "/")
             slot, build_id = self.args
         except ValueError:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         if opts.insecure:
             global CHECK_SSL
             CHECK_SSL = False
-            self.log.debug('ignoring SSL certificates')
+            self.log.debug("ignoring SSL certificates")
 
         dest = opts.dest or os.path.join(slot, build_id)
         if not os.path.exists(dest):
-            self.log.debug('creating directory %s' % dest)
+            self.log.debug("creating directory %s" % dest)
             os.makedirs(dest)
 
-        url = '/'.join([opts.artifacts_root, opts.flavour, slot, build_id])
-        history_file = os.path.join(dest, '.installed')
+        url = "/".join([opts.artifacts_root, opts.flavour, slot, build_id])
+        history_file = os.path.join(dest, ".installed")
 
         # URL for the slot-config file used to get the dependencies
-        metadataurl = '/'.join([url, 'slot-config.json'])
+        metadataurl = "/".join([url, "slot-config.json"])
 
-        lock_file = os.path.join(dest, '.lock')
-        self.log.debug('check for lock file %s', lock_file)
-        for _ in xrange(30):
+        lock_file = os.path.join(dest, ".lock")
+        self.log.debug("check for lock file %s", lock_file)
+        for _ in range(30):
             if not os.path.exists(lock_file):
                 break
             time.sleep(10)
         else:
             # the log file is still there: give up
             try:
-                pid, timestamp = (open(lock_file).readline().strip().split(
-                    ':', 1))
+                pid, timestamp = open(lock_file).readline().strip().split(":", 1)
                 self.log.error(
-                    'lockfile %s still present '
-                    '(generated by pid %s on %s)', lock_file, pid, timestamp)
+                    "lockfile %s still present " "(generated by pid %s on %s)",
+                    lock_file,
+                    pid,
+                    timestamp,
+                )
                 return 2
             except os.error:
                 # if we cannot read the file, probably it just disappeared
                 pass
             except ValueError:
                 # the lock file looks invalid, we can ignore it
                 pass
 
-        f = open(lock_file, 'w')
-        f.write('{0}@{1}:{2}\n'.format(os.getpid(), gethostname(),
-                                       datetime.now().isoformat()))
+        f = open(lock_file, "w")
+        f.write(
+            "{0}@{1}:{2}\n".format(
+                os.getpid(), gethostname(), datetime.now().isoformat()
+            )
+        )
         f.close()
-        self.log.debug('created lock file %s', lock_file)
+        self.log.debug("created lock file %s", lock_file)
 
         try:
             tarfiles = [
-                'packs/{0}/{1}'.format(subdir, f)
-                for subdir in listdir(url + '/packs')
-                for f in listdir(url + '/packs/' + subdir)
-                if f.endswith('.tar.bz2') or f.endswith('.zip')
+                "packs/{0}/{1}".format(subdir, f)
+                for subdir in listdir(url + "/packs")
+                for f in listdir(url + "/packs/" + subdir)
+                if f.endswith(".tar.bz2") or f.endswith(".zip")
             ]
             installed = {}
             if os.path.exists(history_file):
-                installed = dict(
-                    [l.strip().split(':', 1) for l in open(history_file)])
+                installed = dict([l.strip().split(":", 1) for l in open(history_file)])
             tarfiles = requiredPackages(
                 tarfiles,
                 slot,
                 build_id,
                 opts.projects,
                 opts.platforms,
                 installed,
                 metadataurl,
-                add_dependencies=not opts.nodeps)
+                add_dependencies=not opts.nodeps,
+            )
 
             required_files = list(tarfiles)  # tarfiles is a generator (so far)
-            required_files.append('slot-config.json')
+            required_files.append("slot-config.json")
             # add required non-zip files
-            other_files = set([
-                'configuration.xml', 'confSummary.py', 'searchPath.cmake',
-                'slot.patch'
-            ])
+            other_files = set(
+                [
+                    "configuration.xml",
+                    "confSummary.py",
+                    "searchPath.cmake",
+                    "slot.patch",
+                ]
+            )
             already_installed = set(installed)
             required_files.extend(
-                other_files.intersection(listdir(url)) - already_installed)
+                other_files.intersection(listdir(url)) - already_installed
+            )
             if required_files:
-                self.log.info('installing %d files', len(required_files))
+                self.log.info("installing %d files", len(required_files))
             else:
-                self.log.info('nothing to install')
+                self.log.info("nothing to install")
 
             # search for indexes already present so that we can skip fixing them
             pre_existing_indexes = set(findGlimpseFilenames(dest))
 
             index_installed = False
-            for f in required_files:
+
+            def do_install(f):
+                """Worker function for running the installation
+
+                When one process fails all the other running processes are
+                killed. This results in the "finally:" blocks not being called
+                and the temporary files are left hanging around.
+
+                Instead return a tuple of (status, result) where status is a
+                boolean representing if the install was successful. If the
+                install failed, result is an exception that should be raised.
+                """
                 exclude_list = []
                 if opts.no_git:
-                    exclude_list.append('*/.git/*')
+                    exclude_list.append("*/.git/*")
                 if opts.no_build_dir:
-                    exclude_list.append('*/build/*')
-                if install(
-                        url + '/' + f, dest,
-                        exclude=exclude_list):  # 0 or None mean success
-                    raise RuntimeError('error installing %s' % f)
-                installed[f] = datetime.now().isoformat()
+                    exclude_list.append("*/build/*")
+                # Glitches are common so retry up to three times
+                for i in range(3):
+                    if install(
+                        url + "/" + f, dest, exclude=exclude_list
+                    ):  # 0 or None mean success
+                        status, result = False, RuntimeError("error installing %s" % f)
+                    else:
+                        status, result = True, (f, datetime.now().isoformat())
+                        break
+                return status, result
+
+            installed = {}
+            for status, result in Parallel(n_jobs=int(opts.jobs) or 1)(
+                delayed(do_install)(f) for f in required_files
+            ):
+                if status:
+                    installed[result[0]] = result[1]
+                else:
+                    raise result
+
+            for f in installed:
                 # record what has been installed so far
-                histfile = open(history_file, 'w')
-                histfile.writelines(
-                    ['%s:%s\n' % i for i in sorted(installed.items())])
-                histfile.close()
-                if 'index' in f:
+                with open(history_file, "w") as histfile:
+                    histfile.writelines(
+                        ["%s:%s\n" % i for i in sorted(installed.items())]
+                    )
+                if "index" in f:
                     index_installed = True
-            if os.path.exists(os.path.join(dest, 'slot.patch')):
-                self.log.warning('Applying patch file: %s' % os.path.join(
-                    dest, 'slot.patch'))
-                command = ['patch', '-p1', '-f', '-i', 'slot.patch']
+            if os.path.exists(os.path.join(dest, "slot.patch")):
+                self.log.warning(
+                    "Applying patch file: %s" % os.path.join(dest, "slot.patch")
+                )
+                command = ["patch", "-p1", "-f", "-i", "slot.patch"]
                 proc = Popen(command, cwd=dest, stdout=PIPE, stderr=STDOUT)
                 out, _ = proc.communicate()
-                self.log.debug('output of %s:\n%s', command, out.decode())
+                self.log.debug(
+                    "output of %s:\n%s", command, out.decode("utf-8", errors="replace")
+                )
 
             if index_installed:
                 fixGlimpseIndexes(
-                    f for f in findGlimpseFilenames(dest)
-                    if f not in pre_existing_indexes)
+                    f
+                    for f in findGlimpseFilenames(dest)
+                    if f not in pre_existing_indexes
+                )
 
             # if 'confSummary.py' was just installed and actually exists,
             # we use it to generate a setup script for the CMTPROJECTPATH.
-            if ('confSummary.py' in installed
-                    and 'confSummary.py' not in already_installed
-                    and os.path.exists(os.path.join(dest, 'confSummary.py'))):
+            if (
+                "confSummary.py" in installed
+                and "confSummary.py" not in already_installed
+                and os.path.exists(os.path.join(dest, "confSummary.py"))
+            ):
                 # generate shell script equivalents
                 data = {}
-                execfile(os.path.join(dest, 'confSummary.py'), data)
-                search_path = data.get('cmtProjectPathList', [])
+                execfile(os.path.join(dest, "confSummary.py"), data)
+                search_path = data.get("cmtProjectPathList", [])
                 # we need to prepend the installation directory
                 search_path.insert(0, os.path.abspath(dest))
                 # write bash script
-                shell_name = os.path.join(dest, 'setupSearchPath.sh')
-                self.log.info('writing %s', shell_name)
-                with open(shell_name, 'w') as shell_script:
+                shell_name = os.path.join(dest, "setupSearchPath.sh")
+                self.log.info("writing %s", shell_name)
+                with open(shell_name, "w") as shell_script:
                     shell_script.write(
-                        'export CMTPROJECTPATH=%s\n' % (':'.join(search_path)))
+                        "export CMTPROJECTPATH=%s\n" % (":".join(search_path))
+                    )
                 # write tcsh script
-                shell_name = os.path.join(dest, 'setupSearchPath.csh')
-                self.log.info('writing %s', shell_name)
-                with open(shell_name, 'w') as shell_script:
+                shell_name = os.path.join(dest, "setupSearchPath.csh")
+                self.log.info("writing %s", shell_name)
+                with open(shell_name, "w") as shell_script:
                     shell_script.write(
-                        'setenv CMTPROJECTPATH %s\n' % (':'.join(search_path)))
+                        "setenv CMTPROJECTPATH %s\n" % (":".join(search_path))
+                    )
 
             # Create symlinks required to make lb-run work
             try:
-                self.log.info('create version symlinks')
+                self.log.info("create version symlinks")
                 createVersionSymlinks(
-                    dest,
-                    json.load(open(os.path.join(dest, 'slot-config.json'))))
+                    dest, json.load(open(os.path.join(dest, "slot-config.json")))
+                )
             except IOError:
                 pass  # could not read slot-config.json or create the links
 
-        except Exception, ex:
-            self.log.error('Fatal error: %s' % ex)
+        except Exception as ex:
+            self.log.error("Fatal error: %s" % ex)
             if logging.getLogger().level <= logging.DEBUG:
                 # re-raise the exception in debug mode
                 raise
             return 1
 
         finally:
             # this is call even after an exception or a return
-            self.log.debug('removing lock file %s', lock_file)
+            self.log.debug("removing lock file %s", lock_file)
             os.remove(lock_file)
 
         return 0
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/listzip.php` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/listzip.php`

 * *Files identical despite different names*

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Common.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Common.py`

 * *Files 22% similar despite different names*

```diff
@@ -4,810 +4,862 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Common utility functions used in scripts.
 @author Marco Clemencic <marco.clemencic@cern.ch>
-'''
+"""
 
+import logging
 import os
 import re
 import socket
-import logging
+import sys
 from datetime import datetime
-from LbNightlyTools.Utils import TaskQueue, recursive_update
-from LbNightlyTools.Utils import retry_call as call, TemporaryDir
-from LbNightlyTools.Configuration import findSlot, Slot
+from functools import reduce
+
+from LbNightlyTools.Configuration import Slot, findSlot
+from LbNightlyTools.Utils import SlotAborted, TaskQueue, TemporaryDir, recursive_update
+from LbNightlyTools.Utils import retry_call as call
 
 # We first try to import from LbCommon, then revert to the old package (LbUtils)
 # if needed
 try:
     from LbCommon.Script import PlainScript as _PlainScript
 except:
     from LbUtils.Script import PlainScript as _PlainScript
 
 # change the default log format in LbUtils.Script
 try:
     import LbCommon.Log as _lblog
 except:
     import LbUtils.Log as _lblog
 
-_lblog._default_log_format = ('%(asctime)s:' + _lblog._default_log_format)
+_lblog._default_log_format = "%(asctime)s:" + _lblog._default_log_format
 
 
 class PlainScript(_PlainScript):
     def parseOpts(self, args):
-        '''
+        """
         Override LbUtils.Script.PlainScript logging settings.
-        '''
+        """
         _PlainScript.parseOpts(self, args)
         # set the level to the handlers too
         for hdlr in self.log.handlers:
             hdlr.setLevel(self.log.level)
         # reset the message format (LbUtils.Script uses a fixed one for DEBUG)
         if self.log.level <= logging.DEBUG:
             formatter = logging.Formatter(_lblog._default_log_format)
             for h in self.log.handlers:
                 h.setFormatter(formatter)
 
+    def run(self, args=sys.argv[1:]):
+        try:
+            return _PlainScript.run(self, args)
+        except SlotAborted as err:
+            self.log.warning("slot was aborted: %s", err)
+            return 0
+
 
 def addBasicOptions(parser):
-    '''
+    """
     Add some basic (common) options to the option parser (optparse.OptionParser
     instance).
-    '''
+    """
     parser.add_option(
-        '--build-id',
-        action='store',
-        help='string to add to the tarballs of the build to '
-        'distinguish them from others, the string can '
-        'be a format string using the parameter '
-        '"slot" [default: %default]')
+        "--build-id",
+        action="store",
+        help="string to add to the tarballs of the build to "
+        "distinguish them from others, the string can "
+        "be a format string using the parameter "
+        '"slot" [default: %default]',
+    )
 
     parser.add_option(
-        '--slot-build-id',
-        action='store',
-        type='int',
-        help='numeric id of the build [default: '
-        'taken from the slot configuration, '
-        'the environment ${slot_build_id} or 0]')
+        "--slot-build-id",
+        action="store",
+        type="int",
+        help="numeric id of the build [default: "
+        "taken from the slot configuration, "
+        "the environment ${slot_build_id} or 0]",
+    )
 
     parser.add_option(
-        '--artifacts-dir',
-        action='store',
-        metavar='DIR',
-        help='directory where to store the artifacts')
+        "--artifacts-dir",
+        action="store",
+        metavar="DIR",
+        help="directory where to store the artifacts",
+    )
 
     parser.add_option(
-        '--projects',
-        action='store',
-        help='comma-separated list of projects to consider'
-        ' [default: all]')
+        "--projects",
+        action="store",
+        help="comma-separated list of projects to consider" " [default: all]",
+    )
 
     parser.add_option(
-        '--summary-prefix',
-        action='store',
-        help='prefix to use for generated summary directories'
-        ' [default: none]')
+        "--summary-prefix",
+        action="store",
+        help="prefix to use for generated summary directories" " [default: none]",
+    )
 
     parser.set_defaults(
-        build_id='{slot}',
+        build_id="{slot}",
         slot_build_id=None,
-        artifacts_dir='artifacts',
-        summary_prefix='')
+        artifacts_dir="artifacts",
+        summary_prefix="",
+    )
     return parser
 
 
 def addBuildDirOptions(parser):
-    '''
+    """
     Add build directory specific options to the parser.
-    '''
+    """
     from optparse import OptionGroup
+
     group = OptionGroup(parser, "Build Dir Options")
 
     group.add_option(
-        '--clean',
-        action='store_true',
-        help='purge the build directory before building')
+        "--clean", action="store_true", help="purge the build directory before building"
+    )
 
     group.add_option(
-        '--no-clean',
-        action='store_false',
-        dest='clean',
-        help='do not purge the build directory before '
-        'building')
+        "--no-clean",
+        action="store_false",
+        dest="clean",
+        help="do not purge the build directory before " "building",
+    )
 
     group.add_option(
-        '--no-unpack',
-        action='store_true',
-        help='assume that the sources are already present')
+        "--no-unpack",
+        action="store_true",
+        help="assume that the sources are already present",
+    )
 
     parser.add_option_group(group)
     parser.set_defaults(clean=False, no_unpack=False)
     return parser
 
 
 def addDeploymentOptions(parser):
-    '''
+    """
     Add report-specific options to the parser.
-    '''
+    """
     from optparse import OptionGroup
+
     group = OptionGroup(parser, "Deployment Options")
 
     group.add_option(
-        '--rsync-dest',
-        action='store',
-        metavar='DEST',
-        help='deploy artifacts to this location using rsync '
-        '(accepts the same format specification as '
-        '--build-id)')
+        "--rsync-dest",
+        action="store",
+        metavar="DEST",
+        help="deploy artifacts to this location using rsync "
+        "(accepts the same format specification as "
+        "--build-id)",
+    )
 
     parser.add_option_group(group)
     parser.set_defaults(rsync_dest=None)
     return parser
 
 
 def addDashboardOptions(parser, with_submit=True):
-    '''
+    """
     Add dashboard-related options to the option parser (optparse.OptionParser
     instance).
-    '''
+    """
     from optparse import OptionGroup
+
     group = OptionGroup(parser, "Dashboard Options")
 
     if with_submit:
         group.add_option(
-            '--submit',
-            action='store_true',
+            "--submit",
+            action="store_true",
             default=False,
-            help='submit the results to Dashboard server')
+            help="submit the results to Dashboard server",
+        )
 
         group.add_option(
-            '--no-submit',
-            action='store_false',
-            dest='submit',
-            help='do not submit the results to Dashboard server '
-            '(default)')
+            "--no-submit",
+            action="store_false",
+            dest="submit",
+            help="do not submit the results to Dashboard server " "(default)",
+        )
 
     group.add_option(
-        '--flavour',
-        default='nightly',
-        help='which build server to use (build flavour)')
+        "--flavour", default="nightly", help="which build server to use (build flavour)"
+    )
 
     group.add_option(
-        '--db-url', help='database server to use instead of the default one')
+        "--db-url", help="database server to use instead of the default one"
+    )
 
     group.add_option(
-        '--db-name',
-        help='override database name '
-        '[default: nightlies-{flavour}]')
+        "--db-name", help="override database name " "[default: nightlies-{flavour}]"
+    )
 
     parser.add_option_group(group)
     return parser
 
 
 def expandTokensInOptions(options, opt_names, **kwargs):
-    '''
+    """
     Given an options instance, the list of option names, and the list of
     keywords to replace, replace the options with the correct expanded stings.
 
     >>> from optparse import Values
     >>> options = Values()
     >>> options.name = '{token}'
     >>> expandTokensInOptions(options, ['name'], token='Hello')
     >>> options.name
     'Hello'
-    '''
+    """
     for opt_name in opt_names:
         try:
             val = getattr(options, opt_name)
             if val:
                 setattr(options, opt_name, val.format(**kwargs))
         except AttributeError:
             pass
 
 
-class RsyncDestination(object):
-    '''
+class RsyncDestination:
+    """
     Class to manage deployments via rsync.
-    '''
+    """
 
     def __init__(self, rsync_dest, listener=None):
-        '''
+        """
         @param rsync_dest: root destination endpoint for rsync
         @param listener: optional message listener to notify when the sync is
                          completed
-        '''
-        self.log = logging.getLogger('deployment.rsync')
+        """
+        self.log = logging.getLogger("deployment.rsync")
         self.rsync_dest = rsync_dest
         self.listener = listener
 
     def accept(self, msg):
-        '''
+        """
         Implements the receiver side of the message protocol.
 
         Accepts artifacts and transfer them via rsync.
 
         Message: {'type': 'artifacts',
                   'path': <path to file or dir>,
                   'dest': <optional name at destination>}
-        '''
-        if msg.get('type', '').startswith('artifacts') and 'path' in msg:
-            kwargs = {'path': msg['path'], 'dest': msg.get('dest')}
+        """
+        if msg.get("type", "").startswith("artifacts") and "path" in msg:
+            kwargs = {"path": msg["path"], "dest": msg.get("dest")}
             try:
                 retcode = self.transfer(**kwargs)
             except:
                 retcode = 1
             if self.listener:
                 msg = dict(msg)
-                msg.update({
-                    'type': 'ready.' + msg['type'],
-                    'retcode': retcode
-                })
+                msg.update({"type": "ready." + msg["type"], "retcode": retcode})
                 self.listener.send(msg)
 
     def transfer(self, path, dest=None):
-        '''
+        """
         Copy file to the rsync destination.
-        '''
-        cmd = ['eos', 'cp', '-p', '--no-overwrite']
+        """
+        cmd = ["eos", "cp", "-p", "--no-overwrite"]
         if self.log.getEffectiveLevel() > logging.DEBUG:
-            cmd.append('--silent')
+            cmd.append("--silent")
 
         dest = os.path.join(self.rsync_dest, dest) if dest else self.rsync_dest
 
-        self.log.debug('deploying %s to %s', path, dest)
+        self.log.debug("deploying %s to %s", path, dest)
 
         env = dict(os.environ)
-        env['EOS_MGM_URL'] = env['EOS_BASE_URL']
+        env["EOS_MGM_URL"] = env["EOS_BASE_URL"]
 
         # FIXME: workaround for SLC5
         # with TemporaryDir() as tmpdir:
         #     # eos client wants to create basename(path) into dest, so we cheat
         #     os.symlink(path, os.path.join(tmpdir, os.path.basename(dest)))
         #     if os.path.isdir(path):
         #         cmd.append('--recursive')
         #         path += '/'  # eos client requires '/' at end of directories
         #     cmd.extend([path, os.path.dirname(dest)])
         #     return call(cmd, env=env, retry=3)
         def copy_files(srcs, dst):
-            call(['eos', 'mkdir', '-p', dst], env=env)
-            self.log.debug(
-                str(['eos', 'cp', '--no-overwrite'] + srcs + [dst + '/']))
-            call(['eos', 'cp', '--no-overwrite'] + srcs + [dst + '/'], env=env)
+            call(["eos", "mkdir", "-p", dst], env=env)
+            self.log.debug(str(["eos", "cp", "--no-overwrite"] + srcs + [dst + "/"]))
+            call(["eos", "cp", "--no-overwrite"] + srcs + [dst + "/"], env=env)
 
         if os.path.isfile(path):
             copy_files([path], dest)
         else:
             for root, dirs, files in os.walk(path):
                 if files:
-                    copy_files([os.path.join(root, f) for f in files],
-                               os.path.join(dest, os.path.relpath(root, path)))
+                    copy_files(
+                        [os.path.join(root, f) for f in files],
+                        os.path.join(dest, os.path.relpath(root, path)),
+                    )
         return 0
 
 
-class DashboardUpdate(object):
-    '''
+class DashboardUpdate:
+    """
     Handles dashboard database updates.
-    '''
+    """
 
     def __init__(self, script):
         from LbNightlyTools.Utils import Dashboard
 
-        self.log = logging.getLogger('DashboardUpdate')
+        self.log = logging.getLogger("DashboardUpdate")
         opts = script.options
 
         if not opts.submit:
-            self.log.debug('dashboard update not requested')
+            self.log.debug("dashboard update not requested")
             self.dashboard = None
             return
 
         self.slot = script.slot
         self.platform = script.platform
         self.no_test = self.slot.no_test
-        self.build_url = os.environ.get('BUILD_URL')
-        self.hostname = os.environ.get('docker_hostname', socket.gethostname())
-        self.doc_name = '{0}.{1}'.format(self.slot.name, self.slot.build_id)
+        self.build_url = os.environ.get("BUILD_URL")
+        self.hostname = os.environ.get("docker_hostname", socket.gethostname())
+        self.doc_name = "{0}.{1}".format(self.slot.name, self.slot.build_id)
         self.script_type = {
-            'slot-config': 'checkout',
-            'build-result': 'build',
-            'tests-result': 'test'
+            "slot-config": "checkout",
+            "build-result": "build",
+            "tests-result": "test",
         }[script.json_type]
 
         self.dashboard = Dashboard(
             credentials=None,
             flavour=opts.flavour,
             server=opts.db_url,
-            dbname=opts.db_name or Dashboard.dbName(opts.flavour))
+            dbname=opts.db_name or Dashboard.dbName(opts.flavour),
+        )
 
     def checkout_started(self, config):
-        '''
+        """
         record start of slot checkout
-        '''
-        self.log.debug('checkout_started')
+        """
+        self.log.debug("checkout_started")
         data = {
-            'type': 'slot-info',
-            'slot': self.slot.name,
-            'build_id': self.slot.build_id,
-            'config': recursive_update({}, config),  # clone object
-            'checkout': {
-                'host': self.hostname,
-                'projects': {}
-            },
-            'builds': {},
-            'tests': {}
+            "type": "slot-info",
+            "slot": self.slot.name,
+            "build_id": self.slot.build_id,
+            "config": recursive_update({}, config),  # clone object
+            "checkout": {"host": self.hostname, "projects": {}},
+            "builds": {},
+            "tests": {},
         }
-        config = data['config']  # ignore the input data and work on the clone
+        config = data["config"]  # ignore the input data and work on the clone
         # move some infos from the config (message) to the checkout field
-        data['date'] = config.pop('date')
-        data['checkout']['started'] = config.pop('started')
-        data['checkout']['trigger_url'] = config.pop('trigger_url')
+        data["date"] = config.pop("date")
+        data["checkout"]["started"] = config.pop("started")
+        data["checkout"]["trigger_url"] = config.pop("trigger_url")
 
-        data['checkout']['build_url'] = self.build_url
+        data["checkout"]["build_url"] = self.build_url
 
         def changes(d):
-            'reset the slot info'
-            if '_rev' in d:
-                d = {'_rev': d['_rev'], '_id': d['_id']}
+            "reset the slot info"
+            if "_rev" in d:
+                d = {"_rev": d["_rev"], "_id": d["_id"]}
             else:
                 d = {}
             return recursive_update(d, data)
 
         self.dashboard.update(self.doc_name, changes)
 
     def checkout_update(self, msg):
-        self.log.debug('checkout_update')
+        self.log.debug("checkout_update")
 
         def changes(d):
-            name = msg.pop('project')
-            d['checkout']['projects'][name] = msg
+            name = msg.pop("project")
+            d["checkout"]["projects"][name] = msg
             return d
 
         self.dashboard.update(self.doc_name, changes)
 
     def checkout_completed(self, config):
-        '''
+        """
         record end of slot checkout
-        '''
-        self.log.debug('checkout_completed')
-        data = {
-            'config': recursive_update({}, config),  # clone object
-            'checkout': {}
-        }
-        config = data['config']  # ignore the input data and work on the clone
+        """
+        self.log.debug("checkout_completed")
+        data = {"config": recursive_update({}, config), "checkout": {}}  # clone object
+        config = data["config"]  # ignore the input data and work on the clone
         # drop some data from the message
-        config.pop('date')
-        config.pop('started')
-        config.pop('trigger_url')
+        config.pop("date")
+        config.pop("started")
+        config.pop("trigger_url")
         # move fields from config message to checkout field
-        data['checkout']['completed'] = config.pop('completed')
+        data["checkout"]["completed"] = config.pop("completed")
         self.dashboard.update(self.doc_name, data)
 
     def update_ready_builds(self, msg):
-        '''
+        """
         update the "ready-builds" object
-        '''
-        self.log.debug('update_ready_builds: %s', msg['project'].name)
+        """
+        self.log.debug("update_ready_builds: %s", msg["project"].name)
 
         def changes(d):
-            d['type'] = 'ready-builds'
-            if 'entries' not in d:
-                d['entries'] = []
-            d['entries'].append({
-                'project':
-                msg['project'].name,
-                'version':
-                msg['project'].version,
-                'slot':
-                self.slot.name,
-                'build_id':
-                self.slot.build_id,
-                'platform':
-                self.platform,
-                'time':
-                str(datetime.now()),
-                'retcode':
-                msg.get('retcode'),
-                'no_test': (self.slot.no_test or msg['project'].no_test),
-                'scripts': {
-                    'repository': os.environ.get('scripts_repository'),
-                    'version': os.environ.get('scripts_version')
-                },
-                'venv': {
-                    'JENKINS_OVERRIDE_PIP_REQUIREMENTS':
-                    os.environ.get('JENKINS_OVERRIDE_PIP_REQUIREMENTS'),
-                    'JENKINS_RESET_VIRTUALENV':
-                    os.environ.get('JENKINS_RESET_VIRTUALENV')
+            d["type"] = "ready-builds"
+            if "entries" not in d:
+                d["entries"] = []
+            d["entries"].append(
+                {
+                    "project": msg["project"].name,
+                    "version": msg["project"].version,
+                    "slot": self.slot.name,
+                    "build_id": self.slot.build_id,
+                    "platform": self.platform,
+                    "time": str(datetime.now()),
+                    "retcode": msg.get("retcode"),
+                    "no_test": (self.slot.no_test or msg["project"].no_test),
+                    "scripts": {
+                        "repository": os.environ.get("scripts_repository"),
+                        "version": os.environ.get("scripts_version"),
+                    },
+                    "venv": {
+                        "JENKINS_OVERRIDE_PIP_REQUIREMENTS": os.environ.get(
+                            "JENKINS_OVERRIDE_PIP_REQUIREMENTS"
+                        ),
+                        "JENKINS_RESET_VIRTUALENV": os.environ.get(
+                            "JENKINS_RESET_VIRTUALENV"
+                        ),
+                        "env_hash": os.environ.get("env_hash"),
+                    },
                 }
-            })
+            )
             return d
 
-        self.dashboard.update('ready-builds', changes)
+        self.dashboard.update("ready-builds", changes)
 
     def drop_build(self):
-        '''
+        """
         remove info about specific build (platform)
-        '''
-        self.log.debug('drop_build')
+        """
+        self.log.debug("drop_build")
 
         def changes(d):
-            for k in ('builds', 'tests'):
-                if self.platform in d.get(k, ''):
+            for k in ("builds", "tests"):
+                if self.platform in d.get(k, ""):
                     del d[k][self.platform]
             return d
 
         self.dashboard.update(self.doc_name, changes)
 
     def global_build_started(self, msg):
-        '''
+        """
         set build start info
-        '''
-        self.log.debug('global_build_started')
+        """
+        self.log.debug("global_build_started")
         data = {
-            'builds': {
+            "builds": {
                 self.platform: {
-                    'info': {
-                        'started': msg['started'],
-                        'host': self.hostname,
-                        'build_url': self.build_url
+                    "info": {
+                        "started": msg["started"],
+                        "host": self.hostname,
+                        "build_url": self.build_url,
                     }
                 }
             }
         }
         self.dashboard.update(self.doc_name, data)
 
     def global_build_completed(self, msg):
-        '''
+        """
         set build completion info
-        '''
-        self.log.debug('global_build_completed')
-        data = {
-            'builds': {
-                self.platform: {
-                    'info': {
-                        'completed': msg['completed']
-                    }
-                }
-            }
-        }
+        """
+        self.log.debug("global_build_completed")
+        data = {"builds": {self.platform: {"info": {"completed": msg["completed"]}}}}
         self.dashboard.update(self.doc_name, data)
 
     def project_build_started(self, msg):
-        '''
+        """
         set project build start
-        '''
-        self.log.debug('project_build_started: %s', msg['project'])
+        """
+        self.log.debug("project_build_started: %s", msg["project"])
         data = {
-            'builds': {
+            "builds": {
                 self.platform: {
-                    msg['project']: {
-                        'started': msg['started'],
-                        'build_url': self.build_url
+                    msg["project"]: {
+                        "started": msg["started"],
+                        "build_url": self.build_url,
                     }
                 }
             }
         }
         self.dashboard.update(self.doc_name, data)
 
     def project_build_completed(self, msg):
-        '''
+        """
         set project build completion
-        '''
-        self.log.debug('project_build_completed: %s', msg['project'])
+        """
+        self.log.debug("project_build_completed: %s", msg["project"])
         data = {
-            'builds': {
+            "builds": {
                 self.platform: {
-                    msg['project']: {
-                        'completed': msg['completed'],
-                        'retcode': msg['retcode'],
-                        'warnings': msg['warnings'],
-                        'errors': msg['errors'],
+                    msg["project"]: {
+                        "completed": msg["completed"],
+                        "retcode": msg["retcode"],
+                        "warnings": msg["warnings"],
+                        "errors": msg["errors"],
                     }
                 }
             }
         }
         self.dashboard.update(self.doc_name, data)
 
     def project_test_started(self, msg):
-        '''
+        """
         set project build start
-        '''
-        self.log.debug('project_test_started: %s', msg['project'])
+        """
+        self.log.debug("project_test_started: %s", msg["project"])
         data = {
-            'tests': {
+            "tests": {
                 self.platform: {
-                    msg['project']: {
-                        'started': msg['started'],
-                        'completed': None,
-                        'host': self.hostname,
-                        'build_url': self.build_url
+                    msg["project"]: {
+                        "started": msg["started"],
+                        "completed": None,
+                        "host": self.hostname,
+                        "build_url": self.build_url,
                     }
                 }
             }
         }
         self.dashboard.update(self.doc_name, data)
 
     def project_test_completed(self, msg):
-        '''
+        """
         set project build completion
-        '''
-        self.log.debug('project_test_completed: %s', msg['project'])
+        """
+        self.log.debug("project_test_completed: %s", msg["project"])
         from collections import defaultdict
+
         results = defaultdict(list)
-        for res in msg['results']:
-            results[res['outcome']].append(res['id'])
+        for res in msg["results"]:
+            results[res["outcome"]].append(res["id"])
+        # check that we are trying to update the result we created
+        current = self.dashboard.db[self.doc_name]
+        build_url = reduce(
+            lambda d, k: d.get(k) or {},
+            ["tests", self.platform, msg["project"], "build_url"],
+            current,
+        )
+        if build_url != self.build_url:
+            # some other build owns this entry, let's not mess with it
+            self.log.warning(
+                "attempt to update results from another test job (this: %s, other: %s)",
+                self.build_url,
+                build_url,
+            )
+            return
+        # update the results
         data = {
-            'tests': {
+            "tests": {
                 self.platform: {
-                    msg['project']: {
-                        'completed': msg['completed'],
-                        'results': results
-                    }
+                    msg["project"]: {"completed": msg["completed"], "results": results}
                 }
             }
         }
         self.dashboard.update(self.doc_name, data)
 
     def accept(self, msg):
-        '''
+        """
         Implements the receiver side of the message protocol.
-        '''
+        """
         if self.dashboard is None:
             return  # ignore all messages, no update requested
-        msg_type = msg.get('type', '')
-        if self.script_type == 'checkout' and not msg_type:
-            if 'project' in msg:
+        msg_type = msg.get("type", "")
+        if self.script_type == "checkout" and not msg_type:
+            if "project" in msg:
                 self.checkout_update(msg)
-            elif 'completed' in msg:
+            elif "completed" in msg:
                 self.checkout_completed(msg)
             else:
                 self.checkout_started(msg)
 
-        elif self.script_type == 'build':
-            if msg_type == 'drop-build':
+        elif self.script_type == "build":
+            if msg_type == "drop-build":
                 self.drop_build()
-            elif msg_type == 'job-start':
+            elif msg_type == "job-start":
                 self.global_build_started(msg)
-            elif msg_type == 'job-end':
+            elif msg_type == "job-end":
                 self.global_build_completed(msg)
-            elif msg_type == 'ready.artifacts.build':
+            elif msg_type == "ready.artifacts.build":
                 self.update_ready_builds(msg)
-            elif 'artifacts' in msg_type:
+            elif "artifacts" in msg_type:
                 return  # ignore some types of messages
             elif not msg_type:
-                if 'completed' in msg:
+                if "completed" in msg:
                     self.project_build_completed(msg)
                 else:
                     self.project_build_started(msg)
 
-        elif self.script_type == 'test' and not msg_type:
-            if 'completed' in msg:
+        elif self.script_type == "test" and not msg_type:
+            if "completed" in msg:
                 self.project_test_completed(msg)
             else:
                 self.project_test_started(msg)
 
 
-class PeriodicTestMsg(object):
-    '''
+class PeriodicTestMsg:
+    """
     Handles sending the message to the queue
     of ready builds for the periodic tests.
-    '''
+    """
 
     def __init__(self, script):
         self.slot = script.slot
         self.platform = script.platform
-        self.log = logging.getLogger('PeriodicTestMsg')
+        self.log = logging.getLogger("PeriodicTestMsg")
 
     def builds_ready(self, msg):
-        '''
+        """
         sends the message that builds are ready
-        '''
-        deployment_target = self.slot.deployment
+        """
         self.log.debug(
-            'sending the message to the queue that builds '
-            'are ready for slot: %s, project: %s, platform: %s, '
-            'build_id: %s, deployment: %s', self.slot.name,
-            msg['project'].name, self.platform, self.slot.build_id,
-            deployment_target)
+            "sending the message to the queue that builds "
+            "are ready for slot: %s, project: %s, platform: %s, "
+            "build_id: %s",
+            self.slot.name,
+            msg["project"].name,
+            self.platform,
+            self.slot.build_id,
+        )
         try:
             import LbMsg.BuildMsg
+
             build_msg = LbMsg.BuildMsg.NightliesMessenger()
             build_msg.sendBuildDone(
-                self.slot.name,
-                msg['project'].name,
-                self.platform,
-                self.slot.build_id,
-                deployment=deployment_target)
+                self.slot.name, msg["project"].name, self.platform, self.slot.build_id
+            )
         except Exception as x:
-            self.log.warning('problems sending message: %s: %s',
-                             type(x).__name__, x)
+            self.log.warning("problems sending message: %s: %s", type(x).__name__, x)
+
+        try:
+            token_fn = os.path.join(
+                os.environ.get(
+                    "PRIVATE_DIR", os.path.join(os.environ["HOME"], "private")
+                ),
+                "lbtaskrun_token_notify_nightly_built",
+            )
+            with open(token_fn, "rt") as fp:
+                token = fp.read().strip()
+
+            import requests
+
+            r = requests.put(
+                "https://lhcb-core-tasks.web.cern.ch/hooks/build-ready/ci/%s/%s/%s/%s/"
+                % (
+                    self.slot.name,
+                    self.slot.build_id,
+                    msg["project"].name,
+                    self.platform,
+                ),
+                headers={"Authorization": "Bearer %s" % token},
+            )
+            r.raise_for_status()
+        except Exception as e:
+            self.log.exception("Failed to send build ready message to lbtaskweb")
 
     def accept(self, msg):
-        '''
+        """
         Implements the receiver side of the message protocol.
-        '''
-        msg_type = msg.get('type', '')
+        """
+        msg_type = msg.get("type", "")
 
-        if msg_type == 'ready.artifacts.build':
+        if msg_type == "ready.artifacts.build":
             self.builds_ready(msg)
 
 
 class BaseScript(PlainScript):
-    '''
+    """
     Base class for LbNightlyToolsScripts
-    '''
-    __usage__ = '%prog [options] <slot name or config file>'
-    __version__ = ''
+    """
+
+    __usage__ = "%prog [options] <slot name or config file>"
+    __version__ = ""
 
     def defineOpts(self):
-        '''
+        """
         Prepare the option parser.
-        '''
+        """
         addBasicOptions(self.parser)
         addBuildDirOptions(self.parser)
         addDeploymentOptions(self.parser)
         addDashboardOptions(self.parser)
 
     def _setupReceivers(self):
-        '''
+        """
         Prepare deployment destinations.
-        '''
-        if hasattr(self.options, 'rsync_dest') and self.options.rsync_dest:
-            self.receivers.append(
-                RsyncDestination(self.options.rsync_dest, self))
-        if hasattr(self.options, 'submit'):
-            self.receivers.append(DashboardUpdate(self))
+        """
+        if hasattr(self.options, "rsync_dest") and self.options.rsync_dest:
+            self.receivers.append(RsyncDestination(self.options.rsync_dest, self))
+        if hasattr(self.options, "submit"):
+            db_update = DashboardUpdate(self)
+            if db_update.dashboard:
+
+                def abort_check():
+                    db_update.dashboard.assert_not_aborted(db_update.doc_name)
+
+                self.assert_not_aborted = abort_check
+            self.receivers.append(db_update)
             self.receivers.append(PeriodicTestMsg(self))
 
-    def _setup(self,
-               build_dir=None,
-               json_type=None,
-               make_dirs=True,
-               summary_base=''):
-        '''
+    def assert_not_aborted(self):
+        pass
+
+    def _setup(self, build_dir=None, json_type=None, make_dirs=True, summary_base=""):
+        """
         Initialize variables.
-        '''
+        """
         # pylint: disable=W0201
         from os.path import join
+
         from LbNightlyTools.Utils import ensureDirs
 
         self.receivers = []
         self.tasks = TaskQueue()
 
         self.json_type = json_type
 
         opts = self.options
         if len(self.args) != 1:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         self.slot = findSlot(
             self.args[0],
             flavour=opts.flavour,
             server=opts.db_url,
-            dbname=opts.db_name)
+            dbname=opts.db_name,
+            raise_if_aborted=True,
+        )
 
         from LbNightlyTools.Utils import setDayNamesEnv
+
         setDayNamesEnv()
 
         # FIXME: we need something better
-        self.platform = (os.environ.get('CMTCONFIG')
-                         or os.environ.get('BINARY_TAG'))
+        self.platform = os.environ.get("CMTCONFIG") or os.environ.get("BINARY_TAG")
 
         self.starttime = datetime.now()
 
         expandTokensInOptions(
-            opts, ['build_id', 'artifacts_dir', 'rsync_dest'],
-            slot=self.slot.name)
+            opts, ["build_id", "artifacts_dir", "rsync_dest"], slot=self.slot.name
+        )
 
-        self.build_dir = join(os.getcwd(),
-                              'build' if build_dir is None else build_dir)
+        self.build_dir = join(os.getcwd(), "build" if build_dir is None else build_dir)
         self.artifacts_dir = join(os.getcwd(), opts.artifacts_dir)
 
         self.summary_base = summary_base
 
         # ensure that we have the artifacts directory for the sources
         if make_dirs:
             ensureDirs([self.artifacts_dir, self.build_dir])
             if self.summary_base:
                 ensureDirs([self._summaryDir()])
 
         if opts.slot_build_id is not None:
             self.slot.build_id = self.options.slot_build_id
         elif not self.slot.build_id:
-            self.slot.build_id = int(os.environ.get('slot_build_id', 0))
+            self.slot.build_id = int(os.environ.get("slot_build_id", 0))
 
         if opts.projects:
             proj_names = dict(
-                (proj.name.lower(), proj.name) for proj in self.slot.projects)
+                (proj.name.lower(), proj.name) for proj in self.slot.projects
+            )
             try:
-                opts.projects = set(proj_names[p.strip().lower()]
-                                    for p in opts.projects.split(','))
-            except KeyError, exc:
-                self.parser.error(
-                    'requested project not in slot: "%s"' % exc.args)
+                opts.projects = set(
+                    proj_names[p.strip().lower()] for p in opts.projects.split(",")
+                )
+            except KeyError as exc:
+                self.parser.error('requested project not in slot: "%s"' % exc.args)
         else:
             opts.projects = None
 
         self._setupReceivers()
 
     def __del__(self):
-        '''
+        """
         Clean up.
-        '''
-        if hasattr(self, 'tasks'):
+        """
+        if hasattr(self, "tasks"):
             self.tasks.join()
 
     def _summaryDir(self, *subdirs):
-        '''
+        """
         Return the path to the summary directory for a given project.
 
         If extra arguments are given, the output is equivalent to
         os.path.join(self._summaryDir(proj), level1, level2).
-        '''
+        """
         # note that os.path.join('', '') -> ''
         return os.path.join(
-            self.artifacts_dir, self.options.summary_prefix, self.summary_base,
+            self.artifacts_dir,
+            self.options.summary_prefix,
+            self.summary_base,
             self.platform,
-            *[p.name if hasattr(p, 'name') else p for p in subdirs])
+            *[p.name if hasattr(p, "name") else p for p in subdirs]
+        )
 
     def _buildDir(self, proj, *subdirs):
-        '''
+        """
         Return the path to the build directory for a given project.
 
         If extra arguments are given, the output is equivalent to
         os.path.join(self._buildDir(proj), level1, level2).
-        '''
+        """
         return os.path.join(self.build_dir, proj.baseDir, *subdirs)
 
     def send(self, msg, sync=False):
-        '''
+        """
         Send a message to the receivers.
 
         If the parameter sync is True, the call will block until the message is
         handled, otherwise the handling will be deferred.
-        '''
+        """
         if sync:
             for receiver in self.receivers:
                 receiver.accept(msg)
         else:
             self.tasks.add(self.send, (msg, True))
 
     def dumpGitStatus(self, proj):
         from subprocess import Popen
-        if os.path.isdir(self._buildDir(proj, '.git')):
-            with open(self._summaryDir(proj, 'git-status.txt'), 'wb') as f:
-                self.log.debug('running "git status" in %s',
-                               self._buildDir(proj))
-                Popen(['git', 'status', '--porcelain'],
-                      stdout=f,
-                      cwd=self._buildDir(proj)).communicate()
+
+        if os.path.isdir(self._buildDir(proj, ".git")):
+            with open(self._summaryDir(proj, "git-status.txt"), "wb") as f:
+                self.log.debug('running "git status" in %s', self._buildDir(proj))
+                Popen(
+                    ["git", "status", "--porcelain"], stdout=f, cwd=self._buildDir(proj)
+                ).communicate()
 
 
 def genPackageName(proj, platform, build_id=None, artifacts_dir=None):
-    '''
+    """
     Generate the source/binary tarball name for a project/package.
 
     >>> from LbNightlyTools.Configuration import Project, Package
     >>> genPackageName(Project('Gaudi', 'HEAD'),
     ...                'x86_64-slc6-gcc48-opt')
     'packs/x86_64-slc6-gcc48-opt/Gaudi.HEAD.x86_64-slc6-gcc48-opt.zip'
     >>> genPackageName(Package('Gen/DecFiles', 'HEAD'), 'src')
     'packs/src/Gen_DecFiles.head.src.zip'
     >>> genPackageName(Project('Gaudi', 'v25r0'),
     ...                'x86_64-slc6-gcc48-dbg',
     ...                build_id='dummy', artifacts_dir='artifacts')
     'artifacts/packs/x86_64-slc6-gcc48-dbg/Gaudi.v25r0.dummy.x86_64-slc6-gcc48-dbg.zip'
-    '''
-    packname = [proj.name.replace('/', '_'), proj.version]
+    """
+    packname = [proj.name.replace("/", "_"), proj.version]
     if build_id:
         packname.append(build_id)
     packname.append(platform)
-    packname.append('zip')
-    packname = '.'.join(packname)
-    packname = os.path.join('packs', platform, packname)
+    packname.append("zip")
+    packname = ".".join(packname)
+    packname = os.path.join("packs", platform, packname)
     if artifacts_dir:
         packname = os.path.join(artifacts_dir, packname)
     return packname
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Preconditions.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Preconditions.py`

 * *Files 12% similar despite different names*

```diff
@@ -4,47 +4,47 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Module containing the classes and functions used to verify preconditions for
 building a slot.
 
 @author Marco Clemencic <marco.clemencic@cern.ch>
-'''
+"""
 
-import os
 import logging
-
+import os
 from datetime import datetime, timedelta
-from time import sleep
 from os.path import exists
+from time import sleep
 
 from LbNightlyTools.Scripts.Common import PlainScript
+from LbNightlyTools.Utils import compatible_lcg_external_files
 
 
 def waitForFile(path, timeout=timedelta(hours=17), max_age=None):
-    '''
+    """
     Wait until a file becomes available, but not more than the timedelta
     specified as timeout.
     If max_age is not None, it must be a timedelta and an existing file is
     ignored if it is older than that age.
 
     @return: True if a valid file appeared within the timeout, False otherwise
-    '''
+    """
     path = os.path.expanduser(path)
     path = os.path.expandvars(path)
 
-    logging.debug('waiting for file %s', path)
+    logging.debug("waiting for file %s", path)
 
     def fileTime(path):
-        '''helper to return the datetime of last modification of a file'''
+        """helper to return the datetime of last modification of a file"""
         return datetime.fromtimestamp(os.path.getmtime(path))
 
     now = datetime.now()
 
     when_to_stop = now + timeout
 
     if max_age:
@@ -57,84 +57,92 @@
             return True
         sleep(60)
 
     return False
 
 
 def lcgNightly(path, required, timeout=timedelta(hours=17)):
-    '''
+    """
     Compare the externals declared in the file LCG_externals_<platform>.txt
     specified and the list of ones, waiting until all the required externals
     are present. Note: the check is case insensitive.
 
     @return: True if the condition is met within the timeout, False otherwise
-    '''
+    """
     path = os.path.expanduser(path)
     path = os.path.expandvars(path)
 
     required = set(req.lower() for req in required)
 
-    logging.debug('waiting for externals in %s', path)
+    paths = compatible_lcg_external_files(path)
+    logging.debug("waiting for externals in %s", paths)
 
     when_to_stop = datetime.now() + timeout
     two_days_ago = datetime.now() - timedelta(days=2)
 
     def created(path):
-        '''
+        """
         Return datetime of creation of a file.
-        '''
+        """
         return datetime.fromtimestamp(os.stat(path).st_ctime)
 
     found = None
     while datetime.now() < when_to_stop:
-        # we ignore missing or too old files
-        if exists(path) and created(path) > two_days_ago:
-            with open(path) as ext:
-                found = set(l.split(';', 1)[0].strip().lower() for l in ext)
-            if required.issubset(found):
-                return True
+        for path in paths:
+            # we ignore missing or too old files
+            if exists(path) and created(path) > two_days_ago:
+                with open(path) as ext:
+                    found = set(l.split(";", 1)[0].strip().lower() for l in ext)
+                if required.issubset(found):
+                    logging.info("found good file: %s", path)
+                    return path
         sleep(60)
 
     if found is None:
-        msg = '{0} missing or too old'.format(path)
+        msg = "missing or too old files from {}".format(path)
     else:
-        msg = ('some required libs are missing: {0}'.format(', '.join(
-            sorted(required - found))))
+        msg = "some required libs are missing: {0}".format(
+            ", ".join(sorted(required - found))
+        )
     logging.warning(msg)
-    return False
+    return None
 
 
 class Script(PlainScript):
-    '''
+    """
     Script to check slot preconditions.
-    '''
-    __usage__ = '%prog [options] <slot name or config file>'
-    __version__ = ''
+    """
+
+    __usage__ = "%prog [options] <slot name or config file>"
+    __version__ = ""
 
     def main(self):
-        '''
+        """
         Script main function.
-        '''
+        """
         if len(self.args) != 1:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         from LbNightlyTools.Configuration import findSlot
-        slot = findSlot(self.args[0])
+
+        slot = findSlot(self.args[0], raise_if_aborted=True)
 
         from LbNightlyTools.Utils import setDayNamesEnv
+
         setDayNamesEnv()
 
         starttime = datetime.now()
         for precond in slot.preconditions:
-            name = precond[u'name']
-            args = precond.get(u'args', {})
+            name = precond["name"]
+            args = precond.get("args", {})
             f = globals()[name]
-            self.log.info('running %s(%s)', name, args)
+            self.log.info("running %s(%s)", name, args)
             if f(**args):
-                self.log.debug('precondition met')
+                self.log.debug("precondition met")
             else:
-                self.log.error('precondition failed')
+                self.log.error("precondition failed")
                 return 1
 
-        self.log.info('all preconditions are met (time taken: %s).',
-                      datetime.now() - starttime)
+        self.log.info(
+            "all preconditions are met (time taken: %s).", datetime.now() - starttime
+        )
         return 0
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Build.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Build.py`

 * *Files 17% similar despite different names*

```diff
@@ -4,853 +4,981 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Module containing the classes and functions used to build a
 "Nightly Build Slot".
 
 @author: Marco Clemencic <marco.clemencic@cern.ch>
-'''
-
-import os
-from os.path import join
+"""
+from __future__ import division
 
+import codecs
+import html
 import logging
-import shutil
+import os
 import re
+import shutil
 import socket
-import codecs
-import cgi
 import stat
-
-from string import Template
-from datetime import datetime
 from collections import defaultdict
+from datetime import datetime
+from os.path import join
+from string import Template
+
+from LbNightlyTools.Utils import coerce_str
 
 try:
     from multiprocessing import cpu_count
 except ImportError:
     cpu_count = lambda: 0
 
 from LbNightlyTools.Configuration import DataProject, log_timing
-
-from LbNightlyTools.Utils import timeout_call as call, tee_call as _tee_call
-from LbNightlyTools.Utils import log_call
-from LbNightlyTools.Utils import ensureDirs, pack, chdir, wipeDir
-from LbNightlyTools.Utils import cpuinfo, write_json
-
+from LbNightlyTools.HTMLUtils import XTerm2HTML
 from LbNightlyTools.Scripts.CollectBuildLogs import Script as CBLScript
 from LbNightlyTools.Scripts.Common import BaseScript, genPackageName
-
-from LbNightlyTools.HTMLUtils import XTerm2HTML
+from LbNightlyTools.Utils import chdir, cpuinfo, ensureDirs, log_call, pack
+from LbNightlyTools.Utils import tee_call as _tee_call
+from LbNightlyTools.Utils import timeout_call as call
+from LbNightlyTools.Utils import wipeDir, write_json
 
 # no-op 'call' function for testing
-#call = lambda *a,**k: None
+# call = lambda *a,**k: None
 
 __log__ = logging.getLogger(__name__)
 
 LOAD_AVERAGE_SCALE = 1.2
 GB_PER_BUILD_JOB = 1.5
-HOSTNAME = os.environ.get('docker_hostname', socket.gethostname())
+HOSTNAME = os.environ.get("docker_hostname", socket.gethostname())
 MAX_REPORTED_ISSUES = 100  # per severity
 
 
 def listAllFiles(path, excl=None):
-    '''
+    """
     Return the list of all files in a directory and in its subdirectories.
-    '''
+    """
     if excl is None:
         excl = lambda _: False
     for root, dirs, files in os.walk(path):
         for f in files:
             if not excl(f):
                 yield join(root, f)
         dirs[:] = [d for d in dirs if not excl(d)]
 
 
 def unpackArtifacts(src, dest):
-    '''
+    """
     Helper function to unpack the artifacts in src to the build
     directory dest.
-    '''
+    """
     # FIXME: this can be done asynchronously
     if not os.path.isdir(src):
-        __log__.debug('Ignore missing directory %s', src)
+        __log__.debug("Ignore missing directory %s", src)
         return
-    __log__.info('Unpacking artifacts from %s to %s', src, dest)
+    __log__.info("Unpacking artifacts from %s to %s", src, dest)
     for f in os.listdir(src) if os.path.isdir(src) else []:
-        if f.endswith('.tar.bz2'):
+        if f.endswith(".tar.bz2"):
             f = os.path.join(src, f)
-            __log__.info('  unpacking %s to %s', f, dest)
+            __log__.info("  unpacking %s to %s", f, dest)
             # do not overwrite existing sources when unpacking
             # (we must preserve user changes, anyway we have the
             # --clean option)
-            call([
-                'tar', '-x', '--no-overwrite-dir', '--keep-old-files', '-f', f
-            ],
-                 cwd=dest)
-        elif f.endswith('.zip'):
+            call(
+                ["tar", "-x", "--no-overwrite-dir", "--keep-old-files", "-f", f],
+                cwd=dest,
+            )
+        elif f.endswith(".zip"):
             f = os.path.join(src, f)
-            __log__.info('  unpacking %s to %s', f, dest)
+            __log__.info("  unpacking %s to %s", f, dest)
             # do not overwrite existing sources when unpacking
             # (we must preserve user changes, anyway we have the
             # --clean option)
-            call(['unzip', '-n', '-q', f], cwd=dest)
+            call(["unzip", "-n", "-q", f], cwd=dest)
 
 
 try:
     from LbEnv import which
 except ImportError:
 
     def which(cmd):
-        '''
+        """
         Find the given command in the directories specified in the environment
         variable PATH.
 
-        '''
+        """
         if os.path.isfile(cmd):
             return os.path.abspath(cmd)
         for full_cmd in [
-                os.path.join(path, cmd)
-                for path in os.environ.get('PATH', '').split(os.pathsep)
+            os.path.join(path, cmd)
+            for path in os.environ.get("PATH", "").split(os.pathsep)
         ]:
             if os.path.isfile(full_cmd):
                 return full_cmd
         return None
 
 
 DEFAULT_FILE_PERM = stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IROTH
-DEFAULT_DIR_PERM = (stat.S_IRWXU | stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH
-                    | stat.S_IXOTH)
+DEFAULT_DIR_PERM = (
+    stat.S_IRWXU | stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH
+)
 
 
-def fix_permissions(path,
-                    file_perm=DEFAULT_FILE_PERM,
-                    dir_perm=DEFAULT_DIR_PERM):
-    '''
+def fix_permissions(path, file_perm=DEFAULT_FILE_PERM, dir_perm=DEFAULT_DIR_PERM):
+    """
     Make sure all entries in a directory have required permissions.
-    '''
+    """
     for root, dirs, files in os.walk(path):
         for p in [os.path.join(root, p) for p in files]:
             os.chmod(p, file_perm)
         for p in [os.path.join(root, p) for p in dirs]:
             os.chmod(p, dir_perm)
 
 
 class Script(BaseScript):
-    '''
+    """
     Script to build the projects in a slot configuration.
-    '''
+    """
 
     # unavoidable or fake warnings
     # pylint: disable=E1002,W0201
     def defineBuildOptions(self):
-        '''
+        """
         Add build-specific options to the parser.
-        '''
+        """
         from optparse import OptionGroup
+
         group = OptionGroup(self.parser, "Build Options")
 
         group.add_option(
-            '-j',
-            '--jobs',
-            action='store',
-            type='int',
-            help='number of parallel jobs to use during the build '
-            '(default: $LBN_BUILD_JOBS or the smallest '
-            'between total memory / %gGB and N of cores + 1)' %
-            GB_PER_BUILD_JOB)
+            "-j",
+            "--jobs",
+            action="store",
+            type="int",
+            help="number of parallel jobs to use during the build "
+            "(default: $LBN_BUILD_JOBS or the smallest "
+            "between total memory / %gGB and N of cores + 1)" % GB_PER_BUILD_JOB,
+        )
 
         group.add_option(
-            '-l',
-            '--load-average',
-            action='store',
-            type='float',
-            help='load average limit for parallel builds, use 0 '
-            'to remove the limit (default: '
-            '$LBN_LOAD_AVERAGE or N of cores x %g)' % LOAD_AVERAGE_SCALE)
+            "-l",
+            "--load-average",
+            action="store",
+            type="float",
+            help="load average limit for parallel builds, use 0 "
+            "to remove the limit (default: "
+            "$LBN_LOAD_AVERAGE or N of cores x %g)" % LOAD_AVERAGE_SCALE,
+        )
 
         group.add_option(
-            '--ccache',
-            action='store_true',
-            dest='use_ccache',
-            help='use ccache to speed up builds (default if '
-            'the environment variable CCACHE_DIR is defined)')
+            "--ccache",
+            action="store_true",
+            dest="use_ccache",
+            help="use ccache to speed up builds (default if "
+            "the environment variable CCACHE_DIR is defined)",
+        )
 
         group.add_option(
-            '--no-ccache',
-            action='store_false',
-            dest='use_ccache',
-            help='do not use ccache (default if '
-            'the environment variable CCACHE_DIR is not defined)')
+            "--no-ccache",
+            action="store_false",
+            dest="use_ccache",
+            help="do not use ccache (default if "
+            "the environment variable CCACHE_DIR is not defined)",
+        )
 
         group.add_option(
-            '--coverity',
-            action='store_true',
-            help='enable special Coverity static analysis on the '
-            'build (Coverity commands must be on the PATH)')
+            "--coverity",
+            action="store_true",
+            help="enable special Coverity static analysis on the "
+            "build (Coverity commands must be on the PATH)",
+        )
 
         group.add_option(
-            '--coverity-commit',
-            action='store_true',
-            help='commit Coverity detected defects to the '
-            'database (default if the Coverity analysis is '
-            'run)')
+            "--coverity-commit",
+            action="store_true",
+            help="commit Coverity detected defects to the "
+            "database (default if the Coverity analysis is "
+            "run)",
+        )
 
         group.add_option(
-            '--no-coverity-commit',
-            action='store_false',
-            dest='coverity_commit',
-            help='do not commit Coverity detected defects to the '
-            'database')
+            "--no-coverity-commit",
+            action="store_false",
+            dest="coverity_commit",
+            help="do not commit Coverity detected defects to the " "database",
+        )
 
         self.parser.add_option_group(group)
-        if 'LBN_LOAD_AVERAGE' in os.environ:
-            load_average = float(os.environ['LBN_LOAD_AVERAGE'])
+        if "LBN_LOAD_AVERAGE" in os.environ:
+            load_average = float(os.environ["LBN_LOAD_AVERAGE"])
         else:
             load_average = cpu_count() * LOAD_AVERAGE_SCALE
 
-        if 'LBN_BUILD_JOBS' in os.environ:
-            jobs = int(os.environ['LBN_BUILD_JOBS'])
+        if "LBN_BUILD_JOBS" in os.environ:
+            jobs = int(os.environ["LBN_BUILD_JOBS"])
         else:
             # see http://stackoverflow.com/a/28161352
-            sys_mem = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')
-            jobs = min(cpu_count() + 1,
-                       int(sys_mem / (GB_PER_BUILD_JOB * 1024**3)))
+            sys_mem = os.sysconf("SC_PAGE_SIZE") * os.sysconf("SC_PHYS_PAGES")
+            jobs = min(cpu_count() + 1, int(sys_mem / (GB_PER_BUILD_JOB * 1024**3)))
 
         self.parser.set_defaults(
             jobs=jobs,
             load_average=load_average,
-            use_ccache='CCACHE_DIR' in os.environ,
+            use_ccache="CCACHE_DIR" in os.environ,
             coverity=False,
-            coverity_commit=True)
+            coverity_commit=True,
+        )
 
     def defineOpts(self):
-        '''
+        """
         Prepare the option parser.
-        '''
+        """
         from LbNightlyTools.Scripts.Common import (
-            addBasicOptions, addBuildDirOptions, addDeploymentOptions,
-            addDashboardOptions)
+            addBasicOptions,
+            addBuildDirOptions,
+            addDashboardOptions,
+            addDeploymentOptions,
+        )
 
         addBasicOptions(self.parser)
         self.defineBuildOptions()
         addBuildDirOptions(self.parser)
         addDeploymentOptions(self.parser)
         addDashboardOptions(self.parser)
 
     def write(self, path, data):
-        '''
+        """
         Simple function to write some text (UTF-8) to a file.
 
         @param path: name of the file to write
         @param data: string to write
-        '''
-        self.log.debug('writing %s', path)
+        """
+        self.log.debug("writing %s", path)
         ensureDirs([os.path.dirname(path)])
-        with codecs.open(path, 'w', 'utf-8') as f:
+        with codecs.open(path, "w", "utf-8") as f:
             f.write(data)
 
     def writeBin(self, path, data):
-        '''
+        """
         Simple function to write some binary data to a file.
 
         @param path: name of the file to write
         @param data: string to write
-        '''
-        self.log.debug('writing (bin) %s', path)
+        """
+        self.log.debug("writing (bin) %s", path)
         ensureDirs([os.path.dirname(path)])
-        with open(path, 'wb') as f:
+        with open(path, "wb") as f:
             f.write(data)
 
     def _prepareBuildDir(self):
-        '''
+        """
         Prepare the build directory unpacking all the available artifacts
         tarballs, cleaning it before if requested.
-        '''
+        """
         if self.options.clean:
             wipeDir(self.build_dir)
 
         if not self.options.no_unpack:
             unpackArtifacts(
-                os.path.join(self.artifacts_dir, 'packs', 'src'),
-                self.build_dir)
-            unpackArtifacts(
-                os.path.join(self.artifacts_dir, 'packs', self.platform),
-                self.build_dir)
+                os.path.join(self.artifacts_dir, "packs", "src"), self.build_dir
+            )
             unpackArtifacts(
-                os.path.join(self.artifacts_dir, 'ccache'), self.build_dir)
-
-            if os.path.exists(os.path.join(self.artifacts_dir, 'slot.patch')):
-                self.log.warning('Applying patch file: %s' % os.path.join(
-                    self.artifacts_dir, 'slot.patch'))
-                log_call([
-                    'patch', '-p1', '-i',
-                    os.path.join(self.artifacts_dir, 'slot.patch')
-                ],
-                         cwd=self.build_dir)
+                os.path.join(self.artifacts_dir, "packs", self.platform), self.build_dir
+            )
+            unpackArtifacts(os.path.join(self.artifacts_dir, "ccache"), self.build_dir)
+
+            if os.path.exists(os.path.join(self.artifacts_dir, "slot.patch")):
+                self.log.warning(
+                    "Applying patch file: %s"
+                    % os.path.join(self.artifacts_dir, "slot.patch")
+                )
+                log_call(
+                    [
+                        "patch",
+                        "-p1",
+                        "-i",
+                        os.path.join(self.artifacts_dir, "slot.patch"),
+                    ],
+                    cwd=self.build_dir,
+                )
 
         def dumpConfSummary():
-            '''Create special summary file used by SetupProject.'''
+            """Create special summary file used by SetupProject."""
             data = defaultdict(list)
             env = self.slot.environment()
             # collect the expanded values for  CMTPROJECTPATH and
             # CMAKE_PREFIX_PATH in the local environment
-            for name in ('CMTPROJECTPATH', 'CMAKE_PREFIX_PATH'):
+            for name in ("CMTPROJECTPATH", "CMAKE_PREFIX_PATH"):
                 if name in env:
-                    data[name] = os.path.expandvars(env[name]).split(':')
+                    data[name] = os.path.expandvars(env[name]).split(":")
             if data:
-                py_templ = Template(u'''# -*- coding: utf-8 -*-
+                py_templ = Template(
+                    """# -*- coding: utf-8 -*-
 cmtProjectPathList = ${path}
 
 # relocate
 try:
     from os.path import dirname
     nightlyBuildRoot = ${build_root}
     newRoot = dirname(__file__)
     cmtProjectPathList = [s.replace(nightlyBuildRoot, newRoot)
                           for s in cmtProjectPathList]
 except NameError:
-    pass # __file__ gets defined only with LbScripts > v8r0\n''')
+    pass # __file__ gets defined only with LbScripts > v8r0\n"""
+                )
                 values = {
-                    'path':
-                    repr(data['CMAKE_PREFIX_PATH'] + data['CMTPROJECTPATH']),
-                    'build_root':
-                    repr(self.build_dir)
+                    "path": repr(data["CMAKE_PREFIX_PATH"] + data["CMTPROJECTPATH"]),
+                    "build_root": repr(self.build_dir),
                 }
                 summ = py_templ.substitute(values)
-                self.write(self._summaryDir('confSummary.py'), summ)
+                self.write(self._summaryDir("confSummary.py"), summ)
                 # FIXME: this is for backward compatibility with old lb-run
-                self.write(
-                    os.path.join(self.artifacts_dir, 'confSummary.py'), summ)
+                self.write(os.path.join(self.artifacts_dir, "confSummary.py"), summ)
 
                 cmake_templ = Template(
-                    u'''set(NIGHTLY_BUILD_ROOT ${build_root})
+                    """set(NIGHTLY_BUILD_ROOT ${build_root})
 set(CMAKE_PREFIX_PATH ${path} $${CMAKE_PREFIX_PATH})
 
 string(REPLACE "$${NIGHTLY_BUILD_ROOT}" "$${CMAKE_CURRENT_LIST_DIR}"
-       CMAKE_PREFIX_PATH "$${CMAKE_PREFIX_PATH}")\n''')
+       CMAKE_PREFIX_PATH "$${CMAKE_PREFIX_PATH}")\n"""
+                )
                 values = {
-                    'path':
-                    ' '.join(data['CMAKE_PREFIX_PATH'] +
-                             data['CMTPROJECTPATH']),
-                    'build_root':
-                    self.build_dir
+                    "path": " ".join(
+                        data["CMAKE_PREFIX_PATH"] + data["CMTPROJECTPATH"]
+                    ),
+                    "build_root": self.build_dir,
                 }
                 cmake = cmake_templ.substitute(values)
-                self.write(self._summaryDir('searchPath.cmake'), cmake)
+                self.write(self._summaryDir("searchPath.cmake"), cmake)
                 # FIXME: this is for backward compatibility with old lb-run
-                self.write(
-                    os.path.join(self.artifacts_dir, 'searchPath.cmake'),
-                    cmake)
+                self.write(os.path.join(self.artifacts_dir, "searchPath.cmake"), cmake)
 
         dumpConfSummary()
 
     def _sourcesLists(self, proj):
-        '''
+        """
         Return the list of files in the sources directories for a project.
 
         @param proj: project instance to scan
-        '''
-        return sorted(
-            listAllFiles(self._buildDir(proj), self._file_excl_rex.match))
+        """
+        return sorted(listAllFiles(self._buildDir(proj), self._file_excl_rex.match))
 
     def _manifestRequired(self, proj, build_result):
-        '''
+        """
         Return True if the manifest.xml is required for the project.
-        '''
-        return (self.slot.name == 'lhcb-release'
-                and not isinstance(proj, DataProject)
-                and build_result.returncode == 0)
+        """
+        return (
+            self.slot.name == "lhcb-release"
+            and not isinstance(proj, DataProject)
+            and build_result.returncode == 0
+        )
 
     def _ensureGeneratedManifest(self, proj, build_result):
-        '''
+        """
         Generate a manifest.xml if not present and required.
-        '''
+        """
         if not self._manifestRequired(proj, build_result):
             return
 
-        manifest_file = self._buildDir(proj, 'InstallArea', self.platform,
-                                       'manifest.xml')
-        if (not os.path.exists(manifest_file)
-                and not os.path.exists(self._buildDir(proj, 'manifest.xml'))):
+        manifest_file = self._buildDir(
+            proj, "InstallArea", self.platform, "manifest.xml"
+        )
+        if not os.path.exists(manifest_file) and not os.path.exists(
+            self._buildDir(proj, "manifest.xml")
+        ):
             self.log.warning(
-                '%s not generated by the build, '
-                'we try to produce one', manifest_file)
+                "%s not generated by the build, " "we try to produce one", manifest_file
+            )
             from LbNightlyTools.Scripts.Release import createManifestFile
+
             # ensure that the destination directory exists, in case
             # of builds that failed very badly
             if not os.path.exists(os.path.dirname(manifest_file)):
                 os.makedirs(os.path.dirname(manifest_file))
-            with open(manifest_file, 'w') as manif:
+            with open(manifest_file, "w") as manif:
                 manif.write(
-                    createManifestFile(proj.name, proj.version, self.platform,
-                                       proj.baseDir))
+                    createManifestFile(
+                        proj.name, proj.version, self.platform, proj.baseDir
+                    )
+                )
 
     def main(self):
-        '''
+        """
         Main function of the script.
-        '''
+        """
         if len(self.args) != 1:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         opts = self.options
 
-        self._setup(json_type='build-result', summary_base='build')
-        self._file_excl_rex = re.compile((r'^(InstallArea)|(build\.{0})|({0})|'
-                                          r'(\.git)|(\.svn)|'
-                                          r'(\.{0}\.d)|(Testing)|(.*\.pyc)|'
-                                          r'(cov-out)$').format(self.platform))
+        self._setup(json_type="build-result", summary_base="build")
+        self._file_excl_rex = re.compile(
+            (
+                r"^(InstallArea)|(build(\.{0})?)|({0})|"
+                r"(\.git)|(\.svn)|"
+                r"(\.{0}\.d)|(Testing)|(.*\.pyc)|"
+                r"(cov-out)$"
+            ).format(self.platform)
+        )
 
         # See LBCORE-637 (we do not want ccache for releases)
-        if opts.use_ccache and os.environ.get('flavour') == 'release':
-            self.log.warning('cannot use ccache for releases')
+        if opts.use_ccache and os.environ.get("flavour") == "release":
+            self.log.warning("cannot use ccache for releases")
             opts.use_ccache = False
 
         # let's not overwrite what requested in the slot configuration
-        if 'CMAKE_USE_CCACHE' not in self.slot.cache_entries:
-            self.slot.cache_entries['CMAKE_USE_CCACHE'] = opts.use_ccache
-        if 'GAUDI_DIAGNOSTICS_COLOR' not in self.slot.cache_entries:
-            self.slot.cache_entries['GAUDI_DIAGNOSTICS_COLOR'] = 'YES'
+        if "CMAKE_USE_CCACHE" not in self.slot.cache_entries:
+            self.slot.cache_entries["CMAKE_USE_CCACHE"] = opts.use_ccache
+        if "GAUDI_DIAGNOSTICS_COLOR" not in self.slot.cache_entries:
+            self.slot.cache_entries["GAUDI_DIAGNOSTICS_COLOR"] = "YES"
         # FIXME: workaround for typo in Gaudi cmake
         # see https://gitlab.cern.ch/gaudi/Gaudi/merge_requests/578
-        if 'GAUDI_DIAGNOTICS_COLOR' not in self.slot.cache_entries:
-            self.slot.cache_entries['GAUDI_DIAGNOTICS_COLOR'] = 'YES'
+        if "GAUDI_DIAGNOTICS_COLOR" not in self.slot.cache_entries:
+            self.slot.cache_entries["GAUDI_DIAGNOTICS_COLOR"] = "YES"
 
         # See LBCORE-637, LBCORE-953
-        if (str(self.slot.build_tool) == 'CMT' and opts.use_ccache
-                and which('ccache')):  # CMT requires ccache in the PATH
+        if (
+            str(self.slot.build_tool) == "CMT" and opts.use_ccache and which("ccache")
+        ):  # CMT requires ccache in the PATH
             for e in self.slot.env:
-                if e.startswith('CMTEXTRATAGS='):
-                    self.slot.env.append('CMTEXTRATAGS=${CMTEXTRATAGS},'
-                                         'use-ccache')
+                if e.startswith("CMTEXTRATAGS="):
+                    self.slot.env.append("CMTEXTRATAGS=${CMTEXTRATAGS}," "use-ccache")
                     break
             else:  # this must match the 'for'
-                self.slot.env.append('CMTEXTRATAGS=use-ccache')
+                self.slot.env.append("CMTEXTRATAGS=use-ccache")
 
         if opts.submit and not opts.projects:
             # ensure that results for the current slot/build/platform are
             # not in the dashboard (useful in case of rebuild), but only
             # if we need to publish the results and it's not a partial build
-            self.send({'type': 'drop-build'})
+            self.send({"type": "drop-build"})
 
-        self.send({
-            'type': 'job-start',
-            'host': HOSTNAME,
-            'build_number': os.environ.get('BUILD_NUMBER', 0),
-            'started': self.starttime.isoformat()
-        })
+        self.assert_not_aborted()
+        self.send(
+            {
+                "type": "job-start",
+                "host": HOSTNAME,
+                "build_number": os.environ.get("BUILD_NUMBER", 0),
+                "started": self.starttime.isoformat(),
+            }
+        )
 
         self._prepareBuildDir()
 
-        make_cmd = ({
-            'all': [
-                'cov-build', '--dir', 'cov-out', '--build-description',
-                '{slot}-{build_id}'.format(
-                    slot=self.slot.name, build_id=self.slot.build_id), 'make'
-            ]
-        } if opts.coverity else None)
+        make_cmd = (
+            {
+                "all": [
+                    "cov-build",
+                    "--dir",
+                    "cov-out",
+                    "--build-description",
+                    "{slot}-{build_id}".format(
+                        slot=self.slot.name, build_id=self.slot.build_id
+                    ),
+                    "make",
+                ]
+            }
+            if opts.coverity
+            else None
+        )
         # FIXME: we should use the search path
         cov_strip = [
-            '--strip-path', '/afs/cern.ch/sw/lcg/releases', '--strip-path',
-            '/cvmfs/sft.cern.ch/lcg/releases', '--strip-path',
-            '/cvmfs/lhcb.cern.ch/lib/lcg/releases'
+            "--strip-path",
+            "/afs/cern.ch/sw/lcg/releases",
+            "--strip-path",
+            "/cvmfs/sft.cern.ch/lcg/releases",
+            "--strip-path",
+            "/cvmfs/lhcb.cern.ch/lib/lcg/releases",
         ]
 
         # add timing report and command echo
         def echo_call(*args, **kwargs):
-            '''call a command logging it'''
-            self.log.debug('running %s', ' '.join(args[0]))
+            """call a command logging it"""
+            self.log.debug("running %s", " ".join(args[0]))
             result = _tee_call(*args, **kwargs)
-            __log__.debug('command exited with code %d', result[0])
+            __log__.debug("command exited with code %d", result[0])
             return result
 
         tee_call = log_timing(self.log)(echo_call)
 
         # record CPU details
-        write_json(cpuinfo(), self._summaryDir('cpuinfo.json'))
+        write_json(cpuinfo(), self._summaryDir("cpuinfo.json"))
 
         from subprocess import STDOUT
+
         with chdir(self.build_dir):
             sources = []
 
             def record_start(proj):
-                '''helper function to keep track of the start of the build'''
+                """helper function to keep track of the start of the build"""
+                self.assert_not_aborted()
                 # keep a list of the files in the source directories before the build
                 sources[:] = self._sourcesLists(proj)
-                self.send({
-                    'project': proj.name,
-                    'started': datetime.now().isoformat()
-                })
-
-            if os.path.exists(os.path.join(self.artifacts_dir, 'slot.patch')):
-                self.log.warning('Applaying patch file')
-                log_call([
-                    'patch', '-p1', '-i',
-                    os.path.join(self.artifacts_dir, 'slot.patch')
-                ])
+                self.send({"project": proj.name, "started": datetime.now().isoformat()})
+
+            if os.path.exists(os.path.join(self.artifacts_dir, "slot.patch")):
+                self.log.warning("Applaying patch file")
+                log_call(
+                    [
+                        "patch",
+                        "-p1",
+                        "-i",
+                        os.path.join(self.artifacts_dir, "slot.patch"),
+                    ]
+                )
 
             for proj, result in self.slot.buildGen(
-                    projects=opts.projects,
-                    jobs=opts.jobs,
-                    max_load=opts.load_average,
-                    args=['-k'],
-                    make_cmd=make_cmd,
-                    stderr=STDOUT,
-                    before=record_start):
+                projects=opts.projects,
+                jobs=opts.jobs,
+                max_load=opts.load_average,
+                args=["-k"],
+                make_cmd=make_cmd,
+                stderr=STDOUT,
+                # if not in release builds (i.e. no_patch = False) allow missing artifacts
+                relaxed_install=not self.slot.no_patch,
+                before=record_start,
+            ):
                 summary_dir = self._summaryDir(proj)
                 ensureDirs([summary_dir])
 
                 if result.returncode != 0:
-                    self.log.warning('build of %s exited with code %d', proj,
-                                     result.returncode)
+                    self.log.warning(
+                        "build of %s exited with code %d", proj, result.returncode
+                    )
                     if opts.coverity:
-                        self.log.warning('Coverity analysis skipped')
+                        self.log.warning("Coverity analysis skipped")
 
                 self._ensureGeneratedManifest(proj, result)
 
                 collect_retcode = 0
-                if str(proj.build_tool) == 'CMake':
-                    open(join(summary_dir, 'build-raw.log'),
-                         'w').write(result.stdout)
-                    loglines = result.stdout.splitlines(True)
-                    starts = [(line.split()[-2], idx)
-                              for idx, line in enumerate(loglines)
-                              if line.startswith('#### CMake ')]
+                if str(proj.build_tool) == "CMake":
+                    stdout = coerce_str(result.stdout)
+                    open(join(summary_dir, "build-raw.log"), "w").write(stdout)
+                    loglines = stdout.splitlines(True)
+                    starts = [
+                        (line.split()[-2], idx)
+                        for idx, line in enumerate(loglines)
+                        if line.startswith("#### CMake ")
+                    ]
                     end = len(loglines)
                     regions = {}
                     for key, start in starts[-1::-1]:
                         regions[key] = (start, end)
                         end = start
-                    collect_retcode = \
-                        CBLScript().run(['--debug',
-                                         '--exclude', '.*unsafe-install.*',
-                                         '--exclude', '.*python.zip.*',
-                                         '--exclude', '.*precompile-.*',
-                                         self._buildDir(proj, 'build'),
-                                         join(summary_dir, 'build.log')])
-                    with open(join(summary_dir, 'build.log'), 'a') as f:
-                        for key in [
-                                'unsafe-install', 'post-install', 'install'
-                        ]:
+                    collect_retcode = CBLScript().run(
+                        [
+                            "--debug",
+                            "--exclude",
+                            ".*unsafe-install.*",
+                            "--exclude",
+                            ".*python.zip.*",
+                            "--exclude",
+                            ".*precompile-.*",
+                            self._buildDir(proj, "build"),
+                            join(summary_dir, "build.log"),
+                        ]
+                    )
+                    with open(join(summary_dir, "build.log"), "a") as f:
+                        for key in ["unsafe-install", "post-install", "install"]:
                             start, end = regions.get(key, (0, 0))
                             f.writelines(loglines[start:end])
 
-                elif str(proj.build_tool) == 'CMT':
-                    collect_retcode = \
-                        CBLScript().run(['--debug', '--cmt',
-                                         '--platform', self.platform,
-                                         self._buildDir(proj),
-                                         join(summary_dir, 'build.log')])
-                if (collect_retcode
-                        or not os.path.exists(join(summary_dir, 'build.log'))):
-                    with open(join(summary_dir, 'build.log'), 'w') as f:
+                elif str(proj.build_tool) == "CMT":
+                    collect_retcode = CBLScript().run(
+                        [
+                            "--debug",
+                            "--cmt",
+                            "--platform",
+                            self.platform,
+                            self._buildDir(proj),
+                            join(summary_dir, "build.log"),
+                        ]
+                    )
+                if collect_retcode or not os.path.exists(
+                    join(summary_dir, "build.log")
+                ):
+                    with open(join(summary_dir, "build.log"), "w") as f:
                         f.write(proj.build_log)
 
                 # build job specific infos for the report
                 env = proj.environment()
                 # mask possible secrets in the environment
                 for k in env:
-                    if re.search(r'pass(w(or)?d)?|secret|token|admin',
-                                 k.lower()):
-                        env[k] = '***'
+                    if re.search(r"pass(w(or)?d)?|secret|token|admin", k.lower()):
+                        env[k] = "***"
 
                 report = genBuildReport(
-                    join(summary_dir, 'build.log'),
-                    join(summary_dir, 'build_log'),
+                    join(summary_dir, "build.log"),
+                    join(summary_dir, "build_log"),
                     self._buildDir(proj),
                     self.build_dir,
                     exceptions={
-                        'warning': self.slot.warning_exceptions,
-                        'error': self.slot.error_exceptions
+                        "warning": self.slot.warning_exceptions,
+                        "error": self.slot.error_exceptions,
                     },
                     extra_info={
-                        'project': proj.name,
-                        'version': proj.version,
-                        'slot': self.slot.name,
-                        'slot_build_id': self.slot.build_id,
-                        'host': HOSTNAME,
-                        'platform': self.platform,
-                        'started': result.started.isoformat(),
-                        'completed': result.completed.isoformat(),
-                        'retcode': result.returncode,
-                        'environment': env
-                    })
+                        "project": proj.name,
+                        "version": proj.version,
+                        "slot": self.slot.name,
+                        "slot_build_id": self.slot.build_id,
+                        "host": HOSTNAME,
+                        "platform": self.platform,
+                        "started": result.started.isoformat(),
+                        "completed": result.completed.isoformat(),
+                        "retcode": result.returncode,
+                        "environment": env,
+                    },
+                )
 
                 self.send(report)
 
-                for (f, d) in (('sources.list',
-                                sources), ('sources_built.list',
-                                           self._sourcesLists(proj))):
-                    self.write(self._summaryDir(proj, f), '\n'.join(d) + '\n')
-
-                if (not isinstance(proj, DataProject) and not os.path.exists(
-                        self._buildDir(proj, 'manifest.xml'))):
-                    inst_area = os.path.join(proj.baseDir, 'InstallArea')
+                for f, d in (
+                    ("sources.list", sources),
+                    ("sources_built.list", self._sourcesLists(proj)),
+                ):
+                    self.write(self._summaryDir(proj, f), "\n".join(d) + "\n")
+
+                if not isinstance(proj, DataProject) and not os.path.exists(
+                    self._buildDir(proj, "manifest.xml")
+                ):
+                    inst_area = os.path.join(proj.baseDir, "InstallArea")
                     if os.path.exists(inst_area):
-                        self.log.info('packing %s', inst_area)
-                        pack([inst_area,
-                              os.path.join(proj.baseDir, 'build')],
-                             genPackageName(
-                                 proj,
-                                 self.platform,
-                                 build_id=self.options.build_id,
-                                 artifacts_dir=self.artifacts_dir),
-                             cwd=self.build_dir,
-                             checksum='md5')
+                        self.log.info("packing %s", inst_area)
+                        pack(
+                            [inst_area, os.path.join(proj.baseDir, "build")],
+                            genPackageName(
+                                proj,
+                                self.platform,
+                                build_id=self.options.build_id,
+                                artifacts_dir=self.artifacts_dir,
+                            ),
+                            cwd=self.build_dir,
+                            checksum="md5",
+                            # preserve symlinks in build directory (except CMT)
+                            # FIXME: this is only needed because we split build and tests
+                            dereference=str(proj.build_tool) == "CMT",
+                        )
+                        if os.path.exists(os.path.join(proj.baseDir, "build")):
+                            self.log.debug(
+                                "removing %s", os.path.join(proj.baseDir, "build")
+                            )
+                            self.tasks.add(
+                                shutil.rmtree,
+                                (os.path.join(proj.baseDir, "build"),),
+                                {"ignore_errors": True},
+                            )
                     else:
                         self.log.warning(
-                            '%s missing, binary package not '
-                            'produced', inst_area)
+                            "%s missing, binary package not " "produced", inst_area
+                        )
 
                 # FIXME
                 if proj.with_shared:
                     shr_pack = genPackageName(
                         proj,
                         "shared",
                         build_id=self.options.build_id,
-                        artifacts_dir=self.artifacts_dir)
-                    to_pack_list = (
-                        set(open(join(summary_dir, 'sources_built.list'))) -
-                        set(open(join(summary_dir, 'sources.list'))))
-                    pack([
-                        os.path.relpath(f.strip(), self.build_dir)
-                        for f in sorted(to_pack_list)
-                    ],
-                         shr_pack,
-                         cwd=self.build_dir,
-                         checksum='md5')
+                        artifacts_dir=self.artifacts_dir,
+                    )
+                    to_pack_list = set(
+                        open(join(summary_dir, "sources_built.list"))
+                    ) - set(open(join(summary_dir, "sources.list")))
+                    pack(
+                        [
+                            os.path.relpath(f.strip(), self.build_dir)
+                            for f in sorted(to_pack_list)
+                            if f.strip()
+                        ],
+                        shr_pack,
+                        cwd=self.build_dir,
+                        checksum="md5",
+                    )
 
                 self.dumpGitStatus(proj)
 
-                echo_call(['zip', '-r', '-m', '-q', proj.name, proj.name],
-                          cwd=os.path.dirname(summary_dir))
+                echo_call(
+                    ["zip", "-r", "-m", "-q", proj.name, proj.name],
+                    cwd=os.path.dirname(summary_dir),
+                )
                 if opts.coverity:
                     # fix Permissions of artifacts in Coverity builds
                     fix_permissions(self.artifacts_dir)
-                self.send({
-                    'type': 'artifacts.build',
-                    'project': proj,
-                    'platform': self.platform,
-                    'path': self.artifacts_dir
-                })
+                self.send(
+                    {
+                        "type": "artifacts.build",
+                        "project": proj,
+                        "platform": self.platform,
+                        "path": self.artifacts_dir,
+                    }
+                )
 
                 # add current project to the path strip settings
-                cov_strip.append('--strip-path')
-                cov_strip.append(
-                    os.path.dirname(os.path.abspath(proj.baseDir)))
+                cov_strip.append("--strip-path")
+                cov_strip.append(os.path.dirname(os.path.abspath(proj.baseDir)))
 
                 if opts.coverity and result.returncode == 0:
-
                     isDebug = self.log.level <= logging.DEBUG
-                    wipeDir(join(proj.baseDir, 'cov-out', 'output'))
+                    wipeDir(join(proj.baseDir, "cov-out", "output"))
                     cov_result = tee_call(
                         [
-                            'cov-analyze', '--dir', 'cov-out', '--all',
-                            '--enable-constraint-fpp', '--enable-fnptr',
-                            '--enable-single-virtual', '--force'
-                        ] + cov_strip,
+                            "cov-analyze",
+                            "--dir",
+                            "cov-out",
+                            "--all",
+                            "--enable-constraint-fpp",
+                            "--enable-fnptr",
+                            "--enable-single-virtual",
+                            "--force",
+                        ]
+                        + cov_strip,
                         cwd=proj.baseDir,
-                        verbose=isDebug)
-                    log_name = summary_dir + '.cov-analyze'
-                    with open(log_name + '.log', 'w') as f:
+                        verbose=isDebug,
+                    )
+                    log_name = summary_dir + ".cov-analyze"
+                    with open(log_name + ".log", "w") as f:
                         f.write(cov_result[1])
-                    with open(log_name + '.err.log', 'w') as f:
+                    with open(log_name + ".err.log", "w") as f:
                         f.write(cov_result[2])
 
                     if not opts.coverity_commit:
                         continue
                     if cov_result[0] != 0:
                         self.log.warning(
-                            'Coverity analysis for %s exited with '
-                            'code %d, not committing', proj, cov_result[0])
-                    elif 'COVERITY_PASSPHRASE' in os.environ:
-                        cov_result = tee_call([
-                            'cov-commit-defects', '--dir', 'cov-out', '--host',
-                            'lcgapp10.cern.ch', '--port', '8080', '--user',
-                            'admin', '--stream', 'LHCb-{0}-Stream'.format(
-                                proj.name)
-                        ],
-                                              cwd=proj.baseDir)
-                        log_name = summary_dir + '.cov-commit-defects'
-                        with open(log_name + '.log', 'w') as f:
+                            "Coverity analysis for %s exited with "
+                            "code %d, not committing",
+                            proj,
+                            cov_result[0],
+                        )
+                    elif "COVERITY_PASSPHRASE" in os.environ:
+                        cov_result = tee_call(
+                            [
+                                "cov-commit-defects",
+                                "--dir",
+                                "cov-out",
+                                "--host",
+                                "lcgapp10.cern.ch",
+                                "--port",
+                                "8080",
+                                "--user",
+                                "admin",
+                                "--stream",
+                                "LHCb-{0}-Stream".format(proj.name),
+                            ],
+                            cwd=proj.baseDir,
+                        )
+                        log_name = summary_dir + ".cov-commit-defects"
+                        with open(log_name + ".log", "w") as f:
                             f.write(cov_result[1])
-                        with open(log_name + '.err.log', 'w') as f:
+                        with open(log_name + ".err.log", "w") as f:
                             f.write(cov_result[2])
                     else:
                         self.log.warning(
-                            'Coverity analysis cannot be committed'
-                            ': missing password')
+                            "Coverity analysis cannot be committed" ": missing password"
+                        )
                     for extra_file in [
-                            join(proj.baseDir, 'cov-out', 'output',
-                                 'cov-blame', 'cov-blame-errors.log')
+                        join(
+                            proj.baseDir,
+                            "cov-out",
+                            "output",
+                            "cov-blame",
+                            "cov-blame-errors.log",
+                        )
                     ]:
                         if os.path.exists(extra_file):
-                            ensureDirs([summary_dir + '-extra'])
+                            ensureDirs([summary_dir + "-extra"])
                             shutil.copy(
                                 extra_file,
-                                join(summary_dir + '-extra',
-                                     os.path.basename(extra_file)))
+                                join(
+                                    summary_dir + "-extra", os.path.basename(extra_file)
+                                ),
+                            )
 
                     # fix Permissions of artifacts in Coverity builds
                     fix_permissions(self.artifacts_dir)
-                    self.send({
-                        'type': 'artifacts.coverity',
-                        'project': proj,
-                        'platform': self.platform,
-                        'path': self.artifacts_dir
-                    })
+                    self.send(
+                        {
+                            "type": "artifacts.coverity",
+                            "project": proj,
+                            "platform": self.platform,
+                            "path": self.artifacts_dir,
+                        }
+                    )
 
         # ensure we do not have pending tasks
         self.tasks.join()
 
         self.completetime = datetime.now()
 
-        self.send({
-            'type': 'job-end',
-            'completed': self.completetime.isoformat()
-        },
-                  sync=True)
+        self.send(
+            {"type": "job-end", "completed": self.completetime.isoformat()}, sync=True
+        )
 
-        self.log.info('build completed in %s',
-                      self.completetime - self.starttime)
+        self.log.info("build completed in %s", self.completetime - self.starttime)
 
         return 0
 
 
-def genBuildReport(build_log,
-                   output_dir,
-                   proj_build_root=None,
-                   slot_build_root=None,
-                   exceptions=None,
-                   extra_info=None):
-    from os.path import join, dirname, isdir
-    from subprocess import check_output, CalledProcessError
-    from LbNightlyTools.HTMLUtils import (ANSI2HTML, TableizeLine, WrapLine,
-                                          ClassifyByLineNo)
+def genBuildReport(
+    build_log,
+    output_dir,
+    proj_build_root=None,
+    slot_build_root=None,
+    exceptions=None,
+    extra_info=None,
+):
+    from os.path import dirname, isdir, join
+    from subprocess import CalledProcessError, check_output
+
     from LbNightlyTools.BuildLogScanner import (
-        split_build_log, scan_build_log, strip_build_root)
+        scan_build_log,
+        split_build_log,
+        strip_build_root,
+    )
+    from LbNightlyTools.HTMLUtils import (
+        ANSI2HTML,
+        ClassifyByLineNo,
+        TableizeLine,
+        WrapLine,
+    )
     from LbNightlyTools.Scripts.CollectBuildLogs import (
-        TABLE_HEAD, TABLE_TAIL, IssueLinker, GitlabUrlFormat, report_dict,
-        write_report_index)
+        TABLE_HEAD,
+        TABLE_TAIL,
+        GitlabUrlFormat,
+        IssueLinker,
+        report_dict,
+        write_report_index,
+    )
 
     # collect git infos
     git_info = {}
     try:
-        if proj_build_root and isdir(join(proj_build_root, '.git')):
+        if proj_build_root and isdir(join(proj_build_root, ".git")):
             # we can only support projects with checkout recorded in
             # https://gitlab.cern.ch/lhcb-nightlies
-            url = check_output(['git', 'config', 'remote.lhcb-nightlies.url'],
-                               cwd=proj_build_root)
-            git_info['name'] = os.path.basename(os.path.splitext(url)[0])
-
-            git_info['commit'] = check_output(['git', 'rev-parse', 'HEAD'],
-                                              cwd=proj_build_root).strip()
-            git_info['files'] = set(
-                check_output(['git', 'ls-tree', '--name-only', '-r', 'HEAD'],
-                             cwd=proj_build_root).splitlines())
-            git_info['url'] = ('https://gitlab.cern.ch/lhcb-nightlies/'
-                               '{name}/blob/{commit}/').format(**git_info)
+            url = check_output(
+                ["git", "config", "remote.lhcb-nightlies.url"], cwd=proj_build_root
+            )
+            git_info["name"] = os.path.basename(os.path.splitext(url)[0])
+
+            git_info["commit"] = check_output(
+                ["git", "rev-parse", "HEAD"], cwd=proj_build_root
+            ).strip()
+            git_info["files"] = set(
+                check_output(
+                    ["git", "ls-tree", "--name-only", "-r", "HEAD"], cwd=proj_build_root
+                ).splitlines()
+            )
+            git_info["url"] = (
+                "https://gitlab.cern.ch/lhcb-nightlies/" "{name}/blob/{commit}/"
+            ).format(**git_info)
     except CalledProcessError:
         # could not extract git info
         git_info = {}
 
     # 1. strip build root and split log file in chunks (sections)
-    input_data = codecs.open(build_log, 'r', encoding='utf-8', errors='ignore')
+    input_data = codecs.open(build_log, "r", encoding="utf-8", errors="ignore")
     if proj_build_root:
         input_data = strip_build_root(proj_build_root, input_data)
     if slot_build_root:
         input_data = strip_build_root(slot_build_root, input_data)
     chunks = split_build_log(input_data)
 
     # 2. for each chunk look for errors or warnings using specific scanners
     #    and record the begin and end positions of each diagnostics
-    reports = dict(
-        (chunk_id, scan_build_log(lines)) for chunk_id, lines in chunks)
+    reports = dict((chunk_id, scan_build_log(lines)) for chunk_id, lines in chunks)
 
     # 3. generate report files
     ensureDirs([output_dir])
     ensureDirs(dirname(join(output_dir, chunk_id)) for chunk_id, _ in chunks)
 
     for chunk_id, chunk in chunks:
         classification = ClassifyByLineNo(
-            ((issue.log_range[0] + 1, issue.log_range[1] + 1), {
-                'warning': 'alert-warning',
-                'error': 'alert-danger'
-            }.get(issue.severity, '')) for issue in reports[chunk_id])
+            (
+                (issue.log_range[0] + 1, issue.log_range[1] + 1),
+                {"warning": "alert-warning", "error": "alert-danger"}.get(
+                    issue.severity, ""
+                ),
+            )
+            for issue in reports[chunk_id]
+        )
         actions = [
-            lambda line: cgi.escape(line, quote=True),
+            lambda line: html.escape(line, quote=True),
             ANSI2HTML(),
-            WrapLine('pre'),
+            WrapLine("pre"),
             TableizeLine(
-                line_id_prefix=chunk_id + '_',
+                line_id_prefix=chunk_id + "_",
                 add_line_nos=True,
-                row_class=classification)
+                row_class=classification,
+            ),
         ]
         if git_info:
             actions.append(
-                IssueLinker([
-                    issue for issue in reports[chunk_id]
-                    if issue.source.name in git_info['files']
-                ], GitlabUrlFormat(git_info['url'])))
+                IssueLinker(
+                    [
+                        issue
+                        for issue in reports[chunk_id]
+                        if issue.source.name in git_info["files"]
+                    ],
+                    GitlabUrlFormat(git_info["url"]),
+                )
+            )
 
         def process(line):
             for action in actions:
                 line = action(line)
             return line
 
-        with codecs.open(join(output_dir, chunk_id + '.html'), 'w',
-                         'utf-8') as h:
+        with codecs.open(join(output_dir, chunk_id + ".html"), "w", "utf-8") as h:
             h.write(TABLE_HEAD)
-            h.writelines(process(line.rstrip()) + '\n' for line in chunk)
+            h.writelines(process(line.rstrip()) + "\n" for line in chunk)
             h.write(TABLE_TAIL)
 
     jreport = report_dict(chunks, reports)
     # filter issues to remove excluded ones
-    jreport['ignored_issues'] = {
-        severity: {}
-        for severity in jreport['issues']
-    }
+    jreport["ignored_issues"] = {severity: {} for severity in jreport["issues"]}
     exceptions = {
         severity: [(exp, re.compile(exp)) for exp in exceptions[severity]]
         for severity in exceptions or {}
     }
     for severity in exceptions:
         # remove excluded issues from the report and count them per regexp
         for text, exp in exceptions[severity]:
-            before = len(jreport['issues'][severity])
-            jreport['issues'][severity] = [
-                issue for issue in jreport['issues'][severity]
-                if not exp.search(issue['desc'])
+            before = len(jreport["issues"][severity])
+            jreport["issues"][severity] = [
+                issue
+                for issue in jreport["issues"][severity]
+                if not exp.search(issue["desc"])
             ]
-            after = len(jreport['issues'][severity])
-            jreport['ignored_issues'][severity][text] = before - after
+            after = len(jreport["issues"][severity])
+            jreport["ignored_issues"][severity][text] = before - after
 
-    jreport.update({
-        'warnings': len(jreport['issues']['warning']),
-        'errors': len(jreport['issues']['error']),
-        'coverity_messages': len(jreport['issues']['coverity'])
-    })
+    jreport.update(
+        {
+            "warnings": len(jreport["issues"]["warning"]),
+            "errors": len(jreport["issues"]["error"]),
+            "coverity_messages": len(jreport["issues"]["coverity"]),
+        }
+    )
 
     # limit the number of presented issues (see LBCORE-1210)
     # it's done here because I want jreport[severity's] to contain the total
-    for severity in jreport['issues']:
-        count = len(jreport['issues'][severity])
+    for severity in jreport["issues"]:
+        count = len(jreport["issues"][severity])
         if count > MAX_REPORTED_ISSUES:
-            jreport['ignored_issues'][severity]['too many issues'] = (
-                count - MAX_REPORTED_ISSUES)
-            jreport['issues'][severity][MAX_REPORTED_ISSUES:] = []
+            jreport["ignored_issues"][severity]["too many issues"] = (
+                count - MAX_REPORTED_ISSUES
+            )
+            jreport["issues"][severity][MAX_REPORTED_ISSUES:] = []
 
     if extra_info:
         jreport.update(extra_info)
 
-    write_json(jreport, join(output_dir, 'report.json'))
+    write_json(jreport, join(output_dir, "report.json"))
     write_report_index(jreport, output_dir)
     return jreport
 
 
 def run():
     return Script().run()
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/extract.php` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/extract.php`

 * *Files 7% similar despite different names*

```diff
@@ -41,15 +41,15 @@
       if ($ct == 'application/x-gzip'){
         header('Content-Encoding: gzip' );
         header('Accept-Ranges: bytes');
 
         // Since it is sent as a text,
         // remove the end of line char
         // Note: it might well be that we would need
-        // to do this always, but it did not prove 
+        // to do this always, but it did not prove
         // necessary so far
         $content= rtrim($content, "\n");
         $contentLength = strlen($content);
         header("Content-Length: ".strlen($content));
         header("Content-Disposition: attachment; filename=".basename($path));
       }
       echo $content;
@@ -60,31 +60,30 @@
   // keep the output var to know the size of the file inside the archive
   exec('/usr/bin/unzip -qq -l "' . $zip_name . '" "' . $path. '"',
        $output, $return_var);
   if ( $return_var != 0 ) {
     header($_SERVER['SERVER_PROTOCOL'] . ' 404 Not Found', true, 404);
     echo "404 - Not Found";
   } else {
-  
+
     header('Content-Type: ' . $ct);
-    
+
     if ($ct == 'application/x-gzip'){
       // Specify a few headers.
       // We need to set the Content-Length manually
-      // otherwise it is set one char too much because of the 
+      // otherwise it is set one char too much because of the
       // EOL char.
 
-      // output is of the form 
+      // output is of the form
       //     10685  02-28-2019 10:31   00000059/summaryGauss_00086576_00000059_1.xml.gz
       // We want the first element, which is the size
       $sizeArray = explode(" ", trim($output[0]));
       $size = $sizeArray[0];
-  
+
       header('Content-Encoding: gzip' );
       header('Accept-Ranges: bytes');
       header("Content-Length: $size");
     }
     passthru('/usr/bin/unzip -p "' . $zip_name . '" "' . $path. '"');
   }
 }
 ?>
-
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/GitlabMR.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/GitlabMR.py`

 * *Files 14% similar despite different names*

```diff
@@ -21,38 +21,40 @@
 A command line interface `lbn-gitlab-mr` is provided, which is the entry
 point used by the `gitlab-mr` jenkins job triggered by the hook.
 The code for the actual hook is located at [1].
 
 Example uses:
 - from MR lhcb/Rec!222
     /ci-test
-    /ci-test lhcb/LHCb@v50r6 gaudi/Gaudi@a729b15e6
     /ci-test --platforms=x86_64+avx2+fma-centos7-gcc8-opt
-    /ci-test --merge
+    /ci-test --branch
+    /ci-test --branch lhcb/LHCb@v50r6 gaudi/Gaudi@a729b15e6
 - from the command line
     lbn-gitlab-mr lhcb/Rec!222
-    lbn-gitlab-mr lhcb/Rec!222 lhcb/LHCb@v50r6 gaudi/Gaudi@a729b15e6
     lbn-gitlab-mr lhcb/Rec!222 --platforms=x86_64+avx2+fma-centos7-gcc8-opt
-    lbn-gitlab-mr lhcb/Rec!222 --merge
+    lbn-gitlab-mr lhcb/Rec!222 --branch
+    lbn-gitlab-mr lhcb/Rec!222 --branch lhcb/LHCb@v50r6 gaudi/Gaudi@a729b15e6
 
 [1]: https://gitlab.cern.ch/lhcb-core/lb-nightly-builds-frontend/blob/711225cddd663ba3622f3ea8f82d010ec5e287f7/lbnighties/ajax.py#L102-129
 
 """  # noqa
 import argparse
-import gitlab
 import json
 import logging
 import os
 import re
-from LbNightlyTools.GitlabUtils import _gitlabServer, _getGitlabProject
+
+import gitlab
+
+from LbNightlyTools.GitlabUtils import _getGitlabProject, _gitlabServer
 
 logger = logging.getLogger(__name__)
 
-TRIGGER = '/ci-test'
-TRIGGER_LINE_RE = r'^\s*{}($|\s+)'.format(TRIGGER)
+TRIGGER = "/ci-test"
+TRIGGER_LINE_RE = r"^\s*{}($|\s+)".format(TRIGGER)
 
 
 class TriggerError(Exception):
     pass
 
 
 class MissingTriggerError(Exception):
@@ -60,275 +62,324 @@
 
 
 def get_hook_parser():
     """Return a parser for arguments received via the hook trigger."""
 
     parser = argparse.ArgumentParser(prog=TRIGGER, add_help=False)
     parser.add_argument(
-        'sources',
-        nargs='*',
-        metavar='source',
-        help=('Non-default merge requests or commits. Examples of valid '
-              'sources: lhcb/LHCb!222, lhcb/LHCb@v50r6, gaudi/Gaudi@a729b15e6 '
-              '(if group is omitted assume group of trigger project).'))
-    parser.add_argument(
-        '--platforms', help='Comma-separated list of platforms.')
+        "sources",
+        nargs="*",
+        metavar="source",
+        help=(
+            "Non-default merge requests or commits. Examples of valid "
+            "sources: lhcb/LHCb!222, lhcb/LHCb@v50r6, gaudi/Gaudi@a729b15e6 "
+            "(if group/project is omitted assume that of trigger project)."
+        ),
+    )
+    parser.add_argument("--platforms", help="Comma-separated list of platforms.")
     parser.add_argument(
-        '--merge',
-        action='store_true',
-        help='Integration test mode (tip of target branch + MRs).')
+        "--build-reference",
+        action="store_true",
+        help="Also launch reference build for integration test mode",
+    )
+    mr_opts_group = parser.add_mutually_exclusive_group()
+    mr_opts_group.add_argument(
+        "--merge",
+        action="store_true",
+        default=True,
+        help="Integration test mode (tip of target branch + MRs).",
+    )
+    mr_opts_group.add_argument(
+        "--branch", action="store_false", dest="merge", help="Branch only test mode"
+    )
     # extra parameters passed to the main job, useful for testing, e.g.
     # --param scripts_version=branch-of-nightlies-jenkins-scripts
     # --param JENKINS_OVERRIDE_PIP_REQUIREMENTS=git+https://gitlab.
     #         cern.ch/lhcb-core/LbNightlyTools.git@some-branch
     parser.add_argument(
-        '--param',
-        dest='params',
-        action='append',
-        default=[],
-        help=argparse.SUPPRESS)
+        "--param", dest="params", action="append", default=[], help=argparse.SUPPRESS
+    )
 
     # Throw on error from parse_args instead of exiting
     def error(message):
-        raise TriggerError(message + '\n\n' + parser.format_help())
+        raise TriggerError(message + "\n\n" + parser.format_help())
 
     parser.error = error
-    return parser
+    return parser, ["sources", "platforms", "merge", "params", "build_reference"]
 
 
 def parse_comment(comment):
     commands = [
-        line.strip() for line in comment.splitlines()
-        if re.match(TRIGGER_LINE_RE, line)
+        line.strip() for line in comment.splitlines() if re.match(TRIGGER_LINE_RE, line)
     ]
     if not commands:
         return None  # trigger likely present, but not alone on a line
     elif len(commands) == 1:
         return commands[0].split()
     else:
-        raise TriggerError('Comment includes multiple triggers')
+        raise TriggerError("Comment includes multiple triggers")
 
 
 def get_hook_args(content):
-    '''
+    """
     Return arguments by parsing the contents of the gitlab hook.
 
     @param content: Contents of gitlab hook
-    '''
+    """
 
-    comment = content['object_attributes']['note']
-    logger.debug('comment is\n{}'.format(comment))
+    comment = content["object_attributes"]["note"]
+    logger.debug("comment is\n{}".format(comment))
     command_args = parse_comment(comment)
     if not command_args:
         return None
     assert command_args[0] == TRIGGER
     # TODO if len(args) == 0 and if this is not the top comment in
     # the discussion, find the last comment in the discussion with
     # /ci-test and take the arguments from there
-    trigger_project = content['merge_request']['target']['path_with_namespace']
-    trigger_group = trigger_project.rsplit('/', 1)[0]
-    trigger_source = '{}!{}'.format(trigger_project,
-                                    content['merge_request']['iid'])
-
-    # assume trigger project group if not given
-    def ensure_group(arg):
-        return ((trigger_group + '/' + arg)
-                if not arg.startswith('-') and '/' not in arg else arg)
+    trigger_project = content["merge_request"]["target"]["path_with_namespace"]
+    trigger_group = trigger_project.rsplit("/", 1)[0]
+    trigger_source = "{}!{}".format(trigger_project, content["merge_request"]["iid"])
+
+    class HelpAction(argparse.Action):
+        def __call__(self, parser, *args, **kwargs):
+            raise TriggerError(parser.format_help())
+
+    parser = get_hook_parser()[0]
+    parser.add_argument(
+        "-h",
+        "--help",
+        nargs=0,
+        action=HelpAction,
+        dest=argparse.SUPPRESS,
+        default=argparse.SUPPRESS,
+        help="show this help message and exit",
+    )
+    args = parser.parse_args(command_args[1:])
+
+    # assume trigger project and group if not given
+    def normalize_source(arg):
+        URL = (
+            r"^https://gitlab\.cern\.ch/(?P<path>.*)/-"
+            r"/merge_requests/(?P<iid>[0-9]+)$"
+        )
+        if arg.startswith("!"):  # !123
+            return trigger_project + arg
+        elif re.match(URL, arg):
+            # https://gitlab.cern.ch/lhcb/LHCb/-/merge_requests/2761
+            m = re.match(URL, arg)
+            return m.group("path") + "!" + m.group("iid")
+        elif "/" not in arg and "!" in arg:  # Rec!123
+            group = trigger_group
+            proj, _ = arg.split("!", 1)
+            if proj.lower() == "gaudi":
+                group = "gaudi"
+            elif proj.lower() == "gaussino":
+                group = "Gaussino"
+            return group + "/" + arg
+        else:
+            return arg
+
+    args.sources = [normalize_source(arg) for arg in args.sources]
 
-    command_args = [ensure_group(arg) for arg in command_args[1:]]
-    args = get_hook_parser().parse_args(command_args)
     # add trigger source as an implicit argument
     args.sources.insert(0, trigger_source)
     return args
 
 
 def get_hook_trigger(content):
-    '''
+    """
     Return the ids of the note and discussion where the hook was triggered.
 
     @param content: Contents of gitlab hook
-    '''
+    """
     return dict(
-        project_id=content['project']['id'],
-        merge_request_iid=content['merge_request']['iid'],
-        discussion_id=content['object_attributes']['discussion_id'],
-        note_id=content['object_attributes']['id'],
+        project_id=content["project"]["id"],
+        merge_request_iid=content["merge_request"]["iid"],
+        discussion_id=content["object_attributes"]["discussion_id"],
+        note_id=content["object_attributes"]["id"],
     )
 
 
 def gitlab_note_discussion(trigger_source):
-    '''
+    """
     Return GitLab note and discussion objects for the hook.
 
     @param trigger_source: IDs of project, mr, note and discussion.
-    '''
+    """
     gitlab_server = _gitlabServer()
-    project = gitlab_server.projects.get(trigger_source['project_id'])
-    mr = project.mergerequests.get(trigger_source['merge_request_iid'])
-    return (mr.notes.get(trigger_source['note_id']),
-            mr.discussions.get(trigger_source['discussion_id']))
+    project = gitlab_server.projects.get(trigger_source["project_id"])
+    mr = project.mergerequests.get(trigger_source["merge_request_iid"])
+    return (
+        mr.notes.get(trigger_source["note_id"]),
+        mr.discussions.get(trigger_source["discussion_id"]),
+    )
 
 
 def gitlab_award_emoji(obj, name):
-    '''Award an emoji without failing if it exists already.'''
+    """Award an emoji without failing if it exists already."""
     try:
-        obj.awardemojis.create({'name': name})
+        obj.awardemojis.create({"name": name})
     except gitlab.GitlabCreateError:
         pass
 
 
 def invalid_source_reason(source, merge):
     """Return why source is invalid or None."""
-    path_re = r'[A-Za-z0-9_\-.]+'
-    project_re = r'({path}/)+({path})'.format(path=path_re)
-    source_re = (
-        r'^(?P<project>{project})(!(?P<mr>[0-9]+)|@(?P<ref>.+))$'.format(
-            project=project_re))
+    path_re = r"[A-Za-z0-9_\-.]+"
+    project_re = r"({path}/)+({path})".format(path=path_re)
+    source_re = r"^(?P<project>{project})(!(?P<mr>[0-9]+)|@(?P<ref>.+))$".format(
+        project=project_re
+    )
     m = re.match(source_re, source)
     if not m:
         return '"{}" is not a valid source specification'.format(source)
     try:
-        project = _getGitlabProject(m.group('project'))
-        if m.group('mr'):
-            mr = project.mergerequests.get(m.group('mr'))
+        project = _getGitlabProject(m.group("project"))
+        if m.group("mr"):
+            mr = project.mergerequests.get(m.group("mr"))
             if merge:
-                if mr.attributes['state'] == 'merged':
+                if mr.attributes["state"] == "merged":
                     return '"{}" is already merged'.format(source)
-                if mr.attributes['merge_status'] == 'cannot_be_merged':
+                if mr.attributes["merge_status"] == "cannot_be_merged":
                     return '"{}" cannot be merged'.format(source)
-        elif m.group('ref'):
-            project.repository_tree(ref=m.group('ref'))
+        elif m.group("ref"):
+            project.repository_tree(ref=m.group("ref"))
     except gitlab.GitlabGetError as e:
         if e.response_code == 404:
             return '"{}" does not exist'.format(source)
         raise
     return None
 
 
 def get_main_job_config(command_args=None):
-    '''
+    """
     Parse options from command line and hook content (if available).
     Returns a tuple (json configuration, extra parameters, output file).
 
     @param command_args: Optional arguments to use instead of sys.argv.
-    '''
-    hook_parser = get_hook_parser()
-    hook_params = {a.dest for a in hook_parser._actions}
+    """
+    hook_parser, hook_params = get_hook_parser()
     parser = argparse.ArgumentParser(
         parents=[hook_parser],
-        description='define a main job from a {} hook'.format(TRIGGER))
-    parser.add_argument(
-        '--debug', action='store_true', help='debugging output')
+        description="define a main job from a {} hook".format(TRIGGER),
+    )
+    parser.add_argument("--debug", action="store_true", help="debugging output")
     parser.add_argument(
-        '--output', default='gitlab-slots-build.txt', help='output file name')
+        "--output", default="gitlab-slots-build.txt", help="output file name"
+    )
     parser.add_argument(
-        '--feedback',
-        action='store_true',
-        help='send feedback to GitLab discussion if working on a hook')
+        "--feedback",
+        action="store_true",
+        help="send feedback to GitLab discussion if working on a hook",
+    )
     parser.add_argument(
-        '--hook-var',
-        help='name of environment variable containing hook content. '
-        'Command line arguments take precedence')
+        "--hook-var",
+        help="name of environment variable containing hook content. "
+        "Command line arguments take precedence",
+    )
     args = parser.parse_args(command_args)
 
     logging.basicConfig(level=logging.DEBUG if args.debug else logging.INFO)
 
-    logger.debug('args: {}'.format(args))
+    logger.debug("args: {}".format(args))
 
     log_error = logger.error
     if args.hook_var:
         if args.sources:
-            parser.error('cannot give both sources and --hook-var')
+            parser.error("cannot give both sources and --hook-var")
         if args.hook_var not in os.environ:
-            parser.error('environment variable {} not defined'.format(
-                args.hook_var))
+            parser.error("environment variable {} not defined".format(args.hook_var))
 
         content = json.loads(os.environ[args.hook_var])
-        logger.debug('hook content is\n{}'.format(
-            json.dumps(content, indent=2)))
+        logger.debug("hook content is\n{}".format(json.dumps(content, indent=2)))
 
         # find the note and discussion ids for feedback (from here and
         # subsequent jobs)
         hook_trigger = get_hook_trigger(content)
 
         if args.feedback:
             note, discussion = gitlab_note_discussion(hook_trigger)
             # acknowledge the hook was received
-            gitlab_award_emoji(note, 'robot')
+            gitlab_award_emoji(note, "robot")
 
             def log_error(message):
                 logger.error(message)
-                gitlab_award_emoji(note, 'rotating_light')
-                discussion.notes.create({
-                    'body':
-                    'Action failed with\n```\n{}\n```'.format(message)
-                })
+                gitlab_award_emoji(note, "rotating_light")
+                discussion.notes.create(
+                    {"body": "Action failed with\n```\n{}\n```".format(message)}
+                )
 
         try:
             hook_args = get_hook_args(content)
         except TriggerError as e:
-            log_error(e.message)
+            log_error(str(e))
             raise
 
         if hook_args is None:
-            logger.info('No trigger found in comment')
-            raise MissingTriggerError('No trigger found in comment')
+            logger.info("No trigger found in comment")
+            raise MissingTriggerError("No trigger found in comment")
         else:
-            logger.info('Found trigger with arguments {}'.format(hook_args))
+            logger.info("Found trigger with arguments {}".format(hook_args))
 
         # set arguments from hook whenever they were not given on the
         # command line
+        # But always overwrite the merge option based on what's in the hook
         for p in hook_params:
             arg = getattr(hook_args, p)
-            if arg and not getattr(args, p):
+            if (arg and not getattr(args, p)) or p == "merge":
                 setattr(args, p, arg)
     elif not args.sources:
-        parser.error('specify at least one source or --hook-var')
+        parser.error("specify at least one source or --hook-var")
+
+    invalid = [
+        _f for _f in [invalid_source_reason(s, args.merge) for s in args.sources] if _f
+    ]
+    if invalid:
+        msg = "\n".join(invalid)
+        log_error(msg)
+        raise TriggerError(msg)
 
     if not args.merge:
-        invalid = filter(
-            None, [invalid_source_reason(s, args.merge) for s in args.sources])
-        if invalid:
-            msg = '\n'.join(invalid)
-            log_error(msg)
-            raise TriggerError(msg)
-        unique_projects = set(re.split('!|@', s)[0] for s in args.sources)
+        unique_projects = set(re.split("!|@", s)[0] for s in args.sources)
 
         if len(unique_projects) < len(args.sources):
-            msg = 'Some projects given multiple times: {}'.format(args.sources)
+            msg = "Some projects given multiple times: {}".format(args.sources)
             log_error(msg)
             raise TriggerError(msg)
 
+    # for branch only mode we always build a reference
+    if not args.merge:
+        args.build_reference = True
+
     # pass the hook arguments plus some other selected configuration
     config = {p: getattr(args, p) for p in hook_params}
     if args.hook_var:
-        config['trigger'] = hook_trigger
-    params = config.pop('params')
+        config["trigger"] = hook_trigger
+    params = config.pop("params")
 
     return config, params, args.output
 
 
 def main():
     try:
         config, params, output_fn = get_main_job_config()
     except MissingTriggerError:
         # we didn't find a proper trigger, so don't do anything
         # except the hook acknowledgement emoji
-        logger.info('Missing trigger: not triggering main job')
+        logger.info("Missing trigger: not triggering main job")
         return 0
     except TriggerError:
         # error already logged, just return
-        logger.info('Error in trigger: not triggering main job')
+        logger.info("Error in trigger: not triggering main job")
         return 0
 
-    logger.info('json job configuration:\n{}'.format(
-        json.dumps(config, indent=2)))
+    logger.info("json job configuration:\n{}".format(json.dumps(config, indent=2)))
 
     # Write the file which defines variables for the main job.
     # MR_TOKEN: JSON containing the important configuration (i.e. hook
     #           arguments and id of discussion for feedback).
-    with open(output_fn, 'w') as f:
+    with open(output_fn, "w") as f:
         for param in params:
-            f.write(param + '\n')
-        f.write('MR_TOKEN=' + json.dumps(config) + '\n')
+            f.write(param + "\n")
+        f.write("MR_TOKEN=" + json.dumps(config) + "\n")
 
     return 0
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/_entry_points.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/_entry_points.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,65 +1,79 @@
+from __future__ import print_function
+
 ###############################################################################
 # (c) Copyright 2013-2020 CERN                                                #
 #                                                                             #
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
+from future import standard_library
+
+standard_library.install_aliases()
+from builtins import object
+
+
 def ansi2html():
-    '''
+    """
     Script to convert a console output to html.
-    '''
+    """
     import os
-    from LbNightlyTools.HTMLUtils import convertFile
     from optparse import OptionParser
 
-    parser = OptionParser(usage='%prog [options] <input> <output>')
+    from LbNightlyTools.HTMLUtils import convertFile
+
+    parser = OptionParser(usage="%prog [options] <input> <output>")
 
     try:
         opts, (input, output) = parser.parse_args()
     except ValueError:
-        parser.error('wrong number of arguments')
+        parser.error("wrong number of arguments")
 
     return convertFile(input, output)
 
 
 def build_log_to_html():
-    '''
+    """
     Collect the build logs produced by lbn-wrapcmd and write the content grouped by
     subdir and target.
-    '''
+    """
     from LbNightlyTools.Scripts.CollectBuildLogs import LogToHTML as Script
+
     return Script().run()
 
 
 def check_preconditions():
     from LbNightlyTools.CheckSlotPreconditions import Script
+
     return Script().run()
 
 
 def collect_build_logs():
-    '''
+    """
     Collect the build logs produced by lbn-wrapcmd and write the content grouped by
     subdir and target.
-    '''
+    """
     from LbNightlyTools.Scripts.CollectBuildLogs import Script
+
     return Script().run()
 
 
 def enabled_slots():
     from LbNightlyTools.Scripts.EnabledSlots import Script
+
     return Script().run()
 
 
 def generate_compatspec():
     from LbRPMTools.LHCbCompatSpecBuilder import Script
+
     return Script().run()
 
 
 def generate_do0spec():
     #
     # Little tool to generate -do0 RPM spec while we have a problem in the RPM generation.
     #
@@ -69,442 +83,482 @@
     #
     # You have have a lits of entries like: LCG_79_yoda_1.3.1_x86_64_slc6_gcc49_dbg
     # N.b. the RPM version ahs been removed !
     #
     # On each of them run:
     # lbn-generate-do0spec <name> && rpmbuild -bb tmp.spec
 
-    import sys
     import logging
+    import sys
 
     # First checking args
     if len(sys.argv) == 1:
         logging.error("Please specify RPM name")
         sys.exit(2)
 
     rpmname = sys.argv[1]
 
     if rpmname.find("dbg") == -1:
-        logging.error(
-            "RPM is not in dbg config, cannot create meta for do0 version")
+        logging.error("RPM is not in dbg config, cannot create meta for do0 version")
         sys.exit(2)
 
     do0name = rpmname.replace("dbg", "do0")
-    logging.warning(
-        "Generating tmp.spec for %s depending on %s" % (do0name, rpmname))
+    logging.warning("Generating tmp.spec for %s depending on %s" % (do0name, rpmname))
 
     # Now generating the spec
     from subprocess import call
-    call(
-        ["lbn-generate-metaspec", "-o", "tmp.spec", do0name, "1.0.0", rpmname])
+
+    call(["lbn-generate-metaspec", "-o", "tmp.spec", do0name, "1.0.0", rpmname])
 
 
 def generate_extspec():
     from LbRPMTools.LHCbExternalsSpecBuilder import Script
+
     return Script().run()
 
 
 def generate_genericspec():
     from LbRPMTools.LHCbGenericSpecBuilder import GenericScript
+
     return GenericScript().run()
 
 
 def generate_lbscriptsspec():
     from LbRPMTools.LHCbLbScriptsSpecBuilder import Script
+
     return Script().run()
 
 
 def generate_metaspec():
     from LbRPMTools.LHCbMetaSpecBuilder import MetaScript
+
     return MetaScript().run()
 
 
 def generate_spec():
     from LbRPMTools.LHCbRPMSpecBuilder import Script
+
     return Script().run()
 
 
 def gen_release_config():
     from LbNightlyTools.Scripts.Release import ConfigGenerator as Script
+
     return Script().run()
 
 
 def index():
     from LbNightlyTools.Scripts.Index import Script
+
     return Script().run()
 
 
 def install():
     from LbNightlyTools.Scripts.Install import Script
+
     return Script().run()
 
 
 def list_platforms():
-    '''
+    """
     Simple script to extract the list of requested platforms from the slot
     configuration file.
-    '''
-    __author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+    """
+    __author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
 
     import os
     import sys
+
     from LbNightlyTools.Configuration import findSlot
 
-    usage = 'Usage: %s configuration_file' % os.path.basename(sys.argv[0])
+    usage = "Usage: %s configuration_file" % os.path.basename(sys.argv[0])
 
-    if '-h' in sys.argv or '--help' in sys.argv:
-        print usage
+    if "-h" in sys.argv or "--help" in sys.argv:
+        print(usage)
         sys.exit(0)
 
     if len(sys.argv) != 2:
-        print >> sys.stderr, usage
+        print(usage, file=sys.stderr)
         sys.exit(1)
 
-    print ' '.join(findSlot(sys.argv[1]).platforms)
+    print(" ".join(findSlot(sys.argv[1]).platforms))
 
 
 def preconditions():
     from LbNightlyTools.Scripts.Preconditions import Script
+
     return Script().run()
 
 
 def release_poll():
     from LbNightlyTools.Scripts.Release import Poll as Script
+
     return Script().run()
 
 
 def release_trigger():
     from LbNightlyTools.Scripts.Release import Starter as Script
+
     return Script().run()
 
 
 def reschedule_tests():
-    '''
+    """
     Query the results database to find missing tests and produce the
     expected_builds.json file needed to re-schedule them.
-    '''
-    from LbNightlyTools import Dashboard
-    from LbNightlyTools.Scripts.Common import addDashboardOptions
-
-    from datetime import date
-    import time
+    """
     import json
+    import time
+    from datetime import date
 
     # Parse command line
     from optparse import OptionParser
+
+    from LbNightlyTools import Dashboard
+    from LbNightlyTools.Scripts.Common import addDashboardOptions
+
     parser = OptionParser(description=__doc__)
 
     parser.add_option(
-        '--day',
-        action='store',
-        help='day to check as yyyy-mm-dd (default: today)',
-        default=str(date.today()))
+        "--day",
+        action="store",
+        help="day to check as yyyy-mm-dd (default: today)",
+        default=str(date.today()),
+    )
     parser.add_option(
-        '-o',
-        '--output',
-        action='store',
-        help='output file name [default: standard output]')
+        "-o",
+        "--output",
+        action="store",
+        help="output file name [default: standard output]",
+    )
     addDashboardOptions(parser)
 
     opts, args = parser.parse_args()
 
     if args:
-        parser.error('unexpected arguments')
+        parser.error("unexpected arguments")
 
     # Initialize db connection
     dashboard = Dashboard(
         credentials=None,
         flavour=opts.flavour,
         server=opts.db_url,
-        dbname=opts.db_name or Dashboard.dbName(opts.flavour))
+        dbname=opts.db_name or Dashboard.dbName(opts.flavour),
+    )
 
     # Prepare data
-    day_start = time.mktime(time.strptime(opts.day, '%Y-%m-%d'))
+    day_start = time.mktime(time.strptime(opts.day, "%Y-%m-%d"))
     expected_builds = []
 
     def expected_build_info(slot, project, platform, timestamp):
         from os.path import join
+
         version = None
-        for p in slot['projects']:
-            if project == p['name'] and not p.get('no_test'):
-                version = p['version']
+        for p in slot["projects"]:
+            if project == p["name"] and not p.get("no_test"):
+                version = p["version"]
                 break
         else:
             # cannot find the project in the slot or the project is not tested
             return None
-        build_id = str(slot['build_id'])
+        build_id = str(slot["build_id"])
         filename = join(
-            'artifacts', opts.flavour, slot['slot'], build_id, '.'.join(
-                [project, version, slot['slot'], build_id, platform, 'zip']))
+            "artifacts",
+            opts.flavour,
+            slot["slot"],
+            build_id,
+            ".".join([project, version, slot["slot"], build_id, platform, "zip"]),
+        )
         return [
-            filename, slot['slot'], slot['build_id'], project, platform,
+            filename,
+            slot["slot"],
+            slot["build_id"],
+            project,
+            platform,
             timestamp,
-            platform.split('-')[1]
+            platform.split("-")[1],
         ]
 
     for row in dashboard.db.iterview(
-            'summaries/byDay', batch=100, key=opts.day, include_docs=True):
-        slot_name = row.doc['slot']
-        build_id = row.doc['build_id']
+        "summaries/byDay", batch=100, key=opts.day, include_docs=True
+    ):
+        slot_name = row.doc["slot"]
+        build_id = row.doc["build_id"]
 
-        for platform in row.doc['config']['platforms']:
+        for platform in row.doc["config"]["platforms"]:
             builds = set()
             tests = set()
             started = day_start
-            if platform in row.doc['builds']:
+            if platform in row.doc["builds"]:
                 builds.update(
-                    p for p in row.doc['builds'][platform] if p != 'info'
-                    and 'completed' in row.doc['builds'][platform][p])
-                started = row.doc['builds'][platform]['info']['started']
-            if platform in row.doc['tests']:
-                tests.update(p for p in row.doc['tests'][platform]
-                             if 'completed' in row.doc['builds'][platform][p])
+                    p
+                    for p in row.doc["builds"][platform]
+                    if p != "info" and "completed" in row.doc["builds"][platform][p]
+                )
+                started = row.doc["builds"][platform]["info"]["started"]
+            if platform in row.doc["tests"]:
+                tests.update(
+                    p
+                    for p in row.doc["tests"][platform]
+                    if "completed" in row.doc["builds"][platform][p]
+                )
             expected_builds.extend(
-                expected_build_info(row.doc['config'], project, platform,
-                                    started) for project in builds - tests)
+                expected_build_info(row.doc["config"], project, platform, started)
+                for project in builds - tests
+            )
 
     if opts.output:
         import codecs
-        json.dump(
-            expected_builds, codecs.open(opts.output, 'w', 'utf-8'), indent=2)
+
+        json.dump(expected_builds, codecs.open(opts.output, "w", "utf-8"), indent=2)
     else:
-        print json.dumps(expected_builds, indent=2)
+        print(json.dumps(expected_builds, indent=2))
 
 
 def rpm():
     from LbRPMTools.PackageSlot import Script
+
     return Script().run()
 
 
 def rpm_validator():
-    '''
+    """
     Command line client that interfaces to the YUMChecker class
 
     :author: Stefan-Gabriel Chitic
-    '''
+    """
+    import json
     import logging
     import optparse
     import os
     import sys
-    import traceback
     import tempfile
-    import json
+    import traceback
+
     from lbinstall.YumChecker import YumChecker
 
     # Class for known install exceptions
     ###############################################################################
 
     class LHCbRPMReleaseConsistencyException(Exception):
-        """ Custom exception for lb-install
+        """Custom exception for lb-install
 
         :param msg: the exception message
         """
 
         def __init__(self, msg):
-            """ Constructor for the exception """
+            """Constructor for the exception"""
             # super( LHCbRPMReleaseConsistencyException, self).__init__(msg)
             Exception.__init__(self, msg)
 
     # Classes and method for command line parsing
     ###############################################################################
 
     class LHCbRPMReleaseConsistencyOptionParser(optparse.OptionParser):
-        """ Custom OptionParser to intercept the errors and rethrow
-        them as LHCbRPMReleaseConsistencyExceptions """
+        """Custom OptionParser to intercept the errors and rethrow
+        them as LHCbRPMReleaseConsistencyExceptions"""
 
         def error(self, msg):
             """
             Arguments parsing error message exception handler
 
             :param msg: the message of the exception
             :return: Raises LHCbRPMReleaseConsistencyException with the exception message
             """
             raise LHCbRPMReleaseConsistencyException(
-                "Error parsing arguments: " + str(msg))
+                "Error parsing arguments: " + str(msg)
+            )
 
         def exit(self, status=0, msg=None):
             """
             Arguments parsing error message exception handler
 
             :param status: the status of the application
             :param msg: the message of the exception
             :return: Raises LHCbRPMReleaseConsistencyException with the exception message
             """
             raise LHCbRPMReleaseConsistencyException(
-                "Error parsing arguments: " + str(msg))
+                "Error parsing arguments: " + str(msg)
+            )
 
     class LHCbRPMReleaseConsistencyClient(object):
-        """ Main class for the tool """
+        """Main class for the tool"""
 
-        def __init__(self,
-                     configType,
-                     arguments=None,
-                     dry_run=False,
-                     prog=" LHCbRPMReleaseConsistency"):
-            """ Common setup for both clients """
+        def __init__(
+            self,
+            configType,
+            arguments=None,
+            dry_run=False,
+            prog=" LHCbRPMReleaseConsistency",
+        ):
+            """Common setup for both clients"""
             self.configType = configType
             self.log = logging.getLogger(__name__)
             self.arguments = arguments
             self.checker = None
             self.prog = prog
 
-            parser = LHCbRPMReleaseConsistencyOptionParser(
-                usage=usage(self.prog))
+            parser = LHCbRPMReleaseConsistencyOptionParser(usage=usage(self.prog))
             parser.add_option(
-                '-d',
-                '--debug',
+                "-d",
+                "--debug",
                 dest="debug",
                 default=False,
                 action="store_true",
-                help="Show debug information")
+                help="Show debug information",
+            )
             parser.add_option(
-                '--info',
+                "--info",
                 dest="info",
                 default=False,
                 action="store_true",
-                help="Show logging messages with level INFO")
+                help="Show logging messages with level INFO",
+            )
             parser.add_option(
-                '--build-folder',
+                "--build-folder",
                 dest="buildfolder",
-                default='/data/archive/artifacts/release/'
-                'lhcb-release/',
+                default="/data/archive/artifacts/release/" "lhcb-release/",
                 action="store",
-                help="Add custom folder for builds")
+                help="Add custom folder for builds",
+            )
             parser.add_option(
-                '--repo-url',
+                "--repo-url",
                 dest="repourl",
-                default='https://cern.ch/lhcb-nightlies-artifacts/'
-                'release/lhcb-release/',
+                default="https://cern.ch/lhcb-nightlies-artifacts/"
+                "release/lhcb-release/",
                 action="store",
-                help="Add custom repo url")
+                help="Add custom repo url",
+            )
             parser.add_option(
-                '--no-details',
+                "--no-details",
                 dest="nodetails",
                 default=False,
                 action="store_true",
-                help="Displays only the name of"
-                " the missing packages.")
+                help="Displays only the name of" " the missing packages.",
+            )
             self.parser = parser
 
         def main(self):
-            """ Main method for the ancestor:
+            """Main method for the ancestor:
             call parse and run in sequence
 
             :returns: the return code of the call
             """
             rc = 0
             try:
                 opts, args = self.parser.parse_args(self.arguments)
                 # Checkint the siteroot and URL
                 # to choose the siteroot
                 self.siteroot = tempfile.gettempdir()
 
                 # Now setting the logging depending on debug mode...
                 if opts.debug or opts.info:
-                    logging.basicConfig(format="%(levelname)-8s: "
-                                        "%(funcName)-25s - %(message)s")
+                    logging.basicConfig(
+                        format="%(levelname)-8s: " "%(funcName)-25s - %(message)s"
+                    )
                     if opts.info:
                         logging.getLogger().setLevel(logging.INFO)
                     else:
                         logging.getLogger().setLevel(logging.DEBUG)
 
                 self.buildfolder = opts.buildfolder
                 self.repourl = opts.repourl
 
                 # Getting the function to be invoked
                 self.run(opts, args)
 
             except LHCbRPMReleaseConsistencyException as lie:
-                print >> sys.stderr, "ERROR: " + str(lie)
+                print("ERROR: " + str(lie), file=sys.stderr)
                 self.parser.print_help()
                 rc = 1
             except:
-                print >> sys.stderr, "Exception in lb-install:"
-                print >> sys.stderr, '-' * 60
+                print("Exception in lb-install:", file=sys.stderr)
+                print("-" * 60, file=sys.stderr)
                 traceback.print_exc(file=sys.stderr)
-                print >> sys.stderr, '-' * 60
+                print("-" * 60, file=sys.stderr)
                 rc = 1
             return rc
 
         def run(self, opts, args):
-            """ Main method for the command
+            """Main method for the command
 
             :param opts: The option list
             :param args: The arguments list
             """
             # Parsing first argument to check the mode
 
             # Setting up repo url customization
             # By default repourl is none, in which case the hardcoded default
             # is used skipConfig allows returning a config with the LHCb
             # repositories
 
             from lbinstall.LHCbConfig import Config
+
             conf = Config(self.siteroot)
             local_url = "%s" % (self.repourl)
             local_folder = "%s" % (self.buildfolder)
             conf.repos["local_repo"] = {"url": local_url}
-            rpm_list = [
-                f for f in os.listdir(local_folder) if f.endswith('.rpm')
-            ]
+            rpm_list = [f for f in os.listdir(local_folder) if f.endswith(".rpm")]
 
             self.checker = YumChecker(
                 siteroot=self.siteroot,
                 config=conf,
                 strict=True,
-                simple_output=opts.nodetails)
+                simple_output=opts.nodetails,
+            )
             platform = args[0]
             packages = []
-            tmp_platform = platform.replace('-', '_')
+            tmp_platform = platform.replace("-", "_")
             for rpm in rpm_list:
                 if tmp_platform not in rpm:
                     continue
-                tmp = rpm.split('-')
+                tmp = rpm.split("-")
                 if len(tmp) > 0:
                     name = tmp[0]
-                    name = name.replace('+', '\+')
+                    name = name.replace("+", "\+")
                 else:
                     raise Exception("No packages found")
                 if len(tmp) > 1:
                     version = tmp[1]
-                    vaersion = version.split('.')[0]
+                    vaersion = version.split(".")[0]
                 else:
                     version = None
                 if len(tmp) > 2:
                     release = tmp[2]
-                    release = release.split('.')[0]
+                    release = release.split(".")[0]
                 else:
                     release = None
 
                 packages.extend(self.checker.queryPackages(name, None, None))
             for rpmname, version, release in packages:
-                self.log.info("Checking consistency for: %s %s %s" %
-                              (rpmname, version, release))
-            json_file = os.path.join(local_folder, 'build', platform,
-                                     'RPMs_report.json')
-            res = self.checker.getMissingPackgesFromTuples(
-                packages, force_local=True)
+                self.log.info(
+                    "Checking consistency for: %s %s %s" % (rpmname, version, release)
+                )
+            json_file = os.path.join(
+                local_folder, "build", platform, "RPMs_report.json"
+            )
+            res = self.checker.getMissingPackgesFromTuples(packages, force_local=True)
             new_data = {}
             for missing in res:
-                req = missing['dependency']
+                req = missing["dependency"]
                 req_name = "%s.%s.%s" % (req.name, req.version, req.release)
-                p = missing['package']
+                p = missing["package"]
                 p_name = "%s.%s.%s" % (p.name, p.version, p.release)
                 if not new_data.get(p_name, None):
                     new_data[p_name] = []
                 new_data[p_name].append(req_name)
             if not os.path.isdir(os.path.dirname(json_file)):
                 os.makedirs(os.path.dirname(json_file))
-            with open(json_file, 'w') as outfile:
-                new_data = {'missing_dependencies': new_data}
+            with open(json_file, "w") as outfile:
+                new_data = {"missing_dependencies": new_data}
                 json.dump(new_data, outfile)
 
     ###############################################################################
     def usage(cmd):
-        """ Prints out how to use the script...
+        """Prints out how to use the script...
 
         :param cmd: the command executed
         """
         cmd = os.path.basename(cmd)
         return """\n%(cmd)s - '
 
     It can be used in the following way:
@@ -528,161 +582,109 @@
         logging.getLogger().setLevel(logging.WARNING)
         return LHCbRPMReleaseConsistencyClient(configType, prog=prog).main()
 
     # Main just chooses the client and starts it
     return LHCbRPMReleaseConsistency()
 
 
-def slots_by_deployment():
-    import sys
-    import logging
-    from LbNightlyTools.Scripts.Common import PlainScript
-    from LbNightlyTools.Configuration import loadConfig
-
-    CONF_ZIP_URL = ('https://gitlab.cern.ch/lhcb-core/LHCbNightlyConf/'
-                    'repository/archive.zip?ref={0}')
-
-    def getSlotsFromGit(branch='master'):
-        '''
-        Helper to get the list of slots defined on the repository.
-        '''
-        from LbNightlyTools.Utils import TemporaryDir
-        from urllib import urlretrieve
-        from zipfile import ZipFile
-        import os
-        with TemporaryDir(chdir=True):
-            url = CONF_ZIP_URL.format(branch)
-            logging.debug('getting config files from %s', url)
-            urlretrieve(url, 'config.zip')
-            logging.debug('unpacking')
-            z = ZipFile('config.zip')
-            z.extractall()
-            return loadConfig(z.namelist()[0])
-
-    class Script(PlainScript):
-        '''
-        Simple script to get the list of slots by deployment key.
-        '''
-        __usage__ = '%prog [options] deployment_type ...'
-
-        def defineOpts(self):
-            '''
-            Prepare the option parser.
-            '''
-            self.parser.add_option(
-                '--branch',
-                help='branch of the configuration to use '
-                '[default: %default]')
-            self.parser.add_option(
-                '--configdir',
-                help='use configuration from the given '
-                'directory instead of from gitlab')
-            self.parser.set_defaults(branch='master')
-
-        def main(self):
-            deployments = set(map(str.lower, self.args))
-            if not deployments:
-                self.parser.error(
-                    'you must specify at least one deployment type')
-            slots = (loadConfig(self.options.configdir)
-                     if self.options.configdir else getSlotsFromGit(
-                         self.options.branch))
-            print('\n'.join(
-                name for name, slot in sorted(slots.items()) if slot.enabled
-                and deployments.intersection(map(str.lower, slot.deployment))))
-
-    return Script().run()
-
-
 def test_poll():
     from LbNightlyTools.Scripts.Test import Poll as Script
+
     return Script().run()
 
 
 def lbq_builddone():
-    '''
+    """
     Send the message that a build for a project has been done
-    '''
-    __author__ = 'Ben Couturier <ben.couturier@cern.ch>'
+    """
+    __author__ = "Ben Couturier <ben.couturier@cern.ch>"
 
     import sys
+
     import LbMsg.BuildMsg
+
     from LbNightlyTools.Scripts.Common import PlainScript
 
     class Script(PlainScript):
-        '''
+        """
         Sends the message that a build has been done
-        '''
-        __usage__ = '%prog <slot> <project> <config> <buildId>'
-        __version__ = ''
+        """
+
+        __usage__ = "%prog <slot> <project> <config> <buildId>"
+        __version__ = ""
 
         def main(self):
-            '''
+            """
             Main function of the script.
-            '''
+            """
             # Checking the arguments
             if len(self.args) != 4:
-                self.log.error(
-                    'Please specify <slot> <project> <config> <buildId>')
+                self.log.error("Please specify <slot> <project> <config> <buildId>")
                 exit(1)
 
             slot = self.args[0]
             project = self.args[1]
             config = self.args[2]
             buildId = self.args[3]
 
             msg = LbMsg.BuildMsg.NightliesMessenger()
             msg.sendBuildDone(slot, project, config, buildId)
 
     return Script().run()
 
 
 def lbq_buildnotif():
-    '''
+    """
     Receive messages that a build for a project has been done
-    '''
-    __author__ = 'Ben Couturier <ben.couturier@cern.ch>'
+    """
+    __author__ = "Ben Couturier <ben.couturier@cern.ch>"
 
     import sys
+
     import LbMsg.BuildMsg
+
     from LbNightlyTools.Scripts.Common import PlainScript
 
     class Script(PlainScript):
-        '''
+        """
         Sends the message that a build has been done
-        '''
-        __usage__ = '%prog <slot> <project> <config> <buildId>'
-        __version__ = ''
+        """
+
+        __usage__ = "%prog <slot> <project> <config> <buildId>"
+        __version__ = ""
 
         def defineOpts(self):
-            '''
+            """
             Options specific to this script.
-            '''
+            """
             self.parser.add_option(
-                '-q',
-                '--queue',
+                "-q",
+                "--queue",
                 default=None,
-                help='Name of the (persistent) queue to store the messages')
+                help="Name of the (persistent) queue to store the messages",
+            )
             self.parser.add_option(
-                '-b',
-                '--bindings',
+                "-b",
+                "--bindings",
                 default=None,
-                help='Message bindings for this channel')
+                help="Message bindings for this channel",
+            )
 
             self.parser.add_option(
-                '-c',
-                '--consume',
+                "-c",
+                "--consume",
                 action="store_true",
                 default=False,
-                help='Wait and loop on all messages coming from the server')
+                help="Wait and loop on all messages coming from the server",
+            )
 
         def main(self):
-            '''
+            """
             Main function of the script.
-            '''
+            """
 
             queueName = None
             if self.options.queue:
                 queueName = self.options.queue
 
             binds = None
             if self.options.bindings:
@@ -702,153 +704,177 @@
                     )
                 msg.getBuildsDone(queueName, binds)
 
     return Script().run()
 
 
 def lbq_getteststorun():
-    '''
+    """
     Request for a periodic test to be run
-    '''
-    __author__ = 'Ben Couturier <ben.couturier@cern.ch>'
+    """
+    __author__ = "Ben Couturier <ben.couturier@cern.ch>"
 
     import sys
+
     import LbMsg.TestMsg
+    from lbmessaging.exchanges.Common import check_channel, get_connection
+    from lbmessaging.exchanges.PeriodicTestsExchange import PeriodicTestsExchange
+
     from LbNightlyTools.Scripts.Common import PlainScript
     from LbNightlyTools.Utils import JenkinsTest
-    from lbmessaging.exchanges.PeriodicTestsExchange import PeriodicTestsExchange
-    from lbmessaging.exchanges.Common import check_channel, get_connection
 
     class Script(PlainScript):
-        '''
+        """
         Sends the message that a build has been done
-        '''
-        __usage__ = '%prog'
-        __version__ = ''
+        """
+
+        __usage__ = "%prog"
+        __version__ = ""
 
         def defineOpts(self):
-            '''Define options.'''
+            """Define options."""
             from LbNightlyTools.Scripts.Common import addBasicOptions
 
             self.parser.add_option(
-                '-q',
-                '--queue',
-                action='store',
+                "-q",
+                "--queue",
+                action="store",
                 default=None,
-                help='Persistent queue in which to store the messages')
+                help="Persistent queue in which to store the messages",
+            )
             self.parser.add_option(
-                '-j',
-                '--jenkins',
-                action='store_true',
+                "-j",
+                "--jenkins",
+                action="store_true",
                 default=False,
-                help='Stote the jobs to run in Jenkins format')
+                help="Stote the jobs to run in Jenkins format",
+            )
             addBasicOptions(self.parser)
 
         def main(self):
-            '''
+            """
             Main function of the script.
-            '''
+            """
 
             queueName = None
             if self.options.queue:
                 queueName = self.options.queue
 
             # Initializing the messenger and getting the actual list
             if queueName == None:
-                raise Exception('No point in just getting messages '
-                                'on a newly created queue. '
-                                'Name the queue with -q')
+                raise Exception(
+                    "No point in just getting messages "
+                    "on a newly created queue. "
+                    "Name the queue with -q"
+                )
 
             channel = check_channel(get_connection())
             broker = PeriodicTestsExchange(channel)
             testsToRun = broker.get_tests_to_run(queueName)
 
             # Printing out or creating out files
             format = "test-params-{0}.txt"
             idx = 0
 
             for testToRun in testsToRun:
                 # Just printing out CSV by default
                 if not self.options.jenkins:
                     # In this case the callback just prints the message
-                    print testToRun
+                    print(testToRun)
                 else:
                     # Here we writeout the files for Jenkins
-                    self.log.warning(
-                        "Job %d: %s" % (idx, ", ".join(testToRun.body)))
+                    self.log.warning("Job %d: %s" % (idx, ", ".join(testToRun.body)))
                     jenkins_test = JenkinsTest(
-                        testToRun.body.slot, testToRun.body.build_id,
-                        testToRun.body.project, testToRun.body.platform,
-                        testToRun.body.os_label, testToRun.body.group,
-                        testToRun.body.runner, testToRun.body.env)
-                    with open(format.format(idx), 'w') as paramfile:
+                        testToRun.body.slot,
+                        testToRun.body.build_id,
+                        testToRun.body.project,
+                        testToRun.body.platform,
+                        testToRun.body.os_label,
+                        testToRun.body.group,
+                        testToRun.body.runner,
+                        testToRun.body.env,
+                    )
+                    with open(format.format(idx), "w") as paramfile:
                         paramfile.writelines(jenkins_test.getParameterLines())
-                        paramfile.writelines("tests_node=" +
-                                             testToRun.body.os_label)
+                        paramfile.writelines("tests_node=" + testToRun.body.os_label)
                         self.log.warning(format.format(idx))
                     idx += 1
 
     return Script().run()
 
 
 def lbq_requesttest():
-    '''
+    """
     Request for a periodic test to be run
-    '''
-    __author__ = 'Ben Couturier <ben.couturier@cern.ch>'
+    """
+    __author__ = "Ben Couturier <ben.couturier@cern.ch>"
 
     import sys
+
     import LbMsg.TestMsg
+
     from LbNightlyTools.Scripts.Common import PlainScript
 
     class Script(PlainScript):
-        '''
+        """
         request for a periodic test run to be done
-        '''
-        __usage__ = '%prog <slot> <buildId> <project> <config> <group> <env>'
-        __version__ = ''
+        """
+
+        __usage__ = "%prog <slot> <buildId> <project> <config> <group> <env>"
+        __version__ = ""
 
         def defineOpts(self):
-            '''Define options.'''
+            """Define options."""
             from LbNightlyTools.Scripts.Common import addBasicOptions
 
             self.parser.add_option(
-                '-r',
-                '--runner',
-                action='store',
+                "-r",
+                "--runner",
+                action="store",
                 default="lhcbpr",
-                help='Runner to be used for the periodic tests')
+                help="Runner to be used for the periodic tests",
+            )
             self.parser.add_option(
-                '-l',
-                '--os_label',
-                action='store',
+                "-l",
+                "--os_label",
+                action="store",
                 default="perf",
-                help='OS Label for the test to be run on Jenkins')
+                help="OS Label for the test to be run on Jenkins",
+            )
 
             addBasicOptions(self.parser)
 
         def main(self):
-            '''
+            """
             Main function of the script.
-            '''
+            """
 
             # Checking the arguments
             if len(self.args) != 6:
                 self.log.error(
-                    'Please specify <slot> <buildid> <project> <config> '
-                    '<group> <env>. For example: lbq-requesttest 1467 '
-                    'lhcb-sim09  Gauss x86_64-slc6-gcc49-opt '
-                    '"GAUSS-RADLENGTHSCAN" "lb-run|RadLengthHandler"')
+                    "Please specify <slot> <buildid> <project> <config> "
+                    "<group> <env>. For example: lbq-requesttest 1467 "
+                    "lhcb-sim09  Gauss x86_64-slc6-gcc49-opt "
+                    '"GAUSS-RADLENGTHSCAN" "lb-run|RadLengthHandler"'
+                )
                 exit(1)
 
             slot = self.args[0]
             buildId = self.args[1]
             project = self.args[2]
             config = self.args[3]
             group = self.args[4]
             env = self.args[5]
 
             msg = LbMsg.TestMsg.TestMessenger()
-            msg.requestTest(slot, buildId, project, config, group, env,
-                            self.options.runner, self.options.os_label)
+            msg.requestTest(
+                slot,
+                buildId,
+                project,
+                config,
+                group,
+                env,
+                self.options.runner,
+                self.options.os_label,
+            )
 
     return Script().run()
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Release.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Release.py`

 * *Files 17% similar despite different names*

```diff
@@ -5,530 +5,555 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Generate a basic nightly builds configuration file from a list of projects and
 versions.
-'''
-import LbNightlyTools.Configuration
-import LbNightlyTools.CheckoutMethods
+"""
+from __future__ import print_function
 
-import os
-import json
-import urllib2
+from future import standard_library
+
+standard_library.install_aliases()
 import codecs
+import json
+import os
+import urllib.error
+import urllib.parse
+import urllib.request
 
+import LbNightlyTools.CheckoutMethods
+import LbNightlyTools.Configuration
 from LbNightlyTools.Scripts.Common import PlainScript
 from LbNightlyTools.Utils import Dashboard, JobParams
 
 ERR_EXCEPT = ["distcc\\[", "::error::", "^ *Error *$"]
 WARN_EXCEPT = [
     ".*/boost/.*",
     "^--->> genreflex: WARNING:.*",
     " note:",
     "distcc\\[",
-    ("Warning\\:\\ The\\ tag\\ (use-distcc|no-pyzip|"
-     "LCG\\_NIGHTLIES\\_BUILD|COVERITY|"
-     "use\\-dbcompression)\\ is\\ not\\ used.*"),
+    (
+        "Warning\\:\\ The\\ tag\\ (use-distcc|no-pyzip|"
+        "LCG\\_NIGHTLIES\\_BUILD|COVERITY|"
+        "use\\-dbcompression)\\ is\\ not\\ used.*"
+    ),
     ".*#CMT---.*Warning: Structuring style used.*",
     ".*/Boost/.*warning:.*",
     ".*/ROOT/.*warning:.*",
-    (".*stl_algo.h:[0-9]+: warning: array subscript is above array "
-     "bounds"),
+    (".*stl_algo.h:[0-9]+: warning: array subscript is above array " "bounds"),
     # CMake developer warning.
     # this is to ignore CMake (>=3.15) warning about "project(Project)"
     # missing in the top level CMakeLists.txt
-    r'CMake Warning \(dev\) in CMakeLists\.txt\:',
-    r'This warning is for project developers',
+    r"CMake Warning \(dev\) in CMakeLists\.txt\:",
+    r"This warning is for project developers",
 ]
 
 # FIXME: we need a better way to define the default platforms
-DEFAULT_PLATFORMS = ''
+DEFAULT_PLATFORMS = ""
 
 # get the correct case for projects
 try:
     from LbEnv import fixProjectCase
 
 except ImportError:
     try:
         from LbConfiguration.Project import project_names as PROJECT_NAMES
     except ImportError:
         # if we cannot find the list of names, we use a minimal hardcoded list
         PROJECT_NAMES = [
-            'LHCb', 'DaVinci', 'DecFilesTests', 'MooreOnline', 'LbScripts',
-            'VanDerMeer', 'LHCbDirac', 'LHCbGrid'
+            "LHCb",
+            "DaVinci",
+            "DecFilesTests",
+            "MooreOnline",
+            "LbScripts",
+            "VanDerMeer",
+            "LHCbDirac",
+            "LHCbGrid",
         ]
 
     # convert the names to a a conversion dictionary
     PROJECT_NAMES = dict((name.lower(), name) for name in PROJECT_NAMES)
 
     def fixProjectCase(name):
-        '''
+        """
         Convert a project name to it's canonical case.
 
         >>> fixProjectCase('GAUDI')
         'Gaudi'
         >>> fixProjectCase('davinci')
         'DaVinci'
         >>> fixProjectCase('uNkNoWn')
         'Unknown'
-        '''
+        """
         return PROJECT_NAMES.get(name.lower(), name.capitalize())
 
 
 def toListOfPairs(s):
-    '''
+    """
     Convert a spaces-separated string to a list of pairs.
     Raise ValueError if the list length is not even.
 
     >>> toListOfPairs('a b c d e f')
     [('a', 'b'), ('c', 'd'), ('e', 'f')]
-    '''
+    """
     items = s.split()
     if len(items) % 2:
-        raise ValueError('input must contain even number of entries')
-    return zip(items[::2], items[1::2])
+        raise ValueError("input must contain even number of entries")
+    return list(zip(items[::2], items[1::2]))
 
 
-def genConfig(slot='lhcb-release',
-              build_id=0,
-              projects=None,
-              packages=None,
-              platforms=None,
-              build_tool='cmake'):
-    '''
+def genConfig(
+    slot="lhcb-release",
+    build_id=0,
+    projects=None,
+    packages=None,
+    platforms=None,
+    build_tool="cmake",
+):
+    """
     Return the configuration dictionary.
-    '''
+    """
     config_projects = []
     added = []
-    for proj, vers in (projects or []):
+    for proj, vers in projects or []:
         proj = fixProjectCase(proj)
         if proj in added:
-            raise ValueError('project %s repeated: each project can '
-                             'appear only once' % proj)
-        project = {
-            'name': proj,
-            'version': vers,
-            'checkout_opts': {
-                'export': True
-            }
-        }
+            raise ValueError(
+                "project %s repeated: each project can " "appear only once" % proj
+            )
+        project = {"name": proj, "version": vers, "checkout_opts": {"export": True}}
+        # LCG might be in the list, but just as a hint
+        if proj.lower() == "lcg":
+            project["disabled"] = True
 
         added.append(proj)
 
         # look for a project-specific checkout method
         if hasattr(LbNightlyTools.CheckoutMethods, proj.lower()):
-            project['checkout'] = proj.lower()
+            project["checkout"] = proj.lower()
 
-        if proj in ('Geant4', ):
-            project['with_shared'] = True
+        if proj in ("Geant4",):
+            project["with_shared"] = True
 
         config_projects.append(project)
 
     config_packages = []
-    for pack, vers in (packages or []):
-        package = {'version': vers, 'checkout_opts': {'export': True}}
+    for pack, vers in packages or []:
+        package = {"version": vers, "checkout_opts": {"export": True}}
         # the package name could by just the name or <container>:<name>
-        if ':' not in pack:
-            package['name'] = pack
+        if ":" not in pack:
+            package["name"] = pack
         else:
-            package['container'], package['name'] = pack.split(':', 1)
+            package["container"], package["name"] = pack.split(":", 1)
         if package not in config_packages:  # ignore duplicates
             config_packages.append(package)
 
     # prepare the configuration dictionary
     config = {
-        'slot': slot,
-        'build_id': build_id,
-        'description': 'Slot used for releasing projects.',
-        'projects': config_projects,
-        'packages': config_packages,
-        'build_tool': build_tool.lower(),
-        'no_patch': True,
-        'with_version_dir': True,
-        'error_exceptions': ERR_EXCEPT,
-        'warning_exceptions': WARN_EXCEPT,
-        'platforms': platforms or [],
-        'cache_entries': {
-            'GAUDI_STRICT_VERSION_CHECK': True
+        "slot": slot,
+        "build_id": build_id,
+        "description": "Slot used for releasing projects.",
+        "projects": config_projects,
+        "packages": config_packages,
+        "build_tool": build_tool.lower(),
+        "no_patch": True,
+        "with_version_dir": True,
+        "error_exceptions": ERR_EXCEPT,
+        "warning_exceptions": WARN_EXCEPT,
+        "platforms": platforms or [],
+        "cmake_cache": {
+            "GAUDI_STRICT_VERSION_CHECK": True,
+            "GAUDI_LEGACY_CMAKE_SUPPORT": True,
         },
     }
 
     return config
 
 
 class ConfigGenerator(PlainScript):
-    '''
+    """
     Given a list of projects and versions, generate a basic configuration file.
-    '''
-    __usage__ = '%prog [options] project version [project version...]'
+    """
+
+    __usage__ = "%prog [options] project version [project version...]"
 
     def defineOpts(self):
-        '''
+        """
         Options specific to this script.
-        '''
+        """
         self.parser.add_option(
-            '-s', '--slot', help='name of the slot to add to the JSON data')
+            "-s", "--slot", help="name of the slot to add to the JSON data"
+        )
         self.parser.add_option(
-            '-b', '--build-id', help='build id to add to the JSON data')
+            "-b", "--build-id", help="build id to add to the JSON data"
+        )
         self.parser.add_option(
-            '-o',
-            '--output',
-            help='name of the output file [default "-", '
-            'i.e. standard output]')
+            "-o",
+            "--output",
+            help='name of the output file [default "-", ' "i.e. standard output]",
+        )
         self.parser.add_option(
-            '--cmt',
-            action='store_const',
-            const='cmt',
-            dest='build_tool',
-            help='configure to use CMT for the build '
-            '(equivalent to "--build-tool=cmt")')
+            "--cmt",
+            action="store_const",
+            const="cmt",
+            dest="build_tool",
+            help="configure to use CMT for the build "
+            '(equivalent to "--build-tool=cmt")',
+        )
         self.parser.add_option(
-            '--platforms',
-            help='space or comma -separated list of '
-            'platforms required [default: %default]')
+            "--platforms",
+            help="space or comma -separated list of "
+            "platforms required [default: %default]",
+        )
         self.parser.add_option(
-            '--packages',
-            help='space-separated list of data packages, '
-            'with versions, to add')
+            "--packages",
+            help="space-separated list of data packages, " "with versions, to add",
+        )
         self.parser.add_option(
-            '-t',
-            '--build-tool',
-            action='store',
-            help='which build tool to use '
-            '(case insensitive) [default: %default]')
+            "-t",
+            "--build-tool",
+            action="store",
+            help="which build tool to use " "(case insensitive) [default: %default]",
+        )
         self.parser.set_defaults(
-            slot='lhcb-release',
+            slot="lhcb-release",
             build_id=0,
-            output='-',
+            output="-",
             platforms=DEFAULT_PLATFORMS,
-            packages='',
-            build_tool='cmake')
+            packages="",
+            build_tool="cmake",
+        )
 
     def genConfig(self):
         opts = self.options
         return genConfig(
             slot=opts.slot,
             build_id=opts.build_id,
-            projects=toListOfPairs(' '.join(self.args)),
+            projects=toListOfPairs(" ".join(self.args)),
             packages=toListOfPairs(opts.packages),
-            platforms=opts.platforms.replace(',', ' ').split(),
+            platforms=opts.platforms.replace(",", " ").split(),
             build_tool=opts.build_tool,
         )
 
     def main(self):
-        '''
+        """
         Script logic.
-        '''
+        """
 
         if len(self.args) % 2 != 0:
-            self.parser.error('wrong number of arguments: we need a list of '
-                              'projects and their versions')
+            self.parser.error(
+                "wrong number of arguments: we need a list of "
+                "projects and their versions"
+            )
 
         try:
             # prepare the configuration dictionary
             config = self.genConfig()
         except ValueError as err:
             self.parser.error(str(err))
 
-        if self.options.output != '-':
+        if self.options.output != "-":
             LbNightlyTools.Configuration.save(self.options.output, config)
         else:
-            print LbNightlyTools.Configuration.configToString(config)
+            print(LbNightlyTools.Configuration.configToString(config))
 
         return 0
 
 
 class _ReleaseTriggerBase(PlainScript):
-    '''
+    """
     Base class for the release trigger script.
-    '''
-    DEFAULT_BUILD_TOOL = 'cmake'
+    """
+
+    DEFAULT_BUILD_TOOL = "cmake"
 
     @property
     def dashboard(self):
-        if not hasattr(self, '_dashboard'):
-            self._dashboard = Dashboard(flavour='release')
+        if not hasattr(self, "_dashboard"):
+            self._dashboard = Dashboard(flavour="release")
         return self._dashboard
 
     def _gen_release_params(self, stack):
-        projects_list = ' '.join(
-            ' '.join(pv) for pv in stack.get('projects', []))
-        packages_list = ' '.join(
-            ' '.join(pv) for pv in stack.get('packages', []))
-        platforms = ' '.join(stack.get('platforms', []))
-        build_tool = stack.get('build_tool', self.DEFAULT_BUILD_TOOL)
+        projects_list = " ".join(" ".join(pv) for pv in stack.get("projects", []))
+        packages_list = " ".join(" ".join(pv) for pv in stack.get("packages", []))
+        platforms = " ".join(stack.get("platforms", []))
+        build_tool = stack.get("build_tool", self.DEFAULT_BUILD_TOOL)
 
         if projects_list or packages_list:
             if projects_list:
-                self.log.debug('projects: %s', projects_list)
+                self.log.debug("projects: %s", projects_list)
             if packages_list:
-                self.log.debug('packages: %s', packages_list)
+                self.log.debug("packages: %s", packages_list)
             if platforms:
-                self.log.debug('platforms: %s', platforms)
-            self.log.debug('build_tool: %s', build_tool)
+                self.log.debug("platforms: %s", platforms)
+            self.log.debug("build_tool: %s", build_tool)
 
             data = JobParams(
                 projects_list=projects_list,
                 packages_list=packages_list,
                 platforms=platforms,
-                build_tool=build_tool)
+                build_tool=build_tool,
+            )
         else:
-            self.log.error('invalid stack configuration')
+            self.log.error("invalid stack configuration")
             data = None
         return data
 
     def _gen_checkout_params(self):
         data = JobParams(
-            slot='lhcb-release',
-            flavour='release',
+            slot="lhcb-release",
+            flavour="release",
             slot_build_id=self.next_id(),
-            trigger_url=os.environ.get('BUILD_URL'))
-        self.log.debug('slot_build_id: %d', data.slot_build_id)
+            trigger_url=os.environ.get("BUILD_URL"),
+        )
+        self.log.debug("slot_build_id: %d", data.slot_build_id)
         return data
 
 
 class Starter(_ReleaseTriggerBase):
-    '''
+    """
     Generate a property file suitable to trigger a slot from the environment
     variables:
     - projects_list
     - packages_list
     - platforms
     - build_tool
-    '''
-    __usage__ = '%prog'
-    PARAM_FILE = 'release-params.txt'
+    """
+
+    __usage__ = "%prog"
+    PARAM_FILE = "release-params.txt"
 
     def defineOpts(self):
-        '''
+        """
         Options specific to this script.
-        '''
+        """
         pass  # no special options
 
     def next_id(self):
-        doc = self.dashboard.db.get('last_id', {'type': 'last_id', 'value': 0})
-        doc['value'] = max(doc['value'],
-                           self.dashboard.lastBuildId('lhcb-release')) + 1
-        self.dashboard.update('last_id', doc)
-        return doc['value']
+        doc = self.dashboard.db.get("last_id", {"type": "last_id", "value": 0})
+        doc["value"] = max(doc["value"], self.dashboard.lastBuildId("lhcb-release")) + 1
+        self.dashboard.update("last_id", doc)
+        return doc["value"]
 
     def main(self):
-        '''
+        """
         Script logic.
-        '''
+        """
         if self.args:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
         # connect to the dashboard (to have a better debug output later on)
         self.dashboard
 
         # ensure that we will not trigger by mistake
         if os.path.exists(self.PARAM_FILE):
             os.remove(self.PARAM_FILE)
         # handle stack requested via the environment
         env = os.environ
-        self.log.info('generating %s', self.PARAM_FILE)
+        self.log.info("generating %s", self.PARAM_FILE)
         data = self._gen_checkout_params()
-        key = '{0.slot}.{0.slot_build_id}'.format(data)
-        self.log.info('create dashboard entry %s',
-                      self.dashboard.urlForKey(key))
+        key = "{0.slot}.{0.slot_build_id}".format(data)
+        self.log.info("create dashboard entry %s", self.dashboard.urlForKey(key))
         self.dashboard.db[key] = {
-            'type':
-            'slot-info',
-            'slot':
-            data.slot,
-            'build_id':
-            data.slot_build_id,
-            'config':
-            genConfig(
+            "type": "slot-info",
+            "slot": data.slot,
+            "build_id": data.slot_build_id,
+            "config": genConfig(
                 slot=data.slot,
                 build_id=data.slot_build_id,
-                projects=toListOfPairs(env.get('projects_list', '')),
-                packages=toListOfPairs(env.get('packages_list', '')),
-                platforms=env.get('platforms', '').split(),
-                build_tool=env.get('build_tool', self.DEFAULT_BUILD_TOOL),
+                projects=toListOfPairs(env.get("projects_list", "")),
+                packages=toListOfPairs(env.get("packages_list", "")),
+                platforms=env.get("platforms", "").split(),
+                build_tool=env.get("build_tool", self.DEFAULT_BUILD_TOOL),
             ),
         }
-        with open(self.PARAM_FILE, 'w') as params:
+        with open(self.PARAM_FILE, "w") as params:
             params.write(str(data))
 
         return 0
 
 
 class Poll(_ReleaseTriggerBase):
-    '''
+    """
     Poll a URL for the list of stacks not yet released and return those that
     need to be built.
-    '''
-    __usage__ = '%prog [options] url'
-    PARAM_FILE_TPL = 'release-params-{0}.txt'
+    """
+
+    __usage__ = "%prog [options] url"
+    PARAM_FILE_TPL = "release-params-{0}.txt"
 
     def defineOpts(self):
-        '''
+        """
         Options specific to this script.
-        '''
+        """
         pass  # no special options
 
     # FIXME: I'd like to use @property, but it requires inheritance from 'object'
     def get_stacks(self):
-        doc = self.dashboard.db.get('stacks')
-        return doc['value'] if doc else []
+        doc = self.dashboard.db.get("stacks")
+        return doc["value"] if doc else []
 
     def set_stacks(self, value):
-        self.dashboard.update('stacks', {'type': 'stacks', 'value': value})
+        self.dashboard.update("stacks", {"type": "stacks", "value": value})
 
     def main(self):
-        '''
+        """
         Script logic.
-        '''
+        """
         if len(self.args) != 1:
-            self.parser.error('wrong number of arguments')
+            self.parser.error("wrong number of arguments")
 
         # URL to poll
         url = self.args[0]
 
         # get the stacks triggered last time
-        self.log.debug('load previous state')
+        self.log.debug("load previous state")
         previous = self.get_stacks()
-        self.log.debug('found %d stacks', len(previous))
+        self.log.debug("found %d stacks", len(previous))
 
         # retrieve the list of stacks to build
-        self.log.debug('retrieving %s', url)
-        stacks = json.loads(urllib2.urlopen(url).read())
+        self.log.debug("retrieving %s", url)
+        stacks = json.loads(urllib.request.urlopen(url).read())
         # sort the list for stable behavior
         for stack in stacks:
             for k in stack:
-                if hasattr(stack[k], 'sort'):
+                if hasattr(stack[k], "sort"):
                     stack[k].sort()
         stacks.sort()
-        self.log.debug('found %d stacks', len(stacks))
+        self.log.debug("found %d stacks", len(stacks))
 
         # ensure that we will not trigger by mistake
         self._clean_stacks_params()
         # generate one param file for each stack to be built
         for idx, stack in enumerate([s for s in stacks if s not in previous]):
             filename = self.PARAM_FILE_TPL.format(idx)
-            self.log.info('generating %s', filename)
+            self.log.info("generating %s", filename)
             data = self._gen_release_params(stack)
             if data:
-                with open(filename, 'w') as params:
+                with open(filename, "w") as params:
                     params.write(str(data))
 
         # overwrite the last run data for the next poll
         if stacks != previous:
-            self.log.debug('write new state')
+            self.log.debug("write new state")
             self.set_stacks(stacks)
         else:
-            self.log.debug('no changes to the state')
+            self.log.debug("no changes to the state")
 
         return 0
 
     def _clean_stacks_params(self):
-        '''
+        """
         Remove param files matching the produced file names.
-        '''
-        self.log.debug('removing old param files')
+        """
+        self.log.debug("removing old param files")
         from glob import glob
-        map(os.remove, glob(self.PARAM_FILE_TPL.format('*')))
 
+        for f in glob(self.PARAM_FILE_TPL.format("*")):
+            os.remove(f)
 
-_manifest_template = u'''<?xml version='1.0' encoding='UTF-8'?>
+
+_manifest_template = """<?xml version='1.0' encoding='UTF-8'?>
 <manifest>
   <project name="{project}" version="{version}" />
   <heptools>
     <version>{heptools}</version>
     <binary_tag>{platform}</binary_tag>
     <lcg_system>{system}</lcg_system>
   </heptools>{used_projects}{used_data_pkgs}
 </manifest>
-'''
+"""
 
 
 def createManifestFile(project, version, platform, build_dir):
-    '''
+    """
     Generate a manifest.xml from the CMT configuration.
-    '''
-    from subprocess import Popen, PIPE
-    from os.path import dirname, abspath
+    """
+    import logging
     import re
     import sys
-    import logging
-    container_package = ((project + 'Sys')
-                         if project != 'Gaudi' else 'GaudiRelease')
-    container_dir = os.path.join(build_dir, container_package, 'cmt')
-    env = dict((key, value) for key, value in os.environ.iteritems()
-               if key not in ('PWD', 'CWD'))
+    from os.path import abspath, dirname
+    from subprocess import PIPE, Popen
+
+    container_package = (project + "Sys") if project != "Gaudi" else "GaudiRelease"
+    container_dir = os.path.join(build_dir, container_package, "cmt")
+    env = dict(
+        (key, value) for key, value in os.environ.items() if key not in ("PWD", "CWD")
+    )
     # inject the (guessed) build root in the environment
-    env['CMTPROJECTPATH'] = ':'.join(
-        [dirname(dirname(abspath(build_dir))),
-         env.get('CMTPROJECTPATH', '')])
-    proc = Popen(['cmt', 'show', 'projects'],
-                 cwd=build_dir,
-                 env=env,
-                 stdout=PIPE,
-                 stderr=PIPE)
+    env["CMTPROJECTPATH"] = ":".join(
+        [dirname(dirname(abspath(build_dir))), env.get("CMTPROJECTPATH", "")]
+    )
+    proc = Popen(
+        ["cmt", "show", "projects"], cwd=build_dir, env=env, stdout=PIPE, stderr=PIPE
+    )
     out, _err = proc.communicate()
-    out = out.decode()
+    out = out.decode("utf-8", errors="replace")
 
     # no check because we must have a dependency on LCGCMT
-    match = re.search(r'LCGCMT_([^ ]+)', out)
+    match = re.search(r"LCGCMT_([^ ]+)", out)
     if not match:
         logging.error(
-            'problem with "cmt show projects":\n'
-            '--- output ---\n%s\n--------------', out)
-        logging.info('CMTPROJECTPATH=%s', env['CMTPROJECTPATH'])
+            'problem with "cmt show projects":\n' "--- output ---\n%s\n--------------",
+            out,
+        )
+        logging.info("CMTPROJECTPATH=%s", env["CMTPROJECTPATH"])
         sys.exit(1)
     heptools = match.group(1)
 
     projects = [
-        '    <project name="%s" version="%s" />' % (fixProjectCase(name),
-                                                    vers.split('_')[-1])
-        for name, vers in
-        [x.split()[0:2] for x in out.splitlines() if re.match(r'^  [^ ]', x)]
-        if name not in ('DBASE', 'PARAM', 'LCGCMT')
+        '    <project name="%s" version="%s" />'
+        % (fixProjectCase(name), vers.split("_")[-1])
+        for name, vers in [
+            x.split()[0:2] for x in out.splitlines() if re.match(r"^  [^ ]", x)
+        ]
+        if name not in ("DBASE", "PARAM", "LCGCMT")
     ]
     if projects:
-        projects.insert(0, '\n  <used_projects>')
-        projects.append('  </used_projects>')
+        projects.insert(0, "\n  <used_projects>")
+        projects.append("  </used_projects>")
 
     data_pkgs = []
-    if 'DBASE' in out or 'PARAM' in out:
-        proc = Popen(['cmt', 'show', 'uses'],
-                     cwd=container_dir,
-                     env=env,
-                     stdout=PIPE,
-                     stderr=PIPE)
+    if "DBASE" in out or "PARAM" in out:
+        proc = Popen(
+            ["cmt", "show", "uses"],
+            cwd=container_dir,
+            env=env,
+            stdout=PIPE,
+            stderr=PIPE,
+        )
         out, _err = proc.communicate()
-        out = out.decode().splitlines()
+        out = out.decode("utf-8", errors="replace").splitlines()
         data_pkgs = [
-            x.replace(' ', ',').split(',')[1:4:2] for x in out
-            if re.search(r'DBASE|PARAM', x)
+            x.replace(" ", ",").split(",")[1:4:2]
+            for x in out
+            if re.search(r"DBASE|PARAM", x)
         ]
 
         def findVersion(pkg):
-            v = (x.split()[3] for x in out
-                 if re.match(r'^#.*%s' % pkg, x)).next()
-            if v == 'v*':
-                v = '*'
+            v = next((x.split()[3] for x in out if re.match(r"^#.*%s" % pkg, x)))
+            if v == "v*":
+                v = "*"
             return v
 
         data_pkgs = [
-            '    <package name="%s" version="%s" />' %
-            (hat + '/' + name if hat else name, findVersion(name))
+            '    <package name="%s" version="%s" />'
+            % (hat + "/" + name if hat else name, findVersion(name))
             for name, hat in data_pkgs
         ]
         if data_pkgs:
-            data_pkgs.insert(0, '\n  <used_data_pkgs>')
-            data_pkgs.append('  </used_data_pkgs>')
+            data_pkgs.insert(0, "\n  <used_data_pkgs>")
+            data_pkgs.append("  </used_data_pkgs>")
 
     return _manifest_template.format(
         project=project,
         version=version,
         platform=platform,
-        system=platform[:platform.rfind('-')],
+        system=platform[: platform.rfind("-")],
         heptools=heptools,
-        used_projects='\n'.join(projects),
-        used_data_pkgs='\n'.join(data_pkgs))
+        used_projects="\n".join(projects),
+        used_data_pkgs="\n".join(data_pkgs),
+    )
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/__init__.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/__init__.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 ###############################################################################
-# (c) Copyright 2015 CERN                                                     #
+# (c) Copyright 2013 CERN                                                     #
 #                                                                             #
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
-Scripts related modules.
-'''
-__author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+"""
+Package to hold the tests for the nightly build system.
+"""
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Scripts/Checkout.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Scripts/Checkout.py`

 * *Files 20% similar despite different names*

```diff
@@ -4,67 +4,69 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Module containing the classes and functions used to checkout a set of projects,
 fixing their dependencies to produce a consistent set.
-'''
-__author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+"""
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
 
+import codecs
+import html
+import json
 import logging
 import os
-import json
-import cgi
-import codecs
 import re
 import shutil
-from itertools import chain
 from datetime import date, datetime
+from itertools import chain
 from os.path import join
 from subprocess import call
-from LbNightlyTools.Utils import chdir, pack, ensureDirs
-from LbNightlyTools.HTMLUtils import XTerm2HTML, AddGitlabLinks
+
 from LbNightlyTools.Configuration import DataProject
+from LbNightlyTools.HTMLUtils import AddGitlabLinks, XTerm2HTML
 from LbNightlyTools.Scripts.Common import BaseScript, genPackageName
+from LbNightlyTools.Utils import chdir, ensureDirs, pack
 
 __log__ = logging.getLogger(__name__)
 
 
-class PathPrefixRemover(object):
-    '''
+class PathPrefixRemover:
+    """
     Callable that remove "path" prefix from a text
-    '''
+    """
 
     def __init__(self, path):
-        path = path.rstrip('/')
-        self._pattern = re.compile(re.escape(path) + r'/?\b')
+        path = path.rstrip("/")
+        self._pattern = re.compile(re.escape(path) + r"/?\b")
 
     def __call__(self, text):
-        'remove prefix from text'
-        return self._pattern.sub('', text)
+        "remove prefix from text"
+        return self._pattern.sub("", text)
 
 
 def highlightCmdLines(text):
-    '''
+    """
     hightlight command lines in checkout log
-    '''
+    """
     return re.sub(
-        r'^(\([^)]*\)\$.*)$',
+        r"^(\([^)]*\)\$.*)$",
         r'<span class="console-cmd">\1</span>',
         text,
-        flags=re.MULTILINE)
+        flags=re.MULTILINE,
+    )
 
 
 # Special `.htaccess` configurationt to allow old entry points to work with
 # new layout
-HTACCESS_DATA = r'''RewriteEngine On
+HTACCESS_DATA = r"""RewriteEngine On
 # this is a clever trick to avoid RewriteBase
 # see http://stackoverflow.com/a/21063276
 RewriteCond "%{REQUEST_URI}::$1" "^(.*?/)(.*)::\2$"
 RewriteRule "^(.*)$" "-" [E=BASE:%1]
 # Helper to list the content of a zip file
 RewriteCond "%{DOCUMENT_ROOT}/%{REQUEST_URI}" !-f
 RewriteRule "^(.+)/.list" "%{ENV:BASE}listzip.php?zip=$1.zip" [PT,B,L]
@@ -79,19 +81,19 @@
 # - test artifacts
 RewriteRule "^summaries\.([^/]*)/([^/]*)/html/(.*)" "%{ENV:BASE}tests/$1/$2/results/$3" [R,L]
 # Extract artifacts from specific zip files
 RewriteCond "%{DOCUMENT_ROOT}/%{REQUEST_URI}" !-f
 RewriteRule "^(build|tests)/([^/]+)/([^/]+)/(.+)" "%{ENV:BASE}extract.php?zip=$1/$2/$3.zip&path=$3/$4" [PT,B,L]
 RewriteCond "%{DOCUMENT_ROOT}/%{REQUEST_URI}" !-f
 RewriteRule "^checkout/(.+)" "%{ENV:BASE}extract.php?zip=checkout.zip&path=checkout/$1" [PT,B,L]
-'''
+"""
 
 
 class Script(BaseScript):
-    '''
+    """
     Script to checkout a consistent set of projects as described in a
     configuration file.
 
     The configuration file must be in JSON format containing an object with the
     attribute 'projects', a list of objects with defining the projects to be
     checked out.
 
@@ -100,264 +102,282 @@
                        "version": "v23r5",
                        "checkout": "specialCheckoutFunction"},
                       {"name": "LHCb",
                        "version": "v32r5",
                        "overrides": {"GaudiObjDesc": "HEAD",
                                      "GaudiPython": "v12r4",
                                      "Online/RootCnv": null}}]}
-    '''
+    """
 
     def defineOpts(self):
-        """ User options -- has to be overridden """
+        """User options -- has to be overridden"""
         from LbNightlyTools.Scripts.Common import (
-            addBasicOptions, addDashboardOptions, addDeploymentOptions)
+            addBasicOptions,
+            addDashboardOptions,
+            addDeploymentOptions,
+        )
+
         addBasicOptions(self.parser)
         addDashboardOptions(self.parser)
         addDeploymentOptions(self.parser)
 
         self.parser.add_option(
-            '--ignore-checkout-errors',
-            action='store_true',
-            dest='ignore_checkout_errors',
-            help='continue to checkout if there is a '
-            'failure (default)')
+            "--ignore-checkout-errors",
+            action="store_true",
+            dest="ignore_checkout_errors",
+            help="continue to checkout if there is a " "failure (default)",
+        )
         self.parser.add_option(
-            '--no-ignore-checkout-errors',
-            action='store_false',
-            dest='ignore_checkout_errors',
-            help='stop the checkout if there is a failure')
+            "--no-ignore-checkout-errors",
+            action="store_false",
+            dest="ignore_checkout_errors",
+            help="stop the checkout if there is a failure",
+        )
         self.parser.set_defaults(ignore_checkout_errors=True)
 
     def packname(self, element):
-        '''
+        """
         Return the filename of the archive (package) of the given project.
-        '''
+        """
         return genPackageName(
             element,
-            'src',
+            "src",
             build_id=self.options.build_id,
-            artifacts_dir=self.artifacts_dir)
+            artifacts_dir=self.artifacts_dir,
+        )
 
     def main(self):
-        """ Main logic of the script """
-        self._setup(build_dir=join('tmp', 'checkout'), json_type='slot-config')
+        """Main logic of the script"""
+        self._setup(build_dir=join("tmp", "checkout"), json_type="slot-config")
 
         opts = self.options
         slot = self.slot
 
         # prepare special environment, if needed
         os.environ.update(slot.environment())
 
         # Prepare JSON doc for the database
         cfg = slot.toDict()
-        cfg['date'] = os.environ.get('DATE', date.today().isoformat())
-        cfg['started'] = self.starttime.isoformat()
-        platforms = os.environ.get('platforms', '').strip().split()
+        cfg["date"] = os.environ.get("DATE", date.today().isoformat())
+        cfg["started"] = self.starttime.isoformat()
+        platforms = os.environ.get("platforms", "").strip().split()
         if platforms:
-            cfg['platforms'] = platforms
-        cfg['trigger_url'] = os.environ.get('trigger_url')
+            cfg["platforms"] = platforms
+        cfg["trigger_url"] = os.environ.get("trigger_url")
 
         # publish the configuration before the checkout
         self.send(cfg)
 
         # prepare artifacts directory layout
         ensureDirs(
-            os.path.join(self.artifacts_dir, d)
-            for d in ('packs/src', 'checkout'))
-        if 'BUILD_URL' in os.environ:
+            os.path.join(self.artifacts_dir, d) for d in ("packs/src", "checkout")
+        )
+        if "BUILD_URL" in os.environ:
             with open(
-                    os.path.join(self.artifacts_dir, 'checkout',
-                                 'job_url.txt'), 'w') as f:
-                f.write(os.environ['BUILD_URL'])
-                f.write('\n')
+                os.path.join(self.artifacts_dir, "checkout", "job_url.txt"), "w"
+            ) as f:
+                f.write(os.environ["BUILD_URL"])
+                f.write("\n")
 
         script = self
 
-        class CheckoutContext(object):
+        class CheckoutContext:
             def __init__(self, project):
-                self._msg = {'project': project.name}
+                script.assert_not_aborted()
+                self._msg = {"project": project.name}
                 self.result = {}
 
             def __enter__(self):
                 self.send(started=datetime.now().isoformat())
                 return self
 
             def __exit__(self, exc_type, exc_value, traceback):
                 if exc_type:
-                    if 'error' not in self.result:
-                        self.result['error'] = []
-                    self.result['error'].append('{}: {}'.format(
-                        exc_type.__name__, exc_value))
+                    if "error" not in self.result:
+                        self.result["error"] = []
+                    self.result["error"].append(
+                        "{}: {}".format(exc_type.__name__, exc_value)
+                    )
                 self.send(completed=datetime.now().isoformat(), **self.result)
 
             def send(self, **kwargs):
                 self._msg.update(kwargs)
-                for key_to_drop in ('stdout', 'stderr'):
+                for key_to_drop in ("stdout", "stderr"):
                     if key_to_drop in self._msg:
                         del self._msg[key_to_drop]
                 script.send(dict(self._msg))
 
         with chdir(self.build_dir):
             slot.checkout(
                 projects=opts.projects,
                 ignore_errors=opts.ignore_checkout_errors,
-                context=CheckoutContext)
+                context=CheckoutContext,
+            )
 
-            with open(join(self.artifacts_dir, 'slot.patch'),
-                      'w') as patchfile:
+            with open(join(self.artifacts_dir, "slot.patch"), "w") as patchfile:
                 if not slot.no_patch:
                     slot.patch(patchfile, dryrun=True)
                 else:
-                    self.log.info('not patching the sources')
+                    self.log.info("not patching the sources")
 
             # generate explicit dependencies
             # - map position in the list with project name
-            proj_idx = dict(
-                (p['name'], i) for i, p in enumerate(cfg['projects']))
+            proj_idx = dict((p["name"], i) for i, p in enumerate(cfg["projects"]))
             # - extract dependencies and update the configuration dict
             # - make sure platform independent projects are correctly flagged
             # - make sure lcg-toolchains (if present) is in all dependencies
             dependencies = slot.dependencies()
-            for projname, deps in dependencies.iteritems():
-                projdict = cfg['projects'][proj_idx[projname]]
-                projdict['dependencies'] = deps
-                if (projname != 'lcg-toolchains'
-                        and 'lcg-toolchains' in slot.projects
-                        and 'lcg-toolchains' not in deps):
-                    projdict['dependencies'].append('lcg-toolchains')
+            for projname, deps in dependencies.items():
+                projdict = cfg["projects"][proj_idx[projname]]
+                projdict["dependencies"] = deps
+                if (
+                    projname != "lcg-toolchains"
+                    and "lcg-toolchains" in slot.projects
+                    and "lcg-toolchains" not in deps
+                ):
+                    projdict["dependencies"].append("lcg-toolchains")
                 if slot.projects[projname].platform_independent:
-                    projdict['platform_independent'] = True
+                    projdict["platform_independent"] = True
             # disable non interesting projects (only in "-mr" slots)
-            if ('ci_test' in slot.metadata
-                    and slot.metadata['ci_test'].get('is_test')
-                    and slot.metadata['ci_test'].get('requested_projects')):
+            if (
+                "ci_test" in slot.metadata
+                and slot.metadata["ci_test"].get("is_test")
+                and slot.metadata["ci_test"].get("requested_projects")
+            ):
                 from networkx.algorithms.dag import ancestors, descendants
+
                 deps = slot.dependencyGraph()
                 # - we have to build the projects explicitly listed
-                needed = set(slot.metadata['ci_test']['requested_projects'])
+                #   (excluding data packages)
+                needed = set(slot.metadata["ci_test"]["requested_projects"]) & set(deps)
                 # - plus all projects that use the listed ones
                 needed.update(
-                    list(
-                        chain.from_iterable(
-                            descendants(deps, p) for p in needed)))
+                    list(chain.from_iterable(descendants(deps, p) for p in needed))
+                )
+                # - test projects that changed or depend on those that changed
+                need_testing = set(needed)
                 # - and all projects that are needed to build those we need
                 needed.update(
-                    list(
-                        chain.from_iterable(
-                            ancestors(deps, p) for p in needed)))
+                    list(chain.from_iterable(ancestors(deps, p) for p in needed))
+                )
                 # - disable everything else
                 #   (making sure we do not enable something already disabled)
-                for p in slot.projects:
-                    idx = proj_idx[p.name]
-                    if (not cfg['projects'][idx]['disabled']
-                            and p.name not in needed):
-                        __log__.debug('disabling %s', p.name)
-                        cfg['projects'][idx]['disabled'] = True
-                        p.disabled = True
+                for p in cfg["projects"]:
+                    if not p["disabled"]:
+                        n = p["name"]
+                        getattr(slot, n).disabled = p["disabled"] = n not in needed
+                        getattr(slot, n).no_test = p["no_test"] = n not in need_testing
+
+                __log__.debug("projects to build: %s", needed)
+                __log__.debug("projects to test: %s", need_testing)
 
         # write the checkout log of projects to dedicated files
         for project in slot.activeProjects:
-            if hasattr(project, 'checkout_log'):
-                __log__.debug('writing checkout log for %s', project)
-                co_logfile = join(self.artifacts_dir, 'checkout', '.'.join(
-                    (project.name, 'log')))
-                with codecs.open(co_logfile, 'w', 'utf-8') as co_log:
+            if hasattr(project, "checkout_log"):
+                __log__.debug("writing checkout log for %s", project)
+                co_logfile = join(
+                    self.artifacts_dir, "checkout", ".".join((project.name, "log"))
+                )
+                with codecs.open(co_logfile, "w", "utf-8") as co_log:
                     co_log.write(project.checkout_log)
-                with codecs.open(co_logfile + '.html', 'w', 'utf-8') as co_log:
+                with codecs.open(co_logfile + ".html", "w", "utf-8") as co_log:
                     html_filters = [
                         AddGitlabLinks(),
-                        PathPrefixRemover(self.build_dir), highlightCmdLines
+                        PathPrefixRemover(self.build_dir),
+                        highlightCmdLines,
                     ]
                     conv = XTerm2HTML(
                         show_line_no=True,
                         is_escaped=True,
-                        plugins_function=html_filters)
+                        plugins_function=html_filters,
+                    )
                     co_log.write(conv.head(title=os.path.basename(co_logfile)))
-                    log = cgi.escape(project.checkout_log, quote=True)
-                    if not isinstance(log, unicode):
-                        log = log.decode('utf-8', 'replace')
+                    log = html.escape(project.checkout_log, quote=True)
+                    if not isinstance(log, str):
+                        log = log.decode("utf-8", errors="replace")
                     co_log.write(conv.process(log))
                     co_log.write(conv.tail())
 
         def containers():
-            '''
+            """
             Generator for the container projects in the slot.
-            '''
+            """
             for cont in slot.projects:
                 if isinstance(cont, DataProject):
                     yield cont
 
-        packages = list(
-            chain.from_iterable(cont.packages for cont in containers()))
+        packages = list(chain.from_iterable(cont.packages for cont in containers()))
 
         for element in chain(slot.activeProjects, packages):
             # ignore missing directories
             # (the project may not have been checked out)
             if not os.path.exists(join(self.build_dir, element.baseDir)):
-                self.log.warning('no sources for %s, skip packing', element)
+                self.log.warning("no sources for %s, skip packing", element)
                 continue
             if isinstance(element, DataProject):
                 continue  # ignore DataProjects, because we pack packages
 
-            self.log.info('packing %s %s...', element.name, element.version)
+            self.log.info("packing %s %s...", element.name, element.version)
 
-            pack([element.baseDir],
-                 self.packname(element),
-                 cwd=self.build_dir,
-                 checksum='md5')
+            pack(
+                [element.baseDir],
+                self.packname(element),
+                cwd=self.build_dir,
+                checksum="md5",
+            )
         for container in containers():
             container = container.name
-            self.log.info('packing %s (links)...', container)
+            self.log.info("packing %s (links)...", container)
             contname = [container]
             if self.options.build_id:
                 contname.append(self.options.build_id)
-            contname.append('src.zip')
-            pack([container],
-                 join(self.artifacts_dir, 'packs', 'src', '.'.join(contname)),
-                 cwd=self.build_dir,
-                 checksum='md5',
-                 dereference=False,
-                 exclude=[p.baseDir for p in packages])
+            contname.append("src.zip")
+            pack(
+                [container],
+                join(self.artifacts_dir, "packs", "src", ".".join(contname)),
+                cwd=self.build_dir,
+                checksum="md5",
+                dereference=False,
+                exclude=[p.baseDir for p in packages],
+            )
 
         donetime = datetime.now()
-        cfg['completed'] = donetime.isoformat()
+        cfg["completed"] = donetime.isoformat()
 
         # Save a copy as metadata for tools like lbn-install
         with codecs.open(
-                join(self.artifacts_dir, 'slot-config.json'), 'w',
-                'utf-8') as config_dump:
-            data = {
-                'slot': slot.name,
-                'build_id': slot.build_id,
-                'type': 'slot-config'
-            }
+            join(self.artifacts_dir, "slot-config.json"), "w", "utf-8"
+        ) as config_dump:
+            data = {"slot": slot.name, "build_id": slot.build_id, "type": "slot-config"}
             data.update(cfg)
             json.dump(data, config_dump, indent=2)
 
         # Allow old entry points to work with new layout
-        with codecs.open(join(self.artifacts_dir, '.htaccess'), 'w',
-                         'utf-8') as htaccess_file:
+        with codecs.open(
+            join(self.artifacts_dir, ".htaccess"), "w", "utf-8"
+        ) as htaccess_file:
             htaccess_file.write(HTACCESS_DATA)
-        for helper in ('extract.php', 'listzip.php'):
+        for helper in ("extract.php", "listzip.php"):
             shutil.copy(
                 join(os.path.dirname(__file__), helper),
-                join(self.artifacts_dir, helper))
+                join(self.artifacts_dir, helper),
+            )
 
         # publish the updated configuration JSON
         self.send(cfg)
 
-        self.log.debug('compressing artifacts')
-        call(['zip', '-r', '-m', '-q', 'checkout', 'checkout'],
-             cwd=self.artifacts_dir)
-        self.send({'type': 'artifacts', 'path': self.artifacts_dir}, sync=True)
+        self.log.debug("compressing artifacts")
+        call(["zip", "-r", "-m", "-q", "checkout", "checkout"], cwd=self.artifacts_dir)
+        self.send({"type": "artifacts", "path": self.artifacts_dir}, sync=True)
 
         # ensure we do not have pending tasks
         self.tasks.join()
 
-        self.log.info('sources ready for build (time taken: %s).',
-                      donetime - self.starttime)
+        self.log.info(
+            "sources ready for build (time taken: %s).", donetime - self.starttime
+        )
 
         return 0
 
 
 def run():
     return Script().run()
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/ArtifactsServer.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/ArtifactsServer.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,39 +6,43 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Helper to view html files from zip archives (as in artifacts directory).
 
 @author Marco Clemencic <marco.clemencic@cern.ch>
-'''
-import SimpleHTTPServer
+"""
+from future import standard_library
+
+standard_library.install_aliases()
+import http.server
 import os
 import shutil
 import zipfile
-
 from subprocess import call
 
 
-class UnzipHTTPHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):
+class UnzipHTTPHandler(http.server.SimpleHTTPRequestHandler):
     def unzip(self, zip_path, path_in_zip):
-        '''
+        """
         Serve a file from within a .zip file.
-        '''
+        """
         from datetime import datetime
+
         try:
             z = zipfile.ZipFile(zip_path)
             info = z.getinfo(path_in_zip)
             f = z.open(info)
-            timestamp = (datetime(*info.date_time) -
-                         datetime.utcfromtimestamp(0)).total_seconds()
+            timestamp = (
+                datetime(*info.date_time) - datetime.utcfromtimestamp(0)
+            ).total_seconds()
         except (IOError, KeyError):
             self.send_error(404, "File not found")
             return None
 
         ctype = self.guess_type(path_in_zip)
         self.send_response(200)
         self.send_header("Content-type", ctype)
@@ -57,15 +61,15 @@
         and must be closed by the caller under all circumstances), or
         None, in which case the caller has nothing further to do.
 
         """
         path = self.translate_path(self.path)
         f = None
         if os.path.isdir(path):
-            if not self.path.endswith('/'):
+            if not self.path.endswith("/"):
                 # redirect browser - doing basically what apache does
                 self.send_response(301)
                 self.send_header("Location", self.path + "/")
                 self.end_headers()
                 return None
             for index in "index.html", "index.htm":
                 index = os.path.join(path, index)
@@ -78,34 +82,35 @@
         if not os.path.exists(path):
             root = os.getcwd()
             path = os.path.relpath(path, root)
 
             # look for a zip file in the chain of dirs
             zip_base, subpath = os.path.split(path)
             while zip_base:
-                if os.path.exists(zip_base + '.zip'):
+                if os.path.exists(zip_base + ".zip"):
                     return self.unzip(
-                        zip_base + '.zip',
-                        os.path.join(os.path.basename(zip_base), subpath))
+                        zip_base + ".zip",
+                        os.path.join(os.path.basename(zip_base), subpath),
+                    )
                 zip_base, segment = os.path.split(zip_base)
                 subpath = os.path.join(segment, subpath)
 
         ctype = self.guess_type(path)
         try:
             # Always read in binary mode. Opening files in text mode may cause
             # newline translations, making the actual size of the content
             # transmitted *less* than the content-length!
-            f = open(path, 'rb')
+            f = open(path, "rb")
         except IOError:
             self.send_error(404, "File not found")
             return None
         self.send_response(200)
         self.send_header("Content-type", ctype)
         fs = os.fstat(f.fileno())
         self.send_header("Content-Length", str(fs[6]))
         self.send_header("Last-Modified", self.date_time_string(fs.st_mtime))
         self.end_headers()
         return f
 
 
-if __name__ == '__main__':
-    SimpleHTTPServer.test(HandlerClass=UnzipHTTPHandler)
+if __name__ == "__main__":
+    http.server.test(HandlerClass=UnzipHTTPHandler)
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/BuildLogScanner.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/BuildLogScanner.py`

 * *Files 10% similar despite different names*

```diff
@@ -4,158 +4,164 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Collect the build logs produced by lbn-wrapcmd and write the content grouped by
 subdir and target.
-'''
-__author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+"""
+from builtins import object
+
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
 
 import re
 
-_ESCAPE_SEQ = re.compile('\x1b\\[([0-9;]*m|[012]?K)')
+_ESCAPE_SEQ = re.compile("\x1b\\[([0-9;]*m|[012]?K)")
 
 
 def remove_colors(text):
-    '''
+    """
     Strip ANSI color codes from a text.
 
     >>> remove_colors('\\x1b[34;42mHello\\x1b[2m!\\x1b[m')
     'Hello!'
-    '''
-    return _ESCAPE_SEQ.sub('', text)
+    """
+    return _ESCAPE_SEQ.sub("", text)
 
 
 _LOG_SCANNERS = []
 
 
 def log_scanner(func):
-    '''
+    """
     Decorator to declare a function as log scanner.
-    '''
+    """
     global _LOG_SCANNERS
     _LOG_SCANNERS.append(func)
     return func
 
 
 class IssueSource(object):
     def __init__(self, name, line=None, pos=None):
         self.name = name
         self.line = line
         self.pos = pos
 
     def __str__(self):
-        return ':'.join(str(s) for s in [self.name, self.line, self.pos] if s)
+        return ":".join(str(s) for s in [self.name, self.line, self.pos] if s)
 
     def __repr__(self):
-        return 'IssueSource{0!r}'.format(
-            tuple(s for s in [self.name, self.line, self.pos] if s))
+        return "IssueSource{0!r}".format(
+            tuple(s for s in [self.name, self.line, self.pos] if s)
+        )
 
 
 class Issue(object):
-    '''
+    """
     Base class for issues found in logs.
-    '''
-    SEVERITIES = ('error', 'warning', 'coverity')
+    """
+
+    SEVERITIES = ("error", "warning", "coverity")
 
     def __init__(self, severity, source, msg, log_range):
         if severity not in self.SEVERITIES:
-            raise ValueError('invalid severity value %r', severity)
+            raise ValueError("invalid severity value %r", severity)
         self.severity = severity
         if isinstance(source, tuple):
             source = IssueSource(*source)
         self.source = source
         self.msg = msg
         self.log_range = log_range
 
     def linkText(self):
-        return '{}:{}'.format(self.source.name, self.source.line)
+        return "{}:{}".format(self.source.name, self.source.line)
 
     def __str__(self):
-        return ': '.join(
-            str(s) for s in [self.source, self.severity, self.msg])
+        return ": ".join(str(s) for s in [self.source, self.severity, self.msg])
 
     def __repr__(self):
-        return '{0}{1!r}'.format(
+        return "{0}{1!r}".format(
             self.__class__.__name__,
-            (self.severity, self.source, self.msg, self.log_range))
+            (self.severity, self.source, self.msg, self.log_range),
+        )
 
 
 def strip_build_root(path, iterable):
-    '''
+    """
     Helper to strip the build root string from a
-    '''
+    """
     from LbNightlyTools.Scripts.Checkout import PathPrefixRemover
+
     strip = PathPrefixRemover(path)
     for line in iterable:
         yield strip(line)
 
 
 def split_build_log(iterable):
-    '''
+    """
     Split a build.log file in chunks.
 
     @return a list of pairs [(chunk_id, lines)]
-    '''
+    """
     chunks = []
     lines = []
-    chunks.append(('None', lines))
+    chunks.append(("None", lines))
     for line in iterable:
-        if line.startswith('# Building package'):
+        if line.startswith("# Building package"):
             lines = [line]
             chunk_id = line.split()[3]
             chunks.append((chunk_id, lines))
-        elif line.startswith('#### CMake'):
+        elif line.startswith("#### CMake"):
             lines = []
             chunk_id = line.split()[-2]
             chunks.append((chunk_id, lines))
         else:
             lines.append(line)
-    if chunks[0] == ('None', []):
+    if chunks[0] == ("None", []):
         chunks.pop(0)
     return chunks
 
 
 def reports2exclusions(reports=None):
-    '''
+    """
     Translate a list of Issue instances to a list of lines to exclude in an
     enumeration.
 
     >>> reports2exclusions([Issue('warning', ('f1',), 'm1', (10, 15)),
     ...                     Issue('warning', ('f2',), 'm2', (23, 27)),
     ...                     Issue('error', ('f3',), 'm3', (18, 19))])
     [(10, 15), (18, 19), (23, 27)]
-    '''
+    """
     if not reports:
         return None
     exclusions = [issue.log_range for issue in reports]
     exclusions.sort()
     return exclusions
 
 
 def enumerate_x(items, exclusions=None):
-    '''
+    """
     Same as builtin enumerate function, but skip items with id in the ranges
     defined by exclusions.
 
     >>> list(enumerate_x('abcdefghij', [(2, 5), (8, 9)]))
     [(0, 'a'), (1, 'b'), (5, 'f'), (6, 'g'), (7, 'h'), (9, 'j')]
 
     Exclusions may be overlapping:
 
     >>> list(enumerate_x('abcdefghij', [(1, 4), (2, 5), (6, 9), (7, 8)]))
     [(0, 'a'), (5, 'f'), (9, 'j')]
-    '''
+    """
     if not exclusions:
         return enumerate(items)
     from itertools import chain
+
     # invert the exclusions to list of partial enumerations
     ranges = []
     start = 0
     for stop, next_start in exclusions:
         # if there is an overlap in the exclusion we need to skip to the next
         if stop >= start:
             ranges.append(enumerate(items[start:stop], start))
@@ -170,211 +176,231 @@
     pass
 
 
 @log_scanner
 def gcc_output_scanner(lines, reports=None):
     if reports is None:
         reports = []
-    diag_rexp = re.compile(r'^(\S+):([0-9]+):([0-9]+): (warning|error): (.*)')
+    diag_rexp = re.compile(r"^(\S+):([0-9]+):([0-9]+): (warning|error): (.*)")
     try:
         ln_iter = enumerate_x(lines, reports2exclusions(reports))
-        ln, line = ln_iter.next()
+        ln, line = next(ln_iter)
         while True:
             line = remove_colors(line.rstrip())
             m = diag_rexp.match(line)
             if m:
                 startln = ln
-                ln, line = ln_iter.next()
+                ln, line = next(ln_iter)
                 try:
-                    while line.startswith(' '):
-                        ln, line = ln_iter.next()
+                    while line.startswith(" "):
+                        ln, line = next(ln_iter)
                 except StopIteration:
                     pass
                 reports.append(
                     GCCIssue(
                         m.group(4),
                         (m.group(1), int(m.group(2)), int(m.group(3))),
-                        m.group(5), (startln, ln)))
+                        m.group(5),
+                        (startln, ln),
+                    )
+                )
             else:
-                ln, line = ln_iter.next()
+                ln, line = next(ln_iter)
     except StopIteration:
         pass
     return reports
 
 
 class CMakeIssue(Issue):
     pass
 
 
 @log_scanner
 def cmake_output_scanner(lines, reports=None):
     if reports is None:
         reports = []
     diag_rexp = re.compile(
-        r'^CMake (Warning|Error) at (\S+):([0-9]+) \(message\):')
+        r"^CMake (?:Deprecation )?(Warning|Error) (?:\(dev\) )?at (\S+):([0-9]+) \(message\):"
+    )
     try:
         ln_iter = enumerate_x(lines, reports2exclusions(reports))
-        ln, line = ln_iter.next()
+        ln, line = next(ln_iter)
         while True:
             line = line.rstrip()
             m = diag_rexp.match(line)
             if m:
                 startln = ln
-                ln, line = ln_iter.next()
+                ln, line = next(ln_iter)
                 try:
-                    while line.startswith(' '):
-                        ln, line = ln_iter.next()
+                    while line.startswith(" "):
+                        ln, line = next(ln_iter)
                 except StopIteration:
                     pass
-                msg = ' '.join(
-                    l.strip() for l in lines[startln + 1:ln]).strip()
+                msg = " ".join(l.strip() for l in lines[startln + 1 : ln]).strip()
                 if len(msg) > 120:
-                    msg = msg[:80] + '[...]' + msg[-35:]
+                    msg = msg[:80] + "[...]" + msg[-35:]
                 reports.append(
                     CMakeIssue(
-                        m.group(1).lower(), (m.group(2), int(m.group(3))), msg,
-                        (startln, ln)))
+                        m.group(1).lower(),
+                        (m.group(2), int(m.group(3))),
+                        msg,
+                        (startln, ln),
+                    )
+                )
             else:
-                ln, line = ln_iter.next()
+                ln, line = next(ln_iter)
     except StopIteration:
         pass
     return reports
 
 
 class GaudiIssue(Issue):
     pass
 
 
 @log_scanner
 def gaudi_output_scanner(lines, reports=None):
     if reports is None:
         reports = []
-    diag_rexp = re.compile(r'.*?(\S+) *(WARNING|ERROR|FATAL) +(.*)')
+    diag_rexp = re.compile(r".*?(\S+) *(WARNING|ERROR|FATAL) +(.*)")
     try:
         ln_iter = enumerate_x(lines, reports2exclusions(reports))
-        ln, line = ln_iter.next()
+        ln, line = next(ln_iter)
         while True:
             line = line.rstrip()
             m = diag_rexp.match(line)
             if m:
                 diag_type = m.group(2).lower()
-                if diag_type == 'fatal':
-                    diag_type = 'error'
+                if diag_type == "fatal":
+                    diag_type = "error"
                 reports.append(
-                    GaudiIssue(diag_type, (m.group(1), ), m.group(3),
-                               (ln, ln + 1)))
-            ln, line = ln_iter.next()
+                    GaudiIssue(diag_type, (m.group(1),), m.group(3), (ln, ln + 1))
+                )
+            ln, line = next(ln_iter)
     except StopIteration:
         pass
     return reports
 
 
 class PythonIssue(Issue):
     def linkText(self):
         return 'File "{}", line {}'.format(self.source.name, self.source.line)
 
 
 @log_scanner
 def python_output_scanner(lines, reports=None):
     if reports is None:
         reports = []
-    warn_rexp = re.compile(r'(\S+):([0-9]+): \S*(Warning): (.*)')
+    warn_rexp = re.compile(r"(\S+):([0-9]+): \S*(Warning): (.*)")
     tbinfo_rexp = re.compile(r'\s+File "(.+)", line ([0-9]+)')
     try:
         ln_iter = enumerate_x(lines, reports2exclusions(reports))
-        ln, line = ln_iter.next()
+        ln, line = next(ln_iter)
         while True:
             line = line.rstrip()
             m = warn_rexp.match(line)
             if m:
                 startln = ln
-                ln, line = ln_iter.next()
+                ln, line = next(ln_iter)
                 reports.append(
-                    PythonIssue('warning', (m.group(1), int(m.group(2))),
-                                m.group(4), (startln, ln)))
-            elif line.strip() == 'Traceback (most recent call last):':
+                    PythonIssue(
+                        "warning",
+                        (m.group(1), int(m.group(2))),
+                        m.group(4),
+                        (startln, ln),
+                    )
+                )
+            elif line.strip() == "Traceback (most recent call last):":
                 startln = ln
-                ln, line = ln_iter.next()
-                filename, fileln, msg = '<unkown>', None, 'Python traceback'
+                ln, line = next(ln_iter)
+                filename, fileln, msg = "<unkown>", None, "Python traceback"
                 try:
-                    while line.startswith(' '):
-                        ln, line = ln_iter.next()
+                    while line.startswith(" "):
+                        ln, line = next(ln_iter)
                         m = tbinfo_rexp.match(line)
                         if m:
                             filename = m.group(1)
                             fileln = int(m.group(2))
                     # the actual exception message is after of the dump
                     msg = line.strip()
-                    ln, line = ln_iter.next()
+                    ln, line = next(ln_iter)
                 except StopIteration:
                     pass
                 reports.append(
-                    PythonIssue('error', (filename, fileln), msg,
-                                (startln, ln)))
+                    PythonIssue("error", (filename, fileln), msg, (startln, ln))
+                )
             else:
-                ln, line = ln_iter.next()
+                ln, line = next(ln_iter)
     except StopIteration:
         pass
     return reports
 
 
 class ROOTBreakIssue(Issue):
     pass
 
 
 @log_scanner
 def root_stack_trace_output_scanner(lines, reports=None):
     if reports is None:
         reports = []
-    MARKER = '*** Break ***'
+    MARKER = "*** Break ***"
     try:
         ln_iter = enumerate_x(lines, reports2exclusions(reports))
-        ln, line = ln_iter.next()
+        ln, line = next(ln_iter)
         while True:
             line = line.strip()
             if line.startswith(MARKER):
-                msg = line[len(MARKER):].strip()
+                msg = line[len(MARKER) :].strip()
                 reports.append(
-                    ROOTBreakIssue('error', ('<unknown>', ), msg,
-                                   (ln, ln + 1)))
-            ln, line = ln_iter.next()
+                    ROOTBreakIssue("error", ("<unknown>",), msg, (ln, ln + 1))
+                )
+            ln, line = next(ln_iter)
     except StopIteration:
         pass
     return reports
 
 
 class GenericIssue(Issue):
     def __str__(self):
         return self.msg
 
 
 @log_scanner
 def generic_scanner(lines, reports=None):
     if reports is None:
         reports = []
-    WARNING_RE = re.compile('|'.join([r'\bwarning\b', r'\bSyntaxWarning:']),
-                            re.IGNORECASE)
+    WARNING_RE = re.compile(
+        "|".join([r"\bwarning\b", r"\bSyntaxWarning:"]), re.IGNORECASE
+    )
     ERROR_RE = re.compile(
-        '|'.join([
-            r'\berror\b', r'\*\*\* Break \*\*\*',
-            r'^Traceback \(most recent call last\):',
-            r'^make: \*\*\* No rule to make target', r'Assertion.*failed'
-        ]), re.IGNORECASE)
+        "|".join(
+            [
+                r"\berror\b",
+                r"\*\*\* Break \*\*\*",
+                r"^Traceback \(most recent call last\):",
+                r"^make: \*\*\* No rule to make target",
+                r"Assertion.*failed",
+            ]
+        ),
+        re.IGNORECASE,
+    )
     try:
         ln_iter = enumerate_x(lines, reports2exclusions(reports))
-        ln, line = ln_iter.next()
+        ln, line = next(ln_iter)
         while True:
             line = remove_colors(line.strip())
-            diag_type = ((WARNING_RE.search(line) and 'warning')
-                         or (ERROR_RE.search(line) and 'error'))
+            diag_type = (WARNING_RE.search(line) and "warning") or (
+                ERROR_RE.search(line) and "error"
+            )
             if diag_type:
                 reports.append(
-                    GenericIssue(diag_type, ('<unknown>', ), line,
-                                 (ln, ln + 1)))
-            ln, line = ln_iter.next()
+                    GenericIssue(diag_type, ("<unknown>",), line, (ln, ln + 1))
+                )
+            ln, line = next(ln_iter)
     except StopIteration:
         pass
     return reports
 
 
 def scan_build_log(lines):
     reports = None
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/CheckoutMethods.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/CheckoutMethods.py`

 * *Files 20% similar despite different names*

```diff
@@ -5,1047 +5,998 @@
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 # pylint: disable=I0011
-'''
+"""
 Module grouping the common checkout functions.
-'''
+"""
+from __future__ import absolute_import
 
+from future import standard_library
+
+standard_library.install_aliases()
 import logging
-import shutil
 import os
 import re
+import shutil
 import sys
-from subprocess import Popen, PIPE
-from LbNightlyTools.Utils import (retry_log_call, log_call, ensureDirs,
-                                  notifyMergeRequest, getAllMergeRequestIDs,
-                                  getMRTargetBranch, gitlabProjectExists)
+from builtins import object
+from subprocess import PIPE, Popen
+
+from past.builtins import basestring
 
-__author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+from LbNightlyTools.Utils import (
+    ensureDirs,
+    getAllMergeRequestIDs,
+    getMRTargetBranch,
+    gitlabProjectExists,
+    log_call,
+    notifyMergeRequest,
+    retry_log_call,
+)
+
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
 
 __log__ = logging.getLogger(__name__)
 __log__.setLevel(logging.DEBUG)
 
 
 def decorate_log_call(func):
-    '''
+    """
     Wrap *log_call functions to send log messages to __log__ by default.
-    '''
+    """
     from functools import wraps
 
     @wraps(func)
     def wrapped(*args, **kwargs):  # pylint: disable=C0111
         if args:
             cmd = args[0]
-            if 'logger' not in kwargs:
-                kwargs['logger'] = __log__.getChild(cmd[0].replace('.', '_'))
-            where = os.path.abspath(kwargs.get('cwd', os.getcwd()))
-            kwargs['logger'].debug('(%s)$ %s', where, ' '.join(map(repr, cmd)))
+            if "logger" not in kwargs:
+                kwargs["logger"] = __log__.getChild(cmd[0].replace(".", "_"))
+            where = os.path.abspath(kwargs.get("cwd", os.getcwd()))
+            kwargs["logger"].debug("(%s)$ %s", where, " ".join(map(repr, cmd)))
         return func(*args, **kwargs)
 
     return wrapped
 
 
 log_call = decorate_log_call(log_call)
 retry_log_call = decorate_log_call(retry_log_call)
 
 
 def _merge_outputs(outputs):
-    '''
+    """
     Helper function to merge the tuples returned by log_call.
 
-    >>> _merge_outputs([{'retcode': 1, 'stdout': 'a\\n', 'stderr': ''},
-    ...                 {'retcode': 0, 'stdout': 'b\\n', 'stderr': ''}])
-    {'retcode': 1, 'stderr': '', 'stdout': 'a\\nb\\n'}
-    '''
+    >>> out = _merge_outputs([{'retcode': 1, 'stdout': 'a\\n', 'stderr': ''},
+    ...                       {'retcode': 0, 'stdout': 'b\\n', 'stderr': ''}])
+    >>> out == {'retcode': 1, 'stdout': 'a\\nb\\n', 'stderr': ''}
+    True
+
+    The output is guaranteed to be str even when some of the inputs are bytes.
+
+    >>> out = _merge_outputs([{'retcode': 1, 'stdout': 'a\\n', 'stderr': b''},
+    ...                       {'retcode': 0, 'stdout': b'b\\n', 'stderr': ''}])
+    >>> out == {'retcode': 1, 'stdout': 'a\\nb\\n', 'stderr': ''}
+    True
+    """
+    from LbNightlyTools.Utils import coerce_str
+
     returncode = 0
     for out in outputs:
-        if out['retcode']:
-            returncode = out['retcode']
+        if out["retcode"]:
+            returncode = out["retcode"]
     return {
-        'retcode': returncode,
-        'stdout': ''.join(step['stdout'] for step in outputs),
-        'stderr': ''.join(step['stderr'] for step in outputs)
+        "retcode": returncode,
+        "stdout": "".join(coerce_str(step["stdout"]) for step in outputs),
+        "stderr": "".join(coerce_str(step["stderr"]) for step in outputs),
     }
 
 
-class _soft_db_singleton(object):
-    def __init__(self):
-        self._instance = None
-
-    @property
-    def instance(self):
-        '''
-        The singleton instance.
-        '''
-        if self._instance is None:
-            from LbSoftConfDb2Clients.GenericClient import \
-                LbSoftConfDbBase
-            generic_client = LbSoftConfDbBase()
-            self._instance = generic_client.getROInterface()
-        return self._instance
-
-    def __getattr__(self, name):
-        return getattr(self.instance, name)
-
-    def getSourceURI(self, project, version=None):
-        '''
-        Retrieve the source URI for a project.
-        '''
-        try:
-            return self.instance.getSourceURI(project, version)
-        except Exception as x:  # pylint: disable=W0703
-            logging.warning('problem in SoftConfDB.getSourceURI: %s', x)
-            base = 'gaudi' if project.lower() == 'gaudi' else 'lhcb'
-            uri = 'gitlab-cern:{0}/{1}{2}'.format(
-                base, project, ('#' + version) if version else '')
-            logging.warning('using default: %s', uri)
-            return uri
-
-
-_soft_db = _soft_db_singleton()
-del _soft_db_singleton
-
-
-def getpack(desc, recursive_head=None, export=False, protocol=None):
-    '''
-    Checkout the project described by the Project instance 'desc'.
-    '''
-    from os.path import normpath, join
-    log = __log__.getChild('getpack')
-    protocol = protocol or os.environ.get('GETPACK_PROTOCOL', 'anonymous')
-    getpack_cmd = [
-        'getpack', '--batch', '--no-config', '--no-eclipse', '--branches',
-        '--force', '--protocol', protocol
-    ]
-
-    if recursive_head is None:
-        recursive_head = desc.version == 'HEAD'
-
-    rootdir = os.curdir
-    prjroot = normpath(desc.baseDir)
-    from LbNightlyTools.Configuration import Project
-    if isinstance(desc, Project):
-        # we are checking out a project
-        cmd = getpack_cmd + ['-P', '-H' if recursive_head else '-r']
-    else:
-        # we are checking out a data package
-        cmd = getpack_cmd + ['-v']
-        if desc.container:
-            rootdir = desc.container.baseDir
-    if export:
-        cmd.append('--export')
-    cmd.extend([desc.name, desc.version])
-
-    if not os.path.exists(rootdir):
-        log.debug('creating %s', rootdir)
-        os.makedirs(rootdir)
-
-    log.debug('checking out %s', desc)
-    outputs = [retry_log_call(cmd, cwd=rootdir, retry=3)]
-
-    if hasattr(desc, 'overrides') and desc.overrides:
-        errors = False
-        log.debug('overriding packages')
-        for package, version in desc.overrides.items():
-            if version:
-                cmd = getpack_cmd + [package, version]
-                try:
-                    # ensure we do not get conflicts when changing version
-                    vers_cmt_file = join(prjroot, package, 'cmt',
-                                         'version.cmt')
-                    if os.path.exists(vers_cmt_file):
-                        # remove the file generated by getpack
-                        os.remove(vers_cmt_file)
-                        # ensure that the directory matches the svn state
-                        # (if version.cmt was actually under version control)
-                        log_call(['svn', 'revert', package], cwd=prjroot)
-                    outputs.append(retry_log_call(cmd, cwd=prjroot, retry=3))
-                except RuntimeError, x:
-                    log.warning(str(x))
-                    errors = True
-            else:
-                log.debug('removing %s', package)
-                outputs.append({
-                    'retcode': 0,
-                    'stdout': 'Removing %s\n' % package,
-                    'stderr': ''
-                })
-                shutil.rmtree(join(prjroot, package), ignore_errors=True)
-        if errors:
-            raise RuntimeError('problems handling overrides')
-
-    log.debug('checkout of %s completed in %s', desc, prjroot)
-    return _merge_outputs(outputs)
-
-
 def ignore(desc, export=False):
-    '''
+    """
     Special checkout function used to just declare a project version in the
     configuration but do not perform the checkout, so that it's picked up from
     the release area.
-    '''
-    log = __log__.getChild('ignore')
-    log.info('checkout not requested for %s', desc)
+    """
+    log = __log__.getChild("ignore")
+    log.info("checkout not requested for %s", desc)
     return {
-        'retcode': 0,
-        'stdout': 'checkout not requested for %s' % desc,
-        'stderr': ''
+        "retcode": 0,
+        "stdout": "checkout not requested for %s" % desc,
+        "stderr": "",
     }
 
 
 class GitRepository(object):
-    '''
+    """
     Class to simplify manipulation of local git repositories.
-    '''
+    """
 
     def __init__(self, path=os.curdir, url=None):
-        '''
+        """
         Create an instance from an existing repository or cloning a remote one.
-        '''
-        log = __log__.getChild('git')
+        """
+        log = __log__.getChild("git")
         if url:
-            log.debug('cloning git repository %s', url)
-            retry_log_call(['git', 'clone', '--no-checkout', url, path],
-                           retry=3,
-                           retry_sleep=600)
-        assert os.path.isdir(os.path.join(path,
-                                          '.git')), 'not a git repository'
+            log.debug("cloning git repository %s", url)
+            retry_log_call(
+                ["git", "clone", "--no-checkout", url, path], retry=3, retry_sleep=600
+            )
+        assert os.path.isdir(os.path.join(path, ".git")), "not a git repository"
         self.path = path
 
-        if url and 'gitlab.cern.ch' in url:
+        if url and "gitlab.cern.ch" in url:
             # fetch merge request branches (if it's a gitlab repository)
-            proc = Popen(['git', 'config', '--get-all', 'remote.origin.fetch'],
-                         cwd=self.path,
-                         stdout=PIPE)
-            if 'origin/merge-requests' not in proc.communicate()[0].decode():
+            proc = Popen(
+                ["git", "config", "--get-all", "remote.origin.fetch"],
+                cwd=self.path,
+                stdout=PIPE,
+            )
+            if "origin/merge-requests" not in proc.communicate()[0].decode(
+                "utf-8", errors="replace"
+            ):
                 # it must be configured
-                __log__.getChild('git').debug(
-                    'getting merge-requests branches')
-                fetch = ('+refs/merge-requests/*/head:'
-                         'refs/remotes/origin/merge-requests/*')
+                __log__.getChild("git").debug("getting merge-requests branches")
+                fetch = (
+                    "+refs/merge-requests/*/head:"
+                    "refs/remotes/origin/merge-requests/*"
+                )
                 log_call(
-                    ['git', 'config', '--add', 'remote.origin.fetch', fetch],
-                    cwd=self.path)
-                retry_log_call(['git', 'fetch', '-q', 'origin'],
-                               cwd=self.path,
-                               retry=3,
-                               retry_sleep=600)
+                    ["git", "config", "--add", "remote.origin.fetch", fetch],
+                    cwd=self.path,
+                )
+                retry_log_call(
+                    ["git", "fetch", "-q", "origin"],
+                    cwd=self.path,
+                    retry=3,
+                    retry_sleep=600,
+                )
 
     def remotes(self):
-        '''
+        """
         Return the remote repositories defined for fetch, as a dictionary
         name -> url.
-        '''
-        proc = Popen(['git', 'remote', '-v'], cwd=self.path, stdout=PIPE)
-        lines = proc.communicate()[0].decode().splitlines()
-        pattern = re.compile(r'(\S+)\s+(\S+)\s+\(fetch\)$')
-        return dict(
-            m.groups() for m in filter(None, map(pattern.match, lines)))
+        """
+        proc = Popen(["git", "remote", "-v"], cwd=self.path, stdout=PIPE)
+        lines = proc.communicate()[0].decode("utf-8", errors="replace").splitlines()
+        pattern = re.compile(r"(\S+)\s+(\S+)\s+\(fetch\)$")
+        return dict(m.groups() for m in map(pattern.match, lines) if m)
 
     def branches(self):
-        '''
+        """
         Return a list of all branches (local and remote) known by the
         repository.
-        '''
-        proc = Popen(['git', 'branch', '-a'], cwd=self.path, stdout=PIPE)
-        return set(branch[2:].rstrip()
-                   for branch in proc.communicate()[0].decode().splitlines())
+        """
+        proc = Popen(["git", "branch", "-a"], cwd=self.path, stdout=PIPE)
+        return set(
+            branch[2:].rstrip()
+            for branch in proc.communicate()[0]
+            .decode("utf-8", errors="replace")
+            .splitlines()
+        )
 
     def tags(self):
-        '''
+        """
         Return a list of all tags known by the repository.
-        '''
-        proc = Popen(['git', 'tag'], cwd=self.path, stdout=PIPE)
+        """
+        proc = Popen(["git", "tag"], cwd=self.path, stdout=PIPE)
         return set(
-            tag.strip() for tag in proc.communicate()[0].decode().splitlines())
+            tag.strip()
+            for tag in proc.communicate()[0]
+            .decode("utf-8", errors="replace")
+            .splitlines()
+        )
 
     def add_remote(self, name, url, retry=True):
-        '''
+        """
         Add a new remote repository definition.
-        '''
-        __log__.getChild('git').debug('adding remote %s as %s', url, name)
-        log_call(['git', 'remote', 'add', name, url], cwd=self.path)
-        retry_log_call(['git', 'fetch', '-q', name],
-                       cwd=self.path,
-                       retry=3 if retry else 0,
-                       retry_sleep=600)
-        retry_log_call(['git', 'fetch', '-q', '--tags', name],
-                       cwd=self.path,
-                       retry=3 if retry else 0,
-                       retry_sleep=600)
-
-    def create_branch(self, name, commit='HEAD'):
-        __log__.getChild('git').debug(
-            'creating and checkint out branch %s from %s', name, commit)
-        log_call(['git', 'checkout', '-b', name, commit], cwd=self.path)
+        """
+        __log__.getChild("git").debug("adding remote %s as %s", url, name)
+        log_call(["git", "remote", "add", name, url], cwd=self.path)
+        retry_log_call(
+            ["git", "fetch", "-q", name],
+            cwd=self.path,
+            retry=3 if retry else 0,
+            retry_sleep=600,
+        )
+        retry_log_call(
+            ["git", "fetch", "-q", "--tags", name],
+            cwd=self.path,
+            retry=3 if retry else 0,
+            retry_sleep=600,
+        )
+
+    def create_branch(self, name, commit="HEAD"):
+        __log__.getChild("git").debug(
+            "creating and checkint out branch %s from %s", name, commit
+        )
+        log_call(["git", "checkout", "-b", name, commit], cwd=self.path)
 
-    def resolve_commit(self, commit, remote='origin'):
-        '''
+    def resolve_commit(self, commit, remote="origin"):
+        """
         Try to resolve the commit as a qualified branch name (from the remote),
         and return the found name and the commit id.
 
         If the commit is not the name of a branch, it's used as is.
-        '''
-        if not commit or commit == 'HEAD':
+        """
+        if not commit or commit == "HEAD":
             # get the current branch name (http://stackoverflow.com/a/1418022)
-            commit = self.rev_parse('--abbrev-ref', 'HEAD')
+            commit = self.rev_parse("--abbrev-ref", "HEAD")
         else:
             branches = self.branches()
 
             if commit not in branches:
-                for branch in [
-                        '{0}/{1}'.format(remote, commit), '{0}'.format(commit)
-                ]:
-                    if ('remotes/' + branch) in branches:
+                for branch in ["{0}/{1}".format(remote, commit), "{0}".format(commit)]:
+                    if ("remotes/" + branch) in branches:
                         commit = branch
                         break
 
         commit_id = self.rev_parse(commit)
         return commit, commit_id
 
     def checkout(self, commit, paths=None, quiet=False):
-        '''
+        """
         Checkout the required commit, optionally limited to the specified
         paths.
-        '''
+        """
         if isinstance(paths, basestring):
             paths = [paths]
         if paths:
-            paths.insert(0, '--')
+            paths.insert(0, "--")
         else:
             paths = []
-        cmd = ['git', 'checkout', commit] + paths
+        cmd = ["git", "checkout", commit] + paths
         if quiet:
-            cmd.insert(2, '--quiet')
+            cmd.insert(2, "--quiet")
         return log_call(cmd, cwd=self.path)
 
     def init_submodules(self):
-        '''
+        """
         Initialize and update defined submodules, if present.
-        '''
-        if os.path.exists(os.path.join(self.path, '.gitmodules')):
+        """
+        if os.path.exists(os.path.join(self.path, ".gitmodules")):
             try:
                 retry_log_call(
-                    ['git', 'submodule', 'update', '--init', '--recursive'],
+                    ["git", "submodule", "update", "--init", "--recursive"],
                     cwd=self.path,
                     retry=3,
-                    retry_sleep=30)
+                    retry_sleep=30,
+                )
             except RuntimeError as err:
                 __log__.warning(str(err))
             return [
-                os.path.join(self.path,
-                             l.split()[1]) for l in
-                Popen(['git', 'submodule', 'status', '--recursive'],
-                      cwd=self.path,
-                      stdout=PIPE).communicate()[0].decode().splitlines()
+                os.path.join(self.path, l.split()[1])
+                for l in Popen(
+                    ["git", "submodule", "status", "--recursive"],
+                    cwd=self.path,
+                    stdout=PIPE,
+                )
+                .communicate()[0]
+                .decode("utf-8", errors="replace")
+                .splitlines()
             ]
         return []
 
     def merge(self, commit, extra_args=None):
-        '''
+        """
         Merge the specified commit into the current branch.
-        '''
-        cmd = ['git', 'merge', '--no-ff']
+        """
+        cmd = ["git", "merge", "--no-ff"]
         if extra_args:
             cmd.extend(extra_args)
         cmd.append(commit)
         results = log_call(cmd, cwd=self.path)
-        if results['retcode']:
-            __log__.getChild('git').debug('revert to previous state')
+        if results["retcode"]:
+            __log__.getChild("git").debug("revert to previous state")
             self.reset(hard=True)
         return results
 
-    def reset(self, commit='HEAD', hard=False):
-        '''
+    def reset(self, commit="HEAD", hard=False):
+        """
         Call a git reset on the repository.
-        '''
-        cmd = ['git', 'reset']
+        """
+        cmd = ["git", "reset"]
         if hard:
-            cmd.append('--hard')
+            cmd.append("--hard")
         cmd.append(commit)
         log_call(cmd, cwd=self.path)
 
-    def tag(self, name, commit='HEAD', message=None, force=False):
-        '''
+    def tag(self, name, commit="HEAD", message=None, force=False):
+        """
         Tag a given commit (default HEAD).
-        '''
-        cmd = ['git', 'tag']
+        """
+        cmd = ["git", "tag"]
         if force:
-            cmd.append('-f')
+            cmd.append("-f")
         if message:
-            cmd.extend(['-m', message])
+            cmd.extend(["-m", message])
         cmd.extend([name, commit])
         log_call(cmd, cwd=self.path)
 
-    def push_tag(self, name, remote='origin', force=False):
-        '''
+    def push_tag(self, name, remote="origin", force=False):
+        """
         Push a tag to the remote repository.
-        '''
-        cmd = ['git', 'push']
+        """
+        cmd = ["git", "push"]
         if force:
-            cmd.append('-f')
-        cmd.extend([remote, 'tag', name])
+            cmd.append("-f")
+        cmd.extend([remote, "tag", name])
         log_call(cmd, cwd=self.path)
 
-    def push_branch(self, name, remote='origin', force=False):
-        '''
+    def push_branch(self, name, remote="origin", force=False):
+        """
         Push a branch to the remote repository.
-        '''
-        cmd = ['git', 'push']
+        """
+        cmd = ["git", "push"]
         if force:
-            cmd.append('-f')
+            cmd.append("-f")
         cmd.extend([remote, name])
         log_call(cmd, cwd=self.path)
 
     def rev_parse(self, *args):
-        '''
+        """
         Simple wrapper around "git rev-parse".
-        '''
-        cmd = ['git', 'rev-parse']
+        """
+        cmd = ["git", "rev-parse"]
         cmd.extend(args)
-        return Popen(
-            cmd, cwd=self.path, stdout=PIPE).communicate()[0].decode().strip()
+        return (
+            Popen(cmd, cwd=self.path, stdout=PIPE)
+            .communicate()[0]
+            .decode("utf-8", errors="replace")
+            .strip()
+        )
 
     def show_branch(self, *args):
-        '''
+        """
         Simple wrapper around "git show-branch".
-        '''
-        cmd = ['git', 'show-branch']
+        """
+        cmd = ["git", "show-branch"]
         cmd.extend(args)
         log_call(cmd, cwd=self.path)
 
 
 class GitMergeHandler(GitRepository):
-    '''
+    """
     Helper to handle merges to a git repository.
-    '''
+    """
 
     def __init__(self, commit, url=None, remote_name=None, path=os.curdir):
-        '''
+        """
         Initialize the handler with the details of the merge:
 
         @param commit: commit to merge
         @param url: (optional) url for the incoming commit
         @param remote_name: (optional) name to use for the remote repository
-        '''
+        """
         GitRepository.__init__(self, path)
         self.apply_result = None
         self.remote_name = self.prepare_remote(remote_name, url)
-        self.commit, self.commit_id = self.resolve_commit(
-            commit, self.remote_name)
+        self.commit, self.commit_id = self.resolve_commit(commit, self.remote_name)
         if url is None:
             url = self.remotes()[self.remote_name]
-        __log__.getChild('git').debug('merging %s from %s (%s)', self.commit,
-                                      self.remote_name, url)
+        __log__.getChild("git").debug(
+            "merging %s from %s (%s)", self.commit, self.remote_name, url
+        )
 
     def prepare_remote(self, remote_name, url):
-        '''
+        """
         Deduce a valid remote name for the url or check if the provided one can
         be used. If needed add and fetch the remote repository.
 
         Return the correct remote name.
-        '''
+        """
         # check if we need a name for the remote
         remotes = self.remotes()
         if remote_name is None:
             if url is None:
-                return 'origin'
+                return "origin"
             # see if the url is already known
             for remote_name in remotes:
                 if url == remotes[remote_name]:
                     break
             else:
                 # we need a new name
-                remote_name = 'merge_source'
+                remote_name = "merge_source"
                 i = 0
                 while remote_name in remotes:
-                    remote_name = 'merge_source_{0}'.format(i)
+                    remote_name = "merge_source_{0}".format(i)
                     i += 1
         elif remote_name in remotes and url and url != remotes[remote_name]:
-            raise RuntimeError('remote name %s already used for %s',
-                               remote_name, remotes[remote_name])
+            raise RuntimeError(
+                "remote name %s already used for %s", remote_name, remotes[remote_name]
+            )
 
         if remote_name not in remotes:
             # we need to fetch
             self.add_remote(remote_name, url)
 
         return remote_name
 
     def apply(self):
-        '''
+        """
         Apply the merge.
-        '''
-        self.apply_result = self.merge(self.commit)['retcode'] == 0
+        """
+        self.apply_result = self.merge(self.commit)["retcode"] == 0
         return self.apply_result
 
     def __str__(self):
-        '''
+        """
         String representation.
-        '''
+        """
         if self.commit_id.startswith(self.commit):
-            if self.remote_name == 'origin':
+            if self.remote_name == "origin":
                 return self.commit_id
             else:
-                return '{0} ({1})'.format(self.commit_id, self.remote_name)
+                return "{0} ({1})".format(self.commit_id, self.remote_name)
         else:
-            return '{0} ({1})'.format(self.commit_id, self.commit)
+            return "{0} ({1})".format(self.commit_id, self.commit)
 
 
 class GitLabMergeRequestHandler(GitRepository):
-    '''
+    """
     Helper to handle (CERN) GitLab merge requests.
-    '''
+    """
 
     def __init__(self, iid, path=os.curdir, commit=None):
-        '''
+        """
         Initialize the handler with the merge request id.
-        '''
+        """
         GitRepository.__init__(self, path)
 
-        url = self.remotes().get('origin', '')
-        if 'gitlab.cern.ch' not in url:
-            raise RuntimeError('cannot handle merge requests for'
-                               ' repositories not in GitLab (%s)' % url)
+        url = self.remotes().get("origin", "")
+        if "gitlab.cern.ch" not in url:
+            raise RuntimeError(
+                "cannot handle merge requests for"
+                " repositories not in GitLab (%s)" % url
+            )
 
         self.prepare()
 
         self.apply_result = None
-        self.gitlab_name = url.split('/', 3)[-1].replace('.git', '')
+        self.gitlab_name = url.split("/", 3)[-1].replace(".git", "")
         self.iid = iid
-        self.commit, self.commit_id = \
-            self.resolve_commit(commit or 'merge-requests/{0}'.format(iid))
+        self.commit, self.commit_id = self.resolve_commit(
+            commit or "merge-requests/{0}".format(iid)
+        )
 
-        __log__.getChild('git').debug(
-            'applying merge request %s: %s', iid,
-            '{gitlab_name}!{iid}'.format(**self.__dict__))
+        __log__.getChild("git").debug(
+            "applying merge request %s: %s",
+            iid,
+            "{gitlab_name}!{iid}".format(**self.__dict__),
+        )
 
     def prepare(self):
-        '''
+        """
         Fetch merge request special branches from GitLab, if needed.
-        '''
-        proc = Popen(['git', 'config', '--get-all', 'remote.origin.fetch'],
-                     cwd=self.path,
-                     stdout=PIPE)
-        if 'origin/merge-requests' not in proc.communicate()[0].decode():
+        """
+        proc = Popen(
+            ["git", "config", "--get-all", "remote.origin.fetch"],
+            cwd=self.path,
+            stdout=PIPE,
+        )
+        if "origin/merge-requests" not in proc.communicate()[0].decode(
+            "utf-8", errors="replace"
+        ):
             # it must be configured
-            __log__.getChild('git').debug('getting merge-requests branches')
-            fetch = ('+refs/merge-requests/*/head:'
-                     'refs/remotes/origin/merge-requests/*')
-            log_call(['git', 'config', '--add', 'remote.origin.fetch', fetch],
-                     cwd=self.path)
-            retry_log_call(['git', 'fetch', '-q', 'origin'],
-                           cwd=self.path,
-                           retry=3,
-                           retry_sleep=600)
+            __log__.getChild("git").debug("getting merge-requests branches")
+            fetch = (
+                "+refs/merge-requests/*/head:" "refs/remotes/origin/merge-requests/*"
+            )
+            log_call(
+                ["git", "config", "--add", "remote.origin.fetch", fetch], cwd=self.path
+            )
+            retry_log_call(
+                ["git", "fetch", "-q", "origin"],
+                cwd=self.path,
+                retry=3,
+                retry_sleep=600,
+            )
 
     def apply(self):
-        '''
+        """
         Apply the merge.
-        '''
-        self.apply_result = self.merge(self.commit)['retcode'] == 0
+        """
+        self.apply_result = self.merge(self.commit)["retcode"] == 0
         return self.apply_result
 
     def __str__(self):
-        '''
+        """
         String representation.
-        '''
-        return '{0} ({1}!{2})'.format(self.commit_id[:8], self.gitlab_name,
-                                      self.iid)
+        """
+        return "{0} ({1}!{2})".format(self.commit_id[:8], self.gitlab_name, self.iid)
+
+
+_SPECIAL_GITLAB_GROUPS = {
+    "Gaudi": "gaudi",
+    "Gaussino": "gaussino",
+}
+
+
+def gitlabGroup(project):
+    """
+    Gitlab group containing the given project.
+
+    >>> gitlabGroup('Moore')
+    'lhcb'
+    >>> gitlabGroup('Gaudi')
+    'gaudi'
+    >>> gitlabGroup('Gaussino')
+    'gaussino'
+    """
+    return _SPECIAL_GITLAB_GROUPS.get(project, "lhcb")
 
 
 def git(proj, url=None, commit=None, export=False, merges=None):
-    '''
+    """
     Checkout from a git repository.
 
     @param proj: Configuration.Project instance
     @param url: git repository URL (default derived from proj.name)
     @param commit: commit id to checkout (default derived from proj.version)
     @param export: whether to use git "checkout" or "archive"
     @param merge: merge options as (<url>, <commit> [, <remote_name>]) or
                   as merge request id or (merge id, commit), or a list of them,
                   or 'all' for all opened merge requests
-    '''
-    output = {
-        'retcode': 0,
-        'stdout': '',
-        'stderr': '',
-        'warning': [],
-        'error': []
-    }
-    log = __log__.getChild('git')
+    """
+    output = {"retcode": 0, "stdout": "", "stderr": "", "warning": [], "error": []}
+    log = __log__.getChild("git")
 
     if not url:
-        from urlparse import urlsplit
-        uri = urlsplit(_soft_db.getSourceURI(proj.name, proj.version))
-        if not uri.scheme:
-            # we are asked to get a getpack project with git
-            path = 'LHCb-SVN-mirrors/' + proj.name
-        else:
-            path = uri.path
-        url = 'https://gitlab.cern.ch/{0}.git'.format(path)
+        from .Configuration import Package
+
+        gitlab_name = "{group}/{name}".format(
+            group="lhcb-datapkg"
+            if isinstance(proj, Package)
+            else gitlabGroup(proj.name),
+            name=proj.name,
+        )
+        url = "https://gitlab.cern.ch/{}.git".format(gitlab_name)
         inGitLab = True
-        gitlab_name = path
-        del path
     else:
-        inGitLab = 'gitlab.cern.ch' in url
-        gitlab_name = url.split('/', 3)[-1].replace('.git', '')
+        inGitLab = "gitlab.cern.ch" in url
+        gitlab_name = url.split("/", 3)[-1].replace(".git", "")
 
-    if proj.version.lower() == 'head':
-        commit_requested = 'master'
+    if proj.version.lower() == "head":
+        commit_requested = "master"
         if not merges:
-            if 'GITLAB_TOKEN' in os.environ:
+            if "GITLAB_TOKEN" in os.environ:
                 # version 'HEAD' implies all merge requests
                 # (see LBCORE-1132)
-                merges = ['all']
+                merges = ["all"]
             else:
-                log.warning('merge requests not applied: no Gitlab token')
-                output['warning'].append(
-                    'merge requests not applied: no Gitlab token')
-    elif re.match(r'mr[0-9]+$', proj.version):
-        commit_requested = 'master'
+                log.warning("merge requests not applied: no Gitlab token")
+                output["warning"].append("merge requests not applied: no Gitlab token")
+    elif re.match(r"mr[0-9]+$", proj.version):
+        commit_requested = "master"
         if not merges:
-            assert inGitLab, ('cannot handle merge requests for'
-                              ' projects not in GitLab (%s)' % proj)
+            assert inGitLab, (
+                "cannot handle merge requests for" " projects not in GitLab (%s)" % proj
+            )
             merges = [int(proj.version[2:])]
             commit_requested = getMRTargetBranch(gitlab_name, merges[0])
     else:
         commit_requested = proj.version
 
     if not commit:
         commit = commit_requested
 
     dest = proj.baseDir
     repo = GitRepository(dest, url)
     commit, commit_id = repo.resolve_commit(commit)
 
-    if isinstance(merges, (tuple, basestring, int, long)):
+    if isinstance(merges, (tuple, basestring, int)):
         merges = [merges]
 
-    if merges and any(str(m).startswith('all') for m in merges):
-        assert inGitLab, ('cannot handle merge requests for'
-                          ' projects not in GitLab (%s)' % proj)
-        assert 'GITLAB_TOKEN' in os.environ, ('cannot connect to GitLab ',
-                                              '(missing token)')
-        idx, merge = [(i, m) for i, m in enumerate(merges)
-                      if str(m).startswith('all')][0]
-        filters = merge.lower().split(':')[1:]
+    if merges and any(str(m).startswith("all") for m in merges):
+        assert inGitLab, (
+            "cannot handle merge requests for" " projects not in GitLab (%s)" % proj
+        )
+        assert "GITLAB_TOKEN" in os.environ, (
+            "cannot connect to GitLab ",
+            "(missing token)",
+        )
+        idx, merge = [(i, m) for i, m in enumerate(merges) if str(m).startswith("all")][
+            0
+        ]
+        filters = merge.lower().split(":")[1:]
         # ensure that we get only merge requests for the requested branch
-        filters.append('target_branch=%s' % (commit_requested or commit))
+        filters.append("target_branch=%s" % (commit_requested or commit))
 
         slotname = None
-        if hasattr(proj, 'slot') and proj.slot:
+        if hasattr(proj, "slot") and proj.slot:
             slotname = proj.slot.name
-        elif (hasattr(proj, 'container') and proj.container
-              and proj.container.slot):
+        elif hasattr(proj, "container") and proj.container and proj.container.slot:
             slotname = proj.container.slot.name
         all_merges = getAllMergeRequestIDs(
-            gitlab_name, filters=filters, labels=[slotname, 'all-slots'])
-        merges = merges[:idx] + all_merges + merges[idx + 1:]
+            gitlab_name, filters=filters, labels=[slotname, "all-slots"]
+        )
+        merges = merges[:idx] + all_merges + merges[idx + 1 :]
 
-    log.debug('checking out %s from %s (%s)', proj, url, commit)
+    log.debug("checking out %s from %s (%s)", proj, url, commit)
 
     def merge_hdlr(merge):
-        '''
+        """
         Return an instance of the appropriate merge handler:
 
         int -> GitLab merge request
         commit -> git merge
         (int, commit) -> GitLab merge request
         (url, commit) -> git merge
         (url, commit, source_name) -> git merge
-        '''
-        if isinstance(merge, (int, long)):
+        """
+        if isinstance(merge, int):
             return GitLabMergeRequestHandler(merge, path=dest)
         elif isinstance(merge, basestring):
             return GitMergeHandler(merge, path=dest)  # pylint: disable=E0601
         elif isinstance(merge, (tuple, list)):
             if len(merge) == 2:
-                if isinstance(merge[0], (int, long)):
+                if isinstance(merge[0], int):
                     miid, commit = merge
-                    return GitLabMergeRequestHandler(
-                        miid, path=dest, commit=commit)
+                    return GitLabMergeRequestHandler(miid, path=dest, commit=commit)
                 else:
                     url, commit = merge
                     return GitMergeHandler(commit, url, path=dest)
             elif len(merge) == 3:
                 url, commit, source = merge
                 return GitMergeHandler(commit, url, source, path=dest)
-        raise RuntimeError('invalid merge description %r', merge)
+        raise RuntimeError("invalid merge description %r", merge)
 
     if merges:
         if export:
-            log.warning('merges option is ignored when export is True')
+            log.warning("merges option is ignored when export is True")
             merges = []
     else:
         merges = []
 
     merge_hdlrs = []
     if not export:
-        log.debug('checkout commit %s for %s', commit, proj)
+        log.debug("checkout commit %s for %s", commit, proj)
         result = repo.checkout(commit_id)
-        assert result['retcode'] == 0, (
-            "could not checkout commit '{}'{}: retcode {retcode}".format(
-                commit_id,
-                '' if commit == commit_id else ' ({})'.format(commit),
-                **result))
+        assert (
+            result["retcode"] == 0
+        ), "could not checkout commit '{}'{}: retcode {retcode}".format(
+            commit_id, "" if commit == commit_id else " ({})".format(commit), **result
+        )
         # do merges
         for merge in merges:
             merge = merge_hdlr(merge)
             success = merge.apply()
             if isinstance(merge, GitLabMergeRequestHandler):
                 notifyMergeRequest(proj, gitlab_name, merge.iid, success)
             if not success:
-                output['warning'].append('failed to merge {}'.format(merge))
+                output["warning"].append("failed to merge {}".format(merge))
             merge_hdlrs.append(merge)
         repo.init_submodules()
-        if hasattr(proj, 'overrides') and proj.overrides:
-            for subdir, version in proj.overrides.iteritems():
+        if hasattr(proj, "overrides") and proj.overrides:
+            for subdir, version in proj.overrides.items():
                 if version is None:
-                    log.debug('removing %s', subdir)
-                    shutil.rmtree(
-                        path=os.path.join(dest, subdir), ignore_errors=True)
+                    log.debug("removing %s", subdir)
+                    shutil.rmtree(path=os.path.join(dest, subdir), ignore_errors=True)
                 else:
-                    log.debug('checking out commit %s for dir %s', version,
-                              subdir)
-                    if repo.checkout(version, subdir)['retcode']:
-                        output['warning'].append(
-                            'failed to checkout commit {} for {}'.format(
-                                version, subdir))
+                    log.debug("checking out commit %s for dir %s", version, subdir)
+                    if repo.checkout(version, subdir)["retcode"]:
+                        output["warning"].append(
+                            "failed to checkout commit {} for {}".format(
+                                version, subdir
+                            )
+                        )
     else:
         # FIXME: the outputs of git archive is not collected
-        log.debug('export commit %s for %s', commit, proj)
+        log.debug("export commit %s for %s", commit, proj)
         repo.checkout(commit_id)
         submodules = repo.init_submodules()
 
         def git_export(path, commit):
-            '''
+            """
             helper for a git equivalent of svn export
-            '''
-            log.debug('export commit %s in %s', commit, path)
-            proc1 = Popen(['git', 'archive', commit], cwd=path, stdout=PIPE)
-            proc2 = Popen(['tar', '--extract', '--overwrite', '--file', '-'],
-                          cwd=path,
-                          stdin=proc1.stdout)
-            proc1.stdout.close(
-            )  # Allow proc1 to receive a SIGPIPE if proc2 exits.
+            """
+            log.debug("export commit %s in %s", commit, path)
+            proc1 = Popen(["git", "archive", commit], cwd=path, stdout=PIPE)
+            proc2 = Popen(
+                ["tar", "--extract", "--overwrite", "--file", "-"],
+                cwd=path,
+                stdin=proc1.stdout,
+            )
+            proc1.stdout.close()  # Allow proc1 to receive a SIGPIPE if proc2 exits.
             if proc2.wait() or proc1.wait():
-                log.warning('problems exporting commit %s in %s', commit, path)
-            shutil.rmtree(path=os.path.join(path, '.git'), ignore_errors=True)
+                log.warning("problems exporting commit %s in %s", commit, path)
+            shutil.rmtree(path=os.path.join(path, ".git"), ignore_errors=True)
 
         git_export(dest, commit)
         for path in submodules:
-            git_export(path, 'HEAD')
+            git_export(path, "HEAD")
 
     from LbNightlyTools.Configuration import Project
+
     if not isinstance(proj, Project):  # it's a Package
-        xenv_name = os.path.join(dest, proj.name.replace('/', '_') + '.xenv')
-        xenv_oldname = xenv_name.replace('.xenv', 'Environment.xml')
+        xenv_name = os.path.join(dest, proj.name.replace("/", "_") + ".xenv")
+        xenv_oldname = xenv_name.replace(".xenv", "Environment.xml")
         if not os.path.exists(xenv_oldname):
             if os.path.exists(xenv_name):
-                log.debug('create symlink %s -> %s',
-                          os.path.basename(xenv_oldname),
-                          os.path.basename(xenv_name))
+                log.debug(
+                    "create symlink %s -> %s",
+                    os.path.basename(xenv_oldname),
+                    os.path.basename(xenv_name),
+                )
                 os.symlink(os.path.basename(xenv_name), xenv_oldname)
 
-    log.debug('checkout of %s completed in %s', proj, dest)
-    log.debug('using commit %s (%s)', commit_id, commit_requested)
+    log.debug("checkout of %s completed in %s", proj, dest)
+    log.debug("using commit %s (%s)", commit_id, commit_requested)
     for merge in merge_hdlrs:
         if merge.apply_result:
-            log.debug('merged commit %s', merge)
+            log.debug("merged commit %s", merge)
         else:
-            log.debug('not merged commit %s', merge)
+            log.debug("not merged commit %s", merge)
     try:
-        if hasattr(proj, 'slot') and proj.slot and proj.slot.build_id:
-            if not gitlabProjectExists('lhcb-nightlies/{}'.format(proj.name)):
-                raise RuntimeError('lhcb-nightlies/{} does not exist'.format(
-                    proj.name))
+        if hasattr(proj, "slot") and proj.slot and proj.slot.build_id and not export:
+            if not gitlabProjectExists("lhcb-nightlies/{}".format(proj.name)):
+                raise RuntimeError("lhcb-nightlies/{} does not exist".format(proj.name))
 
             def branch_name():
-                if os.environ.get('flavour', 'nightly') != 'nightly':
-                    return '{}/{}'.format(os.environ['flavour'],
-                                          proj.slot.name)
+                if os.environ.get("flavour", "nightly") != "nightly":
+                    return "{}/{}".format(os.environ["flavour"], proj.slot.name)
                 return proj.slot.name
 
             def tag_name(previous=False):
-                'compute a tag name for current slot/build_id'
-                return '{}/{}'.format(branch_name(), (proj.slot.build_id - 1)
-                                      if previous else proj.slot.build_id)
+                "compute a tag name for current slot/build_id"
+                return "{}/{}".format(
+                    branch_name(),
+                    (proj.slot.build_id - 1) if previous else proj.slot.build_id,
+                )
 
-            commit = 'HEAD'
-            log.debug('record build sources in lhcb-nightlies')
+            commit = "HEAD"
+            log.debug("record build sources in lhcb-nightlies")
             repo.add_remote(
-                'lhcb-nightlies',
-                'ssh://git@gitlab.cern.ch:7999/lhcb-nightlies/{0}.git'.format(
-                    proj.name),
-                retry=False)
+                "lhcb-nightlies",
+                "ssh://git@gitlab.cern.ch:7999/lhcb-nightlies/{0}.git".format(
+                    proj.name
+                ),
+                retry=False,
+            )
             # log.debug('branches in lhcb-nightlies:')
             # for b in repo.branches():
             #     if 'lhcb-nightlies' in b:
             #         log.debug(' - %r', b)
             project_uses_branches = True
-            if ('remotes/lhcb-nightlies/' + branch_name()) in repo.branches():
-                log.debug('found branch %s', branch_name())
-                if (repo.rev_parse('HEAD:') != repo.rev_parse(
-                        'remotes/lhcb-nightlies/{}:'.format(branch_name()))):
-                    log.debug('content change detected')
+            if ("remotes/lhcb-nightlies/" + branch_name()) in repo.branches():
+                log.debug("found branch %s", branch_name())
+                if repo.rev_parse("HEAD:") != repo.rev_parse(
+                    "remotes/lhcb-nightlies/{}:".format(branch_name())
+                ):
+                    log.debug("content change detected")
                     repo.merge(
-                        'remotes/lhcb-nightlies/' + branch_name(),
-                        extra_args=['-sours', '--no-edit'])
-                    repo.push_branch(
-                        'HEAD:' + branch_name(), remote='lhcb-nightlies')
+                        "remotes/lhcb-nightlies/" + branch_name(),
+                        extra_args=["-sours", "--no-edit"],
+                    )
+                    repo.push_branch("HEAD:" + branch_name(), remote="lhcb-nightlies")
                 else:
-                    log.debug('no change detected')
-                    commit = 'remotes/lhcb-nightlies/' + branch_name()
+                    log.debug("no change detected")
+                    commit = "remotes/lhcb-nightlies/" + branch_name()
 
             elif tag_name(previous=True) not in repo.tags():
-                log.debug('first time in this slot, create the branch')
+                log.debug("first time in this slot, create the branch")
                 # it's the first time we have this project in the slot
                 repo.create_branch(branch_name())
-                repo.push_branch(
-                    branch_name(), remote='lhcb-nightlies', force=True)
+                repo.push_branch(branch_name(), remote="lhcb-nightlies", force=True)
 
             else:  # old logic
                 project_uses_branches = False
                 # look for a tag with the same content (tree)
-                tree = repo.rev_parse('HEAD:')
-                proc = Popen([
-                    'git', 'for-each-ref', '--python', '--sort=-*creatordate',
-                    '--format=%(refname),'
-                ],
-                             cwd=repo.path,
-                             stdout=PIPE)
+                tree = repo.rev_parse("HEAD:")
+                proc = Popen(
+                    [
+                        "git",
+                        "for-each-ref",
+                        "--python",
+                        "--sort=-*creatordate",
+                        "--format=%(refname),",
+                    ],
+                    cwd=repo.path,
+                    stdout=PIPE,
+                )
                 # (test requested commit first)
-                log.debug('looking for an equivalent commit')
-                for ref in eval('[{!r},'.format(commit_requested) +
-                                proc.communicate()[0].decode() + ']'):
-                    if repo.rev_parse(ref + ':') == tree:
-                        proc = Popen(['git', 'rev-list', '--max-count=1', ref],
-                                     cwd=repo.path,
-                                     stdout=PIPE)
-                        commit = proc.communicate()[0].decode().strip()
-                        log.debug('reusing commit %s (%s)', commit, ref)
+                log.debug("looking for an equivalent commit")
+                for ref in eval(
+                    "[{!r},".format(commit_requested)
+                    + proc.communicate()[0].decode("utf-8", errors="replace")
+                    + "]"
+                ):
+                    if repo.rev_parse(ref + ":") == tree:
+                        proc = Popen(
+                            ["git", "rev-list", "--max-count=1", ref],
+                            cwd=repo.path,
+                            stdout=PIPE,
+                        )
+                        commit = (
+                            proc.communicate()[0]
+                            .decode("utf-8", errors="replace")
+                            .strip()
+                        )
+                        log.debug("reusing commit %s (%s)", commit, ref)
                         break  # we found a commit with the same content
                 else:  # we could not find it, so we stick to HEAD
-                    log.debug('none found')
+                    log.debug("none found")
 
             repo.tag(tag_name(), commit=commit, force=True)
-            repo.push_tag(tag_name(), remote='lhcb-nightlies', force=True)
+            repo.push_tag(tag_name(), remote="lhcb-nightlies", force=True)
             # make sure the commit id of HEAD is exactly that used for the tag
             repo.checkout(tag_name(), quiet=True)
-            if (not proj.slot.metadata.get('ci_test')
-                    and tag_name(previous=True) in repo.tags()):
+            if (
+                not proj.slot.metadata.get("ci_test")
+                and tag_name(previous=True) in repo.tags()
+            ):
                 # report changes between the previous build and this one
                 # (unless it's a special ci-test slot)
                 if project_uses_branches:
-                    repo.show_branch('--sha1-name',
-                                     tag_name(previous=True) + '~',
-                                     tag_name() + '~')
+                    repo.show_branch(
+                        "--sha1-name", tag_name(previous=True) + "~", tag_name() + "~"
+                    )
                 else:
-                    repo.show_branch('--sha1-name', tag_name(previous=True),
-                                     tag_name())
-    except Exception, x:  # pylint: disable=W0703
-        log.warning('failed to record built sources: %s', x)
+                    repo.show_branch("--sha1-name", tag_name(previous=True), tag_name())
+    except Exception as x:  # pylint: disable=W0703
+        log.warning("failed to record built sources: %s", x)
     return output
 
 
 def svn(desc, url, export=False):
-    '''
+    """
     Checkout from an svn repository.
-    '''
-    log = __log__.getChild('svn')
-    log.debug('checking out %s from %s', desc, url)
+    """
+    log = __log__.getChild("svn")
+    log.debug("checking out %s from %s", desc, url)
     dest = desc.baseDir
-    output = log_call(
-        ['svn', 'checkout' if not export else 'export', url, dest])
-    log.debug('checkout of %s completed in %s', desc, dest)
+    output = log_call(["svn", "checkout" if not export else "export", url, dest])
+    log.debug("checkout of %s completed in %s", desc, dest)
     return output
 
 
 def copy(desc, src, export=False):
-    '''
+    """
     Copy the content of a directory.
-    '''
-    log = __log__.getChild('copy')
-    log.debug('copying %s from %s', desc, src)
+    """
+    log = __log__.getChild("copy")
+    log.debug("copying %s from %s", desc, src)
     dest = desc.baseDir
     shutil.copytree(os.path.join(src, os.curdir), dest)
-    log.debug('copy of %s completed in %s', desc, dest)
-    return {
-        'retcode': 0,
-        'stdout': 'copied %s from %s' % (desc, src),
-        'stderr': ''
-    }
+    log.debug("copy of %s completed in %s", desc, dest)
+    return {"retcode": 0, "stdout": "copied %s from %s" % (desc, src), "stderr": ""}
 
 
 def untar(desc, src, export=False):
-    '''
+    """
     Unpack a tarball in the current directory (assuming that the tarball
     already contains the <PROJECT>/<PROJECT>_<version> directories).
-    '''
-    log = __log__.getChild('untar')
-    log.debug('unpacking %s', src)
-    output = log_call(['tar', '-x', '-f', src])
+    """
+    log = __log__.getChild("untar")
+    log.debug("unpacking %s", src)
+    output = log_call(["tar", "-x", "-f", src])
     dest = desc.baseDir
     if not os.path.isdir(dest):
-        raise RuntimeError('the tarfile %s does not contain %s', src,
-                           desc.baseDir)
-    log.debug('unpacking of %s from %s completed', desc, src)
+        raise RuntimeError("the tarfile %s does not contain %s", src, desc.baseDir)
+    log.debug("unpacking of %s from %s completed", desc, src)
     return output
 
 
 def unzip(desc, src, export=False):
-    '''
+    """
     Unpack a tarball in the current directory (assuming that the tarball
     already contains the <PROJECT>/<PROJECT>_<version> directories).
-    '''
-    log = __log__.getChild('unzip')
-    log.debug('unpacking %s', src)
-    output = log_call(['unzip', '-q', '-o', src])
+    """
+    log = __log__.getChild("unzip")
+    log.debug("unpacking %s", src)
+    output = log_call(["unzip", "-q", "-o", src])
     dest = desc.baseDir
     if not os.path.isdir(dest):
-        raise RuntimeError('the zipfile %s does not contain %s', src,
-                           desc.baseDir)
-    log.debug('unpacking of %s from %s completed', desc, src)
+        raise RuntimeError("the zipfile %s does not contain %s", src, desc.baseDir)
+    log.debug("unpacking of %s from %s completed", desc, src)
     return output
 
 
-LCG_MAKEFILE_TEMPLATE = '''
+LCG_MAKEFILE_TEMPLATE = """
 configure:
 \tfor s in "{src}"/* ; do if [ -d "$$s" ] ; then ln -svf "$$s" . ; else cp -vf "$$s" . ; fi ; done
 \tfor s in LCG_externals_*.txt ; do sed -i 's*{src}*'$$(pwd)'*' "$$s" ; done
 
 all:
 install:
 \tmkdir -p InstallArea/$${{CMTCONFIG:-$$BINARY_TAG}}
 \ttouch InstallArea/$${{CMTCONFIG:-$$BINARY_TAG}}/.empty
 unsafe-install: install
 post-install:
 test:
-'''
+"""
 
 
 def lcg(proj, src=None):
-    '''
+    """
     Special checkout method to create a shallow clone of the LCG special
     project.
-    '''
-    log = __log__.getChild('lcg')
+    """
+    log = __log__.getChild("lcg")
 
     if not src:
         src = proj.src
     dest = proj.baseDir
 
     if not os.path.exists(dest):
-        log.debug('created %s', dest)
+        log.debug("created %s", dest)
         os.makedirs(dest)
 
-    with open(os.path.join(dest, 'Makefile'), 'w') as mkf:
+    with open(os.path.join(dest, "Makefile"), "w") as mkf:
         mkf.write(LCG_MAKEFILE_TEMPLATE.format(src=src))
-        log.debug('created %s', mkf.name)
+        log.debug("created %s", mkf.name)
 
-    log.info('created shallow project %s in %s', proj, dest)
+    log.info("created shallow project %s in %s", proj, dest)
 
-    return {'retcode': 0, 'stdout': '', 'stderr': ''}
+    return {"retcode": 0, "stdout": "", "stderr": ""}
 
 
 def lbscripts(proj, url=None, export=False, merges=None, commit=None):
-    '''
+    """
     Specific checkout wrapper for lbscripts
-    '''
-    from LbScriptsUtils import (updateInstallProject,
-                                updateLbConfigurationRequirements,
-                                updateVersionCmt)
+    """
+    from .LbScriptsUtils import (
+        updateInstallProject,
+        updateLbConfigurationRequirements,
+        updateVersionCmt,
+    )
 
-    log = __log__.getChild('lbscripts')
+    log = __log__.getChild("lbscripts")
 
     # Utilities to gather the results of our calls
     outputs = []
 
     def call(*args, **kwargs):
-        'helper to simplify the code'
-        kwargs['logger'] = log
+        "helper to simplify the code"
+        kwargs["logger"] = log
         outputs.append(log_call(*args, **kwargs))
 
     # First checking out LbScripts with GIT
-    outputs.append(
-        git(proj, url=url, commit=commit, export=export, merges=merges))
+    outputs.append(git(proj, url=url, commit=commit, export=export, merges=merges))
 
     # Now hacking the sources.
     # We need to set the version in LbConfiguration and in install_project
     updateInstallProject(proj.baseDir, proj.version)
     updateLbConfigurationRequirements(proj.baseDir, proj.version)
 
     # Create the version.cmt file in all packages
     updateVersionCmt(proj.baseDir, proj.version)
 
     # Now calling make directly after the checkout
     # This is needed to have the InstallArea directory in the source archive
-    call(['make', 'USE_CMT=1'], cwd=proj.baseDir)
+    call(["make", "USE_CMT=1"], cwd=proj.baseDir)
 
     # make sure that the project is flagged as platform independent
     proj.platform_independent = True
 
     # Returning the checkout results
     return _merge_outputs(outputs)
 
 
-def default(proj, *args, **kwargs):
-    '''
-    Delegate to the correct method, depending on the project name and version.
-    '''
-    from Configuration import Package
-    if isinstance(proj, Package):
-        # packages are not yet in the database
-        url = kwargs.get('url')
-        if not url:
-            gitlab_name = 'lhcb-datapkg/{}'.format(proj.name)
-            if gitlabProjectExists(gitlab_name):
-                logging.debug('%s is in CERN Gitlab', proj.name)
-                kwargs['url'] = (
-                    'https://gitlab.cern.ch/{}.git').format(gitlab_name)
-                return git(proj, *args, **kwargs)
-            else:
-                logging.debug('could not find %s in CERN Gitlab', proj.name)
-        elif '.git' in url:
-            return git(proj, *args, **kwargs)
-        return getpack(proj, *args, **kwargs)
-
-    from urlparse import urlsplit
-    logging.debug('getting source URI from SoftDB')
-    uri = _soft_db.getSourceURI(proj.name, proj.version)
-    logging.debug('got %s', uri)
-
-    uri = urlsplit(uri)
-    if not uri.scheme:
-        return getpack(proj, *args, **kwargs)
-    elif uri.scheme == 'gitlab-cern':
-        if not args and 'url' not in kwargs:
-            kwargs['url'] = 'https://gitlab.cern.ch/{0.path}.git'.format(uri)
-        if 'commit' not in kwargs and proj.version != uri.fragment:
-            kwargs['commit'] = uri.fragment
-        return git(proj, *args, **kwargs)
+def default(*args, **kwargs):
+    return git(*args, **kwargs)
 
 
 def getMethod(method=None):
-    '''
+    """
     Helper function to get a checkout method by name.
 
     If method is a callable we return it, otherwise we look for the name in the
     current module or as a function coming from another module.
     If method is None, we return the default checkout method.
-    '''
+    """
     if method is None:
         return default
-    if hasattr(method, '__call__'):
+    if hasattr(method, "__call__"):
         return method
     if isinstance(method, basestring):
-        if '.' in method:
+        if "." in method:
             # method is a fully qualified function name
-            m, f = method.rsplit('.', 1)
+            m, f = method.rsplit(".", 1)
             return getattr(__import__(m, fromlist=[f]), f)
         else:
             # it must be a name in this module
             return globals()[method]
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/Configuration.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/Configuration.py`

 * *Files 10% similar despite different names*

```diff
@@ -5,57 +5,76 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Common functions to deal with the configuration files.
-'''
-__author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+"""
+from __future__ import absolute_import, print_function
 
+from future import standard_library
+
+standard_library.install_aliases()
+from builtins import object
+
+from future.utils import with_metaclass
+from past.builtins import basestring
+
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
+
+import copy
+import json
+import logging
 import os
 import re
-import logging
 import sys
-import copy
-import urllib2
-import urllib
-import json
-from datetime import datetime
+import urllib.error
+import urllib.parse
+import urllib.request
 from collections import OrderedDict, namedtuple
-from StringIO import StringIO
+from datetime import datetime
+from io import StringIO
 
-from LbNightlyTools.Utils import (applyenv, ensureDirs, shallow_copytree,
-                                  IgnorePackageVersions, find_path,
-                                  write_patch, Dashboard)
-from LbNightlyTools import CheckoutMethods, BuildMethods
+from LbNightlyTools import BuildMethods, CheckoutMethods
+from LbNightlyTools.Utils import (
+    Dashboard,
+    IgnorePackageVersions,
+    applyenv,
+    ensureDirs,
+    find_path,
+    shallow_copytree,
+    write_patch,
+)
 
 __log__ = logging.getLogger(__name__)
-__meta_log__ = logging.getLogger(__name__ + '.meta')
+__meta_log__ = logging.getLogger(__name__ + ".meta")
 __meta_log__.setLevel(
-    logging.DEBUG if os.environ.get('DEBUG_METACLASSES') else logging.WARNING)
+    logging.DEBUG if os.environ.get("DEBUG_METACLASSES") else logging.WARNING
+)
 
 _slot_factories = set()
 
 
 def slot_factory(f):
-    '''
+    """
     Decorator used to flag a function as a Slot factory to correctly
     trace the module defining a slot.
-    '''
+    """
     global _slot_factories
     _slot_factories.add(f.__name__)
     return f
 
 
 # constants
-GP_EXP = re.compile(r'gaudi_project\(([^)]+)\)')
-HT_EXP = re.compile(r'set\(\s*heptools_version\s+([^)]+)\)')
+GP_EXP = re.compile(r"gaudi_project\(([^)]+)\)")
+HT_EXP = re.compile(r"set\(\s*heptools_version\s+([^)]+)\)")
+VALID_PLATFORM_RE = r"^[0-9a-z_+.]+-[0-9a-z_]+-[0-9a-z_+]+-[0-9a-z_+]+$"
 
 # all configured slots (Slot instances)
 slots = {}
 
 DEFAULT_REQUIRED_EXTERNALS = [
     "AIDA",
     "Boost",
@@ -90,93 +109,86 @@
     "XercesC",
     "xqilla",
     "xrootd",
 ]
 
 
 def sortedByDeps(deps):
-    '''
+    """
     Take a dictionary of dependencies as {'depender': ['dependee', ...]} and
     return the list of keys sorted according to their dependencies so that
     that a key comes after its dependencies.
 
-    >>> sortedByDeps({'4':['2','3'],'3':['1'],'2':['1'],'1':['0'],'0':[]})
-    ['0', '1', '3', '2', '4']
-
-    If the argument is an OrderedDict, the returned list preserves the order of
-    the keys (if possible).
-
-    >>> sortedByDeps(dict([('1', []), ('2', ['1']), ('3', ['1'])]))
-    ['1', '3', '2']
-    >>> sortedByDeps(OrderedDict([('1', []), ('2', ['1']), ('3', ['1'])]))
-    ['1', '2', '3']
-    '''
+    >>> sortedByDeps({'4':['2','3'],'3':['1'],'2':['1'],'1':['0'],'0':[]})  # doctest: +SKIP
+    ['0', '1', '2', '3', '4']
+    """
 
     def unique(iterable):
-        '''Return only the unique elements in the list l.
+        """Return only the unique elements in the list l.
 
         >>> unique([0, 0, 1, 2, 1])
         [0, 1, 2]
-        '''
+        """
         uniquelist = []
         for item in iterable:
             if item not in uniquelist:
                 uniquelist.append(item)
         return uniquelist
 
     def recurse(keys):
-        '''
+        """
         Recursive helper function to sort by dependency: for each key we
-        first add (recursively) its dependencies then the key itself.'''
+        first add (recursively) its dependencies then the key itself."""
         result = []
         for k in keys:
             result.extend(recurse(deps[k]))
             result.append(k)
         return unique(result)
 
     return recurse(deps)
 
 
 class UTFStringIO(StringIO):
-    '''
+    """
     Avoid issues with mixed ASCII and Unicode inputs to StringIO.
-    '''
+    """
 
     def write(self, s):
         if isinstance(s, bytes):
-            s = s.decode('utf-8')
+            s = s.decode("utf-8", errors="replace")
         return StringIO.write(self, s)
 
 
 class RecordLogger(object):
-    '''
+    """
     Decorator to collect the log messages of a Logger instance in a data member
     of the instance.
 
     @param logger: Logger instance or name (default: use the root Logger)
     @param data_member: name of the property of the instance bound to the method
                         where to record the log (default: method name + '_log')
-    '''
+    """
 
-    def __init__(self, logger='', data_member=None):
-        '''
+    def __init__(self, logger="", data_member=None):
+        """
         Initialize the decorator.
-        '''
+        """
         if isinstance(logger, basestring):
             logger = logging.getLogger(logger)
         self.logger = logger
         self.data_member = data_member
 
     def __call__(self, method):
-        '''
+        """
         Decorate the method.
-        '''
+        """
         from functools import wraps
+
         logger = self.logger
-        data_member = self.data_member or (method.__name__ + '_log')
+        data_member = self.data_member or (method.__name__ + "_log")
 
         @wraps(method)
         def log_recorder(self, *args, **kwargs):
             data = UTFStringIO()
             hdlr = logging.StreamHandler(data)
             logger.addHandler(hdlr)
 
@@ -187,77 +199,77 @@
                 logger.removeHandler(hdlr)
 
             return result
 
         return log_recorder
 
 
-def log_timing(logger='', level=logging.DEBUG):
-    '''
+def log_timing(logger="", level=logging.DEBUG):
+    """
     Decorator to add log messages about the time a method takes.
-    '''
+    """
     if isinstance(logger, basestring):
         logger = logging.getLogger(logger)
 
     def decorate(method):
         from functools import wraps
 
         @wraps(method)
         def log_timing_wrapper(*args, **kwargs):
             start_time = datetime.now()
-            logger.log(level, 'Started at: %s', start_time)
+            logger.log(level, "Started at: %s", start_time)
             result = method(*args, **kwargs)
             end_time = datetime.now()
-            logger.log(level, 'Completed at: %s', end_time)
-            logger.log(level, 'Elapsed time: %s', end_time - start_time)
+            logger.log(level, "Completed at: %s", end_time)
+            logger.log(level, "Elapsed time: %s", end_time - start_time)
             return result
 
         return log_timing_wrapper
 
     return decorate
 
 
 def log_enter_step(msg=None):
-    '''
+    """
     Decorator to log entering and exiting from a method of an object.
-    '''
+    """
 
     def decorate(method):
         from functools import wraps
 
         @wraps(method)
         def log_enter_step_wrapper(self, *args, **kwargs):
-            __log__.info(msg + ' %s', self)
-            __log__.debug('  with args %s, %s', args, kwargs)
+            __log__.info(msg + " %s", self)
+            __log__.debug("  with args %s, %s", args, kwargs)
             return method(self, *args, **kwargs)
 
         return log_enter_step_wrapper
 
     return decorate
 
 
 def extend_kwargs(extra_opts_name):
-    '''
+    """
     Decorator to define default keyword arguments of a method via an instance
     property.
 
     >>> class MyClass(object):
     ...     def __init__(self):
     ...         self.defaults = {'a': 0, 'b': 1}
     ...     @extend_kwargs('defaults')
     ...     def __call__(self, **kwargs):
-    ...         print kwargs
+    ...         print(kwargs)
     ...
     >>> obj = MyClass()
     >>> obj()
     {'a': 0, 'b': 1}
     >>> obj.defaults = {'c': -1}
     >>> obj(d=-2)
     {'c': -1, 'd': -2}
-    '''
+    """
 
     def decorate(method):
         from functools import wraps
 
         @wraps(method)
         def extend_kwargs_wrapper(self, *args, **kwargs):
             opts = dict(getattr(self, extra_opts_name))
@@ -266,73 +278,77 @@
 
         return extend_kwargs_wrapper
 
     return decorate
 
 
 class _BuildToolProperty(object):
-    '''
+    """
     Descriptor for the build_tool property of a slot
-    '''
+    """
 
     def __get__(self, instance, owner):
-        'getter'
-        if (hasattr(instance, 'ignore_slot_build_tool')
-                and instance.ignore_slot_build_tool):
+        "getter"
+        if (
+            hasattr(instance, "ignore_slot_build_tool")
+            and instance.ignore_slot_build_tool
+        ):
             return instance._build_tool
         try:
             return instance.slot.build_tool
         except AttributeError:
             return instance._build_tool
 
     def __set__(self, instance, value):
-        'setter'
-        __meta_log__.debug('setting %s build tool to %s', instance, value)
-        if hasattr(instance, 'slot') and instance.slot:
-            raise AttributeError("can't change build tool to a project "
-                                 "in a slot")
+        "setter"
+        __meta_log__.debug("setting %s build tool to %s", instance, value)
+        if hasattr(instance, "slot") and instance.slot:
+            raise AttributeError("can't change build tool to a project " "in a slot")
         from LbNightlyTools.BuildMethods import getMethod as getBuildMethod
+
         instance._build_tool = getBuildMethod(value)()
 
 
 class _CheckoutMethodProperty(object):
-    '''
+    """
     Descriptor for the checkout property of a project.
-    '''
+    """
 
     def __init__(self, default=None):
         self.default = default
 
     def __get__(self, instance, owner):
-        'getter'
+        "getter"
         return instance._checkout_wrap if instance is not None else self.default
 
     @classmethod
     def make_wrapper(self, instance, method):
-        '''
+        """
         helper to add wrappers to the checkout method of the instance
-        '''
+        """
         from functools import partial, update_wrapper
+
         timelog = log_timing(CheckoutMethods.__log__)
-        reclog = RecordLogger(
-            CheckoutMethods.__log__, data_member='checkout_log')
-        info = log_enter_step('checking out')
-        opts = extend_kwargs('checkout_opts')
+        reclog = RecordLogger(CheckoutMethods.__log__, data_member="checkout_log")
+        info = log_enter_step("checking out")
+        opts = extend_kwargs("checkout_opts")
         return update_wrapper(
-            partial(opts(info(reclog(timelog(method)))), instance), method)
+            partial(opts(info(reclog(timelog(method)))), instance), method
+        )
 
     def getCheckoutMethod(self, instance, method):
-        '''
+        """
         Helper to map "method" to the correct checkout method.
 
         If not None, map the method argument to the corresponding checkout
         method.  If None, we select an appropriate default: an explicit default,
         or a method based on the instance name or the generic default.
-        '''
+        """
         from LbNightlyTools.CheckoutMethods import getMethod as get
+
         if method is None:
             # we want the default method
             if self.default:
                 # we have an explicit default
                 method = get(self.default)
             else:
                 try:
@@ -344,95 +360,94 @@
         else:
             # setting from an explicit value
             method = get(method)
 
         return method
 
     def __set__(self, instance, value):
-        'setter'
+        "setter"
         if isinstance(value, tuple):
             value, instance.checkout_opts = value
         method = self.getCheckoutMethod(instance, value)
         instance._checkout = method
         instance._checkout_wrap = self.make_wrapper(instance, method)
 
 
 class _ProjectMeta(type):
-    '''
+    """
     Metaclass for Project.
-    '''
+    """
 
     def __new__(cls, name, bases, dct):
-        '''
+        """
         Instrument Project classes.
-        '''
-        __meta_log__.debug('preparing class %s(%s)', name, bases)
-        if 'build_tool' in dct:
-            build_tool = dct.get('build_tool')
-            __meta_log__.debug('selected build tool %s', build_tool)
+        """
+        __meta_log__.debug("preparing class %s(%s)", name, bases)
+        if "build_tool" in dct:
+            build_tool = dct.get("build_tool")
+            __meta_log__.debug("selected build tool %s", build_tool)
         else:
             for base in bases:
-                if hasattr(base, '__build_tool__'):
+                if hasattr(base, "__build_tool__"):
                     build_tool = base.__build_tool__
-                    __meta_log__.debug('inherited build tool %s', build_tool)
+                    __meta_log__.debug("inherited build tool %s", build_tool)
                     break
             else:  # this 'else' is bound to the 'for' loop
-                __meta_log__.debug('use default build tool')
+                __meta_log__.debug("use default build tool")
                 build_tool = None
-        dct['__build_tool__'] = build_tool
-        dct['build_tool'] = _BuildToolProperty()
-        if 'name' in dct:
-            __meta_log__.debug('default name %s', dct.get('name'))
-            dct['__project_name__'] = dct.pop('name')
-        __meta_log__.debug('prepare checkout method property')
-        if 'checkout' not in dct:
+        dct["__build_tool__"] = build_tool
+        dct["build_tool"] = _BuildToolProperty()
+        if "name" in dct:
+            __meta_log__.debug("default name %s", dct.get("name"))
+            dct["__project_name__"] = dct.pop("name")
+        __meta_log__.debug("prepare checkout method property")
+        if "checkout" not in dct:
             for base in bases:
-                if hasattr(base, 'checkout'):
-                    __meta_log__.debug('inherited checkout %s', base.checkout)
-                    dct['checkout'] = base.checkout
+                if hasattr(base, "checkout"):
+                    __meta_log__.debug("inherited checkout %s", base.checkout)
+                    dct["checkout"] = base.checkout
                     break
-        dct['checkout'] = _CheckoutMethodProperty(dct.get('checkout'))
+        dct["checkout"] = _CheckoutMethodProperty(dct.get("checkout"))
 
-        __meta_log__.debug('adding build logging wrappers')
+        __meta_log__.debug("adding build logging wrappers")
         timelog = log_timing(BuildMethods.__log__)
         reclog = RecordLogger(BuildMethods.__log__)
-        for method in ('build', 'clean', 'test'):
+        for method in ("build", "clean", "test"):
             if method in dct:
-                info = log_enter_step(method + 'ing')
+                info = log_enter_step(method + "ing")
                 dct[method] = info(reclog(timelog(dct[method])))
 
         return type.__new__(cls, name, bases, dct)
 
     def __call__(self, *args, **kwargs):
-        '''
+        """
         Use the class name as project name in classes derived from Project
         (if it does not end by 'Project').
-        '''
+        """
         name = None
-        if hasattr(self, '__project_name__'):
+        if hasattr(self, "__project_name__"):
             name = self.__project_name__
-        elif not self.__name__.endswith('Project'):
+        elif not self.__name__.endswith("Project"):
             name = self.__name__
         if name:
             # we prepend the class name to the arguments.
-            args = (name, ) + args
-        __meta_log__.debug('instantiating: %s(*%r, **%r)', self.__name__, args,
-                           kwargs)
+            args = (name,) + args
+        __meta_log__.debug("instantiating: %s(*%r, **%r)", self.__name__, args, kwargs)
         return type.__call__(self, *args, **kwargs)
 
 
-class Project(object):
-    '''
+class Project(with_metaclass(_ProjectMeta, object)):
+    """
     Describe a project to be checked out, built and tested.
-    '''
-    __metaclass__ = _ProjectMeta
+    """
+
     __checkout__ = None
 
     def __init__(self, name, version, **kwargs):
-        '''
+        """
         @param name: name of the project
         @param version: version of the project as 'vXrY' or 'HEAD', where 'HEAD'
                         means the head version of all the packages
         @param dependencies: optional list of dependencies (as list of project
                              names), can be used to extend the actual (code)
                              dependencies of the project
         @param overrides: dictionary describing the differences between the
@@ -448,1018 +463,1118 @@
         @param env: override the environment for the project
         @param build_tool: build method used for the project
         @param with_shared: if True, the project requires packing of data
                             generated at build time in the source tree
         @param platform_independent: if True, the project does not require a
                                      build, just the checkout [default: False]
         @param no_test: if True, the tests of the project should not be run
-        '''
+        """
         self.name = name
-        self.version = 'HEAD' if version.upper() == 'HEAD' else version
+        self.version = "HEAD" if version.upper() == "HEAD" else version
 
         # slot owning this project
         self.slot = None
 
-        self.disabled = kwargs.get('disabled', False)
-        self.overrides = kwargs.get('overrides', {})
-        self._deps = kwargs.get('dependencies', [])
-        self.env = kwargs.get('env', [])
+        self.disabled = kwargs.get("disabled", False)
+        self.overrides = kwargs.get("overrides", {})
+        self._deps = kwargs.get("dependencies", [])
+        self.env = kwargs.get("env", [])
 
         # we need to try setting checkout_opts before checkout, because
         # it could be overridden if checkout is a tuple
-        self.checkout_opts = kwargs.get('checkout_opts', {})
+        self.checkout_opts = kwargs.get("checkout_opts", {})
         # Get the checkout method using:
         #  - checkout parameter
         #  - __checkout__ class property
         #  - name of the project
         #  - default
-        self.checkout = (kwargs.get('checkout') or self.__checkout__)
+        self.checkout = kwargs.get("checkout") or self.__checkout__
 
-        self.build_tool = kwargs.get('build_tool', self.__build_tool__)
-        self.with_shared = kwargs.get('with_shared', False)
-        self.platform_independent = kwargs.get('platform_independent', False)
-        self.no_test = kwargs.get('no_test', False)
-        if 'ignore_slot_build_tool' in kwargs:
-            self.ignore_slot_build_tool = kwargs['ignore_slot_build_tool']
+        self.build_tool = kwargs.get("build_tool", self.__build_tool__)
+        self.with_shared = kwargs.get("with_shared", False)
+        self.platform_independent = kwargs.get("platform_independent", False)
+        self.no_test = kwargs.get("no_test", False)
+        if "ignore_slot_build_tool" in kwargs:
+            self.ignore_slot_build_tool = kwargs["ignore_slot_build_tool"]
 
         self.build_results = None
 
     def toDict(self):
-        '''
+        """
         Return a dictionary describing the project, suitable to conversion to
         JSON.
-        '''
+        """
         data = {
-            'name': self.name,
-            'version': self.version,
-            'dependencies': self._deps,
-            'overrides': self.overrides,
-            'checkout': self._checkout.__name__,
-            'checkout_opts': self.checkout_opts,
-            'disabled': self.disabled,
-            'env': self.env,
-            'with_shared': self.with_shared
+            "name": self.name,
+            "version": self.version,
+            "dependencies": self._deps,
+            "overrides": self.overrides,
+            "checkout": self._checkout.__name__,
+            "checkout_opts": self.checkout_opts,
+            "disabled": self.disabled,
+            "env": self.env,
+            "with_shared": self.with_shared,
         }
         if self.platform_independent:
-            data['platform_independent'] = True
+            data["platform_independent"] = True
         if self.no_test:
-            data['no_test'] = True
-        if hasattr(self,
-                   'ignore_slot_build_tool') and self.ignore_slot_build_tool:
-            data['ignore_slot_build_tool'] = True
-        if not self.slot or data.get('ignore_slot_build_tool'):
-            data['build_tool'] = self.build_tool.__class__.__name__
+            data["no_test"] = True
+        if hasattr(self, "ignore_slot_build_tool") and self.ignore_slot_build_tool:
+            data["ignore_slot_build_tool"] = True
+        if not self.slot or data.get("ignore_slot_build_tool"):
+            data["build_tool"] = self.build_tool.__class__.__name__
         return data
 
     @classmethod
     def fromDict(cls, data):
-        '''
+        """
         Create a Project instance from a dictionary like the one returned by
         Project.toDict().
-        '''
+        """
         return cls(**data)
 
     def __eq__(self, other):
-        '''Equality operator.'''
-        elems = ('__class__', 'name', 'version', 'disabled', 'overrides',
-                 '_deps', 'env', '_checkout', 'checkout_opts')
+        """Equality operator."""
+        elems = (
+            "__class__",
+            "name",
+            "version",
+            "disabled",
+            "overrides",
+            "_deps",
+            "env",
+            "_checkout",
+            "checkout_opts",
+        )
         for elem in elems:
             if getattr(self, elem) != getattr(other, elem):
                 return False
-        return (self.build_tool.__class__.__name__ == other.build_tool.
-                __class__.__name__)
+        return self.build_tool.__class__.__name__ == other.build_tool.__class__.__name__
 
     def __ne__(self, other):
-        '''Non-equality operator.'''
+        """Non-equality operator."""
         return not (self == other)
 
     def __getstate__(self):
-        '''
+        """
         Allow pickling.
-        '''
-        dct = dict((elem, getattr(self, elem))
-                   for elem in ('name', 'version', 'disabled', 'overrides',
-                                '_deps', 'env', 'checkout_opts'))
-        dct['build_tool'] = self._build_tool.__class__.__name__
-        dct['checkout'] = self._checkout
+        """
+        dct = dict(
+            (elem, getattr(self, elem))
+            for elem in (
+                "name",
+                "version",
+                "disabled",
+                "overrides",
+                "_deps",
+                "env",
+                "checkout_opts",
+            )
+        )
+        dct["build_tool"] = self._build_tool.__class__.__name__
+        dct["checkout"] = self._checkout
         return copy.deepcopy(dct)
 
     def __setstate__(self, state):
-        '''
+        """
         Allow unpickling.
-        '''
+        """
         for key in state:
             setattr(self, key, state[key])
 
     def build(self, **kwargs):
-        '''
+        """
         Build the project.
         @param jobs: number of parallel jobs to use [default: cpu count + 1]
-        '''
-        if 'jobs' not in kwargs:
+        """
+        if "jobs" not in kwargs:
             from multiprocessing import cpu_count
-            kwargs['jobs'] = cpu_count() + 1
+
+            kwargs["jobs"] = cpu_count() + 1
         self.build_results = self.build_tool.build(self, **kwargs)
         return self.build_results
 
     def clean(self, **kwargs):
-        '''
+        """
         Clean the project.
-        '''
+        """
         return self.build_tool.clean(self, **kwargs)
 
     def test(self, **kwargs):
-        '''
+        """
         Test the project.
-        '''
+        """
         return self.build_tool.test(self, **kwargs)
 
     @property
     def baseDir(self):
-        '''Name of the project directory (relative to the build directory).'''
+        """Name of the project directory (relative to the build directory)."""
         if self.slot and self.slot.with_version_dir:
             upcase = self.name.upper()
-            bdir = os.path.join(upcase, '{0}_{1}'.format(upcase, self.version))
+            bdir = os.path.join(upcase, "{0}_{1}".format(upcase, self.version))
             __log__.debug(
-                'Using file structure with version directory. Base dir=%s' %
-                bdir)
+                "Using file structure with version directory. Base dir=%s" % bdir
+            )
             return bdir
-        return '%s/' % self.name
+        return "%s/" % self.name
 
     @property
     def enabled(self):
         return not self.disabled
 
     @enabled.setter
     def enabled(self, value):
         self.disabled = not value
 
     def dependencies(self):
-        '''
+        """
         Return the dependencies of a checked out project using the information
         retrieved from the configuration files.
         @return: list of used projects (all converted to lowercase)
-        '''
+        """
         proj_root = self.baseDir
 
         def fromCMake():
-            '''
+            """
             Helper to extract dependencies from CMake configuration.
-            '''
+            """
             deps = []
-            cmake = os.path.join(proj_root, 'CMakeLists.txt')
+            cmake = os.path.join(proj_root, "CMakeLists.txt")
             # arguments to the gaudi_project call
             args = GP_EXP.search(open(cmake).read()).group(1).split()
-            if 'USE' in args:
+            if "USE" in args:
                 # look for the indexes of the range 'USE' ... 'DATA'
-                use_idx = args.index('USE') + 1
-                if 'DATA' in args:
-                    data_idx = args.index('DATA')
+                use_idx = args.index("USE") + 1
+                if "DATA" in args:
+                    data_idx = args.index("DATA")
                 else:
                     data_idx = len(args)
                 deps = [p for p in args[use_idx:data_idx:2]]
 
             # artificial dependency on LCGCMT, if needed
-            toolchain = os.path.join(proj_root, 'toolchain.cmake')
-            if (os.path.exists(toolchain)
-                    and HT_EXP.search(open(toolchain).read())):
+            toolchain = os.path.join(proj_root, "toolchain.cmake")
+            if os.path.exists(toolchain) and HT_EXP.search(open(toolchain).read()):
                 # we set explicit the version of heptools,
                 # so we depend on LCGCMT and LCG
-                deps.extend(['LCGCMT', 'LCG'])
-            if 'DATA' in args:
+                deps.extend(["LCGCMT", "LCG"])
+            if "DATA" in args:
                 # if we need data packages, add a dependency on DBASE and PARAM
-                deps.extend(['DBASE', 'PARAM'])
+                deps.extend(["DBASE", "PARAM"])
             return deps
 
         def fromCMT():
-            '''
+            """
             Helper to extract dependencies from CMT configuration.
-            '''
-            cmt = os.path.join(proj_root, 'cmt', 'project.cmt')
+            """
+            cmt = os.path.join(proj_root, "cmt", "project.cmt")
             # from all the lines in project.cmt that start with 'use',
             # we extract the second word (project name) and convert it to
             # lower case
             return [
-                l.split()[1] for l in [l.strip() for l in open(cmt)]
-                if l.startswith('use')
+                l.split()[1]
+                for l in [l.strip() for l in open(cmt)]
+                if l.startswith("use")
             ]
 
         def fromProjInfo():
-            '''
+            """
             Helper to get the dependencies from an info file in the project,
             called 'project.info'.
             The file must be in "config" format (see ConfigParser module) and
             the dependencies must be declared as a comma separated list in
             the section project.
 
             E.g.:
             [Project]
             dependencies: ProjectA, ProjectB
-            '''
-            import ConfigParser
-            config = ConfigParser.ConfigParser()
-            config.read(os.path.join(proj_root, 'project.info'))
+            """
+            import configparser
+
+            config = configparser.ConfigParser()
+            config.read(os.path.join(proj_root, "project.info"))
             return [
                 proj.strip()
-                for proj in config.get('Project', 'dependencies').split(',')
+                for proj in config.get("Project", "dependencies").split(",")
+            ]
+
+        def fromLHCbProjectYml():
+            """
+            Helper to get the dependencies from a metadata file in the project,
+            called 'lhcbproject.yml'.
+            The file (in YAML) must contain a `dependencies` field as a list of
+            strings
+
+            E.g.::
+
+                ---
+                name: MyProject
+                dependencies:
+                  - ProjectA
+                  - ProjectB
+            """
+            import yaml
+
+            return yaml.safe_load(open(os.path.join(proj_root, "lhcbproject.yml")))[
+                "dependencies"
+            ]
+
+        def fromLHCbProjectJson():
+            """
+            Helper to get the dependencies from a metadata file in the project,
+            called 'lhcbproject.json'.
+            The file (in JSON) must contain a `dependencies` field as a list of
+            strings
+
+            E.g.::
+
+                {
+                    "name": "MyProject",
+                    "dependencies": [
+                        "ProjectA",
+                        "ProjectB"
+                    ]
+                }
+            """
+            import json
+
+            return json.load(open(os.path.join(proj_root, "lhcbproject.json")))[
+                "dependencies"
             ]
 
         # Try all the helpers until one succeeds
         deps = []
-        for helper in (fromCMake, fromCMT, fromProjInfo):
+        for helper in (
+            fromCMake,
+            fromCMT,
+            fromLHCbProjectJson,
+            fromLHCbProjectYml,
+            fromProjInfo,
+        ):
             try:
                 deps = helper()
                 break
             except:
                 pass
         else:
-            __log__.warning('cannot discover dependencies for %s', self)
+            __log__.warning("cannot discover dependencies for %s", self)
 
         deps = sorted(set(deps + self._deps))
         if self.slot:
             # helper dict to map case insensitive name to correct project names
             names = dict((p.name.lower(), p.name) for p in self.slot.projects)
 
             def fixNames(iterable):
-                'helper to fix the cases of names in dependencies'
+                "helper to fix the cases of names in dependencies"
                 return [names.get(name.lower(), name) for name in iterable]
 
             deps = fixNames(deps)
 
         return deps
 
     def __str__(self):
-        '''String representation of the project.'''
+        """String representation of the project."""
         return "{0}/{1}".format(self.name, self.version)
 
     def id(self):
-        '''
+        """
         String representing the project instance.
 
         >>> p = Project('AProject', 'v1r0')
         >>> p.id()
         'AProject/v1r0'
         >>> s = Slot('test', build_id=10, projects=[p])
         >>> s.AProject.id()
         'nightly/test/10/AProject'
-        '''
+        """
         return (self.slot.id() + "/" + self.name) if self.slot else str(self)
 
     def __hash__(self):
         return hash(self.id())
 
     def environment(self, envdict=None):
-        '''
+        """
         Return a dictionary with the environment for the project.
 
         If envdict is provided, it will be used as a starting point, otherwise
         the environment defined by the slot or by the system will be used.
-        '''
+        """
         # get the initial env from the argument or the system
         if envdict is None:
             envdict = os.environ
         # if we are in a slot, we first process the environment through it
         if self.slot:
             result = self.slot.environment(envdict)
         else:
             # we make a copy to avoid changes to the input
             result = dict(envdict)
         applyenv(result, self.env)
         return result
 
     def _fixCMakeLists(self, patchfile=None, dryrun=False):
-        '''
+        """
         Fix the 'CMakeLists.txt'.
-        '''
-        from os.path import join, exists
-        cmakelists = join(self.baseDir, 'CMakeLists.txt')
+        """
+        from os.path import exists, join
+
+        cmakelists = join(self.baseDir, "CMakeLists.txt")
 
         if exists(cmakelists):
-            __log__.info('patching %s', cmakelists)
+            __log__.info("patching %s", cmakelists)
             with open(cmakelists) as f:
                 data = f.read()
             try:
                 # find the project declaration call
                 m = GP_EXP.search(data)
                 if m is None:
                     __log__.warning(
-                        '%s does not look like a Gaudi/CMake '
-                        'project, I\'m not touching it', self)
+                        "%s does not look like a Gaudi/CMake "
+                        "project, I'm not touching it",
+                        self,
+                    )
                     return
                 args = m.group(1).split()
                 # the project version is always the second
                 args[1] = self.version
 
                 # fix the dependencies
-                if 'USE' in args:
+                if "USE" in args:
                     # look for the indexes of the range 'USE' ... 'DATA'
-                    use_idx = args.index('USE') + 1
-                    if 'DATA' in args:
-                        data_idx = args.index('DATA')
+                    use_idx = args.index("USE") + 1
+                    if "DATA" in args:
+                        data_idx = args.index("DATA")
                     else:
                         data_idx = len(args)
                     # for each key, get the version (if available)
                     for i in range(use_idx, data_idx, 2):
                         if hasattr(self.slot, args[i]):
                             args[i + 1] = getattr(self.slot, args[i]).version
                 # FIXME: we should take into account the declared deps
                 start, end = m.start(1), m.end(1)
-                newdata = data[:start] + ' '.join(args) + data[end:]
+                newdata = data[:start] + " ".join(args) + data[end:]
             except:  # pylint: disable=W0702
-                __log__.error('failed parsing of %s, not patching it',
-                              cmakelists)
+                __log__.error("failed parsing of %s, not patching it", cmakelists)
                 return
 
             if newdata != data:
                 if not dryrun:
-                    with open(cmakelists, 'w') as f:
+                    with open(cmakelists, "w") as f:
                         f.write(newdata)
                 if patchfile:
                     write_patch(patchfile, data, newdata, cmakelists)
 
     def _fixCMakeToolchain(self, patchfile=None, dryrun=False):
-        '''
+        """
         Fix 'toolchain.cmake'.
-        '''
-        from os.path import join, exists
-        toolchain = join(self.baseDir, 'toolchain.cmake')
+        """
+        from os.path import exists, join
+
+        toolchain = join(self.baseDir, "toolchain.cmake")
 
         if exists(toolchain):
             # case insensitive list of projects
             projs = dict((p.name.lower(), p) for p in self.slot.projects)
-            for name in ('heptools', 'lcgcmt', 'lcg'):
+            for name in ("heptools", "lcgcmt", "lcg"):
                 if name in projs:
                     heptools_version = projs[name].version
                     break
             else:
                 # no heptools in the slot
                 return
-            __log__.info('patching %s', toolchain)
+            __log__.info("patching %s", toolchain)
             with open(toolchain) as f:
                 data = f.read()
             try:
                 # find the heptools version setting
                 m = HT_EXP.search(data)
                 if m is None:
                     __log__.debug(
-                        '%s does not set heptools_version, '
-                        'no need to touch', self)
+                        "%s does not set heptools_version, " "no need to touch", self
+                    )
                     return
                 start, end = m.start(1), m.end(1)
                 newdata = data[:start] + heptools_version + data[end:]
             except:  # pylint: disable=W0702
-                __log__.error('failed parsing of %s, not patching it',
-                              toolchain)
+                __log__.error("failed parsing of %s, not patching it", toolchain)
                 return
 
             if newdata != data:
                 if not dryrun:
-                    with open(toolchain, 'w') as f:
+                    with open(toolchain, "w") as f:
                         f.write(newdata)
                 if patchfile:
                     write_patch(patchfile, data, newdata, toolchain)
 
     def _fixCMake(self, patchfile=None, dryrun=False):
-        '''
+        """
         Fix the CMake configuration of a project, if it exists, and write
         the changes in 'patchfile'.
-        '''
+        """
         self._fixCMakeLists(patchfile, dryrun=dryrun)
         self._fixCMakeToolchain(patchfile, dryrun=dryrun)
 
     def _fixCMT(self, patchfile=None, dryrun=False):
-        '''
+        """
         Fix the CMT configuration of a project, if it exists, and write
         the changes in 'patchfile'.
-        '''
-        from os.path import join, exists
-        project_cmt = join(self.baseDir, 'cmt', 'project.cmt')
+        """
+        from os.path import exists, join
+
+        project_cmt = join(self.baseDir, "cmt", "project.cmt")
 
         if exists(project_cmt):
-            __log__.info('patching %s', project_cmt)
+            __log__.info("patching %s", project_cmt)
             with open(project_cmt) as f:
                 data = f.readlines()
 
             # case insensitive list of projects
             projs = dict((p.name.upper(), p) for p in self.slot.projects)
 
             newdata = []
             for line in data:
                 tokens = line.strip().split()
-                if len(tokens) == 3 and tokens[0] == 'use':
+                if len(tokens) == 3 and tokens[0] == "use":
                     if tokens[1] in projs:
                         tokens[1] = projs[tokens[1]].name
-                        tokens[2] = ''
-                        line = ' '.join(tokens) + '\n'
-                        __log__.info('result %s', line)
+                        tokens[2] = ""
+                        line = " ".join(tokens) + "\n"
+                        __log__.info("result %s", line)
                 newdata.append(line)
 
             if newdata != data:
                 if not dryrun:
-                    with open(project_cmt, 'w') as f:
+                    with open(project_cmt, "w") as f:
                         f.writelines(newdata)
                 if patchfile:
                     write_patch(patchfile, data, newdata, project_cmt)
 
         # find the container package
-        requirements = join(self.baseDir, self.name + 'Release', 'cmt',
-                            'requirements')
+        requirements = join(self.baseDir, self.name + "Release", "cmt", "requirements")
         if not exists(requirements):
-            requirements = join(self.baseDir, self.name + 'Sys', 'cmt',
-                                'requirements')
+            requirements = join(self.baseDir, self.name + "Sys", "cmt", "requirements")
 
         if exists(requirements):
-            __log__.info('patching %s', requirements)
+            __log__.info("patching %s", requirements)
             with open(requirements) as f:
                 data = f.readlines()
 
             used_pkgs = set()
 
             newdata = []
             for line in data:
                 tokens = line.strip().split()
-                if len(tokens) >= 3 and tokens[0] == 'use':
-                    tokens[2] = '*'
-                    if len(tokens) >= 4 and tokens[3][0] not in ('-', '#'):
-                        used_pkgs.add('{3}/{1}'.format(*tokens))
+                if len(tokens) >= 3 and tokens[0] == "use":
+                    tokens[2] = "*"
+                    if len(tokens) >= 4 and tokens[3][0] not in ("-", "#"):
+                        used_pkgs.add("{3}/{1}".format(*tokens))
                     else:
                         used_pkgs.add(tokens[1])
-                    line = ' '.join(tokens) + '\n'
+                    line = " ".join(tokens) + "\n"
                 newdata.append(line)
 
             for added_pkg in set(self.overrides.keys()) - used_pkgs:
-                if '/' in added_pkg:
-                    hat, added_pkg = added_pkg.rsplit('/', 1)
+                if "/" in added_pkg:
+                    hat, added_pkg = added_pkg.rsplit("/", 1)
                 else:
-                    hat = ''
-                newdata.append('use {0} * {1}\n'.format(added_pkg, hat))
+                    hat = ""
+                newdata.append("use {0} * {1}\n".format(added_pkg, hat))
 
             if not dryrun:
-                with open(requirements, 'w') as f:
+                with open(requirements, "w") as f:
                     f.writelines(newdata)
 
             if patchfile:
                 write_patch(patchfile, data, newdata, requirements)
 
     def _fixProjectConfigJSON(self, patchfile=None, dryrun=False):
-        '''
+        """
         Fix 'dist-tools/projectConfig.json'.
-        '''
-        import json
+        """
         import codecs
-        from os.path import join, exists
-        configfile = join(self.baseDir, 'dist-tools', 'projectConfig.json')
+        import json
+        from os.path import exists, join
+
+        configfile = join(self.baseDir, "dist-tools", "projectConfig.json")
 
         if exists(configfile):
-            __log__.info('patching %s', configfile)
-            with codecs.open(configfile, encoding='utf-8') as f:
+            __log__.info("patching %s", configfile)
+            with codecs.open(configfile, encoding="utf-8") as f:
                 data = f.read()
 
             config = json.loads(data)
             data = data.splitlines(True)
 
-            config['version'] = self.version
+            config["version"] = self.version
 
             # case insensitive list of projects
-            projs = dict(
-                (p.name.lower(), p.version) for p in self.slot.projects)
+            projs = dict((p.name.lower(), p.version) for p in self.slot.projects)
             # update project versions (if defined
-            if 'used_projects' in config:
-                for dep in config['used_projects']['project']:
+            if "used_projects" in config:
+                for dep in config["used_projects"]["project"]:
                     dep[1] = projs.get(dep[0].lower(), dep[1])
 
-            if 'heptools' in config:
-                for name in ('heptools', 'lcgcmt', 'lcg'):
+            if "heptools" in config:
+                for name in ("heptools", "lcgcmt", "lcg"):
                     if name in projs:
-                        config['heptools']['version'] = projs[name]
+                        config["heptools"]["version"] = projs[name]
                         break
 
             newdata = json.dumps(config, indent=2).splitlines(True)
 
             if not dryrun:
-                with codecs.open(configfile, 'w', encoding='utf-8') as f:
+                with codecs.open(configfile, "w", encoding="utf-8") as f:
                     f.writelines(newdata)
 
             if patchfile:
                 write_patch(patchfile, data, newdata, configfile)
 
     def patch(self, patchfile=None, dryrun=False):
-        '''
+        """
         Modify dependencies and references of the project to the other projects
         in a slot.
 
         @param patchfile: a file object where the applied changes can be
                           recorded in the form of "patch" instructions.
 
         @warning: It make sense only for projects within a slot.
-        '''
+        """
         if not self.slot:
-            raise ValueError('project %s is not part of a slot' % self)
+            raise ValueError("project %s is not part of a slot" % self)
 
         self._fixCMake(patchfile, dryrun=dryrun)
         self._fixCMT(patchfile, dryrun=dryrun)
         self._fixProjectConfigJSON(patchfile, dryrun=dryrun)
 
 
 class Package(object):
-    '''
+    """
     Describe a package to be checked out.
-    '''
+    """
+
     checkout = _CheckoutMethodProperty()
 
     def __init__(self, name, version, **kwargs):
-        '''
+        """
         @param name: name of the package
         @param version: version of the package as 'vXrY' or 'HEAD'
         @param checkout: callable that can check out the specified package
         @param checkout_opts: dictionary with extra options for the checkout
                               callable
-        '''
+        """
         self.name = name
-        if version.lower() == 'head':
-            version = 'head'
+        if version.lower() == "head":
+            version = "head"
         self.version = version
         self.container = None
-        self.checkout = kwargs.get('checkout')
-        self.checkout_opts = kwargs.get('checkout_opts', {})
+        # we need to try setting checkout_opts before checkout, because
+        # it could be overridden if checkout is a tuple
+        self.checkout_opts = kwargs.get("checkout_opts", {})
+        self.checkout = kwargs.get("checkout")
 
     @property
     def slot(self):
         return self.container.slot if self.container else None
 
     def toDict(self):
-        '''
+        """
         Return a dictionary describing the package, suitable to conversion to
         JSON.
-        '''
+        """
         data = {
-            'name': self.name,
-            'version': self.version,
-            'checkout': self._checkout.__name__,
-            'checkout_opts': self.checkout_opts
+            "name": self.name,
+            "version": self.version,
+            "checkout": self._checkout.__name__,
+            "checkout_opts": self.checkout_opts,
         }
         if self.container:
-            data['container'] = self.container.name
+            data["container"] = self.container.name
         return data
 
     def __eq__(self, other):
-        '''Equality operator.'''
-        elems = ('__class__', 'name', 'version', '_checkout', 'checkout_opts')
+        """Equality operator."""
+        elems = ("__class__", "name", "version", "_checkout", "checkout_opts")
         for elem in elems:
             if getattr(self, elem) != getattr(other, elem):
                 return False
         return True
 
     def __ne__(self, other):
-        '''Non-equality operator.'''
+        """Non-equality operator."""
         return not (self == other)
 
     def __getstate__(self):
-        '''
+        """
         Allow pickling.
-        '''
-        dct = dict((elem, getattr(self, elem))
-                   for elem in ('name', 'version', 'checkout_opts'))
-        dct['checkout'] = self._checkout
+        """
+        dct = dict(
+            (elem, getattr(self, elem)) for elem in ("name", "version", "checkout_opts")
+        )
+        dct["checkout"] = self._checkout
         return copy.deepcopy(dct)
 
     def __setstate__(self, state):
-        '''
+        """
         Allow unpickling.
-        '''
+        """
         for key in state:
             setattr(self, key, state[key])
 
     @property
     def baseDir(self):
-        '''Name of the package directory (relative to the build directory).'''
+        """Name of the package directory (relative to the build directory)."""
         if self.container:
-            return os.path.join(self.container.baseDir, self.name,
-                                self.version)
+            return os.path.join(self.container.baseDir, self.name, self.version)
         else:
             return os.path.join(self.name, self.version)
 
     @RecordLogger(CheckoutMethods.__log__)
     @log_timing(CheckoutMethods.__log__)
     def build(self, **kwargs):
-        '''
+        """
         Build the package and return the return code of the build process.
-        '''
-        from .CheckoutMethods import __log__ as log, log_call
+        """
+        from .CheckoutMethods import __log__ as log
+        from .CheckoutMethods import log_call
+
         base = self.baseDir
-        if os.path.exists(os.path.join(base, 'Makefile')):
-            log.info('building %s (make)', self)
-            return log_call(['make'], cwd=base, **kwargs)
-        elif os.path.exists(os.path.join(base, 'cmt', 'requirements')):
-            log.info('building %s (cmt make)', self)
+        if os.path.exists(os.path.join(base, "Makefile")):
+            log.info("building %s (make)", self)
+            return log_call(["make"], cwd=base, **kwargs)
+        elif os.path.exists(os.path.join(base, "cmt", "requirements")):
+            log.info("building %s (cmt make)", self)
             # CMT is very sensitive to these variables (better to unset them)
-            env = dict((key, value) for key, value in os.environ.items()
-                       if key not in ('PWD', 'CWD', 'CMTSTRUCTURINGSTYLE'))
-            base = os.path.join(base, 'cmt')
-
-            log_call(['cmt', 'config'], cwd=base, env=env, **kwargs)
-            return log_call(['cmt', 'make'], cwd=base, env=env, **kwargs)
-        log.info('%s does not require build', self)
+            env = dict(
+                (key, value)
+                for key, value in list(os.environ.items())
+                if key not in ("PWD", "CWD", "CMTSTRUCTURINGSTYLE")
+            )
+            base = os.path.join(base, "cmt")
+
+            log_call(["cmt", "config"], cwd=base, env=env, **kwargs)
+            return log_call(["cmt", "make"], cwd=base, env=env, **kwargs)
+        log.info("%s does not require build", self)
         return {
-            'retcode': 0,
-            'stdout': '%s does not require build' % self,
-            'stderr': ''
+            "retcode": 0,
+            "stdout": "%s does not require build" % self,
+            "stderr": "",
         }
 
     def getVersionLinks(self):
-        '''
+        """
         Return a list of version aliases for the current package (only if the
-        requested version is head).
-        '''
-        if self.version != 'head':
+        requested version is not vXrY[pZ]).
+        """
+        if re.match(r"v\d+r\d+(p\d+)?$", self.version):
             return []
         base = self.baseDir
-        aliases = ['v999r999']
-        if os.path.exists(os.path.join(base, 'cmt', 'requirements')):
-            for l in open(os.path.join(base, 'cmt', 'requirements')):
+        aliases = ["v999r999"]
+        if os.path.exists(os.path.join(base, "cmt", "requirements")):
+            for l in open(os.path.join(base, "cmt", "requirements")):
                 l = l.strip()
-                if l.startswith('version'):
+                if l.startswith("version"):
                     version = l.split()[1]
-                    aliases.append(version[:version.rfind('r')] + 'r999')
+                    aliases.append(version[: version.rfind("r")] + "r999")
                     break
         return aliases
 
     def __str__(self):
-        '''String representation of the package.'''
+        """String representation of the package."""
         return "{0}/{1}".format(self.name, self.version)
 
 
 class _ContainedList(object):
-    '''
+    """
     Helper class to handle a list of projects bound to a slot.
-    '''
+    """
+
     __type__ = None
-    __container_member__ = ''
-    __id_member__ = 'name'
+    __container_member__ = ""
+    __id_member__ = "name"
 
     def _assertType(self, element):
-        '''
+        """
         Ensure that the type of the parameter is the allowed one.
-        '''
+        """
         types = self.__type__
         if not isinstance(element, types):
             try:
                 if len(types) > 1:
-                    typenames = ', '.join(t.__name__ for t in types[:-1])
-                    typenames += ' and ' + types[-1].__name__
+                    typenames = ", ".join(t.__name__ for t in types[:-1])
+                    typenames += " and " + types[-1].__name__
                 elif types:
                     typenames = types[0].__name__
                 else:
-                    typenames = '()'
+                    typenames = "()"
             except TypeError:
                 typenames = types.__name__
-            msg = 'only %s instances are allowed' % typenames
+            msg = "only %s instances are allowed" % typenames
             raise ValueError(msg)
         return element
 
     def __init__(self, container, iterable=None):
-        '''
+        """
         Initialize the list from an optional iterable, which must contain
         only instances of the required class.
-        '''
+        """
         self.container = container
         if iterable is None:
             self._elements = []
         else:
-            self._elements = list(map(self._assertType, iterable))
+            self._elements = [self._assertType(i) for i in iterable]
             for element in self._elements:
                 setattr(element, self.__container_member__, self.container)
 
     def __eq__(self, other):
-        '''Equality operator.'''
-        return ((self.__class__ == other.__class__)
-                and (self._elements == other._elements))
+        """Equality operator."""
+        return (self.__class__ == other.__class__) and (
+            self._elements == other._elements
+        )
 
     def __ne__(self, other):
-        '''Non-equality operator.'''
+        """Non-equality operator."""
         return not (self == other)
 
     def __getitem__(self, key):
-        '''
+        """
         Get contained element either by name or by position.
-        '''
+        """
         if isinstance(key, basestring):
             for element in self._elements:
                 id_key = getattr(element, self.__id_member__)
-                if key in (id_key, id_key.replace('/', '_')):
+                if key in (id_key, id_key.replace("/", "_")):
                     return element
-            raise KeyError(
-                '%s %r not found' % (self.__type__.__name__.lower(), key))
+            raise KeyError("%s %r not found" % (self.__type__.__name__.lower(), key))
         return self._elements[key]
 
     def __setitem__(self, key, value):
-        '''
+        """
         Item assignment that keeps the binding between container and containee
         in sync.
-        '''
+        """
         if isinstance(key, slice):
-            map(self._assertType, value)
+            for v in value:
+                self._assertType(v)
         else:
             self._assertType(value)
         old = self[key]
         self._elements[key] = value
         if isinstance(key, slice):
             for elem in value:
                 setattr(elem, self.__container_member__, self.container)
             for elem in old:
                 setattr(elem, self.__container_member__, None)
         else:
             setattr(value, self.__container_member__, self.container)
             setattr(old, self.__container_member__, None)
 
     def __iter__(self):
-        '''
+        """
         Implement Python iteration protocol.
-        '''
+        """
         for element in self._elements:
             yield element
 
     def __contains__(self, item):
-        '''
+        """
         Implement Python membership protocol.
-        '''
+        """
 
         def match(element):
             if item is element:
                 return True
             key = getattr(element, self.__id_member__)
-            return item == key or item == key.replace('/', '_')
+            return item == key or item == key.replace("/", "_")
 
         return any(match(element) for element in self)
 
     def insert(self, idx, element):
-        '''
+        """
         Item insertion that binds the added object to the container.
-        '''
+        """
         self._assertType(element)
         setattr(element, self.__container_member__, self.container)
         return self._elements.insert(idx, element)
 
     def append(self, element):
-        '''
+        """
         Item insertion that binds the added object to the container.
-        '''
+        """
         self._assertType(element)
         setattr(element, self.__container_member__, self.container)
         return self._elements.append(element)
 
     def extend(self, iterable):
-        '''
+        """
         Extend list by appending elements from the iterable.
-        '''
+        """
         for element in iterable:
             self.append(element)
 
     def __delitem__(self, key):
-        '''
+        """
         Item removal that disconnect the element from the container.
-        '''
+        """
         if isinstance(key, slice):
             old = self[key]
         else:
             old = [self[key]]
-        map(self.remove, old)
+        for el in old:
+            self.remove(el)
 
     def remove(self, element):
-        '''
+        """
         Item removal that disconnect the element from the container.
-        '''
+        """
         self._assertType(element)
         self._elements.remove(element)
         setattr(element, self.__container_member__, None)
 
     def __len__(self):
-        '''
+        """
         Return the number of elements in the list.
-        '''
+        """
         return len(self._elements)
 
 
 class ProjectsList(_ContainedList):
-    '''
+    """
     Helper class to handle a list of projects bound to a slot.
-    '''
+    """
+
     __type__ = Project
-    __container_member__ = 'slot'
+    __container_member__ = "slot"
 
 
 class PackagesList(_ContainedList):
-    '''
+    """
     Helper class to handle a list of projects bound to a slot.
-    '''
+    """
+
     __type__ = Package
-    __container_member__ = 'container'
+    __container_member__ = "container"
 
 
 class DataProject(Project):
-    '''
+    """
     Special Project class for projects containing only data packages.
-    '''
+    """
+
     ignore_slot_build_tool = True
-    build_tool = 'no_build'
+    build_tool = "no_build"
 
     def __init__(self, name, packages=None, **kwargs):
-        '''
+        """
         Initialize the instance with name and list of packages.
-        '''
+        """
         # we use 'None' as version just to comply with Project.__init__, but the
         # version is ignored
-        Project.__init__(self, name, 'None', **kwargs)
+        Project.__init__(self, name, "None", **kwargs)
         # data projects are platform independent by definition
         self.platform_independent = True
         # data projects cannot be tested by definition
         self.no_test = True
         if packages is None:
             packages = []
         self._packages = PackagesList(self, packages)
 
     def toDict(self):
-        '''
+        """
         Return a dictionary describing the data project, suitable to conversion
         to JSON.
-        '''
+        """
         data = {
-            'name': self.name,
-            'version': self.version,
-            'checkout': 'ignore',
-            'disabled': False,
-            'platform_independent': True,
-            'no_test': True
+            "name": self.name,
+            "version": self.version,
+            "checkout": "ignore",
+            "disabled": False,
+            "platform_independent": True,
+            "no_test": True,
         }
         return data
 
     def __eq__(self, other):
-        '''Equality operator.'''
-        return Project.__eq__(self,
-                              other) and (self.packages == other.packages)
+        """Equality operator."""
+        return Project.__eq__(self, other) and (self.packages == other.packages)
 
     def __ne__(self, other):
-        '''Non-equality operator.'''
+        """Non-equality operator."""
         return not (self == other)
 
     def __getstate__(self):
-        '''
+        """
         Allow pickling.
-        '''
+        """
         dct = Project.__getstate__(self)
-        dct['_packages'] = self._packages
-        dct['checkout'] = None
+        dct["_packages"] = self._packages
+        dct["checkout"] = None
         return copy.deepcopy(dct)
 
     def __setstate__(self, state):
-        '''
+        """
         Allow unpickling.
-        '''
+        """
         for key in state:
             setattr(self, key, state[key])
 
     def __str__(self):
-        '''String representation of the project.'''
+        """String representation of the project."""
         return self.name
 
     @property
     def baseDir(self):
-        '''Name of the package directory (relative to the build directory).'''
+        """Name of the package directory (relative to the build directory)."""
         return self.name.upper()
 
     @property
     def packages(self):
-        'List of contained packages'
+        "List of contained packages"
         return self._packages
 
     def __getattr__(self, name):
-        '''
+        """
         Get the project with given name in the slot.
-        '''
+        """
         try:
             return self._packages[name]
         except KeyError:
-            raise AttributeError('%r object has no attribute %r' %
-                                 (self.__class__.__name__, name))
+            raise AttributeError(
+                "%r object has no attribute %r" % (self.__class__.__name__, name)
+            )
 
     def checkout(self, **kwargs):
-        '''
+        """
         Special checkout method to create a valid local copy of a DataProject
         using an existing one as a baseline (cloning it with symlinks).
-        '''
-        from .CheckoutMethods import __log__ as log
+        """
         from shutil import rmtree
+
+        from .CheckoutMethods import __log__ as log
+
         # look for an existing version of the project before creating the local
         # directory
         path = find_path(self.baseDir)
 
-        log.debug('create packages directories')
-        ensureDirs(
-            [os.path.dirname(package.baseDir) for package in self.packages])
+        log.debug("create packages directories")
+        ensureDirs([os.path.dirname(package.baseDir) for package in self.packages])
 
-        log.debug('create shallow clone of %s', self.name)
+        log.debug("create shallow clone of %s", self.name)
 
         ignore_package_versions = IgnorePackageVersions(self.packages)
 
         def ignore(src, names):
             ignored = ignore_package_versions(src, names)
             ignored.extend(name for name in names if name.startswith(".cvmfs"))
             return ignored
 
         if path:
             shallow_copytree(path, self.baseDir, ignore)
         else:
-            cmt_dir = os.path.join(self.baseDir, 'cmt')
+            cmt_dir = os.path.join(self.baseDir, "cmt")
             ensureDirs([cmt_dir])
-            with open(os.path.join(cmt_dir, 'project.cmt'), 'w') as proj_cmt:
-                proj_cmt.write('project {0}\n'.format(self.name))
+            with open(os.path.join(cmt_dir, "project.cmt"), "w") as proj_cmt:
+                proj_cmt.write("project {0}\n".format(self.name))
 
         # separate checkout arguments from build arguments
-        co_kwargs = dict([(key, value) for key, value in kwargs.iteritems()
-                          if key in ('export')])
-        b_kwargs = dict([(key, value) for key, value in kwargs.iteritems()
-                         if key in ('jobs')])
+        co_kwargs = dict(
+            [(key, value) for key, value in kwargs.items() if key in ("export")]
+        )
+        b_kwargs = dict(
+            [(key, value) for key, value in kwargs.items() if key in ("jobs")]
+        )
 
-        log.info('checkout data packages in %s', self.name)
+        log.info("checkout data packages in %s", self.name)
         outputs = [package.checkout(**co_kwargs) for package in self.packages]
 
-        log.info('building data packages in %s', self.name)
+        log.info("building data packages in %s", self.name)
         outputs += [package.build(**b_kwargs) for package in self.packages]
 
-        log.debug('create symlinks')
+        log.debug("create symlinks")
         for package in self.packages:
             for link in package.getVersionLinks():
-                dest = os.path.normpath(
-                    os.path.join(package.baseDir, os.pardir, link))
+                dest = os.path.normpath(os.path.join(package.baseDir, os.pardir, link))
                 if os.path.islink(dest) or os.path.exists(dest):
-                    __log__.debug('removing %s', dest)
+                    __log__.debug("removing %s", dest)
                     if os.path.isdir(dest) and not os.path.islink(dest):
                         rmtree(dest)
                     else:
                         os.remove(dest)
-                __log__.debug('creating symlink %s for %s', link, package.name)
+                __log__.debug("creating symlink %s for %s", link, package.name)
                 os.symlink(package.version, dest)
 
-        from CheckoutMethods import _merge_outputs
+        from .CheckoutMethods import _merge_outputs
+
         return _merge_outputs(outputs)
 
 
 class DBASE(DataProject):
     pass
 
 
 class PARAM(DataProject):
     pass
 
 
 class _SlotMeta(type):
-    '''
+    """
     Metaclass for Slot.
-    '''
+    """
 
     def __new__(cls, name, bases, dct):
-        '''
+        """
         Instrument Slot classes.
-        '''
-        dct['__build_tool__'] = dct.get('build_tool')
-        dct['build_tool'] = _BuildToolProperty()
+        """
+        dct["__build_tool__"] = dct.get("build_tool")
+        dct["build_tool"] = _BuildToolProperty()
         return type.__new__(cls, name, bases, dct)
 
     def __init__(cls, name, bases, dct):
-        '''
+        """
         Class initialization by the metaclass.
-        '''
+        """
         super(_SlotMeta, cls).__init__(name, bases, dct)
 
-        if 'projects' in dct:
-            cls.__projects__ = dct['projects']
+        if "projects" in dct:
+            cls.__projects__ = dct["projects"]
         cls.projects = property(lambda self: self._projects)
 
-        env = dct.get('env', [])
-        if bases and hasattr(bases[0], '__env__'):
+        env = dct.get("env", [])
+        if bases and hasattr(bases[0], "__env__"):
             cls.__env__ = bases[0].__env__ + env
         else:
             cls.__env__ = env
 
 
-class Slot(object):
-    '''
+class Slot(with_metaclass(_SlotMeta, object)):
+    """
     Generic nightly build slot.
-    '''
-    __metaclass__ = _SlotMeta
-    __slots__ = ('_name', '_projects', 'env', '_build_tool', 'disabled',
-                 'desc', 'platforms', 'error_exceptions', 'warning_exceptions',
-                 'preconditions', 'cache_entries', 'build_id', 'no_patch',
-                 'with_version_dir', 'no_test', 'deployment', 'metadata',
-                 '_source')
+    """
+
+    __slots__ = (
+        "_name",
+        "_projects",
+        "env",
+        "_build_tool",
+        "disabled",
+        "desc",
+        "platforms",
+        "error_exceptions",
+        "warning_exceptions",
+        "preconditions",
+        "cache_entries",
+        "build_id",
+        "no_patch",
+        "with_version_dir",
+        "no_test",
+        "metadata",
+        "_source",
+    )
     __projects__ = []
     __env__ = []
 
     def __init__(self, name, projects=None, **kwargs):
-        '''
+        """
         Initialize the slot with name and optional list of projects.
 
         @param name: name of the slot
         @param projects: (optional) list of Project instances
         @param env: (optional) list of strings ('name=value') used to modify the
                     environment for the slot
         @param disabled: if True the slot should not be used in the nightly
@@ -1472,868 +1587,739 @@
         @param cache_entries: dictionary of CMake cache variables to preset
         @param build_id: numeric id for the build
         @param no_patch: if set to True, sources will not be patched (default to
                          False) Kept for retro-compatibility
         @param with_version_dir: if set to True, sources will be checkout in
                                  the path: Project/Project_version
         @param no_test: if set to True, tests should not be run for this slot)
-        @param deployment: list of deployment destinations (strings)
         @param metadata: dictionary with extra information, e.g. for the dashboard
-        '''
+        """
         self._name = name
-        self.build_id = kwargs.get('build_id', 0)
+        self.build_id = kwargs.get("build_id", 0)
 
         if projects is None:
             projects = self.__projects__
         self._projects = ProjectsList(self, projects)
-        self.env = kwargs.get('env', list(self.__env__))
-        self.build_tool = kwargs.get('build_tool', self.__build_tool__)
-        self.disabled = kwargs.get('disabled', False)
-        desc = kwargs.get('desc')
+        self.env = kwargs.get("env", list(self.__env__))
+        self.build_tool = kwargs.get("build_tool", self.__build_tool__)
+        self.disabled = kwargs.get("disabled", False)
+        desc = kwargs.get("desc")
         if desc is None:
-            desc = (self.__doc__ or '<no description>').strip()
+            desc = (self.__doc__ or "<no description>").strip()
         self.desc = desc
 
-        self.platforms = kwargs.get('platforms', [])
+        self.platforms = kwargs.get("platforms", [])
         if isinstance(self.platforms, basestring):
             self.platforms = [self.platforms]
         for p in self.platforms:
-            assert re.match(r'^[0-9a-z_+]+-[0-9a-z_]+-[0-9a-z_]+-[0-9a-z_+]+$',
-                            p), 'invalid platform: %r' % p
+            assert re.match(VALID_PLATFORM_RE, p), "invalid platform: %r" % p
 
-        self.error_exceptions = kwargs.get('error_exceptions', [])
-        self.warning_exceptions = kwargs.get('warning_exceptions', [])
+        self.error_exceptions = kwargs.get("error_exceptions", [])
+        self.warning_exceptions = kwargs.get("warning_exceptions", [])
 
-        self.preconditions = kwargs.get('preconditions', [])
+        self.preconditions = kwargs.get("preconditions", [])
 
-        self.cache_entries = kwargs.get('cache_entries', {})
+        self.cache_entries = kwargs.get("cache_entries", {})
 
-        self.no_patch = kwargs.get('no_patch', False)
-        self.with_version_dir = kwargs.get('with_version_dir', False)
-        self.no_test = kwargs.get('no_test', False)
+        self.no_patch = kwargs.get("no_patch", False)
+        self.with_version_dir = kwargs.get("with_version_dir", False)
+        self.no_test = kwargs.get("no_test", False)
 
-        self.deployment = kwargs.get('deployment', [])
-
-        self.metadata = kwargs.get('metadata', {})
+        self.metadata = kwargs.get("metadata", {})
 
         # get the name of the Python module calling the constructor,
         # excluding irrelevant frames
         import inspect
+
         caller = inspect.currentframe().f_back
         while caller.f_code.co_name in _slot_factories:
             caller = caller.f_back
-        self._source = caller.f_globals['__name__']
+        self._source = caller.f_globals["__name__"]
 
         # add this slot to the global list of slots
         global slots
         slots[name] = self
 
     def toDict(self):
-        '''
+        """
         Return a dictionary describing the slot, suitable to conversion to JSON.
-        '''
+        """
         from itertools import chain
+
         data = {
-            'slot': self.name,
-            'description': self.desc,
-            'projects': [proj.toDict() for proj in self.projects],
-            'disabled': self.disabled,
-            'build_tool': self.build_tool.__class__.__name__,
-            'env': self.env,
-            'error_exceptions': self.error_exceptions,
-            'warning_exceptions': self.warning_exceptions,
-            'preconditions': self.preconditions,
-            'build_id': self.build_id,
+            "slot": self.name,
+            "description": self.desc,
+            "projects": [proj.toDict() for proj in self.projects],
+            "disabled": self.disabled,
+            "build_tool": self.build_tool.__class__.__name__,
+            "env": self.env,
+            "error_exceptions": self.error_exceptions,
+            "warning_exceptions": self.warning_exceptions,
+            "preconditions": self.preconditions,
+            "build_id": self.build_id,
         }
         if self.cache_entries:
-            data['cmake_cache'] = self.cache_entries
+            data["cmake_cache"] = self.cache_entries
         if self.no_patch:
-            data['no_patch'] = True
+            data["no_patch"] = True
         if self.with_version_dir:
-            data['with_version_dir'] = True
+            data["with_version_dir"] = True
         if self.no_test:
-            data['no_test'] = True
-        if self.deployment:
-            data['deployment'] = self.deployment
+            data["no_test"] = True
         if self.metadata:
-            data['metadata'] = self.metadata
+            data["metadata"] = self.metadata
 
         pkgs = list(
-            chain.from_iterable([pack.toDict() for pack in cont.packages]
-                                for cont in self.projects
-                                if isinstance(cont, DataProject)))
-        data['packages'] = pkgs
-        data['platforms'] = self.platforms
+            chain.from_iterable(
+                [pack.toDict() for pack in cont.packages]
+                for cont in self.projects
+                if isinstance(cont, DataProject)
+            )
+        )
+        data["packages"] = pkgs
+        data["platforms"] = self.platforms
 
         return data
 
     @classmethod
     @slot_factory
     def fromDict(cls, data):
-        '''
+        """
         Create a Slot instance from a dictionary like the one returned by
         Slot.toDict().
-        '''
+        """
         containers = {}
-        for pkg in data.get('packages', []):
-            container = pkg.get('container', 'DBASE')
+        for pkg in data.get("packages", []):
+            container = pkg.get("container", "DBASE")
             if container not in containers:
                 containers[container] = globals()[container]()
             container = containers[container]
             pkg = Package(
-                pkg['name'],
-                pkg['version'],
-                checkout=pkg.get('checkout'),
-                checkout_opts=pkg.get('checkout_opts', {}))
+                pkg["name"],
+                pkg["version"],
+                checkout=pkg.get("checkout"),
+                checkout_opts=pkg.get("checkout_opts", {}),
+            )
             container.packages.append(pkg)
 
         slot = cls(
-            name=data.get('slot', None),
-            projects=containers.values(),
-            env=data.get('env', []),
-            desc=data.get('description'),
-            disabled=data.get('disabled', False),
-            deployment=data.get('deployment', []),
-            metadata=data.get('metadata', {}))
-        slot.platforms = data.get('platforms', data.get(
-            'default_platforms', []))
-
-        if data.get('USE_CMT'):
-            slot.build_tool = 'cmt'
-        if 'build_tool' in data:
-            slot.build_tool = data['build_tool']
-
-        slot.projects.extend([
-            Project.fromDict(prj) for prj in data.get('projects', [])
-            if prj['name'] not in containers
-        ])
-
-        slot.error_exceptions = data.get('error_exceptions', [])
-        slot.warning_exceptions = data.get('warning_exceptions', [])
-        slot.preconditions = data.get('preconditions', [])
-
-        slot.cache_entries = data.get('cmake_cache', {})
-
-        slot.build_id = data.get('build_id', 0)
-
-        slot.no_patch = data.get('no_patch', False)
-        slot.with_version_dir = data.get('with_version_dir', False)
-        slot.no_test = data.get('no_test', False)
+            name=data.get("slot", None),
+            projects=list(containers.values()),
+            env=data.get("env", []),
+            desc=data.get("description"),
+            disabled=data.get("disabled", False),
+            metadata=data.get("metadata", {}),
+        )
+        slot.platforms = data.get("platforms", data.get("default_platforms", []))
+
+        if data.get("USE_CMT"):
+            slot.build_tool = "cmt"
+        if "build_tool" in data:
+            slot.build_tool = data["build_tool"]
+
+        slot.projects.extend(
+            [
+                Project.fromDict(prj)
+                for prj in data.get("projects", [])
+                if prj["name"] not in containers
+            ]
+        )
+
+        slot.error_exceptions = data.get("error_exceptions", [])
+        slot.warning_exceptions = data.get("warning_exceptions", [])
+        slot.preconditions = data.get("preconditions", [])
+
+        slot.cache_entries = data.get("cmake_cache", {})
+
+        slot.build_id = data.get("build_id", 0)
+
+        slot.no_patch = data.get("no_patch", False)
+        slot.with_version_dir = data.get("with_version_dir", False)
+        slot.no_test = data.get("no_test", False)
 
         return slot
 
     def __eq__(self, other):
-        '''
+        """
         Equality operator.
-        '''
-        elems = ('__class__', 'name', 'projects', 'env', 'disabled', 'desc',
-                 'platforms', 'error_exceptions', 'warning_exceptions',
-                 'preconditions')
+        """
+        elems = (
+            "__class__",
+            "name",
+            "projects",
+            "env",
+            "disabled",
+            "desc",
+            "platforms",
+            "error_exceptions",
+            "warning_exceptions",
+            "preconditions",
+        )
         for elem in elems:
             if getattr(self, elem) != getattr(other, elem):
                 return False
-        return (self.build_tool.__class__.__name__ == other.build_tool.
-                __class__.__name__)
+        return self.build_tool.__class__.__name__ == other.build_tool.__class__.__name__
 
     def __ne__(self, other):
-        '''Non-equality operator.'''
+        """Non-equality operator."""
         return not (self == other)
 
     def __getstate__(self):
-        '''
+        """
         Allow pickling.
-        '''
-        dct = dict((elem, getattr(self, elem))
-                   for elem in ('_projects', 'env', 'disabled', 'desc',
-                                'platforms', 'error_exceptions',
-                                'warning_exceptions', 'preconditions'))
-        dct['_name'] = self._name
-        dct['build_tool'] = self._build_tool.__class__.__name__
+        """
+        dct = dict(
+            (elem, getattr(self, elem))
+            for elem in (
+                "_projects",
+                "env",
+                "disabled",
+                "desc",
+                "platforms",
+                "error_exceptions",
+                "warning_exceptions",
+                "preconditions",
+            )
+        )
+        dct["_name"] = self._name
+        dct["build_tool"] = self._build_tool.__class__.__name__
         return copy.deepcopy(dct)
 
     def __setstate__(self, state):
-        '''
+        """
         Allow unpickling.
-        '''
+        """
         for key in state:
             setattr(self, key, state[key])
         global slots
         slots[self._name] = self
 
     def _clone(self, new_name):
-        '''
+        """
         Return a new instance configured as this one except for the name.
-        '''
+        """
         return Slot(new_name, projects=self.projects)
 
     @property
     def name(self):
-        '''
+        """
         Name of the slot.
-        '''
+        """
         return self._name
 
     @name.setter
     def name(self, value):
-        '''
+        """
         Change the name of the slot, keeping the slots global list in sync.
-        '''
+        """
         global slots
         del slots[self._name]
         self._name = value
         slots[self._name] = self
 
     @property
     def enabled(self):
         return not self.disabled
 
     @enabled.setter
     def enabled(self, value):
         self.disabled = not value
 
     def __getattr__(self, name):
-        '''
+        """
         Get the project with given name in the slot.
-        '''
+        """
         try:
             return self._projects[name]
         except KeyError:
-            raise AttributeError('%r object has no attribute %r' %
-                                 (self.__class__.__name__, name))
+            raise AttributeError(
+                "%r object has no attribute %r" % (self.__class__.__name__, name)
+            )
 
     def __delattr__(self, name):
-        '''
+        """
         Remove a project from the slot.
-        '''
+        """
         self.projects.remove(self.projects[name])
 
     def __dir__(self):
-        '''
+        """
         Return the list of names of the attributes of the instance.
-        '''
-        return self.__dict__.keys() + [proj.name for proj in self.projects]
+        """
+        return list(self.__dict__.keys()) + [proj.name for proj in self.projects]
 
     def __str__(self):
-        '''String representation of the slot.'''
-        return ('{0}.{1}'.format(self.name, self.build_id)
-                if self.build_id else self.name)
+        """String representation of the slot."""
+        return (
+            "{0}.{1}".format(self.name, self.build_id) if self.build_id else self.name
+        )
 
     def id(self):
-        '''
+        """
         String representing the slot instance.
 
         >>> s = Slot('test', build_id=10)
         >>> s.id()
         'nightly/test/10'
         >>> s = Slot('another')
         >>> s.metadata['flavour'] = 'testing'
         >>> s.id()
         'testing/another/0'
-        '''
-        return "/".join([
-            self.metadata.get("flavour", "nightly"),
-            self.name,
-            str(self.build_id),
-        ])
+        """
+        return "/".join(
+            [
+                self.metadata.get("flavour", "nightly"),
+                self.name,
+                str(self.build_id),
+            ]
+        )
 
     def __hash__(self):
         return hash(self.id())
 
     @property
     def activeProjects(self):
-        '''
+        """
         Generator yielding the projects in the slot that do not have the
         disabled property set to True.
-        '''
+        """
         for p in self.projects:
             if p.enabled:
                 yield p
 
     def checkout(self, projects=None, ignore_errors=False, **kwargs):
-        '''
+        """
         Checkout all the projects in the slot.
-        '''
+        """
 
         class NullContext(object):
             def __init__(self, project):
                 pass
 
             def __enter__(self):
                 return self
 
             def __exit__(self, *args):
                 pass
 
-        context = kwargs.pop('context', NullContext)
+        context = kwargs.pop("context", NullContext)
 
         results = OrderedDict()
         for project in self.activeProjects:
             if projects is None or project.name in projects:
                 results[project.name] = {}
                 try:
                     with context(project) as ctx:
                         results[project.name] = project.checkout(**kwargs)
                         ctx.result = results[project.name]
                 except (RuntimeError, AssertionError) as x:
-                    msg = 'failed to checkout {}: {}: {}'.format(
-                        project,
-                        type(x).__name__, x)
-                    if 'error' not in results[project.name]:
-                        results[project.name]['error'] = []
-                    results[project.name]['error'].append(msg)
+                    msg = "failed to checkout {}: {}: {}".format(
+                        project, type(x).__name__, x
+                    )
+                    if "error" not in results[project.name]:
+                        results[project.name]["error"] = []
+                    results[project.name]["error"].append(msg)
                     if ignore_errors:
                         __log__.warning(msg)
                     else:
                         raise
         return results
 
     def patch(self, patchfile=None, dryrun=False):
-        '''
+        """
         Patch all active projects in the slot to have consistent dependencies.
-        '''
+        """
         if self.no_patch:
-            raise ValueError(
-                'slot %s cannot be patched (no_patch=True)' % self)
+            raise ValueError("slot %s cannot be patched (no_patch=True)" % self)
         for project in self.activeProjects:
             project.patch(patchfile, dryrun=dryrun)
 
     def dependencies(self, projects=None):
-        '''
+        """
         Dictionary of dependencies between projects (only within the slot).
-        '''
+        """
         deps = self.fullDependencies()
         if projects:
-            for unwanted in (set(deps) - set(projects)):
+            for unwanted in set(deps) - set(projects):
                 deps.pop(unwanted)
         for key in deps:
             deps[key] = [val for val in deps[key] if val in deps]
         return deps
 
     def fullDependencies(self):
-        '''
+        """
         Dictionary of dependencies of projects (also to projects not in the
         slot).
-        '''
+        """
         return OrderedDict([(p.name, p.dependencies()) for p in self.projects])
 
     def dependencyGraph(self, keep_extern_nodes=False):
-        '''
+        """
         Return a networkx.OrderedDiGraph of the dependencies between projects.
 
         If keep_extern_nodes is False, only the projects in the slot are considered,
         otherwise we get also dependencies outside the slot.
 
         The edges go from dependee to depender (e.g. Gaudi -> LHCb).
-        '''
+        """
         from networkx import OrderedDiGraph
+
         if keep_extern_nodes:
             deps = self.fullDependencies()
         else:
             deps = self.dependencies()
         return OrderedDiGraph((d, p) for p in deps for d in deps[p])
 
     def environment(self, envdict=None):
-        '''
+        """
         Return a dictionary with the environment for the slot.
 
         If envdict is provided, it will be used as a starting point, otherwise
         the environment defined by the system will be used.
-        '''
+        """
         result = dict(os.environ) if envdict is None else dict(envdict)
         applyenv(result, self.env)
         # ensure that the current directory is first in the CMake and CMT
         # search paths
         from os import pathsep
+
         curdir = os.getcwd()
-        for var in ('CMTPROJECTPATH', 'CMAKE_PREFIX_PATH'):
+        for var in ("CMTPROJECTPATH", "CMAKE_PREFIX_PATH"):
             if var in result:
                 result[var] = pathsep.join([curdir, result[var]])
             else:
                 result[var] = curdir
         return result
 
     def _projects_by_deps(self, projects=None):
         deps = self.dependencies(projects=projects)
         return [
-            project for project in [
-                getattr(self, project_name)
-                for project_name in sortedByDeps(deps)
-            ] if project.enabled
+            project
+            for project in [
+                getattr(self, project_name) for project_name in sortedByDeps(deps)
+            ]
+            if project.enabled
         ]
 
     def buildGen(self, **kwargs):
-        '''
+        """
         Generator to build projects in the slot, one by one.
 
         @param projects: optional list of projects to build [default: all]
 
         @return: tuples (project_name, build_result)
-        '''
-        before = kwargs.pop('before', None)
-        for project in self._projects_by_deps(kwargs.pop('projects', None)):
+        """
+        before = kwargs.pop("before", None)
+        for project in self._projects_by_deps(kwargs.pop("projects", None)):
             if project.enabled:
                 if before:
                     before(project)
-                yield (project,
-                       project.build(
-                           cache_entries=self.cache_entries, **kwargs))
+                yield (
+                    project,
+                    project.build(cache_entries=self.cache_entries, **kwargs),
+                )
 
     def build(self, **kwargs):
-        '''
+        """
         Build projects in the slot.
 
         @param projects: optional list of projects to build [default: all]
-        '''
+        """
         return OrderedDict(
-            (proj.name, result) for proj, result in self.buildGen(**kwargs))
+            (proj.name, result) for proj, result in self.buildGen(**kwargs)
+        )
 
     def clean(self, **kwargs):
-        '''
+        """
         Clean projects in the slot.
 
         @param projects: optional list of projects to build [default: all]
-        '''
+        """
         results = OrderedDict()
-        for project in self._projects_by_deps(kwargs.pop('projects', None)):
+        for project in self._projects_by_deps(kwargs.pop("projects", None)):
             results[project.name] = project.clean(**kwargs)
         return results
 
     def testGen(self, **kwargs):
-        '''
+        """
         Generator to test projects in the slot, one by one.
 
         @param projects: optional list of projects to build [default: all]
-        '''
+        """
         if self.no_test:
-            raise ValueError('slot %s cannot be tested (no_test=True)' % self)
-        before = kwargs.pop('before', None)
-        for project in self._projects_by_deps(kwargs.pop('projects', None)):
+            raise ValueError("slot %s cannot be tested (no_test=True)" % self)
+        before = kwargs.pop("before", None)
+        for project in self._projects_by_deps(kwargs.pop("projects", None)):
             if project.enabled and not project.no_test:
                 if before:
                     before(project)
-                yield (project,
-                       project.test(
-                           cache_entries=self.cache_entries, **kwargs))
+                yield (
+                    project,
+                    project.test(cache_entries=self.cache_entries, **kwargs),
+                )
 
     def test(self, **kwargs):
-        '''
+        """
         Test projects in the slot.
 
         @param projects: optional list of projects to build [default: all]
-        '''
+        """
         return OrderedDict(
-            (proj.name, result) for proj, result in self.testGen(**kwargs))
+            (proj.name, result) for proj, result in self.testGen(**kwargs)
+        )
 
 
 def extractVersion(tag):
-    '''
+    """
     Extract the version number from as SVN tag.
 
     >>> extractVersion('GAUDI_v23r8')
     'v23r8'
     >>> extractVersion('LCGCMT_preview')
     'preview'
     >>> extractVersion('HEAD')
     'HEAD'
-    '''
-    if '_' in tag:
-        return tag.split('_', 1)[1]
+    """
+    if "_" in tag:
+        return tag.split("_", 1)[1]
     return tag
 
 
-def loadFromOldXML(source, slot):
-    '''
-    Read an old-style XML configuration and generate the corresponding
-    dictionary in the new-style configuration.
-
-    @param source: XML path, file object, URL
-    @param slot: name of the slot to extract
-    '''
-    import LbNightlyTools.CheckoutMethods
-    from xml.etree.ElementTree import parse
-    doc = parse(source)
-
-    def fixPlaceHolders(s):
-        '''
-        Replace the old placeholders with the new ones.
-        '''
-        s = s.replace('%DAY%', '${TODAY}')
-        s = s.replace('%YESTERDAY%', '${YESTERDAY}')
-        s = s.replace('%PLATFORM%', '${CMTCONFIG}')
-        return s
-
-    __log__.debug('loading %s from %s', slot, source)
-    data = {'slot': slot, 'env': []}
-    try:
-        slot_el = (el for el in doc.findall('slot')
-                   if el.attrib.get('name') == slot).next()
-
-        cmt_proj_path = ':'.join([
-            fixPlaceHolders(el.attrib['value'])
-            for el in slot_el.findall('cmtprojectpath/path')
-        ])
-        if cmt_proj_path:
-            data['env'].append('CMTPROJECTPATH=' + cmt_proj_path)
-
-        desc = slot_el.attrib.get('description', '(no description)')
-        m = re.match(r'%s(:| -|\.)\s+' % slot, desc)
-        if m:
-            desc = desc[:m.start()] + desc[m.end():]
-        data['description'] = desc
-
-        elem = slot_el.find('cmtextratags')
-        if elem is not None:
-            data['env'].append('CMTEXTRATAGS=' + elem.attrib['value'])
-
-        if slot.startswith('lhcb-compatibility'):
-            data['env'].append('GAUDI_QMTEST_DEFAULT_SUITE=compatibility')
-
-        elem = slot_el.find('waitfor')
-        if elem is not None:
-            path = fixPlaceHolders(elem.attrib['flag'])
-            if 'isDone-' in path:
-                path = path.replace('isDone-', 'LCG_externals_') + '.txt'
-                data['preconditions'] = [{
-                    "name": "lcgNightly",
-                    "args": {
-                        "path": path,
-                        "required": DEFAULT_REQUIRED_EXTERNALS
-                    }
-                }]
-            else:
-                data['preconditions'] = [{
-                    "name": "waitForFile",
-                    "args": {
-                        "path": path
-                    }
-                }]
-
-        data['default_platforms'] = [
-            p.attrib['name'] for p in slot_el.findall('platforms/platform')
-            if 'name' in p.attrib
-        ]
-        # if attrib 'disabled' is not set or 'false', then ste to False
-        data['disabled'] = (slot_el.attrib.get('disabled', 'false').lower() !=
-                            'false')
-
-        projects = []
-        project_names = set()
-        for proj in slot_el.findall('projects/project'):
-            name = proj.attrib['name']
-            version = extractVersion(proj.attrib['tag'])
-            overrides = {}
-            for elem in proj.findall('addon') + proj.findall('change'):
-                overrides[elem.attrib['package']] = elem.attrib['value']
-            # check if we have dep overrides
-            project_names.add(name)  # keep track of the names found so far
-            for elem in proj.findall('dependence'):
-                dep_name = elem.attrib['project']
-                if dep_name not in project_names:
-                    project_names.add(dep_name)
-                    dep_vers = extractVersion(elem.attrib['tag'])
-                    projects.append({
-                        'name': dep_name,
-                        'version': dep_vers,
-                        'overrides': {},
-                        'checkout': 'ignore',
-                        'disabled': True
-                    })
-
-            proj_data = {
-                'name': name,
-                'version': version,
-                'overrides': overrides
-            }
-            if proj.attrib.get('disabled', 'false').lower() != 'false':
-                proj_data['checkout'] = 'ignore'
-                proj_data['disabled'] = True
-            else:
-                # look for a project-specific checkout method
-                if hasattr(LbNightlyTools.CheckoutMethods, name.lower()):
-                    proj_data['checkout'] = name.lower()
-
-            if 'headofeverything' in proj.attrib:
-                recursive_head = proj.attrib.get('headofeverything').lower()
-                recursive_head = recursive_head == 'true'
-                if (version == 'HEAD') != recursive_head:
-                    # HEAD implies recursive_head True, so add the special
-                    # option only if needed
-                    proj_data['checkout_opts'] = {
-                        'recursive_head': recursive_head
-                    }
-            if name == 'Geant4':
-                # By default, created the shared tarball for Geant4
-                proj_data['with_shared'] = True
-            projects.append(proj_data)
-
-        data['projects'] = projects
-
-        if slot_el.attrib.get('use_cmake', 'false').lower() != 'true':
-            data['USE_CMT'] = True
-
-        def el2re(elem):
-            '''Regex string for ignored warning or error.'''
-            val = elem.attrib['value']
-            if elem.attrib.get('type', 'string') == 'regex':
-                return val
-            else:
-                return re.escape(val)
-
-        data['error_exceptions'] = map(el2re,
-                                       doc.findall('general/ignore/error'))
-        data['warning_exceptions'] = map(el2re,
-                                         doc.findall('general/ignore/warning'))
-
-        return data
-    except StopIteration:
-        raise RuntimeError('cannot find slot {0}'.format(slot))
-
-
-def load(path):
-    '''
-    Load the configuration from a file.
-
-    By default, the file is assumed to be a JSON file, unless it ends with
-    '#<slot-name>', in which case the XML parsing is used.
-    '''
-    try:
-        source, slot = path.rsplit('#', 1)
-        return loadFromOldXML(source, slot)
-    except ValueError:
-        import json
-        from os.path import splitext, basename
-        __log__.debug('loading %s', path)
-        data = json.load(open(path, 'rb'))
-        if u'slot' not in data:
-            data[u'slot'] = splitext(basename(path))[0]
-        return data
-
-
 def save(dest, config):
-    '''
+    """
     Helper function to dump the current configuration to a file.
-    '''
-    f = open(dest, 'wb')
+    """
+    f = open(dest, "w")
     f.write(configToString(config))
     f.close()
 
 
 def configToString(config):
-    '''
+    """
     Convert the configuration to a string.
-    '''
+    """
     import json
+    from builtins import str
+
     if isinstance(config, Slot):
         config = config.toDict()
-    return json.dumps(config, sort_keys=True, indent=2, separators=(',', ': '))
+    return str(json.dumps(config, sort_keys=True, indent=2, separators=(",", ": ")))
 
 
 def parse(path):
-    '''
-    Read a JSON file describing the configuration of a slot.
-    '''
-    data = load(path)
+    """
+    Create a Slot instance from a JSON file describing the configuration.
+    """
+    import json
+    from os.path import basename, splitext
+
+    __log__.debug("loading %s", path)
+    data = json.load(open(path, "rb"))
+    if "slot" not in data:
+        data["slot"] = splitext(basename(path))[0]
     slot = Slot.fromDict(data)
     slot._source = path
     return slot
 
 
 def getSlot(name, module=None):
-    '''
+    """
     Find the slot with the given name.
 
     It's possible to specify a module name then forwarded to loadConfig().
-    '''
+    """
     slot = loadConfig(module).get(name)
     if slot:
-        __log__.debug('using slot {0.name} from {0._source}'.format(slot))
+        __log__.debug("using slot {0.name} from {0._source}".format(slot))
     else:
-        raise RuntimeError('cannot find slot {0}{1}'.format(
-            name, (' in ' + module) if module else ''))
+        raise RuntimeError(
+            "cannot find slot {0}{1}".format(name, (" in " + module) if module else "")
+        )
     return slot
 
 
 ###############################################################################
 # Helpers
 ###############################################################################
 @slot_factory
 def cloneSlot(slot, name):
-    '''
+    """
     Clone a slot creating a new one with the given name.
-    '''
+    """
     if not name:
-        raise ValueError('name argument must not be empty')
+        raise ValueError("name argument must not be empty")
     if isinstance(slot, basestring):
         global slots
         slot = slots[slot]
     desc = slot.toDict()
-    desc['slot'] = name
-    # a clone does not inherit the deployment target
-    desc['deployment'] = []
+    desc["slot"] = name
     return Slot.fromDict(copy.deepcopy(desc))
 
 
 # used by try_call to keep track of the failures
 _failures_count = 0
 
 
 def try_call(msg, default_result=None):
-    '''
+    """
     Decorator to wrap a function call in a try-except block and ignore
     exceptions (printing a warning message).
-    '''
+    """
 
     def decorate(method):
         from functools import wraps
 
         @wraps(method)
         def wrapper(*args, **kwargs):
             global _failures_count
             try:
                 return method(*args, **kwargs)
             except Exception as x:
                 _failures_count += 1
                 __log__.warning(
-                    msg.format(*args, **kwargs) +
-                    ': {0}: {1}'.format(x.__class__.__name__, x))
+                    msg.format(*args, **kwargs)
+                    + ": {0}: {1}".format(x.__class__.__name__, x)
+                )
                 return default_result
 
         return wrapper
 
     return decorate
 
 
 def loadConfig(module=None):
-    '''
+    """
     Load all slots from a config module.
-    '''
-    from os.path import join, splitext, abspath
-    from os.path import exists, isdir
-    from xml.etree.ElementTree import parse as xml_parse
+    """
     from importlib import import_module
+    from os.path import abspath, exists, isdir, join, splitext
+
     import git
 
     orig_path = list(sys.path)
     try:
         if module is None:
-            module_name, attribute = 'lhcbnightlyconf', 'slots'
-        elif ':' in module:
-            module_name, attribute = module.split(':', 1)
+            module_name, attribute = "lhcbnightlyconf", "slots"
+        elif ":" in module:
+            module_name, attribute = module.split(":", 1)
         else:
-            module_name, attribute = module, 'slots'
+            module_name, attribute = module, "slots"
         sys.path.insert(0, os.curdir)
-        sys.path.insert(0, 'configs')
+        sys.path.insert(0, "configs")
         m = import_module(module_name)
         try:  # to get the commit id of the config directory
-            config_id = git.Repo(
-                m.__path__[0],
-                search_parent_directories=True).rev_parse('HEAD').hexsha
+            config_id = (
+                git.Repo(m.__path__[0], search_parent_directories=True)
+                .rev_parse("HEAD")
+                .hexsha
+            )
         except git.GitError:
             config_id = None
         slot_list = getattr(m, attribute)
-        logging.debug('using explicit configuration')
+        logging.debug("using explicit configuration")
         slot_dict = {}
         for slot in slot_list:
-            assert slot.name not in slot_dict, \
-                'Slot {} defined in 2 places: {} and {}'.format(
-                    slot.name, slot_dict[slot.name]._source, slot._source)
+            assert (
+                slot.name not in slot_dict
+            ), "Slot {} defined in 2 places: {} and {}".format(
+                slot.name, slot_dict[slot.name]._source, slot._source
+            )
             if config_id:
-                slot.metadata['config_id'] = config_id
+                slot.metadata["config_id"] = config_id
             slot_dict[slot.name] = slot
         return slot_dict
     except (ImportError, AttributeError, TypeError):
-        pass
+        import traceback
+
+        traceback.print_exc()
     sys.path = orig_path
 
-    logging.warning('using implicit configuration')
-    configdir = 'configs' if module is None else module
+    logging.warning("using implicit configuration")
+    configdir = "configs" if module is None else module
 
     if not isdir(configdir):
         global _failures_count
         _failures_count += 1
-        __log__.warning('%s is not a valid directory', configdir)
+        __log__.warning("%s is not a valid directory", configdir)
         return slots
 
-    __log__.debug('loading all slots from %s', configdir)
+    __log__.debug("loading all slots from %s", configdir)
     names = os.listdir(configdir)
     names.sort()
 
     # protect from exceptions
-    xml_parse = try_call('failed to parse {0}')(xml_parse)
-    parse_ = try_call('failed to parse {0}')(parse)
-    import_module = try_call('failed to import {0}')(import_module)
-
-    # Get all slots defined in XML
-    xml_config = join(configdir, 'configuration.xml')
-    if exists(xml_config):
-        __log__.debug('getting list of slots from %s', xml_config)
-        xml = xml_parse(xml_config)
-        if xml:
-            for name in [s.attrib['name'] for s in xml.findall('slot')]:
-                parse_('{0}#{1}'.format(xml_config, name))
+    parse_ = try_call("failed to parse {0}")(parse)
+    import_module = try_call("failed to import {0}")(import_module)
 
     # Get all slots defined as JSON
-    for name in [name for name in names if name.endswith('.json')]:
+    for name in [name for name in names if name.endswith(".json")]:
         parse_(join(configdir, name))
 
     # Now looking for python modules to load
     # First finding all python modules in this directory
     submodules = [f[0] for f in map(splitext, names) if f[1] == ".py"]
 
     # Now importing them in turn...
     old_path = list(sys.path)
     try:
         sys.path.insert(0, abspath(configdir))
         for submodule in submodules:
-            __log__.debug('loading %s', submodule)
+            __log__.debug("loading %s", submodule)
             import_module(submodule)
     finally:
         sys.path = old_path
-    __log__.debug('loaded %d slots', len(slots))
+    __log__.debug("loaded %d slots", len(slots))
     return slots
 
 
-def findSlot(name, flavour='nightly', server=None, dbname=None):
-    '''
+def findSlot(name, flavour="nightly", server=None, dbname=None, raise_if_aborted=False):
+    """
     Helper to load a Slot configuration from filename or from slot name.
 
     If name matches '<name>.<build_id>', the configuration is retrieved from
     the dashboard.
-    '''
+    """
     if re.match(r"^[-_0-9a-zA-Z]+\.\d+$", name):
-        url = '/'.join([
-            server or Dashboard.SERVER_URL, dbname
-            or Dashboard.dbName(flavour), name
-        ])
-        __log__.debug('retrieving %s', url)
-        return Slot.fromDict(json.load(urllib2.urlopen(url))['config'])
-    elif os.path.exists(name.split('#')[0]):
+        url = "/".join(
+            [server or Dashboard.SERVER_URL, dbname or Dashboard.dbName(flavour), name]
+        )
+        __log__.debug("retrieving %s", url)
+        raw = json.load(urllib.request.urlopen(url))
+        slot = Slot.fromDict(raw["config"])
+        if raw.get("aborted"):
+            if raise_if_aborted:
+                from LbNightlyTools.Utils import SlotAborted
+
+                raise SlotAborted(name, raw["aborted"])
+            slot.metadata["aborted"] = raw["aborted"]
+        return slot
+    elif os.path.exists(name.split("#")[0]):
         return parse(name)
     else:
         return getSlot(name)
 
 
-KeyTuple = namedtuple('KeyTuple', ['flavour', 'name', 'id', 'project'])
-KeyTuple.__str__ = lambda self: '/'.join(str(i) for i in self if i is not None)
+KeyTuple = namedtuple("KeyTuple", ["flavour", "name", "id", "project"])
+KeyTuple.__str__ = lambda self: "/".join(str(i) for i in self if i is not None)
 
 
 def _parse_key(key):
     """
     Parse a key like "[flavour/]slotname[/build_id][/project]" to its parts.
 
     Returns a named tuple with the elements.
 
     NOTE: if `flavour/` is present, there must be also at least one of `/build_id`
           or `/project`, as the string "a/b" is always interpreted as "slot/project"
     """
     # defaults for optional entries
-    flavour, build_id, project = 'nightly', '0', None
+    flavour, build_id, project = "nightly", "0", None
     name = None  # used to flag invalid keys
 
-    tokens = key.split('/')
+    tokens = key.split("/")
     if len(tokens) == 1:  # only slot name
         name = tokens[0]
     elif len(tokens) == 2:  # slot/build_id or slot/project
         name = tokens[0]
         if tokens[1].isdigit():
             build_id = tokens[1]
         else:
@@ -2346,126 +2332,196 @@
         else:  # f/s/p
             flavour, name, project = tokens
     elif len(tokens) == 4:
         if tokens[2].isdigit():
             flavour, name, build_id, project = tokens
 
     if not name:
-        raise ValueError('%r is not a valid key' % key)
+        raise ValueError("%r is not a valid key" % key)
 
     return KeyTuple(flavour, name, int(build_id), project)
 
 
 def get(key):
     """
     Return the instance identified by a key like "[flavour/]slotname[/build_id][/project]".
 
     When the build_id part is present, the slot configuration is taken from CouchDB.
     """
     flavour, slot, build_id, project = _parse_key(key)
     if build_id:
-        slot = '{}.{}'.format(slot, build_id)
+        slot = "{}.{}".format(slot, build_id)
     slot = findSlot(slot, flavour)
     slot.metadata["flavour"] = flavour
     # clone slot instance
     slot = Slot.fromDict(slot.toDict())
     if project is None:
         return slot
     else:
         return slot.projects[project]
 
 
 def pushDataToFrontEnd(config_module):
-    '''
+    """
     Sends slots name that can be built to the front-end
-    '''
-    front_end_token = os.environ.get('FRONT_END_TOKEN', None)
-    front_end_url = os.environ.get('FRONT_END_URL', None)
+    """
+    front_end_token = os.environ.get("FRONT_END_TOKEN", None)
+    front_end_url = os.environ.get("FRONT_END_URL", None)
 
     if front_end_url is None:
         raise Exception("Front-end url does not exists in the environment")
 
     if front_end_token is None:
         raise Exception("Front-end token does not exists in the environment")
 
     params = {
-        'token': front_end_token,
-        'slots': ';'.join([name for name in sorted(loadConfig(config_module))])
+        "token": front_end_token,
+        "slots": ";".join([name for name in sorted(loadConfig(config_module))]),
     }
-    send_data = urllib.urlencode(params)
-    response = urllib2.urlopen(front_end_url, send_data)
+    send_data = urllib.parse.urlencode(params)
+    response = urllib.request.urlopen(front_end_url, send_data)
     response.read()
 
 
+def check_slot(slot):
+    """
+    Check that a slot configuration is valid.
+    """
+    good = True
+    log = logging.getLogger(slot.name)
+
+    def check_type(field_name, types, value=None):
+        if value is None:
+            value = getattr(slot, field_name)
+        if not isinstance(value, types):
+            log.error(
+                "invalid %s type: found %s, expected one of [%s]",
+                field_name,
+                type(value).__name__,
+                ", ".join(t.__name__ for t in types),
+            )
+            return False
+        return True
+
+    def check_list_of_strings(field_name, name, regex):
+        good = check_type(field_name, (list, tuple))
+        if good:
+            for x in getattr(slot, field_name):
+                if check_type(name, (str,), x):
+                    if not re.match(regex, x):
+                        log.error("invalid %s value: %r", name, x)
+                        good = False
+                else:
+                    good = False
+        return good
+
+    for field_name in ("warning_exceptions", "error_exceptions"):
+        good &= check_type(field_name, (list, tuple))
+        for x in getattr(slot, field_name):
+            try:
+                re.compile(x)
+            except Exception as err:
+                good = False
+                log.error("%s: invalid value %r: %s", field_name, x, err)
+
+    good &= check_list_of_strings("platforms", "platform", VALID_PLATFORM_RE)
+    good &= check_list_of_strings("env", "env setting", r"^[a-zA-Z_][a-z0-9A-Z_]*=")
+
+    return good
+
+
 def check_config():
-    from LbNightlyTools.Configuration import loadConfig
+    from argparse import ArgumentParser
+
     import LbNightlyTools.Configuration as LBNC
+    from LbNightlyTools.Configuration import loadConfig
     from LbNightlyTools.GitlabUtils import resolveMRs
-    from argparse import ArgumentParser
 
     parser = ArgumentParser()
     parser.add_argument(
-        'module',
-        nargs='?',
-        help='name of the Python module to import to get the slots from'
+        "module",
+        nargs="?",
+        help="name of the Python module to import to get the slots from"
         ' (by default "lhcbnightlyconf"),'
         ' an optional ":name" suffix can be used to specify the attribute '
-        'of the module that contains the list of slots to use (by default '
-        '"slots")')
+        "of the module that contains the list of slots to use (by default "
+        '"slots")',
+    )
     parser.add_argument(
-        '--debug',
-        action='store_const',
-        dest='log_level',
+        "--debug",
+        action="store_const",
+        dest="log_level",
         const=logging.DEBUG,
-        help='print debug messages')
+        help="print debug messages",
+    )
     parser.add_argument(
-        '--dump-json',
-        metavar='FILENAME',
-        help='dump all loaded slots configuration as a JSON list of objects')
+        "--dump-json",
+        metavar="FILENAME",
+        help="dump all loaded slots configuration as a JSON list of objects",
+    )
     parser.add_argument(
-        '--resolve-mrs',
-        action='store_true',
-        help='resolve symbolic merge requests (all, label=X...) to a list '
-        'pairs (mr_iid, commit_id)')
+        "--resolve-mrs",
+        action="store_true",
+        help="resolve symbolic merge requests (all, label=X...) to a list "
+        "pairs (mr_iid, commit_id)",
+    )
     parser.set_defaults(
-        module='lhcbnightlyconf', log_level=logging.INFO, resolve_mrs=False)
+        module="lhcbnightlyconf", log_level=logging.INFO, resolve_mrs=False
+    )
     args = parser.parse_args()
 
-    if args.resolve_mrs and not os.environ.get('GITLAB_TOKEN'):
-        parser.error('evironment variable GITLAB_TOKEN must be '
-                     'set to use --resolve-mrs')
+    if args.resolve_mrs and not os.environ.get("GITLAB_TOKEN"):
+        parser.error(
+            "evironment variable GITLAB_TOKEN must be " "set to use --resolve-mrs"
+        )
 
     logging.basicConfig(level=args.log_level)
 
     slots = loadConfig(args.module)
 
-    print('{0} slots configured ({1} enabled)'.format(
-        len(slots), len([s for s in slots.values() if s.enabled])))
+    print(
+        "{0} slots configured ({1} enabled)".format(
+            len(slots), len([s for s in list(slots.values()) if s.enabled])
+        )
+    )
     if args.resolve_mrs:
-        for slot in slots.values():
+        for slot in list(slots.values()):
             resolveMRs(slot)
 
     from tabulate import tabulate
-    print(tabulate([[
-        name, 'X' if slots[name].enabled else ' ', ', '.join(
-            slots[name].deployment), slots[name]._source
-    ] for name in sorted(slots)],
-                   headers=('slot', 'enabled', 'deployment', 'source'),
-                   tablefmt='grid'))
-
-    logging.debug('converting slots to JSON')
-    json_str = json.dumps([slots[name].toDict() for name in sorted(slots)],
-                          indent=2)
+
+    print(
+        tabulate(
+            [
+                [
+                    name,
+                    "X" if slots[name].enabled else " ",
+                    slots[name]._source,
+                ]
+                for name in sorted(slots)
+            ],
+            headers=("slot", "enabled", "source"),
+            tablefmt="grid",
+        )
+    )
+
+    logging.debug("running semantics checks")
+    if not all(check_slot(slot) for slot in slots.values()):
+        return 1
+
+    logging.debug("converting slots to JSON")
+    json_str = json.dumps([slots[name].toDict() for name in sorted(slots)], indent=2)
     if args.dump_json:
-        logging.info('writing slot details to %s', args.dump_json)
-        with open(args.dump_json, 'w') as f:
+        logging.info("writing slot details to %s", args.dump_json)
+        with open(args.dump_json, "w") as f:
             f.write(json_str)
 
     if LBNC._failures_count:
-        logging.error('%d failures loading nightly builds configuration',
-                      LBNC._failures_count)
+        logging.error(
+            "%d failures loading nightly builds configuration", LBNC._failures_count
+        )
         return 1
     return 0
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     sys.exit(check_config())
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/GetNightlyRefs.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/GetNightlyRefs.py`

 * *Files 19% similar despite different names*

```diff
@@ -8,79 +8,90 @@
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 from __future__ import print_function
 
-import time
+from future import standard_library
+
+standard_library.install_aliases()
 import os
 import sys
-
+import time
+from io import BytesIO
+from urllib.error import HTTPError
+from urllib.request import urlopen
 from zipfile import ZipFile
-from StringIO import StringIO
-from urllib2 import urlopen, HTTPError
 
 from LbEnv import fixProjectCase
 
 
 def guess_project_name():
     proj = os.path.basename(os.getcwd())
-    if '_' in proj:
-        proj = proj.split('_', 1)[0]
-    if proj.endswith('Dev'):
+    if "_" in proj:
+        proj = proj.split("_", 1)[0]
+    if proj.endswith("Dev"):
         proj = proj[:-3]
     return fixProjectCase(proj)
 
 
 def main():
     import argparse
     import textwrap
 
     parser = argparse.ArgumentParser(
         formatter_class=argparse.RawDescriptionHelpFormatter,
         description="\n".join(
             textwrap.wrap(
                 "Script to copy test result ref.new files into local "
                 "test directories to avoid re-running the tests locally",
-                width=80)),
-        epilog=textwrap.dedent("""\
+                width=80,
+            )
+        ),
+        epilog=textwrap.dedent(
+            """\
             Note: the order of options is fixed
 
             Standard usage:
               check your local cmtconfig
               setup local project structure for the correct project
               get the packages you want to update
               go to the PROJECT_version top directory
               call this script
-              go through and replace the references you want to update"""))
+              go through and replace the references you want to update"""
+        ),
+    )
 
-    parser.add_argument('slot', help='name of the slot')
+    parser.add_argument("slot", help="name of the slot")
     parser.add_argument(
-        'build_id',
+        "build_id",
         nargs="?",
-        default=time.strftime('%a'),
-        help="build id for the slot (numeric or day name) "
-        "[default: latest build]")
+        default=time.strftime("%a"),
+        help="build id for the slot (numeric or day name) " "[default: latest build]",
+    )
     parser.add_argument(
-        'application',
+        "application",
         nargs="?",
-        help="application name [default: deduced from current directory]")
+        help="application name [default: deduced from current directory]",
+    )
     parser.add_argument(
-        'destination',
+        "destination",
         nargs="?",
         help="where to put the references, if not specified local references "
         "will be updated, but new directories will not be added "
-        "[default: current directory]")
+        "[default: current directory]",
+    )
 
     parser.add_argument(
-        '-c',
+        "-c",
         "--platform",
-        default=os.environ.get('BINARY_TAG') or os.environ.get('CMTCONFIG'),
-        help="platform to use [default: from $BINARY_TAG or $CMTCONFIG]")
+        default=os.environ.get("BINARY_TAG") or os.environ.get("CMTCONFIG"),
+        help="platform to use [default: from $BINARY_TAG or $CMTCONFIG]",
+    )
 
     args = parser.parse_args()
 
     # if set to True, do not extract files if the directory is missing
     ignore_missing_dirs = True
 
     if args.application:
@@ -90,53 +101,57 @@
 
     if not args.destination:
         args.destination = os.curdir
     else:
         ignore_missing_dirs = False
 
     if not args.platform:
-        parser.error("missing option --platform and cannot be deduced from "
-                     "the environment (BINARY_TAG or CMTCONFIG)")
-
-    print("looking for slot: %s, build_id: %s, app: %s, platform: %s" %
-          (args.slot, args.build_id, args.application, args.platform))
+        parser.error(
+            "missing option --platform and cannot be deduced from "
+            "the environment (BINARY_TAG or CMTCONFIG)"
+        )
+
+    print(
+        "looking for slot: %s, build_id: %s, app: %s, platform: %s"
+        % (args.slot, args.build_id, args.application, args.platform)
+    )
 
     arch_url = (
-        'https://lhcb-nightlies-artifacts.web.cern.ch/lhcb-nightlies-artifacts/'
-        '{flavour}/{args.slot}/{args.build_id}/tests/{args.platform}/newrefs/{args.application}.zip'
-    ).format(
-        args=args, flavour='nightly')
+        "https://lhcb-nightlies-artifacts.web.cern.ch/lhcb-nightlies-artifacts/"
+        "{flavour}/{args.slot}/{args.build_id}/tests/{args.platform}/newrefs/{args.application}.zip"
+    ).format(args=args, flavour="nightly")
 
     try:
         print("Getting data from:", arch_url)
         arch_data = urlopen(arch_url).read()
     except HTTPError:
         # treat HTTP errors as "no data available"
-        print('cannot find data for the requested combination')
+        print("cannot find data for the requested combination")
         exit(1)
 
-    arch = ZipFile(StringIO(arch_data))
+    arch = ZipFile(BytesIO(arch_data))
 
-    print('Extracting', 'specific' if ignore_missing_dirs else 'all',
-          'refs...')
+    print("Extracting", "specific" if ignore_missing_dirs else "all", "refs...")
 
     def should_extract(filename):
-        '''
+        """
         Tell if a filename should be extracted.
-        '''
-        return (not ignore_missing_dirs  # True means extract everything
-                or (not filename.endswith('/')  # ignore directories
-                    and os.path.isdir(os.path.dirname(filename))))
+        """
+        return not ignore_missing_dirs or (  # True means extract everything
+            not filename.endswith("/")  # ignore directories
+            and os.path.isdir(os.path.dirname(filename))
+        )
 
     for info in arch.infolist():
         if should_extract(info.filename):
             if args.destination == os.curdir:
                 print(info.filename)
             else:
-                print(info.filename, '->',
-                      os.path.join(args.destination, info.filename))
+                print(
+                    info.filename, "->", os.path.join(args.destination, info.filename)
+                )
 
             arch.extract(info, path=args.destination)
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     main()
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/BuildMethods.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/BuildMethods.py`

 * *Files 27% similar despite different names*

```diff
@@ -4,733 +4,974 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Module grouping the common build functions.
-'''
-__author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+"""
+from builtins import object
 
+from past.builtins import basestring
+
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
+
+import logging
 import os
 import re
-import logging
 import shutil
 from datetime import datetime
-from LbNightlyTools.Utils import log_call as _log_call, find_path
+
+from LbNightlyTools.Utils import compatible_lcg_external_files, find_path
+from LbNightlyTools.Utils import log_call as _log_call
+
 try:  # py3
     from shlex import quote
 except ImportError:  # py2
     from pipes import quote
 
 __log__ = logging.getLogger(__name__)
 __log__.setLevel(logging.DEBUG)
 
 try:
     from LbDevTools import initProject
 except ImportError:
 
     def initProject(dest):
-        log = __log__.getChild('initProject')
-        if not os.path.exists(os.path.join(dest, 'Makefile')):
-            log.debug('create default generic Makefile')
-            with open(os.path.join(dest, 'Makefile'), 'w') as f:
-                f.write('include $(LBCONFIGURATIONROOT)/data/Makefile\n')
-        if not os.path.exists(os.path.join(dest, 'toolchain.cmake')):
-            log.debug('create default toolchain.cmake')
-            with open(os.path.join(dest, 'toolchain.cmake'), 'w') as f:
-                f.write('include($ENV{LBUTILSROOT}/data/toolchain.cmake)\n')
-
-
-def log_call(*args, **kwargs):
-    '''
-    Helper to send log messages of log_call to __log__ by default.
-    '''
-    if 'logger' not in kwargs:
-        kwargs['logger'] = __log__.getChild(args[0][0].replace('.', '_'))
-    return _log_call(*args, **kwargs)
+        log = __log__.getChild("initProject")
+        if not os.path.exists(os.path.join(dest, "Makefile")):
+            log.debug("create default generic Makefile")
+            with open(os.path.join(dest, "Makefile"), "w") as f:
+                f.write("include $(LBCONFIGURATIONROOT)/data/Makefile\n")
+        if not os.path.exists(os.path.join(dest, "toolchain.cmake")):
+            log.debug("create default toolchain.cmake")
+            with open(os.path.join(dest, "toolchain.cmake"), "w") as f:
+                f.write("include($ENV{LBUTILSROOT}/data/toolchain.cmake)\n")
+
+
+def _apptainer_wrap_cmd(platform, cmd, host_root, cont_root, env, cwd):
+    """
+    Return the passed command wrapped in an apptainer invocation.
+    """
+    import re
+
+    from whichcraft import which
+
+    apptainer = which("apptainer")
+    if not apptainer:
+        return cmd
+
+    image = None
+    if re.match(r"x86_64.*-centos7-.*", platform):
+        image = "/cvmfs/cernvm-prod.cern.ch/cvm4"
+    elif re.match(r"x86_64.*-slc[56]-.*", platform):
+        image = "/cvmfs/cernvm-prod.cern.ch/cvm3"
+    elif re.match(r"x86_64.*-el9-.*", platform):
+        image = "/cvmfs/lhcb.cern.ch/containers/os-base/alma9-devel/prod/amd64"
+    elif re.match(r"arm.*-centos7-.*", platform):
+        image = "/cvmfs/lhcb.cern.ch/containers/os-base/centos7-devel/prod/aarch64"
+    elif re.match(r"arm.*-el9-.*", platform):
+        image = "/cvmfs/lhcb.cern.ch/containers/os-base/alma9-devel/prod/aarch64"
+
+    if not image:
+        return cmd
+
+    apptainer_cmd = [
+        apptainer,
+        "exec",
+        "--bind",
+        "/cvmfs",
+        "--bind",
+        "{}:{}".format(host_root, cont_root),
+        # we bind host_root as itself to fix issues with non relocatable local conda environments
+        "--bind",
+        host_root,
+    ]
+
+    apptainer_cmd.extend(
+        ["--pwd", os.path.join(cont_root, os.path.relpath(cwd, host_root))]
+    )
+
+    # guarantee that we have all system directories in PATH in the container
+    if env.get("PATH"):
+        env["PATH"] = (
+            env["PATH"]
+            + ":/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
+        )
+
+    for variable in ("PATH", "LD_LIBRARY_PATH"):
+        if env.get(variable):
+            apptainer_cmd.extend(["--env", "{}={}".format(variable, env[variable])])
+    apptainer_cmd.append(image)
+
+    apptainer_cmd.extend(cmd)
+
+    __log__.debug("apptainer command: %s", " ".join(quote(a) for a in apptainer_cmd))
+    return apptainer_cmd
+
+
+def log_call(cmd, *args, **kwargs):
+    """
+    Helper to use apptainer and send log messages of log_call to __log__ by default.
+    """
+    if "logger" not in kwargs:
+        kwargs["logger"] = __log__.getChild(cmd[0].replace(".", "_"))
+
+    host_root = os.environ.get("WORKSPACE") or os.getcwd()
+    cont_root = "/workspace"
+
+    # patch the environment for the wrapped command
+    kwargs["env"] = {
+        key: value.replace(host_root, cont_root)
+        for key, value in (kwargs.get("env") or os.environ).items()
+    }
+
+    cmd = _apptainer_wrap_cmd(
+        os.environ["BINARY_TAG"],
+        cmd,
+        host_root,
+        cont_root,
+        env=kwargs["env"],
+        cwd=kwargs.get("cwd", os.getcwd()),
+    )
+
+    return _log_call(cmd, *args, **kwargs)
 
 
 def ensure_dir(path):
-    '''
+    """
     Make sure that a directory exist, creating it and printing a warning if not.
-    '''
+    """
     if not os.path.exists(path):
-        __log__.warning('directory %s is missing, I create it', path)
+        __log__.warning("directory %s is missing, I create it", path)
         os.makedirs(path)
 
 
+def to_cmake_version(v):
+    """
+    Helper to convert "vXrYpZ" to "X.Y.Z".
+
+    >>> to_cmake_version('v1r0p0')
+    '1.0.0'
+    """
+    return ".".join(re.findall(r"\d+", v))
+
+
 class BuildResults(object):
-    '''
+    """
     Class used to analyze the build reports of projects.
-    '''
+    """
 
-    def __init__(self,
-                 project,
-                 returncode,
-                 stdout,
-                 stderr,
-                 started,
-                 completed=None):
-        '''
+    def __init__(self, project, returncode, stdout, stderr, started, completed=None):
+        """
         Initialize the instance with raw data from the build.
-        '''
+        """
         self.project = project
         self.returncode = returncode
         self.stdout = stdout
         self.stderr = stderr
         self.started = started
         self.completed = completed or datetime.now()
 
 
 class make(object):
-    '''
+    """
     Base class for build tools based on make.
-    '''
+    """
 
     def _make(self, target, proj, **kwargs):
-        '''
+        """
         Internal function to wrap the call to make for CMT.
 
         @param target: name of the target to build
         @param proj: Project instance to build
         @param jobs: number of parallel build processes [default: 1]
         @param max_load: maximum allowed load beyond which no new process are
                          started
         @param env: dictionary used to override environment variables from the
                     project configuration
         @param args: list of extra arguments to pass to make
         @param make_cmd: command to be used to build [default: ['make']]
-        '''
-        jobs = kwargs.get('jobs')
-        max_load = kwargs.get('max_load')
+        """
+        jobs = kwargs.get("jobs")
+        max_load = kwargs.get("max_load")
 
         env = proj.environment()
-        env.update(kwargs.get('env', {}))
+        env.update(kwargs.get("env", {}))
         # "unset" variables set to None
-        env = dict((key, value) for key, value in env.iteritems()
-                   if value is not None)
+        env = dict((key, value) for key, value in env.items() if value is not None)
 
-        cmd_kwargs = {'env': env, 'cwd': proj.baseDir}
-        if 'stderr' in kwargs:
-            cmd_kwargs['stderr'] = kwargs['stderr']
+        cmd_kwargs = {"env": env, "cwd": proj.baseDir}
+        if "stderr" in kwargs:
+            cmd_kwargs["stderr"] = kwargs["stderr"]
 
-        cmd = kwargs.get('make_cmd') or 'make'
+        cmd = kwargs.get("make_cmd") or "make"
         if isinstance(cmd, basestring):
             cmd = cmd.split()
         else:
             # make a copy of make_cmd argumens to avoid modifying it
             cmd = list(cmd)
 
         if jobs:
-            cmd.append('-j%d' % jobs)
+            cmd.append("-j%d" % jobs)
         if max_load:
-            cmd.append('-l%.1f' % max_load)
-        cmd.extend(kwargs.get('args', []))
+            cmd.append("-l%.1f" % max_load)
+        cmd.extend(kwargs.get("args", []))
         cmd.append(target)
 
-        ensure_dir(cmd_kwargs['cwd'])
-        initProject(cmd_kwargs['cwd'])
+        ensure_dir(cmd_kwargs["cwd"])
+        initProject(cmd_kwargs["cwd"])
 
-        __log__.debug('running %s', ' '.join(cmd))
+        __log__.debug("running %s", " ".join(cmd))
         started = datetime.now()
         result = log_call(cmd, **cmd_kwargs)
         completed = datetime.now()
-        __log__.debug('command exited with code %d', result['retcode'])
+        __log__.debug("command exited with code %d", result["retcode"])
 
-        out = ('#### {0} {1} ####\n'
-               '# Start: {2}\n'
-               '# Command: {3}\n{4}'
-               '# End: {5}\n').format(
-                   self, target, started.isoformat(), ' '.join(
-                       quote(a) for a in cmd), result['stdout'],
-                   completed.isoformat())
-        return BuildResults(proj, result['retcode'], out, result['stderr'],
-                            started, completed)
+        out = (
+            (
+                "#### {0} {1} ####\n"
+                "# Start: {2}\n"
+                "# Command: {3}\n{4}"
+                "# End: {5}\n"
+            )
+            .format(
+                self,
+                target,
+                started.isoformat(),
+                " ".join(quote(a) for a in cmd),
+                result["stdout"],
+                completed.isoformat(),
+            )
+            .encode("utf-8")
+        )
+        return BuildResults(
+            proj, result["retcode"], out, result["stderr"], started, completed
+        )
 
     def build(self, proj, **kwargs):
-        '''
+        """
         Build a project.
-        '''
-        return self._make('all', proj, **kwargs)
+        """
+        return self._make("all", proj, **kwargs)
 
     def clean(self, proj, **kwargs):
-        '''
+        """
         Clean the build products.
-        '''
-        return self._make('clean', proj, **kwargs)
+        """
+        return self._make("clean", proj, **kwargs)
 
     def test(self, proj, **kwargs):
-        '''
+        """
         Run the tests.
-        '''
-        return self._make('test', proj, **kwargs)
+        """
+        return self._make("test", proj, **kwargs)
 
     def __str__(self):
-        '''
+        """
         Conversion to string.
-        '''
-        return 'make'
+        """
+        return "make"
 
 
 class cmt(make):
-    '''
+    """
     Class to wrap the build/test semantics for CMT-based projects.
-    '''
+    """
 
     def _make(self, target, proj, **kwargs):
-        '''
+        """
         Override basic make call to set the environment variable USE_CMT=1.
-        '''
-        env = kwargs.pop('env', {})
+        """
+        env = kwargs.pop("env", {})
         # PWD and CWD may cause troubles to CMT, so we unset them
-        env.update({'USE_CMT': '1', 'PWD': None, 'CWD': None})
-        if 'CMTROOT' not in env and 'make_cmd' not in kwargs:
-            kwargs['make_cmd'] = ['cmt', 'run', 'make']
+        env.update({"USE_CMT": "1", "PWD": None, "CWD": None})
+        if "CMTROOT" not in env and "make_cmd" not in kwargs:
+            kwargs["make_cmd"] = ["cmt", "run", "make"]
         return make._make(self, target, proj, env=env, **kwargs)
 
     def clean(self, proj, **kwargs):
-        '''
+        """
         Override default clean method to call the 'purge' target (more
         aggressive).
-        '''
-        return self._make('purge', proj, **kwargs)
+        """
+        return self._make("purge", proj, **kwargs)
 
     def test(self, proj, **kwargs):
-        '''
+        """
         Run the tests in a Gaudi/LHCb project using CMT.
-        '''
-        # ensure that tests are not run in parallel
-        kwargs.pop('max_load', None)
-        kwargs.pop('jobs', None)
-        env = kwargs.get('env', {})
-        if 'CMTCONFIG' not in env:
-            env['CMTCONFIG'] = (os.environ.get('CMTCONFIG')
-                                or os.environ.get('BINARY_TAG'))
-        if 'GAUDI_QMTEST_HTML_OUTPUT' not in env:
-            bin_dir = os.path.join(
-                os.path.abspath(proj.baseDir), 'build', 'html')
-            env['GAUDI_QMTEST_HTML_OUTPUT'] = bin_dir
-        kwargs['env'] = env
-        return self._make('test', proj, **kwargs)
+        """
+        env = kwargs.get("env", {})
+        if "CMTCONFIG" not in env:
+            env["CMTCONFIG"] = os.environ.get("CMTCONFIG") or os.environ.get(
+                "BINARY_TAG"
+            )
+        if "GAUDI_QMTEST_HTML_OUTPUT" not in env:
+            bin_dir = os.path.join(os.path.abspath(proj.baseDir), "build", "html")
+            env["GAUDI_QMTEST_HTML_OUTPUT"] = bin_dir
+        kwargs["env"] = env
+        return self._make("test", proj, **kwargs)
 
     def __str__(self):
-        '''
+        """
         Conversion to string.
-        '''
-        return 'CMT'
+        """
+        return "CMT"
 
 
 class cmake_old(make):
-    '''
+    """
     Class to wrap the build/test semantics for CMT-based projects.
-    '''
+    """
 
     def _cache_preload_file(self, proj):
-        '''
+        """
         Name of the cache preload file to be passed to CMake.
-        '''
-        return os.path.join(proj.baseDir, 'cache_preload.cmake')
+        """
+        return os.path.join(proj.baseDir, "cache_preload.cmake")
 
     def _prepare_cache(self, proj, cache_entries=None):
-        '''
+        """
         Prepare the cache_preload.cmake file passed to CMake during the
         configuration.
-        '''
+        """
         # prepare the cache to give to CMake: add the launcher rules commands,
         # followed by what is found passed as argument
         if cache_entries is None:
             cache_entries = []
-        elif hasattr(cache_entries, 'items'):
-            cache_entries = cache_entries.items()
+        elif hasattr(cache_entries, "items"):
+            cache_entries = list(cache_entries.items())
 
         # add the RULE_LAUNCH settings for the build
-        launcher_cmd = 'lbn-wrapcmd <CMAKE_CURRENT_BINARY_DIR> <TARGET_NAME>'
-        cache_entries = (
-            [('GAUDI_RULE_LAUNCH_%s' % n, launcher_cmd)
-             for n in ('COMPILE', 'LINK', 'CUSTOM')] + cache_entries)
+        launcher_cmd = "lbn-wrapcmd <CMAKE_CURRENT_BINARY_DIR> <TARGET_NAME>"
+        cache_entries = [
+            ("GAUDI_RULE_LAUNCH_%s" % n, launcher_cmd)
+            for n in ("COMPILE", "LINK", "CUSTOM")
+        ] + cache_entries
+        cache_entries.extend(
+            ("%s_INSTALL_VERSION" % p.name, p.version)
+            for p in (proj.slot.projects if proj.slot else [])
+        )
 
         cache_file = self._cache_preload_file(proj)
         ensure_dir(os.path.dirname(cache_file))
-        with open(cache_file, 'w') as cache:
-            cache.writelines([
-                'set(%s "%s" CACHE STRING "override")\n' % item
-                for item in cache_entries
-            ])
+        with open(cache_file, "w") as cache:
+            cache.writelines(
+                [
+                    'set(%s "%s" CACHE STRING "override")\n' % item
+                    for item in cache_entries
+                ]
+            )
+
+            # constrain versions of projects not built in the slot
+            if proj.slot:
+                cache.writelines(
+                    'set({project}_EXACT_VERSION "{version}" CACHE STRING "")\n'.format(
+                        project=p.name, version=to_cmake_version(p.version)
+                    )
+                    for p in proj.slot.projects
+                    if p.disabled
+                )
 
     def _make(self, target, proj, **kwargs):
-        '''
+        """
         Override basic make call to set the environment variable USE_CMT=1.
-        '''
+        """
         # copy kwargs to be able to change it
         kwargs = dict(kwargs)
-        self._prepare_cache(
-            proj, cache_entries=kwargs.pop('cache_entries', None))
+        self._prepare_cache(proj, cache_entries=kwargs.pop("cache_entries", None))
 
-        env = kwargs.pop('env', {})
-        preload_file = os.path.join(os.getcwd(),
-                                    self._cache_preload_file(proj))
-        env.update({
-            'USE_CMAKE': '1',
-            'USE_MAKE': '1',
-            'CMAKEFLAGS': '-C' + preload_file
-        })
+        env = kwargs.pop("env", {})
+        preload_file = os.path.join(os.getcwd(), self._cache_preload_file(proj))
+        env.update(
+            {"USE_CMAKE": "1", "USE_MAKE": "1", "CMAKEFLAGS": "-C" + preload_file}
+        )
         try:
-            kwargs['make_cmd'] = kwargs['make_cmd'].get(target)
+            kwargs["make_cmd"] = kwargs["make_cmd"].get(target)
         except (KeyError, TypeError, AttributeError):
             # no target-specific make_cmd
             pass
+        if "relaxed_install" in kwargs:
+            del kwargs["relaxed_install"]
         return make._make(self, target, proj, env=env, **kwargs)
 
     def build(self, proj, **kwargs):
-        '''
+        """
         Override the basic build method to call the different targets used in
         CMake builds: configure, all, unasfe-install, post-install.
-        '''
-        kwargs['args'] = ['BUILDDIR=build'] + kwargs.get('args', [])
+        """
+        kwargs["args"] = ["BUILDDIR=build"] + kwargs.get("args", [])
         output = [
             self._make(target, proj, **kwargs)
-            for target in ('configure', 'all', 'unsafe-install',
-                           'post-install', 'clean')
+            for target in (
+                "configure",
+                "all",
+                "unsafe-install",
+                "post-install",
+                "clean",
+            )
         ]
 
         # Write configuration logfile fragment for "collect logs" script
-        ensure_dir(os.path.join(proj.baseDir, 'build', 'configure'))
+        ensure_dir(os.path.join(proj.baseDir, "build", "configure"))
         with open(
-                os.path.join(
-                    proj.baseDir, 'build', 'configure',
-                    '{:%s%f000}-build.log'.format(output[0].completed)),
-                'w') as conf_log:
+            os.path.join(
+                proj.baseDir,
+                "build",
+                "configure",
+                "{:%s%f000}-build.log".format(output[0].completed),
+            ),
+            "wb",
+        ) as conf_log:
             # conf_log.write('\033[0;32m({})\$ {}\033[0m\n'.format(
             #     os.path.join(proj.baseDir), ' '.join(quote(a) for a in cmd)))
             conf_log.writelines(output[0].stdout.splitlines(True)[2:-1])
             conf_log.write(
-                '\033[0;34mConfiguration completed in {} seconds\033[0m\n'.
-                format(
-                    (output[0].completed - output[0].started).total_seconds()))
+                "\033[0;34mConfiguration completed in {} seconds\033[0m\n".format(
+                    (output[0].completed - output[0].started).total_seconds()
+                ).encode("utf-8")
+            )
 
         output = (
             output[1].returncode,  # use the build return code
-            ''.join(step.stdout for step in output),
-            ''.join(step.stderr for step in output),
+            b"".join(step.stdout for step in output),
+            b"".join(step.stderr for step in output),
             output[0].started,
-            output[-1].completed)
+            output[-1].completed,
+        )
 
         return BuildResults(proj, *output)
 
     def clean(self, proj, **kwargs):
-        '''
+        """
         Override default clean method to call the 'purge' target (more
         aggressive).
-        '''
-        return self._make('purge', proj, **kwargs)
+        """
+        return self._make("purge", proj, **kwargs)
 
     def test(self, proj, **kwargs):
-        '''
+        """
         Run the tests in a Gaudi/LHCb project using CMT.
-        '''
-        # ensure that tests are not run in parallel
-        kwargs.pop('max_load', None)
-        kwargs.pop('jobs', None)
-        kwargs['args'] = ['BUILDDIR=build'] + kwargs.get('args', [])
+        """
+        kwargs["args"] = ["BUILDDIR=build"] + kwargs.get("args", [])
+        flags = []  # ["--repeat until-pass:3"]
+        if "jobs" in kwargs:
+            flags.append("-j{}".format(kwargs.pop("jobs")))
+
+        for i, arg in enumerate(kwargs["args"]):
+            if arg.startswith("ARGS="):
+                kwargs["args"][i] += " " + " ".join(flags)
+                break
+        else:  # (this else matches the for) no ARGS= in args
+            kwargs["args"].append("ARGS={}".format(" ".join(flags)))
+
         output = [
-            self._make(target, proj, **kwargs)
-            for target in ('configure', 'test')
+            self._make(target, proj, **kwargs) for target in ("configure", "test")
         ]
         output = (
             output[-1].returncode,  # use the test return code
-            ''.join(step.stdout for step in output),
-            ''.join(step.stderr for step in output),
+            b"".join(step.stdout for step in output),
+            b"".join(step.stderr for step in output),
             output[0].started,
-            output[-1].completed)
+            output[-1].completed,
+        )
 
         return BuildResults(proj, *output)
 
     def __str__(self):
-        '''
+        """
         Conversion to string.
-        '''
-        return 'CMake (old)'
+        """
+        return "CMake (old)"
 
 
 class cmake_new(object):
-
     # known "kwargs" not to be propagated to subprocess
-    SPECIAL_ARGS = ('jobs', 'max_load', 'args', 'make_cmd', 'cache_entries',
-                    'step')
+    SPECIAL_ARGS = (
+        "jobs",
+        "max_load",
+        "args",
+        "make_cmd",
+        "cache_entries",
+        "step",
+        "relaxed_install",
+    )
 
     def _cache_preload_file(self, proj):
-        '''
+        """
         Name of the cache preload file to be passed to CMake.
-        '''
-        return os.path.join(proj.baseDir, 'cache_preload.cmake')
+        """
+        return os.path.join(proj.baseDir, "cache_preload.cmake")
 
     def _prepare_cache(self, proj, cache_entries=None, log_writer=None):
-        '''
+        """
         Prepare the cache_preload.cmake file passed to CMake during the
         configuration.
-        '''
+        """
         # prepare the cache to give to CMake: add the launcher rules commands,
         # followed by what is found passed as argument
         if cache_entries is None:
             cache_entries = []
-        elif hasattr(cache_entries, 'items'):
-            cache_entries = cache_entries.items()
+        elif hasattr(cache_entries, "items"):
+            cache_entries = list(cache_entries.items())
 
         cache_file = self._cache_preload_file(proj)
         ensure_dir(os.path.dirname(cache_file))
-        with open(cache_file, 'w') as cache:
-            cache.writelines([
-                'set(%s "%s" CACHE STRING "override")\n' % item
-                for item in cache_entries
-            ])
+        with open(cache_file, "w") as cache:
+            cache.writelines(
+                [
+                    'set(%s "%s" CACHE STRING "override")\n' % item
+                    for item in cache_entries
+                ]
+            )
             # force use of ccache
             cache.writelines(
-                'set(CMAKE_{}_COMPILER_LAUNCHER ccache CACHE STRING "override")\n'
-                .format(lang) for lang in ('C', 'CXX'))
+                'set(CMAKE_{}_COMPILER_LAUNCHER ccache CACHE STRING "override")\n'.format(
+                    lang
+                )
+                for lang in ("C", "CXX")
+            )
             # enable rule wrappers
-            cache.writelines((
-                'set(CMAKE_RULE_LAUNCH_{} "lbn-wrapcmd <CMAKE_CURRENT_BINARY_DIR> <TARGET_NAME>"\n'
-                '    CACHE STRING "override")\n').format(action)
-                             for action in ('COMPILE', 'LINK', 'CUSTOM'))
+            cache.writelines(
+                (
+                    'set(CMAKE_RULE_LAUNCH_{} "lbn-wrapcmd <CMAKE_CURRENT_BINARY_DIR> <TARGET_NAME>"\n'
+                    '    CACHE STRING "override")\n'
+                ).format(action)
+                for action in ("COMPILE", "LINK", "CUSTOM")
+            )
+            # constrain versions of projects not built in the slot
+            if proj.slot:
+                cache.writelines(
+                    'set({project}_EXACT_VERSION "{version}" CACHE STRING "")\n'.format(
+                        project=p.name, version=to_cmake_version(p.version)
+                    )
+                    for p in proj.slot.projects
+                    if p.disabled
+                )
+
         if log_writer:
-            log_writer('created cache preload file:\n```{}\n{}\n```\n'.format(
-                cache_file,
-                open(cache_file).read().rstrip()))
+            log_writer(
+                "created cache preload file:\n```{}\n{}\n```\n".format(
+                    cache_file, open(cache_file).read().rstrip()
+                )
+            )
 
     def _env(self, project, env=None):
-        '''
+        """
         Compute the environment for the project.
-        '''
+        """
         new_env = project.environment()
         if env:
             new_env.update(env)
         return new_env
 
     def _call(self, proj, cmd, **kwargs):
         # strip special kwargs before command invocation
         cmd_kwargs = {
-            n: v
-            for n, v in kwargs.items() if n not in self.SPECIAL_ARGS
+            n: v for n, v in list(kwargs.items()) if n not in self.SPECIAL_ARGS
         }
-        cmd_kwargs['env'] = self._env(proj, kwargs.get('env'))
+        cmd_kwargs["env"] = self._env(proj, kwargs.get("env"))
 
-        __log__.debug('running %s', ' '.join(cmd))
+        __log__.debug("running %s", " ".join(cmd))
         started = datetime.now()
         result = log_call(cmd, **cmd_kwargs)
         completed = datetime.now()
-        __log__.debug('command exited with code %d', result['retcode'])
+        __log__.debug("command exited with code %d", result["retcode"])
 
-        out = ('#### {0} {1} ####\n'
-               '# Start: {2}\n'
-               '# Command: {3}\n{4}'
-               '# Return code: {5}\n'
-               '# End: {6}\n').format(self, kwargs.get('step',
-                                                       '(no step name)'),
-                                      started.isoformat(), ' '.join(
-                                          quote(a) for a in cmd),
-                                      result['stdout'], result['retcode'],
-                                      completed.isoformat())
-        return BuildResults(proj, result['retcode'], out, result['stderr'],
-                            started, completed)
+        out = (
+            (
+                "#### {0} {1} ####\n"
+                "# Start: {2}\n"
+                "# Command: {3}\n{4}"
+                "# Return code: {5}\n"
+                "# End: {6}\n"
+            )
+            .format(
+                self,
+                kwargs.get("step", "(no step name)"),
+                started.isoformat(),
+                " ".join(quote(a) for a in cmd),
+                result["stdout"].decode("utf-8", errors="replace"),
+                result["retcode"],
+                completed.isoformat(),
+            )
+            .encode("utf-8", errors="replace")
+        )
+        return BuildResults(
+            proj, result["retcode"], out, result["stderr"], started, completed
+        )
 
     def configure(self, proj, **kwargs):
-        '''
+        """
         Configure the project.
-        '''
+        """
         # Prepare configuration logfile fragment for "collect logs" script
         started = datetime.now()
-        config_log = os.path.join(proj.baseDir, 'build', 'configure',
-                                  '{:%s%f000}-build.log'.format(started))
+        config_log = os.path.join(
+            proj.baseDir, "build", "configure", "{:%s%f000}-build.log".format(started)
+        )
         ensure_dir(os.path.dirname(config_log))
         # make sure we start from an empty one
         if os.path.exists(config_log):
             os.remove(config_log)
 
         def write_to_log(data):
-            '''
+            """
             Helper to open+write+close the log file.
-            '''
-            with open(config_log, 'ab') as log:
-                log.write(data)
+            """
+            with open(config_log, "ab") as log:
+                log.write(
+                    data.encode("utf-8", errors="replace")
+                    if hasattr(data, "encode")
+                    else data
+                )
+
+        if "LCG_EXTERNALS_FILE" in kwargs.get("cache_entries", []):
+            ext_file = kwargs["cache_entries"]["LCG_EXTERNALS_FILE"]
+            # we usually pass "$ENV{BINARY_TAG}" as platform in LCG_EXTERNALS_FILE
+            ext_file = ext_file.replace("$ENV{BINARY_TAG}", os.environ["BINARY_TAG"])
+            # find an existing, compatible externals file
+            for ext_file in compatible_lcg_external_files(ext_file):
+                # FIXME: this does not guarantee the file is actually good
+                #        we may have multiple compatible files, but only one
+                #        with the right time and the full list of requirements
+                #        (we should re-run the precondition check to find the
+                #        right match)
+                if os.path.exists(ext_file):
+                    # let's use this one instead of the suggested one
+                    kwargs["cache_entries"]["LCG_EXTERNALS_FILE"] = ext_file
+                    # and make sure we use the required architecture flags
+                    kwargs["cache_entries"]["LHCB_PLATFORM"] = os.environ["BINARY_TAG"]
+                    kwargs["cache_entries"]["LCG_ARCHITECTURE"] = os.environ[
+                        "BINARY_TAG"
+                    ].split("-", 1)[0]
+                    break
 
         self._prepare_cache(
-            proj,
-            cache_entries=kwargs.get('cache_entries'),
-            log_writer=write_to_log)
+            proj, cache_entries=kwargs.get("cache_entries"), log_writer=write_to_log
+        )
 
         # basic cmake command
         cmd = [
-            'cmake', '-S', proj.baseDir, '-B',
-            os.path.join(proj.baseDir, 'build'), '-G',
-            kwargs.get('generator', 'Ninja'), '-C',
-            self._cache_preload_file(proj)
+            "cmake",
+            "-S",
+            proj.baseDir,
+            "-B",
+            os.path.join(proj.baseDir, "build"),
+            "-G",
+            kwargs.get("generator", "Ninja"),
+            "-C",
+            self._cache_preload_file(proj),
         ]
         # get the toolchain to use
-        if proj.slot and hasattr(proj.slot, 'LCG'):
+        if proj.slot and hasattr(proj.slot, "LCG"):
             LCG_VERSION = proj.slot.LCG.version
-        elif 'LCG_VERSION' in os.environ:
-            LCG_VERSION = os.environ['LCG_VERSION']
+        elif "LCG_VERSION" in os.environ:
+            LCG_VERSION = os.environ["LCG_VERSION"]
         else:
-            out = ('\033[0;31mslot configuration error: '
-                   'version of LCG not defined (required for new '
-                   'CMake configuration)\033[0m\n')
+            out = (
+                "\033[0;31mslot configuration error: "
+                "version of LCG not defined (required for new "
+                "CMake configuration)\033[0m\n"
+            )
             write_to_log(out)
-            return BuildResults(proj, 1, out, '', started, datetime.now())
+            return BuildResults(proj, 1, out, "", started, datetime.now())
+
+        # When the configuration sets LCG_EXTERNALS_FILE, we have to use the
+        # toolchain special/lcg-nightly.cmake
+        if "LCG_EXTERNALS_FILE" not in kwargs.get("cache_entries", []):
+            toolchain = find_path(
+                os.path.join(
+                    "lcg-toolchains",
+                    "LCG_{}".format(LCG_VERSION),
+                    "{}.cmake".format(os.environ["BINARY_TAG"]),
+                ),
+                search_path=self._env(proj)
+                .get("CMAKE_PREFIX_PATH", "")
+                .split(os.pathsep),
+            )
+        else:
+            toolchain = find_path(
+                os.path.join("lcg-toolchains", "special", "lcg-nightly.cmake"),
+                search_path=self._env(proj)
+                .get("CMAKE_PREFIX_PATH", "")
+                .split(os.pathsep),
+            )
 
-        toolchain = find_path(
-            os.path.join('lcg-toolchains', 'LCG_{}'.format(LCG_VERSION),
-                         '{}.cmake'.format(os.environ['BINARY_TAG'])),
-            search_path=self._env(proj).get('CMAKE_PREFIX_PATH',
-                                            '').split(os.pathsep))
         if not toolchain:
-            out = ('\033[0;31mslot configuration error: '
-                   'cannot find toolchain file for {} {}\033[0m\n').format(
-                       LCG_VERSION, os.environ['BINARY_TAG'])
+            out = (
+                "\033[0;31mslot configuration error: "
+                "cannot find toolchain file for {} {}\033[0m\n"
+            ).format(LCG_VERSION, os.environ["BINARY_TAG"])
             write_to_log(out)
-            return BuildResults(proj, 1, out, '', started, datetime.now())
+            return BuildResults(proj, 1, out, "", started, datetime.now())
 
-        cmd.append('-DCMAKE_TOOLCHAIN_FILE=' + toolchain)
+        cmd.append("-DCMAKE_TOOLCHAIN_FILE=" + toolchain)
 
-        write_to_log('\033[0;32m({})$ {}\033[0m\n'.format(
-            os.getcwd(), ' '.join(quote(a) for a in cmd)))
-        result = self._call(proj, cmd, step='configure', **kwargs)
+        write_to_log(
+            "\033[0;32m({})$ {}\033[0m\n".format(
+                os.getcwd(), " ".join(quote(a) for a in cmd)
+            )
+        )
+        result = self._call(proj, cmd, step="configure", **kwargs)
 
         # write configuration log
-        write_to_log(''.join(result.stdout.splitlines(True)[3:-2]))
         write_to_log(
-            '\033[0;34mConfiguration completed in {} seconds\033[0m\n'.format(
-                (result.completed - result.started).total_seconds()))
+            "".join(
+                result.stdout.decode("utf-8", errors="replace").splitlines(True)[3:-2]
+            )
+        )
+        write_to_log(
+            "\033[0;34mConfiguration completed in {} seconds\033[0m\n".format(
+                (result.completed - result.started).total_seconds()
+            )
+        )
 
         return result
 
     def install(self, proj, **kwargs):
+        # modify all cmake_install.cmake scripts to do not fail if an artifact
+        # is missing
+        if kwargs.get("relaxed_install"):
+            for dirpath, _dirnames, filenames in os.walk(
+                os.path.join(proj.baseDir, "build")
+            ):
+                if "cmake_install.cmake" in filenames:
+                    with open(os.path.join(dirpath, "cmake_install.cmake")) as f:
+                        data = f.read()
+                    with open(os.path.join(dirpath, "cmake_install.cmake"), "w") as f:
+                        f.write(data.replace("file(INSTALL", "file(INSTALL OPTIONAL"))
         return self._call(
-            proj, [
-                'cmake', '--install',
-                os.path.join(proj.baseDir, 'build'), '--prefix',
-                os.path.join(proj.baseDir, 'InstallArea',
-                             os.environ['BINARY_TAG'])
+            proj,
+            [
+                "cmake",
+                "--install",
+                os.path.join(proj.baseDir, "build"),
+                "--prefix",
+                os.path.join(proj.baseDir, "InstallArea", os.environ["BINARY_TAG"]),
             ],
-            step='install',
-            **kwargs)
+            step="install",
+            **kwargs
+        )
 
     def build(self, proj, **kwargs):
         config_result = self.configure(proj, **kwargs)
         if config_result.returncode:
             # no point trying to build if we failed to configure
             return config_result
 
-        cmd = ['cmake', '--build', os.path.join(proj.baseDir, 'build')]
-        if 'jobs' in kwargs:
-            cmd.extend(['-j', str(kwargs['jobs'])])
-        if 'args' in kwargs:
-            cmd.append('--')
-            cmd.extend(
-                (arg if arg != '-k' else '-k0') for arg in kwargs['args'])
-        build_result = self._call(proj, cmd, step='build', **kwargs)
+        cmd = ["cmake", "--build", os.path.join(proj.baseDir, "build")]
+        if "jobs" in kwargs:
+            cmd.extend(["-j", str(kwargs["jobs"])])
+        if "args" in kwargs:
+            cmd.append("--")
+            cmd.extend((arg if arg != "-k" else "-k0") for arg in kwargs["args"])
+        build_result = self._call(proj, cmd, step="build", **kwargs)
 
         install_result = self.install(proj, **kwargs)
 
         output = (
             build_result.returncode,  # use the build return code
-            ''.join(
-                step.stdout
-                for step in (config_result, build_result, install_result)),
-            ''.join(
-                step.stderr
-                for step in (config_result, build_result, install_result)),
+            b"".join(
+                step.stdout for step in (config_result, build_result, install_result)
+            ),
+            b"".join(
+                step.stderr for step in (config_result, build_result, install_result)
+            ),
             config_result.started,
-            install_result.completed)
+            install_result.completed,
+        )
 
         return BuildResults(proj, *output)
 
     def clean(self, proj, **kwargs):
         return self._call(
-            proj, [
-                'cmake', '--build',
-                os.path.join(proj.baseDir, 'build'), '--target', 'clean'
+            proj,
+            [
+                "cmake",
+                "--build",
+                os.path.join(proj.baseDir, "build"),
+                "--target",
+                "clean",
             ],
-            step='clean',
-            **kwargs)
+            step="clean",
+            **kwargs
+        )
 
     def test(self, proj, **kwargs):
         config_result = self.configure(proj, **kwargs)
         if config_result.returncode:
             # no point trying to run the tests if we failed to configure
             return config_result
 
-        cmd = ['ctest', '-T', 'test']
-        if 'jobs' in kwargs:
-            cmd.extend(['-j', str(kwargs['jobs'])])
+        cmd = ["ctest", "-T", "test"]
+        # cmd.extend(['--repeat', 'until-pass:3'])
+        if "jobs" in kwargs:
+            cmd.extend(["-j", str(kwargs["jobs"])])
         test_result = self._call(
-            proj,
-            cmd,
-            step='test',
-            cwd=os.path.join(proj.baseDir, 'build'),
-            **kwargs)
+            proj, cmd, step="test", cwd=os.path.join(proj.baseDir, "build"), **kwargs
+        )
 
         output = (
             test_result.returncode,  # use the test return code
-            ''.join(step.stdout for step in (config_result, test_result)),
-            ''.join(step.stderr for step in (config_result, test_result)),
+            b"".join(step.stdout for step in (config_result, test_result)),
+            b"".join(step.stderr for step in (config_result, test_result)),
             config_result.started,
-            test_result.completed)
+            test_result.completed,
+        )
 
         return BuildResults(proj, *output)
 
     def __str__(self):
-        return 'CMake (new)'
+        return "CMake (new)"
 
 
 def is_new_cmake_style(project_dir):
-    '''
+    """
     Check if the project uses the old or new CMake configuration style.
-    '''
-    top_config = os.path.join(project_dir, 'CMakeLists.txt')
+    """
+    top_config = os.path.join(project_dir, "CMakeLists.txt")
     if not os.path.exists(top_config):
         # no CMakeLists.tst -> it's a CMT project
         return False
-    if os.path.exists(os.path.join(project_dir, 'toolchain.cmake')):
+    if os.path.exists(os.path.join(project_dir, "toolchain.cmake")):
         # custom toolchain file in the sources -> must be old style
         return False
     with open(top_config) as f:
         content = f.read()
     # new style projects do not call "find_package(GaudiProject)"
-    return not bool(re.search(r'find_package\s*\(\s*GaudiProject', content))
+    return not bool(re.search(r"find_package\s*\(\s*GaudiProject", content))
 
 
 class cmake(object):
-    '''
+    """
     Dispatcher to use the old or new style CMake build procedure
     depending on the project.
-    '''
+    """
 
     def __init__(self):
         self._proj_dir = None
         self._impl_instance = None
 
     def _impl(self, project):
-        '''
+        """
         Return the correct implementation of CMake builder for the given project.
-        '''
+        """
         if project.baseDir != self._proj_dir:
-            self._impl_instance = (cmake_new() if is_new_cmake_style(
-                project.baseDir) else cmake_old())
+            self._impl_instance = (
+                cmake_new() if is_new_cmake_style(project.baseDir) else cmake_old()
+            )
         return self._impl_instance
 
     def build(self, proj, **kwargs):
         return self._impl(proj).build(proj, **kwargs)
 
     def clean(self, proj, **kwargs):
         return self._impl(proj).clean(proj, **kwargs)
 
     def test(self, proj, **kwargs):
         return self._impl(proj).test(proj, **kwargs)
 
     def __str__(self):
-        '''
+        """
         Conversion to string.
-        '''
-        return 'CMake'
+        """
+        return "CMake"
 
 
 class no_build(object):
-    '''
+    """
     No-op build tool, used for projects that do no require a build
     (e.g. projects containing only data packages).
-    '''
+    """
 
     def build(self, proj, **kwargs):
-        '''
+        """
         Build method.
-        '''
-        __log__.debug('no build for %s', proj)
-        return BuildResults(proj, 0, 'no build for %s' % proj, '',
-                            datetime.now())
+        """
+        __log__.debug("no build for %s", proj)
+        return BuildResults(proj, 0, "no build for %s" % proj, "", datetime.now())
 
     def clean(self, proj, **kwargs):
-        '''
+        """
         Clean method.
-        '''
-        __log__.debug('no clean for %s', proj)
-        return BuildResults(proj, 0, 'no clean for %s' % proj, '',
-                            datetime.now())
+        """
+        __log__.debug("no clean for %s", proj)
+        return BuildResults(proj, 0, "no clean for %s" % proj, "", datetime.now())
 
     def test(self, proj, **kwargs):
-        '''
+        """
         Test method.
-        '''
-        __log__.debug('no test for %s', proj)
-        return BuildResults(proj, 0, 'no test for %s' % proj, '',
-                            datetime.now())
+        """
+        __log__.debug("no test for %s", proj)
+        return BuildResults(proj, 0, "no test for %s" % proj, "", datetime.now())
 
     def __str__(self):
-        '''
+        """
         Conversion to string.
-        '''
-        return 'no-build'
+        """
+        return "no-build"
 
 
 class echo(object):
-    '''
+    """
     Dummy build tool class used for testing.
-    '''
+    """
 
     def _report(self, target, proj, **kwargs):
-        '''
+        """
         Helper.
-        '''
-        output = ' '.join([target, str(proj), str(kwargs)])
+        """
+        output = " ".join([target, str(proj), str(kwargs)])
         __log__.debug(output)
-        return BuildResults(proj, 0, output, '', datetime.now())
+        return BuildResults(proj, 0, output, "", datetime.now())
 
     def build(self, proj, **kwargs):
-        '''
+        """
         Build method.
-        '''
-        return self._report('build', proj, **kwargs)
+        """
+        return self._report("build", proj, **kwargs)
 
     def clean(self, proj, **kwargs):
-        '''
+        """
         Clean method.
-        '''
-        return self._report('clean', proj, **kwargs)
+        """
+        return self._report("clean", proj, **kwargs)
 
     def test(self, proj, **kwargs):
-        '''
+        """
         Test method.
-        '''
-        return self._report('test', proj, **kwargs)
+        """
+        return self._report("test", proj, **kwargs)
 
     def __str__(self):
-        '''
+        """
         Conversion to string.
-        '''
-        return 'echo'
+        """
+        return "echo"
 
 
 default = cmake
 
 
 def getMethod(method=None):
-    '''
+    """
     Helper function to get a build method by name.
 
     If method is a callable we return it, otherwise we look for the name in the
     current module or as a function coming from another module.
     If method is None, we return the default checkout method.
-    '''
+    """
     if method is None:
         return default
-    if hasattr(method, 'build'):
+    if hasattr(method, "build"):
         return method
     if isinstance(method, basestring):
-        if '.' in method:
+        if "." in method:
             # method is a fully qualified function name
-            m, f = method.rsplit('.', 1)
+            m, f = method.rsplit(".", 1)
             return getattr(__import__(m, fromlist=[f]), f)
         else:
             # it must be a name in this module
             return globals()[method]
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/GitlabUtils.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/GitlabUtils.py`

 * *Files 18% similar despite different names*

```diff
@@ -5,55 +5,60 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Gitlab utilities
-'''
+"""
 import logging
+
+from past.builtins import basestring
+
 _logger = logging.getLogger(__name__)
 
-GITLAB_URL = 'https://gitlab.cern.ch/'
+GITLAB_URL = "https://gitlab.cern.ch/"
 
 
 def cached(f):
-    '''
+    """
     Decorator to add caching to functions.
-    '''
+    """
     from functools import wraps
+
     _cache = {}
 
     @wraps(f)
     def wrapper(*args, **kwargs):
-        _logger.debug('%s invoked with %r', f.__name__, (args, kwargs))
+        _logger.debug("%s invoked with %r", f.__name__, (args, kwargs))
         try:
             key = (tuple(args), tuple(kwargs.items()))
             if key in _cache:
-                _logger.debug('result in cache')
+                _logger.debug("result in cache")
                 return _cache[key]
         except TypeError:
             # a TypeError at this point means one of the arguments is not hashable
-            _logger.debug('unhashable arguments, invoking the function')
+            _logger.debug("unhashable arguments, invoking the function")
             return f(*args, **kwargs)
-        _logger.debug('result not in cache, invoking the function')
+        _logger.debug("result not in cache, invoking the function")
         result = _cache[key] = f(*args, **kwargs)
         return result
 
     return wrapper
 
 
 @cached
 def _gitlabServer():
     import os
+
     import gitlab
-    return gitlab.Gitlab(
-        GITLAB_URL, private_token=os.environ.get('GITLAB_TOKEN'))
+
+    return gitlab.Gitlab(GITLAB_URL, private_token=os.environ.get("GITLAB_TOKEN"))
 
 
 @cached
 def _getGitlabProject(project_id):
     return _gitlabServer().projects.get(project_id)
 
 
@@ -63,146 +68,177 @@
     for c in mr.commits():
         return c.id
     return None
 
 
 @cached
 def _getAllProjectMRs(project_id):
-    return _getGitlabProject(project_id).mergerequests.list(
-        state='opened', all=True)
+    return _getGitlabProject(project_id).mergerequests.list(state="opened", all=True)
 
 
 def getMergeRequests(project_id, labels=None, wip=None, target_branch=None):
     from gitlab import GitlabGetError
-    wip_condition = (lambda _: True) if wip is None else (
-        lambda mr: mr.work_in_progress == wip)
+
+    wip_condition = (
+        (lambda _: True) if wip is None else (lambda mr: mr.work_in_progress == wip)
+    )
     label_condition = (lambda _: True) if not labels else ()
     if labels:
         labels = set(labels)
-        label_condition = lambda (mr): labels.intersection(mr.labels)
+        label_condition = lambda mr: labels.intersection(mr.labels)
     else:
         label_condition = lambda _: True
-    condition = lambda mr: (mr.target_branch == target_branch and wip_condition(mr) and label_condition(mr))
+    condition = lambda mr: (
+        mr.target_branch == target_branch and wip_condition(mr) and label_condition(mr)
+    )
     try:
-        return sorted((mr.iid, getMRCommit(project_id, mr.iid))
-                      for mr in _getAllProjectMRs(project_id) if condition(mr))
+        return sorted(
+            (mr.iid, getMRCommit(project_id, mr.iid))
+            for mr in _getAllProjectMRs(project_id)
+            if condition(mr)
+        )
 
     except GitlabGetError:
-        _logger.warning('problem getting MRs for %s', project_id)
+        _logger.warning("problem getting MRs for %s", project_id)
         return []
 
 
 def getProjectId(project):
-    '''
+    """
     Given a Project instance return the corresponding Gitlab project id
     ('group/name').
-    '''
+    """
+    from LbNightlyTools.Configuration import Package
+
     project_id = project.name
 
-    if 'url' in project.checkout_opts:
-        if project.checkout_opts['url'].startswith(GITLAB_URL):
-            project_id = project.checkout_opts['url'][len(GITLAB_URL):]
-            if project_id.endswith('.git'):
+    if "url" in project.checkout_opts:
+        if project.checkout_opts["url"].startswith(GITLAB_URL):
+            project_id = project.checkout_opts["url"][len(GITLAB_URL) :]
+            if project_id.endswith(".git"):
                 project_id = project_id[:-4]
 
-    if '/' not in project_id:
+    if isinstance(project, Package):
+        project_id = "lhcb-datapkg/" + project_id
+    elif "/" not in project_id:
         # FIXME: we should get the gitlab group from soft conf db
-        project_id = {
-            'Gaudi': 'gaudi',
-            'Gaussino': 'Gaussino',
-        }.get(project_id, 'lhcb') + '/' + project_id
+        project_id = (
+            {
+                "Gaudi": "gaudi",
+                "Gaussino": "Gaussino",
+            }.get(project_id, "lhcb")
+            + "/"
+            + project_id
+        )
 
     return project_id
 
 
 @cached
 def getBranchCommitId(project_id, branch):
     project = _getGitlabProject(project_id)
-    return project.branches.get(branch).commit['id']
+    return project.branches.get(branch).commit["id"]
 
 
 def resolveProjectMRs(project):
-    '''
+    """
     Given a project, convert the list of requested MRs to a list
     of (mr_iid, commit_id) pairs.
 
     The supported merge requests are:
     - 'all' (same as 'label=all-slots' + 'label=<slot-name>',
       if the project is in a slot)
     - 'label=<abc>'
     - '<id>'
 
     If the project version is 'HEAD', it's equivalent to version == 'master'
     and adding 'all' to the merges.
 
     The project is not modified.
-    '''
+    """
     project_id = getProjectId(project)
     target_branch = project.version
 
-    merges = project.checkout_opts.get('merges', [])
+    merges = project.checkout_opts.get("merges", [])
     if not isinstance(merges, list):
         merges = [merges]
     else:
         merges = list(merges)
 
-    if target_branch.lower() == 'head':
-        target_branch = 'master'
-        merges.insert(0, 'all')
+    if target_branch.lower() == "head":
+        target_branch = "master"
+        merges.insert(0, "all")
 
     new_merges = []
     for m in merges:
-        if m == 'all':
+        if m == "all":
             tmp = getMergeRequests(
-                project_id,
-                labels=('all-slots', ),
-                target_branch=target_branch)
+                project_id, labels=("all-slots",), target_branch=target_branch
+            )
             if project.slot:
                 tmp.extend(
                     getMergeRequests(
                         project_id,
-                        labels=(project.slot.name, ),
-                        target_branch=target_branch))
+                        labels=(project.slot.name,),
+                        target_branch=target_branch,
+                    )
+                )
             tmp.sort()
             new_merges.extend(tmp)
-        elif isinstance(m, (int, long)):
+        elif isinstance(m, int):
             new_merges.append((m, getMRCommit(project_id, m)))
-        elif isinstance(m, basestring) and m.startswith('label='):
+        elif isinstance(m, basestring) and m.startswith("label="):
             new_merges.extend(
                 getMergeRequests(
-                    project_id, labels=(m[6:], ), target_branch=target_branch))
+                    project_id, labels=(m[6:],), target_branch=target_branch
+                )
+            )
         else:
             new_merges.append(m)
 
     # deduplicate
     merges = []
     for m in new_merges:
         if m not in merges:
             merges.append(m)
 
     return merges
 
 
 def resolveMRs(item):
-    from LbNightlyTools.Configuration import Slot, Project, DataProject
     from gitlab import GitlabGetError
 
-    if isinstance(item, DataProject):
-        pass  # FIXME: ignore DataProject for the moment
-    elif isinstance(item, Project):
-        if not item.disabled:
-            item.checkout_opts['merges'] = resolveProjectMRs(item)
-            if not 'commit' in item.checkout_opts:
+    from LbNightlyTools.Configuration import DataProject, Package, Project, Slot
+
+    if isinstance(item, Slot):
+        resolveMRs(item.projects)
+    elif isinstance(item, DataProject):
+        resolveMRs(item.packages)
+    elif isinstance(item, (Project, Package)):
+        if isinstance(item, Package) or not item.disabled:
+            item.checkout_opts["merges"] = resolveProjectMRs(item)
+            if not "commit" in item.checkout_opts:
                 try:
-                    item.checkout_opts['commit'] = getBranchCommitId(
+                    item.checkout_opts["commit"] = getBranchCommitId(
                         getProjectId(item),
-                        ('master'
-                         if item.version.lower() == 'head' else item.version))
+                        ("master" if item.version.lower() == "head" else item.version),
+                    )
                 except GitlabGetError:
                     # this means the requested version is a tag rather
                     # (not a branch)
                     pass
-    elif isinstance(item, Slot):
-        resolveMRs(item.projects)
+        else:  # disabled project case, just clean up pointless checkout opts
+            item.checkout = ("ignore", {})
     else:
         return [resolveMRs(p) for p in item]
     return item
+
+
+@cached
+def getMRLabels(project, mr_iid):
+    try:
+        project_id = getProjectId(project)
+        mr = _getGitlabProject(project_id).mergerequests.get(mr_iid)
+        return mr.labels
+    except Exception as err:
+        _logger.warning("exception in getMRLabels(%s,%s): %s", project, mr_iid, err)
+        return []
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/__init__.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -4,28 +4,29 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 LHCb Nightly Build System module.
-'''
-__author__ = 'Marco Clemencic <marco.clemencic@cern.ch>'
+"""
+__author__ = "Marco Clemencic <marco.clemencic@cern.ch>"
 
 # FIXME: add method getChild to logging.Logger (introduced in Python 2.7)
 import logging
-if not hasattr(logging.Logger, 'getChild'):
+
+if not hasattr(logging.Logger, "getChild"):
 
     def logger_getChild(self, suffix):
-        '''Copied from Python 2.7 logging.Logger.getChild'''
+        """Copied from Python 2.7 logging.Logger.getChild"""
         if self.root is not self:
-            suffix = '.'.join((self.name, suffix))
+            suffix = ".".join((self.name, suffix))
         return self.manager.getLogger(suffix)
 
     logging.Logger.getChild = logger_getChild
 
+from LbNightlyTools.Configuration import findSlot
+
 # Make the Dashboard class visible from the top level for convenience.
 from LbNightlyTools.Utils import Dashboard
-
-from LbNightlyTools.Configuration import findSlot
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_config_pickle.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_config_pickle.py`

 * *Files 18% similar despite different names*

```diff
@@ -5,57 +5,62 @@
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 # Uncomment to disable the tests.
-#__test__ = False
+# __test__ = False
 
-from LbNightlyTools.Configuration import slots, Project, Package, Slot, DBASE
 import pickle
 
+from LbNightlyTools.Configuration import DBASE, Package, Project, Slot, slots
+
 
 def setup():
     slots.clear()
 
 
 def test_project():
     orig = Project(
-        'Gaudi',
-        'v26r1',
-        checkout='git',
-        checkout_opts=dict(url='http://git.cern.ch/pub/gaudi'),
-        build_method='cmake',
-        env=['USE_MAKE=1'])
+        "Gaudi",
+        "v26r1",
+        checkout="git",
+        checkout_opts=dict(url="http://git.cern.ch/pub/gaudi"),
+        build_method="cmake",
+        env=["USE_MAKE=1"],
+    )
     clone = pickle.loads(pickle.dumps(orig))
     assert orig == clone
 
 
 def test_package():
-    orig = Package('AppConfig', 'head')
+    orig = Package("AppConfig", "head")
     clone = pickle.loads(pickle.dumps(orig))
     assert orig == clone
 
 
 def _test_dataproject():  # FIXME: temporarily disabled
-    orig = DBASE([Package('AppConfig', 'head')])
+    orig = DBASE([Package("AppConfig", "head")])
     clone = pickle.loads(pickle.dumps(orig))
     assert orig == clone
 
 
 def _test_slot():  # FIXME: temporarily disabled
     orig = Slot(
-        'test', [
+        "test",
+        [
             Project(
-                'Gaudi',
-                'v26r1',
-                checkout='git',
-                checkout_opts=dict(url='http://git.cern.ch/pub/gaudi'),
-                build_method='cmake',
-                env=['USE_MAKE=1']),
-            DBASE([Package('AppConfig', 'head')])
+                "Gaudi",
+                "v26r1",
+                checkout="git",
+                checkout_opts=dict(url="http://git.cern.ch/pub/gaudi"),
+                build_method="cmake",
+                env=["USE_MAKE=1"],
+            ),
+            DBASE([Package("AppConfig", "head")]),
         ],
-        build_method='cmt',
-        env=['Hello=World'])
+        build_method="cmt",
+        env=["Hello=World"],
+    )
     clone = pickle.loads(pickle.dumps(orig))
     assert orig == clone
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_jobconfig.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_jobconfig.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,53 +1,53 @@
-'''
+"""
 Created on Jan 8, 2014
 
 @author: Ben Couturier
-'''
+"""
 import unittest
 
 from LbNightlyTools.Utils import JenkinsTest
 
 
 class Test(unittest.TestCase):
     def test_simple_withlabel(self):
-        'JenkinsTest'
-        teststr = 'lhcb-testing.74.LHCb.x86_64-slc5-gcc46-opt.mylabel'
+        "JenkinsTest"
+        teststr = "lhcb-testing.74.LHCb.x86_64-slc5-gcc46-opt.mylabel"
         test = JenkinsTest.fromJenkinsString(teststr)
-        assert test.slot == 'lhcb-testing'
+        assert test.slot == "lhcb-testing"
         assert test.slot_build_id == "74"
-        assert test.project == 'LHCb'
-        assert test.platform == 'x86_64-slc5-gcc46-opt'
-        assert test.os_label == 'mylabel'
+        assert test.project == "LHCb"
+        assert test.platform == "x86_64-slc5-gcc46-opt"
+        assert test.os_label == "mylabel"
 
     def test_simple_nolabel(self):
-        'JenkinsTest'
-        teststr = 'lhcb-testing.74.LHCb.x86_64-slc5-gcc46-opt'
+        "JenkinsTest"
+        teststr = "lhcb-testing.74.LHCb.x86_64-slc5-gcc46-opt"
         test = JenkinsTest.fromJenkinsString(teststr)
-        assert test.os_label == 'slc5'
+        assert test.os_label == "slc5"
 
     def test_simple_withgroup(self):
-        'JenkinsTest'
-        teststr = 'lhcb-testing.74.LHCb.x86_64-slc5-gcc46-opt.mylabel.mygroup'
+        "JenkinsTest"
+        teststr = "lhcb-testing.74.LHCb.x86_64-slc5-gcc46-opt.mylabel.mygroup"
         test = JenkinsTest.fromJenkinsString(teststr)
-        assert test.os_label == 'mylabel'
-        assert test.testgroup == 'mygroup'
+        assert test.os_label == "mylabel"
+        assert test.testgroup == "mygroup"
 
     def test_simple_withgroup_nolabel(self):
-        'JenkinsTest'
-        teststr = 'lhcb-testing.74.LHCb.x86_64-slc5-gcc46-opt.none.mygroup'
+        "JenkinsTest"
+        teststr = "lhcb-testing.74.LHCb.x86_64-slc5-gcc46-opt.none.mygroup"
         test = JenkinsTest.fromJenkinsString(teststr)
         assert test.os_label == "slc5"
-        assert test.testgroup == 'mygroup'
+        assert test.testgroup == "mygroup"
 
     def test_simple_withrunner(self):
-        'JenkinsTest'
-        teststr = 'lhcb-testing.74.LHCb.x86_64-slc5-gcc46-opt.mylabel.mygroup.myrunner'
+        "JenkinsTest"
+        teststr = "lhcb-testing.74.LHCb.x86_64-slc5-gcc46-opt.mylabel.mygroup.myrunner"
         test = JenkinsTest.fromJenkinsString(teststr)
-        assert test.os_label == 'mylabel'
-        assert test.testgroup == 'mygroup'
-        assert test.testrunner == 'myrunner'
+        assert test.os_label == "mylabel"
+        assert test.testgroup == "mygroup"
+        assert test.testrunner == "myrunner"
 
 
 if __name__ == "__main__":
-    #import sys;sys.argv = ['', 'Test.testName']
+    # import sys;sys.argv = ['', 'Test.testName']
     unittest.main()
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_indexer.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_indexer.py`

 * *Files 10% similar despite different names*

```diff
@@ -5,39 +5,41 @@
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 import os
-from os.path import normpath, join
+from os.path import join, normpath
+
+from LbNightlyTools.Scripts import Index
 
 # Uncomment to disable the tests.
-#__test__ = False
+# __test__ = False
 
-from LbNightlyTools.Scripts import Index
 
-_testdata = normpath(join(*([__file__] + [os.pardir] * 4 + ['testdata'])))
+_testdata = normpath(join(*([__file__] + [os.pardir] * 4 + ["testdata"])))
 
 
 def test_filesToIndex():
-    'Index.filesToIndex()'
-    files = list(Index.filesToIndex(join(_testdata, 'indexer', 'AProject')))
+    "Index.filesToIndex()"
+    files = list(Index.filesToIndex(join(_testdata, "indexer", "AProject")))
 
     expected = [
-        'InstallArea/include/GeneratedHeader.h',
-        'InstallArea/include/MyHeader.h',
+        "InstallArea/include/GeneratedHeader.h",
+        "InstallArea/include/MyHeader.h",
         #'InstallArea/python/AProject_merged_confDb.py',
-        'InstallArea/python/GeneratedPython.py',
+        "InstallArea/python/GeneratedPython.py",
         #'InstallArea/python/MyPackage/MyPackageConf.py',
         #'InstallArea/python/MyPackage/MyPackage_confDb.py',
         #'InstallArea/python/MyPackage/MyPackage_user_confDb.py',
-        'InstallArea/python/MyPackage/SomeModule.py',
-        'InstallArea/python/MyPackage/SomethingConf.py',
+        "InstallArea/python/MyPackage/SomeModule.py",
+        "InstallArea/python/MyPackage/SomethingConf.py",
         #'MyPackage/python/MyPackage/__init__.py',
-        'MyPackage/scripts/MyScript',
-        'MyPackage/src/MySource.cpp',
+        "MyPackage/scripts/MyScript",
+        "MyPackage/src/MySource.cpp",
     ]
 
     from pprint import pprint
+
     pprint(files)
     assert files == expected
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_retry.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_retry.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,24 +6,26 @@
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 
 # Uncomment to disable the tests.
-#__test__ = False
+# __test__ = False
 
-from LbNightlyTools.Utils import retry_call, _retry_wrapper
+from builtins import object
+
+from LbNightlyTools.Utils import _retry_wrapper, retry_call
 
 
 def test_retry_call():
     try:
-        retry_call(['false'], retry=3)
+        retry_call(["false"], retry=3)
         assert False, "exception expected"
-    except RuntimeError, exc:
+    except RuntimeError as exc:
         assert str(exc) == "the command ['false'] failed 3 times"
 
 
 def test_retry_wrapper():
     import time
 
     class F(object):
@@ -31,14 +33,14 @@
             self.counter = fail_count + 1
 
         def __call__(self):
             self.counter -= 1
             return self.counter
 
     f = F()
-    f.__name__ = 'f'
+    f.__name__ = "f"
 
     rf = _retry_wrapper(f, lambda r: r == 0)
 
     start = time.time()
     rf(retry=5, retry_sleep=1)
     assert time.time() - start >= 2
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_checkout_script.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_checkout_script.py`

 * *Files 24% similar despite different names*

```diff
@@ -6,32 +6,30 @@
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 
 # Uncomment to disable the tests.
-#__test__ = False
-
-from LbNightlyTools import Configuration
-from LbNightlyTools.Scripts import Checkout
+# __test__ = False
 
+import json
 import os
-import shutil
 import re
-import json
-import nose
-
+import shutil
+from os.path import isfile, join, normpath
 from subprocess import call
 from tempfile import mkdtemp
-from os.path import normpath, join, isfile
-from LbNightlyTools.Utils import ensureDirs
+
+from LbNightlyTools import Configuration
+from LbNightlyTools.Scripts import Checkout
 from LbNightlyTools.tests.utils import TemporaryDir, which
+from LbNightlyTools.Utils import ensureDirs
 
-_testdata = normpath(join(*([__file__] + [os.pardir] * 4 + ['testdata'])))
+_testdata = normpath(join(*([__file__] + [os.pardir] * 4 + ["testdata"])))
 
 _env_bk = dict(os.environ)
 
 
 def setup():
     global _env_bk
     _env_bk = dict(os.environ)
@@ -41,117 +39,100 @@
     global _env_bk
     os.environ.clear()
     os.environ.update(_env_bk)
 
 
 def test_noop_patch():
     with TemporaryDir(chdir=True):
+        call(
+            [
+                "unzip",
+                "-q",
+                "-o",
+                join(
+                    _testdata,
+                    "artifacts",
+                    "packs",
+                    "src",
+                    "TestProject.HEAD.testing-slot.src.zip",
+                ),
+            ]
+        )
 
-        call([
-            'unzip', '-q', '-o',
-            join(_testdata, 'artifacts', 'packs', 'src',
-                 'TestProject.HEAD.testing-slot.src.zip')
-        ])
-
-        configfile = join(_testdata, 'testing-slot.json')
+        configfile = join(_testdata, "testing-slot.json")
         slot = Configuration.parse(configfile)
 
-        with open('slot.patch', 'w') as pfile:
+        with open("slot.patch", "w") as pfile:
             slot.patch(pfile)
 
-        assert isfile('slot.patch')
-        assert not open('slot.patch').read().strip(), 'patch file not empty'
+        assert isfile("slot.patch")
+        assert not open("slot.patch").read().strip(), "patch file not empty"
 
-        reqfile = join('TestProject', 'TestProjectSys', 'cmt', 'requirements')
+        reqfile = join("TestProject", "TestProjectSys", "cmt", "requirements")
         assert isfile(reqfile)
 
 
 def test_lbcore_192():
-    '''https://its.cern.ch/jira/browse/LBCORE-192
+    """https://its.cern.ch/jira/browse/LBCORE-192
 
     The *Sys package of a project is not correctly updated when new packages are
     added.
-    '''
+    """
     with TemporaryDir(chdir=True) as tmpd:
-        call([
-            'unzip', '-q', '-o',
-            join(_testdata, 'artifacts', 'packs', 'src',
-                 'TestProject.HEAD.testing-slot.src.zip')
-        ])
+        call(
+            [
+                "unzip",
+                "-q",
+                "-o",
+                join(
+                    _testdata,
+                    "artifacts",
+                    "packs",
+                    "src",
+                    "TestProject.HEAD.testing-slot.src.zip",
+                ),
+            ]
+        )
 
-        configfile = join(_testdata, 'testing-slot-lbcore-192.json')
+        configfile = join(_testdata, "testing-slot-lbcore-192.json")
         slot = Configuration.parse(configfile)
 
-        with open('slot.patch', 'w') as pfile:
+        with open("slot.patch", "w") as pfile:
             slot.patch(pfile)
 
-        assert isfile('slot.patch')
+        assert isfile("slot.patch")
 
-        reqfile = join('TestProject', 'TestProjectSys', 'cmt', 'requirements')
+        reqfile = join("TestProject", "TestProjectSys", "cmt", "requirements")
         assert isfile(reqfile)
 
-        #print open(reqfile).read()
+        # print open(reqfile).read()
         assert [
-            l for l in open(reqfile)
-            if re.match(r'^\s*use\s+NewPack\s+\*\s*$', l)
-        ], 'NewPack not in requirements'
+            l for l in open(reqfile) if re.match(r"^\s*use\s+NewPack\s+\*\s*$", l)
+        ], "NewPack not in requirements"
 
 
 def test_empty_conf():
     with TemporaryDir(chdir=True):
-        with open('test.json', 'w') as cfg:
-            cfg.write('{}')
-        retval = Checkout.Script().run(['test.json'])
+        with open("test.json", "w") as cfg:
+            cfg.write("{}")
+        retval = Checkout.Script().run(["test.json"])
         assert retval == 0
 
 
 def test_only_projects_conf():
     with TemporaryDir(chdir=True):
-        with open('test.json', 'w') as cfg:
+        with open("test.json", "w") as cfg:
             conf_data = {
-                'projects': [{
-                    'name': 'Gaudi',
-                    'version': 'HEAD',
-                    'checkout': 'git',
-                    'checkout_opts': {
-                        'url': 'https://gitlab.cern.ch/gaudi/Gaudi.git'
+                "projects": [
+                    {
+                        "name": "Gaudi",
+                        "version": "HEAD",
+                        "checkout": "git",
+                        "checkout_opts": {
+                            "url": "https://gitlab.cern.ch/gaudi/Gaudi.git"
+                        },
                     }
-                }]
+                ]
             }
             cfg.write(json.dumps(conf_data))
-        retval = Checkout.Script().run(['test.json'])
+        retval = Checkout.Script().run(["test.json"])
         assert retval == 0
-
-
-def test_only_packages_conf():
-    if not which('getpack'):
-        raise nose.SkipTest
-    with TemporaryDir(chdir=True):
-        with open('test.json', 'w') as cfg:
-            conf_data = {
-                'packages': [{
-                    'name': 'WG/CharmConfig',
-                    'version': 'head'
-                }]
-            }
-            cfg.write(json.dumps(conf_data))
-        retval = Checkout.Script().run(['test.json'])
-        assert retval == 0
-
-
-def test_lbcore_664():
-    '''https://its.cern.ch/jira/browse/LBCORE-664
-    '''
-    if not which('getpack'):
-        raise nose.SkipTest
-    configfile = join(_testdata, 'testing-slot-lbcore-664.json')
-    with TemporaryDir(chdir=True):
-        Checkout.Script().run(['--ignore-checkout-errors', configfile])
-    with TemporaryDir(chdir=True):
-        Checkout.Script().run([configfile])
-
-    with TemporaryDir(chdir=True):
-        try:
-            Checkout.Script().run(['--no-ignore-checkout-errors', configfile])
-            assert False, 'the script should have failed'
-        except:
-            pass
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_coverity_support.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_coverity_support.py`

 * *Files 20% similar despite different names*

```diff
@@ -4,181 +4,189 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
+import pytest
 
 # Uncomment to disable the tests.
-__test__ = False  # FIXME: to be adapted to new layout
+pytestmark = pytest.mark.skip("FIXME: to be adapted to new layout")
 
 import os
-from os.path import join, exists, abspath
-from subprocess import CalledProcessError
 from json import load
-
-from .utils import TESTDATA_PATH, TemporaryDir
+from os.path import abspath, exists, join
+from subprocess import CalledProcessError
 
 from ..Scripts.Build import Script as Builder
+from .utils import TESTDATA_PATH, TemporaryDir
 
-COV_DATA = join(TESTDATA_PATH, 'coverity')
+COV_DATA = join(TESTDATA_PATH, "coverity")
 
 
 def setup():
     # add to the path the Coverity mock tools
-    os.environ['PATH'] = ':'.join([
-        join(COV_DATA, 'bin'),
-        join(TESTDATA_PATH, '../scripts'), os.environ['PATH']
-    ])
-    os.environ['COVERITY_PASSPHRASE'] = 'dummy'
-    if 'CMTCONFIG' not in os.environ:
-        os.environ['CMTCONFIG'] = 'x86_64-slc6-gcc49-opt'
+    os.environ["PATH"] = ":".join(
+        [join(COV_DATA, "bin"), join(TESTDATA_PATH, "../scripts"), os.environ["PATH"]]
+    )
+    os.environ["COVERITY_PASSPHRASE"] = "dummy"
+    if "CMTCONFIG" not in os.environ:
+        os.environ["CMTCONFIG"] = "x86_64-slc6-gcc49-opt"
 
 
 def in_temp_dir(func):
-    '''
+    """
     Decorator to run a test in a temporary directory.
-    '''
+    """
     from functools import wraps
 
     @wraps(func)
     def wrapper():
         with TemporaryDir(chdir=True, skel=COV_DATA):
             return func()
 
     return wrapper
 
 
 def run_build(args):
-    '''
+    """
     Helper to run the build script.
-    '''
+    """
     rc = Builder().run(args)
     if rc:
-        raise CalledProcessError(rc, ['lbn-build'] + args)
+        raise CalledProcessError(rc, ["lbn-build"] + args)
 
 
-COV_OUT = join('build', 'TEST', 'TEST_HEAD', 'cov-out')
+COV_OUT = join("build", "TEST", "TEST_HEAD", "cov-out")
 
 
 def collect_reports(names=None):
     if names is None:
-        names = ['build', 'analyze', 'commit-defects']
+        names = ["build", "analyze", "commit-defects"]
 
-    assert exists(COV_OUT), 'missing directory %s' % COV_OUT
+    assert exists(COV_OUT), "missing directory %s" % COV_OUT
 
     reports = {}
     for name in names:
-        filename = join(COV_OUT, 'cov-{0}.report.json'.format(name))
-        assert exists(filename), 'missing {0}'.format(filename)
+        filename = join(COV_OUT, "cov-{0}.report.json".format(name))
+        assert exists(filename), "missing {0}".format(filename)
         reports[name] = load(open(filename))
     return reports
 
 
 def cov_log_file(step):
-    return join('artifacts', 'summaries.' + os.environ['CMTCONFIG'], 'Test',
-                'cov-' + step)
+    return join(
+        "artifacts", "summaries." + os.environ["CMTCONFIG"], "Test", "cov-" + step
+    )
 
 
 def check_logfiles(expected, not_expected=None):
     not_expected = not_expected or []
     for logfile in [
-            cov_log_file(step) + ext for step in expected
-            for ext in ['.log', '.err.log']
+        cov_log_file(step) + ext for step in expected for ext in [".log", ".err.log"]
     ]:
-        assert exists(logfile), 'missing %s' % logfile
+        assert exists(logfile), "missing %s" % logfile
     for logfile in [
-            cov_log_file(step) + ext for step in not_expected
-            for ext in ['.log', '.err.log']
+        cov_log_file(step) + ext
+        for step in not_expected
+        for ext in [".log", ".err.log"]
     ]:
-        assert not exists(logfile), 'found unexpected %s' % logfile
+        assert not exists(logfile), "found unexpected %s" % logfile
 
 
 @in_temp_dir
 def test_analyze():
-    run_build(['--coverity', '--slot-build-id', '273', 'test-slot'])
+    run_build(["--coverity", "--slot-build-id", "273", "test-slot"])
 
     reports = collect_reports()
     for name in reports:
-        assert reports[name]['retcode'] == 0, 'failure in %s' % name
+        assert reports[name]["retcode"] == 0, "failure in %s" % name
 
-    assert reports['build']['desc'] == 'test-slot-273'
+    assert reports["build"]["desc"] == "test-slot-273"
 
     expected = [
-        '/afs/cern.ch/sw/lcg/releases', '/cvmfs/sft.cern.ch/lcg/releases',
-        '/cvmfs/lhcb.cern.ch/lib/lcg/releases',
-        abspath(join('build', 'TEST'))
+        "/afs/cern.ch/sw/lcg/releases",
+        "/cvmfs/sft.cern.ch/lcg/releases",
+        "/cvmfs/lhcb.cern.ch/lib/lcg/releases",
+        abspath(join("build", "TEST")),
     ]
 
-    assert reports['analyze']['strip_path'] == expected, \
-        'expected strip-path {0}, found {1}'.format(expected, reports['analyze']['strip_path'])
+    assert (
+        reports["analyze"]["strip_path"] == expected
+    ), "expected strip-path {0}, found {1}".format(
+        expected, reports["analyze"]["strip_path"]
+    )
 
-    for k, v in {
+    for k, v in list(
+        {
             "stream": "LHCb-Test-Stream",
             "host": "lcgapp10.cern.ch",
             "user": "admin",
-            "port": "8080"
-    }.items():
-        assert reports['commit-defects'][k] == v, \
-            'bad value for {0}: expected {1}, found {2}' \
-                .format(k, v, reports['commit-defects'][k])
+            "port": "8080",
+        }.items()
+    ):
+        assert (
+            reports["commit-defects"][k] == v
+        ), "bad value for {0}: expected {1}, found {2}".format(
+            k, v, reports["commit-defects"][k]
+        )
 
-    check_logfiles(['analyze', 'commit-defects'])
+    check_logfiles(["analyze", "commit-defects"])
 
 
 @in_temp_dir
 def test_failed_build():
-    os.environ['COV_TEST_BUILD_ERROR'] = '1'
-    run_build(['--coverity', 'test-slot'])
-    del os.environ['COV_TEST_BUILD_ERROR']
-
-    reports = collect_reports(['build'])
-    assert reports['build']['retcode'] != 0
-    for name in ('analyze', 'commit-defects'):
-        assert not exists(join(COV_OUT, 'cov-{0}.report.json'.format(name)))
+    os.environ["COV_TEST_BUILD_ERROR"] = "1"
+    run_build(["--coverity", "test-slot"])
+    del os.environ["COV_TEST_BUILD_ERROR"]
+
+    reports = collect_reports(["build"])
+    assert reports["build"]["retcode"] != 0
+    for name in ("analyze", "commit-defects"):
+        assert not exists(join(COV_OUT, "cov-{0}.report.json".format(name)))
 
-    check_logfiles([], ['analyze', 'commit-defects'])
+    check_logfiles([], ["analyze", "commit-defects"])
 
 
 @in_temp_dir
 def test_failed_analysis():
-    os.environ['COV_TEST_ANALYZE_RC'] = '1'
-    run_build(['--coverity', 'test-slot'])
-    del os.environ['COV_TEST_ANALYZE_RC']
-
-    reports = collect_reports(['build', 'analyze'])
-    assert reports['build']['retcode'] == 0
-    assert reports['analyze']['retcode'] != 0
-    for name in ('commit-defects'):
-        assert not exists(join(COV_OUT, 'cov-{0}.report.json'.format(name)))
+    os.environ["COV_TEST_ANALYZE_RC"] = "1"
+    run_build(["--coverity", "test-slot"])
+    del os.environ["COV_TEST_ANALYZE_RC"]
+
+    reports = collect_reports(["build", "analyze"])
+    assert reports["build"]["retcode"] == 0
+    assert reports["analyze"]["retcode"] != 0
+    for name in "commit-defects":
+        assert not exists(join(COV_OUT, "cov-{0}.report.json".format(name)))
 
-    check_logfiles(['analyze'], ['commit-defects'])
+    check_logfiles(["analyze"], ["commit-defects"])
 
 
 @in_temp_dir
 def test_missing_password():
-    if 'COVERITY_PASSPHRASE' in os.environ:
-        del os.environ['COVERITY_PASSPHRASE']
-    run_build(['--coverity', 'test-slot'])
-    os.environ['COVERITY_PASSPHRASE'] = 'dummy'
-
-    reports = collect_reports(['build', 'analyze'])
-    assert reports['build']['retcode'] == 0
-    assert reports['analyze']['retcode'] == 0
-    for name in ('commit-defects'):
-        assert not exists(join(COV_OUT, 'cov-{0}.report.json'.format(name)))
+    if "COVERITY_PASSPHRASE" in os.environ:
+        del os.environ["COVERITY_PASSPHRASE"]
+    run_build(["--coverity", "test-slot"])
+    os.environ["COVERITY_PASSPHRASE"] = "dummy"
+
+    reports = collect_reports(["build", "analyze"])
+    assert reports["build"]["retcode"] == 0
+    assert reports["analyze"]["retcode"] == 0
+    for name in "commit-defects":
+        assert not exists(join(COV_OUT, "cov-{0}.report.json".format(name)))
 
-    check_logfiles(['analyze'], ['commit-defects'])
+    check_logfiles(["analyze"], ["commit-defects"])
 
 
 @in_temp_dir
 def test_no_commit():
-    run_build(['--coverity', '--no-coverity-commit', 'test-slot'])
+    run_build(["--coverity", "--no-coverity-commit", "test-slot"])
 
-    reports = collect_reports(['build', 'analyze'])
-    assert reports['build']['retcode'] == 0
-    assert reports['analyze']['retcode'] == 0
-    for name in ('commit-defects'):
-        assert not exists(join(COV_OUT, 'cov-{0}.report.json'.format(name)))
+    reports = collect_reports(["build", "analyze"])
+    assert reports["build"]["retcode"] == 0
+    assert reports["analyze"]["retcode"] == 0
+    for name in "commit-defects":
+        assert not exists(join(COV_OUT, "cov-{0}.report.json".format(name)))
 
-    check_logfiles(['analyze'], ['commit-defects'])
+    check_logfiles(["analyze"], ["commit-defects"])
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_install.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_install.py`

 * *Files 18% similar despite different names*

```diff
@@ -5,77 +5,81 @@
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 import os
-from os.path import normpath, join
+import shutil
+from os.path import join, normpath
+from tempfile import mkdtemp
+
+from LbNightlyTools.Scripts import Install
 
 # Uncomment to disable the tests.
-#__test__ = False
+# __test__ = False
 
-from LbNightlyTools.Scripts import Install
-from tempfile import mkdtemp
-import shutil
 
-_testdata = normpath(join(*([__file__] + [os.pardir] * 4 + ['testdata'])))
+_testdata = normpath(join(*([__file__] + [os.pardir] * 4 + ["testdata"])))
 
 
 def test_fixGlimpseIndexes():
-    'Install.fixGlimpseIndexes()'
+    "Install.fixGlimpseIndexes()"
     tmpd = mkdtemp()
-    src = join(_testdata, 'fix_glimpse')
-    dst = join(tmpd, 'fix_glimpse')
+    src = join(_testdata, "fix_glimpse")
+    dst = join(tmpd, "fix_glimpse")
     shutil.copytree(src, dst)
 
-    untouched = set([join(dst, 'untouched', '.glimpse_filenames')])
+    untouched = set([join(dst, "untouched", ".glimpse_filenames")])
 
     # FIXME: this is equivalent to the code in the script, but we should test
     #        the real code
     Install.fixGlimpseIndexes(
-        f for f in Install.findGlimpseFilenames(dst) if f not in untouched)
+        f for f in Install.findGlimpseFilenames(dst) if f not in untouched
+    )
 
-    expected = '''4
+    expected = """4
 {0}/file1
 {0}/path/file2
 {0}/other/path/file3
 /this/is/absolute
-'''.format(join(dst, 'level1'))
-
-    found = open(join(dst, 'level1', '.glimpse_filenames')).read()
-    #print 'level1'
-    #print found
-    #print expected
+""".format(
+        join(dst, "level1")
+    )
+
+    found = open(join(dst, "level1", ".glimpse_filenames")).read()
+    # print 'level1'
+    # print found
+    # print expected
     assert found == expected
 
-    expected = '''2
+    expected = """2
 file1
 path/file2
-'''
+"""
 
-    found = open(join(dst, 'level1', 'level2', '.glimpse_filenames')).read()
-    #print 'level1/level2'
-    #print found
+    found = open(join(dst, "level1", "level2", ".glimpse_filenames")).read()
+    # print 'level1/level2'
+    # print found
     assert found == expected
 
-    expected = '''1\n{0}/another\n'''.format(join(dst, 'levelA', 'levelB'))
+    expected = """1\n{0}/another\n""".format(join(dst, "levelA", "levelB"))
 
-    found = open(join(dst, 'levelA', 'levelB', '.glimpse_filenames')).read()
-    #print 'levelA/levelB'
-    #print found
+    found = open(join(dst, "levelA", "levelB", ".glimpse_filenames")).read()
+    # print 'levelA/levelB'
+    # print found
     assert found == expected
 
-    expected = '''1
+    expected = """1
 untouched
-'''
+"""
 
-    found = open(join(dst, 'untouched', '.glimpse_filenames')).read()
-    #print 'untouched'
-    #print found
+    found = open(join(dst, "untouched", ".glimpse_filenames")).read()
+    # print 'untouched'
+    # print found
     assert found == expected
 
     # ignored directories
-    found = open(join(dst, 'docs', '.glimpse_filenames')).read()
-    #print 'untouched'
-    #print found
+    found = open(join(dst, "docs", ".glimpse_filenames")).read()
+    # print 'untouched'
+    # print found
     assert found == expected
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_copytree.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_copytree.py`

 * *Files 22% similar despite different names*

```diff
@@ -4,75 +4,76 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-from os import makedirs, readlink, listdir
-from os.path import isdir, islink, realpath, join, basename
+from os import listdir, makedirs, readlink
+from os.path import basename, isdir, islink, join, realpath
 
 from LbNightlyTools.tests.utils import TemporaryDir
 from LbNightlyTools.Utils import shallow_copytree
 
 
 def test_no_dst():
     with TemporaryDir(chdir=True):
         for i in range(3):
-            makedirs(join('src', 'a', str(i)))
-        shallow_copytree('src', 'dst')
-        assert islink('dst')
-        assert realpath('src') == realpath('dst')
-        assert realpath('src') == readlink('dst')
+            makedirs(join("src", "a", str(i)))
+        shallow_copytree("src", "dst")
+        assert islink("dst")
+        assert realpath("src") == realpath("dst")
+        assert realpath("src") == readlink("dst")
 
 
 def test_recursion():
     with TemporaryDir(chdir=True):
         for i in range(3):
-            makedirs(join('src', 'a', str(i)))
-            makedirs(join('src', 'b', str(i)))
-        makedirs(join('dst', 'b'))
+            makedirs(join("src", "a", str(i)))
+            makedirs(join("src", "b", str(i)))
+        makedirs(join("dst", "b"))
 
-        shallow_copytree('src', 'dst')
+        shallow_copytree("src", "dst")
 
-        assert isdir('dst') and not islink('dst')
-        assert set(listdir('src')) == set(listdir('dst'))
+        assert isdir("dst") and not islink("dst")
+        assert set(listdir("src")) == set(listdir("dst"))
 
-        assert realpath(join('src', 'a')) == realpath(join('dst', 'a'))
-        assert realpath(join('src', 'a')) == readlink(join('dst', 'a'))
+        assert realpath(join("src", "a")) == realpath(join("dst", "a"))
+        assert realpath(join("src", "a")) == readlink(join("dst", "a"))
 
-        src_b = join('src', 'b')
-        dst_b = join('dst', 'b')
+        src_b = join("src", "b")
+        dst_b = join("dst", "b")
         assert isdir(dst_b) and not islink(dst_b)
         assert set(listdir(src_b)) == set(listdir(dst_b))
 
-        for n in [n for n in listdir(src_b) if n not in ('.', '..')]:
+        for n in [n for n in listdir(src_b) if n not in (".", "..")]:
             assert realpath(join(src_b, n)) == realpath(join(dst_b, n))
             assert realpath(join(src_b, n)) == readlink(join(dst_b, n))
 
 
 def test_ignore():
     with TemporaryDir(chdir=True):
         for i in range(3):
-            makedirs(join('src', 'a', str(i)))
-            makedirs(join('src', 'b', str(i)))
-        makedirs(join('dst', 'b'))
+            makedirs(join("src", "a", str(i)))
+            makedirs(join("src", "b", str(i)))
+        makedirs(join("dst", "b"))
 
         shallow_copytree(
-            'src',
-            'dst',
-            ignore=lambda src, names: ([] if basename(src) != 'b' else ['1']))
+            "src",
+            "dst",
+            ignore=lambda src, names: ([] if basename(src) != "b" else ["1"]),
+        )
 
-        assert isdir('dst') and not islink('dst')
-        assert set(listdir('src')) == set(listdir('dst'))
+        assert isdir("dst") and not islink("dst")
+        assert set(listdir("src")) == set(listdir("dst"))
 
-        assert realpath(join('src', 'a')) == realpath(join('dst', 'a'))
-        assert realpath(join('src', 'a')) == readlink(join('dst', 'a'))
+        assert realpath(join("src", "a")) == realpath(join("dst", "a"))
+        assert realpath(join("src", "a")) == readlink(join("dst", "a"))
 
-        src_b = join('src', 'b')
-        dst_b = join('dst', 'b')
+        src_b = join("src", "b")
+        dst_b = join("dst", "b")
         assert isdir(dst_b) and not islink(dst_b)
-        assert (set(listdir(src_b)) - set(listdir(dst_b))) == set(['1'])
+        assert (set(listdir(src_b)) - set(listdir(dst_b))) == set(["1"])
 
-        for n in [n for n in listdir(src_b) if n not in ('.', '..', '1')]:
+        for n in [n for n in listdir(src_b) if n not in (".", "..", "1")]:
             assert realpath(join(src_b, n)) == realpath(join(dst_b, n))
             assert realpath(join(src_b, n)) == readlink(join(dst_b, n))
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/tests/utils.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/utils.py`

 * *Files 17% similar despite different names*

```diff
@@ -4,102 +4,116 @@
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
-'''
+"""
 Utility functions used for testing.
-'''
+"""
+import logging
 import os
 import shutil
 import tempfile
-import logging
-from os.path import normpath, join, exists
+from builtins import object
+from os.path import exists, join, normpath
+
 from ..Utils import TemporaryDir
 
-__all__ = ('which', 'MockFunc', 'processFile', 'processFileWithName',
-           'MockLoggingHandler', 'TemporaryDir', 'TESTDATA_PATH')
+__all__ = (
+    "which",
+    "MockFunc",
+    "processFile",
+    "processFileWithName",
+    "MockLoggingHandler",
+    "TemporaryDir",
+    "TESTDATA_PATH",
+)
 
-TESTDATA_PATH = normpath(join(*([__file__] + [os.pardir] * 4 + ['testdata'])))
+TESTDATA_PATH = normpath(join(*([__file__] + [os.pardir] * 4 + ["testdata"])))
 
 
 def which(cmd):
-    '''
+    """
     find a command in the path
-    '''
+    """
     try:
-        return (join(d, cmd) for d in os.environ['PATH'].split(os.pathsep)
-                if exists(join(d, cmd))).next()
+        return next(
+            (
+                join(d, cmd)
+                for d in os.environ["PATH"].split(os.pathsep)
+                if exists(join(d, cmd))
+            )
+        )
     except StopIteration:
         return None
 
 
 class MockFunc(object):
-    '''
+    """
     Helper class to record the arguments a callback is called with.
-    '''
+    """
 
     def __init__(self):
         self.args = None
         self.kwargs = None
-        self.__name__ = 'mock'
+        self.__name__ = "mock"
 
     def __call__(self, *args, **kwargs):
         self.args = args
         self.kwargs = kwargs
 
 
 def processFile(data, function):
-    '''
+    """
     Process the string data via the function 'function' that accepts a filename
     as parameter.
-    '''
+    """
     fdesc, path = tempfile.mkstemp()
-    f = os.fdopen(fdesc, 'w')
+    f = os.fdopen(fdesc, "w")
     try:
         f.write(data)
         f.close()
         return function(path)
     finally:
         os.remove(path)
 
 
 def processFileWithName(data, name, function):
-    '''
+    """
     Process the string data via the function 'function' that accepts a filename
     as parameter, using the given name for the file.
-    '''
+    """
     with TemporaryDir() as path:
         filepath = os.path.join(path, name)
-        with open(filepath, 'w') as f:
+        with open(filepath, "w") as f:
             f.write(data)
         return function(filepath)
 
 
 # Code taken from http://stackoverflow.com/a/1049375/576333
 class MockLoggingHandler(logging.Handler):
     """Mock logging handler to check for expected logs.
     To use it:
     >>> mlh = MockLoggingHandler()
     >>> logging.getLogger().addHandler(mlh)
     >>> logging.debug('hello')
-    >>> mlh.messages['debug']
+    >>> mlh.messages['debug']  # doctest: +SKIP
     ['hello']
     """
 
     def __init__(self, *args, **kwargs):
         self.reset()
         logging.Handler.__init__(self, *args, **kwargs)
 
     def emit(self, record):
         self.messages[record.levelname.lower()].append(record.getMessage())
 
     def reset(self):
         self.messages = {
-            'debug': [],
-            'info': [],
-            'warning': [],
-            'error': [],
-            'critical': [],
+            "debug": [],
+            "info": [],
+            "warning": [],
+            "error": [],
+            "critical": [],
         }
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_enabled_slots_script.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_enabled_slots_script.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,66 +1,68 @@
+from __future__ import print_function
+
 ##############################################################################
 # (c) Copyright 2013 CERN                                                     #
 #                                                                             #
 # This software is distributed under the terms of the GNU General Public      #
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
+import pytest
 
 # Uncomment to disable the tests.
-__test__ = False  # FIXME: to review (required CouchDB connection?)
-__author__ = 'Colas Pomies <colas.pomies@cern.ch>'
+pytestmark = pytest.mark.skip("FIXME: to review (required CouchDB connection?)")
+__author__ = "Colas Pomies <colas.pomies@cern.ch>"
 __test_mode__ = True
 
-from LbNightlyTools.Scripts import EnabledSlots
-import LbNightlyTools.Configuration
-
+import json
 import os
 import re
-import json
+from os.path import exists, join
 
-from os.path import join, exists
+import LbNightlyTools.Configuration
+from LbNightlyTools.Scripts import EnabledSlots
 from LbNightlyTools.tests.utils import TemporaryDir
 
 _env_bk = dict(os.environ)
 
 
 class TmpDirWithConfig(TemporaryDir):
     def __init__(self, *args, **kwargs):
         TemporaryDir.__init__(self, *args, **kwargs)
-        os.makedirs(os.path.join(self.path, 'configs'))
+        os.makedirs(os.path.join(self.path, "configs"))
 
 
 def setup():
     global _env_bk
     _env_bk = dict(os.environ)
-    os.environ['JENKINS_HOME'] = 'JENKINS_HOME'
+    os.environ["JENKINS_HOME"] = "JENKINS_HOME"
     LbNightlyTools.Configuration.slots.clear()
 
 
 def teardown():
     global _env_bk
     os.environ.clear()
     os.environ.update(_env_bk)
     LbNightlyTools.Configuration.slots.clear()
 
 
-def generated_files(pattern=r'^slot-params-.*\.txt$'):
-    return [x for x in os.listdir('.') if re.match(pattern, x)]
+def generated_files(pattern=r"^slot-params-.*\.txt$"):
+    return [x for x in os.listdir(".") if re.match(pattern, x)]
 
 
 def test_wrong_number_arguments():
     with TemporaryDir(chdir=True):
         try:
-            EnabledSlots.Script().run(['abc'])
-            assert False, 'Script should have exited'
-        except SystemExit, x:
+            EnabledSlots.Script().run(["abc"])
+            assert False, "Script should have exited"
+        except SystemExit as x:
             assert x.code != 0
             assert not generated_files()
 
 
 def test_no_data():
     with TemporaryDir(chdir=True):
         retval = EnabledSlots.Script().run([])
@@ -73,340 +75,329 @@
         retval = EnabledSlots.Script().run([])
         assert retval == 0
         assert not generated_files()
 
 
 def test_one_file_json_chmod_111():
     conf_data = {
-        'slot': 'lhcb-TEST',
-        'description': 'Test for unit test',
-        'disabled': False,
-        'projects': [],
-        'default_platforms':
-        ['x86_64-slc6-gcc48-opt', 'x86_64-slc6-gcc46-opt'],
-        'USE_CMT': True
+        "slot": "lhcb-TEST",
+        "description": "Test for unit test",
+        "disabled": False,
+        "projects": [],
+        "default_platforms": ["x86_64-slc6-gcc48-opt", "x86_64-slc6-gcc46-opt"],
+        "USE_CMT": True,
     }
 
     with TmpDirWithConfig(chdir=True):
-        with open('configs/lhcb-TEST.json', 'w') as slot_file:
+        with open("configs/lhcb-TEST.json", "w") as slot_file:
             slot_file.write(json.dumps(conf_data))
-        os.chmod('configs/lhcb-TEST.json', 0111)
+        os.chmod("configs/lhcb-TEST.json", 0o111)
         retval = EnabledSlots.Script().run([])
         assert retval == 0
-        assert exists(join('configs/lhcb-TEST.json'))
+        assert exists(join("configs/lhcb-TEST.json"))
         assert not generated_files()
 
 
 def test_one_file_json_disabled_false():
     conf_data = {
-        'slot': 'lhcb-TEST',
-        'description': 'Test for unit test',
-        'disabled': False,
-        'projects': [],
-        'default_platforms':
-        ['x86_64-slc6-gcc48-opt', 'x86_64-slc6-gcc46-opt'],
-        'USE_CMT': True
+        "slot": "lhcb-TEST",
+        "description": "Test for unit test",
+        "disabled": False,
+        "projects": [],
+        "default_platforms": ["x86_64-slc6-gcc48-opt", "x86_64-slc6-gcc46-opt"],
+        "USE_CMT": True,
     }
 
     with TmpDirWithConfig(chdir=True):
-        with open('configs/lhcb-TEST.json', 'w') as slot_file:
+        with open("configs/lhcb-TEST.json", "w") as slot_file:
             slot_file.write(json.dumps(conf_data))
         retval = EnabledSlots.Script().run([])
         assert retval == 0
-        assert exists(join('configs/lhcb-TEST.json'))
-        assert json.load(open('configs/lhcb-TEST.json')) == conf_data
-        assert generated_files() == ['slot-params-lhcb-TEST.txt']
+        assert exists(join("configs/lhcb-TEST.json"))
+        assert json.load(open("configs/lhcb-TEST.json")) == conf_data
+        assert generated_files() == ["slot-params-lhcb-TEST.txt"]
 
 
 def test_one_file_json_disabled_true():
     conf_data = {
-        'slot': 'lhcb-TEST',
-        'description': 'Test for unit test',
-        'disabled': True,
-        'projects': [],
-        'default_platforms':
-        ['x86_64-slc6-gcc48-opt', 'x86_64-slc6-gcc46-opt'],
-        'USE_CMT': True
+        "slot": "lhcb-TEST",
+        "description": "Test for unit test",
+        "disabled": True,
+        "projects": [],
+        "default_platforms": ["x86_64-slc6-gcc48-opt", "x86_64-slc6-gcc46-opt"],
+        "USE_CMT": True,
     }
 
     with TmpDirWithConfig(chdir=True):
-        with open('configs/lhcb-TEST.json', 'w') as slot_file:
+        with open("configs/lhcb-TEST.json", "w") as slot_file:
             slot_file.write(json.dumps(conf_data))
         retval = EnabledSlots.Script().run([])
         assert retval == 0
-        assert exists(join('configs/lhcb-TEST.json'))
-        assert json.load(open('configs/lhcb-TEST.json')) == conf_data
+        assert exists(join("configs/lhcb-TEST.json"))
+        assert json.load(open("configs/lhcb-TEST.json")) == conf_data
         assert not generated_files()
 
 
 def test_one_file_json_no_disabled():
     conf_data = {
-        'slot': 'lhcb-TEST',
-        'description': 'Test for unit test',
-        'projects': [],
-        'default_platforms':
-        ['x86_64-slc6-gcc48-opt', 'x86_64-slc6-gcc46-opt'],
-        'USE_CMT': True
+        "slot": "lhcb-TEST",
+        "description": "Test for unit test",
+        "projects": [],
+        "default_platforms": ["x86_64-slc6-gcc48-opt", "x86_64-slc6-gcc46-opt"],
+        "USE_CMT": True,
     }
 
     with TmpDirWithConfig(chdir=True):
-        with open('configs/lhcb-TEST.json', 'w') as slot_file:
+        with open("configs/lhcb-TEST.json", "w") as slot_file:
             slot_file.write(json.dumps(conf_data))
         retval = EnabledSlots.Script().run([])
         assert retval == 0
-        assert exists(join('configs/lhcb-TEST.json'))
-        assert json.load(open('configs/lhcb-TEST.json')) == conf_data
-        assert generated_files() == ['slot-params-lhcb-TEST.txt']
+        assert exists(join("configs/lhcb-TEST.json"))
+        assert json.load(open("configs/lhcb-TEST.json")) == conf_data
+        assert generated_files() == ["slot-params-lhcb-TEST.txt"]
 
 
 def test_one_file_json_no_slot():
     conf_data = {
-        'description': 'Test for unit test',
-        'disabled': False,
-        'projects': [],
-        'default_platforms':
-        ['x86_64-slc6-gcc48-opt', 'x86_64-slc6-gcc46-opt'],
-        'USE_CMT': True
+        "description": "Test for unit test",
+        "disabled": False,
+        "projects": [],
+        "default_platforms": ["x86_64-slc6-gcc48-opt", "x86_64-slc6-gcc46-opt"],
+        "USE_CMT": True,
     }
 
     with TmpDirWithConfig(chdir=True):
-        with open('configs/lhcb-TEST.json', 'w') as slot_file:
+        with open("configs/lhcb-TEST.json", "w") as slot_file:
             slot_file.write(json.dumps(conf_data))
         retval = EnabledSlots.Script().run([])
         assert retval == 0
-        assert exists(join('configs/lhcb-TEST.json'))
-        assert json.load(open('configs/lhcb-TEST.json')) == conf_data
-        assert generated_files() == ['slot-params-lhcb-TEST.txt']
+        assert exists(join("configs/lhcb-TEST.json"))
+        assert json.load(open("configs/lhcb-TEST.json")) == conf_data
+        assert generated_files() == ["slot-params-lhcb-TEST.txt"]
 
 
 def test_two_files_json():
     conf_data1 = {
-        'description': 'Test for unit test',
-        'disabled': False,
-        'projects': [],
-        'default_platforms':
-        ['x86_64-slc6-gcc48-opt', 'x86_64-slc6-gcc46-opt'],
-        'USE_CMT': True
+        "description": "Test for unit test",
+        "disabled": False,
+        "projects": [],
+        "default_platforms": ["x86_64-slc6-gcc48-opt", "x86_64-slc6-gcc46-opt"],
+        "USE_CMT": True,
     }
     conf_data2 = {
-        'slot': 'lhcb-TEST2',
-        'description': 'Test for unit test',
-        'disabled': False,
-        'projects': [],
-        'default_platforms':
-        ['x86_64-slc6-gcc48-opt', 'x86_64-slc6-gcc46-opt'],
-        'USE_CMT': True
+        "slot": "lhcb-TEST2",
+        "description": "Test for unit test",
+        "disabled": False,
+        "projects": [],
+        "default_platforms": ["x86_64-slc6-gcc48-opt", "x86_64-slc6-gcc46-opt"],
+        "USE_CMT": True,
     }
 
     with TmpDirWithConfig(chdir=True):
-        print generated_files('.*')
-        with open('configs/lhcb-TEST1.json', 'w') as slot_file:
+        print(generated_files(".*"))
+        with open("configs/lhcb-TEST1.json", "w") as slot_file:
             slot_file.write(json.dumps(conf_data1))
-        with open('configs/lhcb-TEST2.json', 'w') as slot_file:
+        with open("configs/lhcb-TEST2.json", "w") as slot_file:
             slot_file.write(json.dumps(conf_data2))
-        print LbNightlyTools.Configuration.slots
+        print(LbNightlyTools.Configuration.slots)
         retval = EnabledSlots.Script().run([])
         assert retval == 0
-        assert exists(join('configs/lhcb-TEST1.json'))
-        assert exists(join('configs/lhcb-TEST2.json'))
-        assert json.load(open('configs/lhcb-TEST1.json')) == conf_data1
-        assert json.load(open('configs/lhcb-TEST2.json')) == conf_data2
-        print LbNightlyTools.Configuration.slots
+        assert exists(join("configs/lhcb-TEST1.json"))
+        assert exists(join("configs/lhcb-TEST2.json"))
+        assert json.load(open("configs/lhcb-TEST1.json")) == conf_data1
+        assert json.load(open("configs/lhcb-TEST2.json")) == conf_data2
+        print(LbNightlyTools.Configuration.slots)
         assert sorted(generated_files()) == [
-            'slot-params-lhcb-TEST1.txt', 'slot-params-lhcb-TEST2.txt'
+            "slot-params-lhcb-TEST1.txt",
+            "slot-params-lhcb-TEST2.txt",
         ]
 
 
 def test_one_job_xml_disbaled_false():
-
-    test_xml = u'''
+    test_xml = """
     <configuration xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="configuration.xsd">
         <slot disabled="false" hidden="false" name="lhcb-TEST" renice="+2" mails="true" description="lhcb-TEST use for unit TEST">
         </slot>
     </configuration>
-    '''
+    """
     with TmpDirWithConfig(chdir=True):
-        with open('configs/configuration.xml', 'w') as cfg_file:
+        with open("configs/configuration.xml", "w") as cfg_file:
             cfg_file.write(test_xml)
         retval = EnabledSlots.Script().run([])
         assert retval == 0
-        assert exists(join('configs/configuration.xml'))
-        assert generated_files() == ['slot-params-lhcb-TEST.txt']
+        assert exists(join("configs/configuration.xml"))
+        assert generated_files() == ["slot-params-lhcb-TEST.txt"]
 
 
 def test_one_job_xml_disabled_true():
-
-    test_xml = u'''
+    test_xml = """
     <configuration xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="configuration.xsd">
         <slot disabled="true" hidden="false" name="lhcb-TEST" renice="+2" mails="true" description="lhcb-TEST use for unit TEST">
         </slot>
     </configuration>
-    '''
+    """
     with TmpDirWithConfig(chdir=True):
-        with open('configs/configuration.xml', 'w') as cfg_file:
+        with open("configs/configuration.xml", "w") as cfg_file:
             cfg_file.write(test_xml)
         retval = EnabledSlots.Script().run([])
         assert retval == 0
-        assert exists(join('configs/configuration.xml'))
+        assert exists(join("configs/configuration.xml"))
         assert not generated_files()
 
 
 def test_one_job_xml_no_disabled():
-
-    test_xml = u'''
+    test_xml = """
     <configuration xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="configuration.xsd">
         <slot hidden="false" name="lhcb-TEST" renice="+2" mails="true" description="lhcb-TEST use for unit TEST">
         </slot>
     </configuration>
-    '''
+    """
     with TmpDirWithConfig(chdir=True):
-        with open('configs/configuration.xml', 'w') as cfg_file:
+        with open("configs/configuration.xml", "w") as cfg_file:
             cfg_file.write(test_xml)
         retval = EnabledSlots.Script().run([])
         assert retval == 0
-        assert exists(join('configs/configuration.xml'))
-        assert generated_files() == ['slot-params-lhcb-TEST.txt']
+        assert exists(join("configs/configuration.xml"))
+        assert generated_files() == ["slot-params-lhcb-TEST.txt"]
 
 
 def test_two_job_xml():
-
-    test_xml = u'''
+    test_xml = """
     <configuration xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="configuration.xsd">
         <slot disabled="false" hidden="false" name="lhcb-TEST1" renice="+2" mails="true" description="lhcb-TEST1 use for unit TEST">
         </slot>
         <slot disabled="false" hidden="false" name="lhcb-TEST2" renice="+2" mails="true" description="lhcb-TEST2 use for unit TEST">
         </slot>
     </configuration>
-    '''
+    """
     with TmpDirWithConfig(chdir=True):
-        with open('configs/configuration.xml', 'w') as cfg_file:
+        with open("configs/configuration.xml", "w") as cfg_file:
             cfg_file.write(test_xml)
         retval = EnabledSlots.Script().run([])
         assert retval == 0
-        assert exists(join('configs/configuration.xml'))
+        assert exists(join("configs/configuration.xml"))
         assert sorted(generated_files()) == [
-            'slot-params-lhcb-TEST1.txt', 'slot-params-lhcb-TEST2.txt'
+            "slot-params-lhcb-TEST1.txt",
+            "slot-params-lhcb-TEST2.txt",
         ]
 
 
 def test_same_job_xml_and_json():
-
-    test_xml = u'''
+    test_xml = """
      <configuration xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="configuration.xsd">
         <slot disabled="false" hidden="false" name="lhcb-TEST" renice="+2" mails="true" description="lhcb-TEST use for unit TEST">
         </slot>
     </configuration>
-    '''
+    """
     conf_data = {
-        'slot': 'lhcb-TEST',
-        'description': 'Test for unit test',
-        'disabled': False,
-        'projects': [],
-        'default_platforms':
-        ['x86_64-slc6-gcc48-opt', 'x86_64-slc6-gcc46-opt'],
-        'USE_CMT': True
+        "slot": "lhcb-TEST",
+        "description": "Test for unit test",
+        "disabled": False,
+        "projects": [],
+        "default_platforms": ["x86_64-slc6-gcc48-opt", "x86_64-slc6-gcc46-opt"],
+        "USE_CMT": True,
     }
 
     with TmpDirWithConfig(chdir=True):
-        with open('configs/configuration.xml', 'w') as cfg_file:
+        with open("configs/configuration.xml", "w") as cfg_file:
             cfg_file.write(test_xml)
-        with open('configs/lhcb-TEST.json', 'w') as slot_file:
+        with open("configs/lhcb-TEST.json", "w") as slot_file:
             slot_file.write(json.dumps(conf_data))
 
         retval = EnabledSlots.Script().run([])
         assert retval == 0
-        assert exists(join('configs/configuration.xml'))
-        assert exists(join('configs/lhcb-TEST.json'))
-        assert generated_files() == ['slot-params-lhcb-TEST.txt']
+        assert exists(join("configs/configuration.xml"))
+        assert exists(join("configs/lhcb-TEST.json"))
+        assert generated_files() == ["slot-params-lhcb-TEST.txt"]
 
 
 def test_different_job_xml_and_json():
-
-    test_xml = u'''
+    test_xml = """
      <configuration xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="configuration.xsd">
         <slot disabled="false" hidden="false" name="lhcb-TEST1" renice="+2" mails="true" description="lhcb-TEST1 use for unit TEST">
         </slot>
     </configuration>
-    '''
+    """
     conf_data = {
-        'slot': 'lhcb-TEST2',
-        'description': 'Test for unit test',
-        'disabled': False,
-        'projects': [],
-        'default_platforms':
-        ['x86_64-slc6-gcc48-opt', 'x86_64-slc6-gcc46-opt'],
-        'USE_CMT': True
+        "slot": "lhcb-TEST2",
+        "description": "Test for unit test",
+        "disabled": False,
+        "projects": [],
+        "default_platforms": ["x86_64-slc6-gcc48-opt", "x86_64-slc6-gcc46-opt"],
+        "USE_CMT": True,
     }
 
     with TmpDirWithConfig(chdir=True):
-        with open('configs/configuration.xml', 'w') as cfg_file:
+        with open("configs/configuration.xml", "w") as cfg_file:
             cfg_file.write(test_xml)
-        with open('configs/lhcb-TEST.json', 'w') as slot_file:
+        with open("configs/lhcb-TEST.json", "w") as slot_file:
             slot_file.write(json.dumps(conf_data))
 
         retval = EnabledSlots.Script().run([])
         assert retval == 0
-        assert exists(join('configs/configuration.xml'))
-        assert exists(join('configs/lhcb-TEST.json'))
+        assert exists(join("configs/configuration.xml"))
+        assert exists(join("configs/lhcb-TEST.json"))
         assert sorted(generated_files()) == [
-            'slot-params-lhcb-TEST1.txt', 'slot-params-lhcb-TEST2.txt'
+            "slot-params-lhcb-TEST1.txt",
+            "slot-params-lhcb-TEST2.txt",
         ]
 
 
 def test_one_job_param():
     with TemporaryDir(chdir=True):
-        retval = EnabledSlots.Script().run(['--slots', 'lhcb-test'])
+        retval = EnabledSlots.Script().run(["--slots", "lhcb-test"])
         assert retval == 0
-        assert generated_files() == ['slot-params-lhcb-test.txt']
+        assert generated_files() == ["slot-params-lhcb-test.txt"]
 
 
 def test_two_job_param():
     with TemporaryDir(chdir=True):
-        retval = EnabledSlots.Script().run(['--slots', 'lhcb-test lhcb-test2'])
+        retval = EnabledSlots.Script().run(["--slots", "lhcb-test lhcb-test2"])
         assert retval == 0
         assert sorted(generated_files()) == [
-            'slot-params-lhcb-test.txt', 'slot-params-lhcb-test2.txt'
+            "slot-params-lhcb-test.txt",
+            "slot-params-lhcb-test2.txt",
         ]
     with TemporaryDir(chdir=True):
-        retval = EnabledSlots.Script().run(
-            ['--slots', 'lhcb-test, lhcb-test2'])
+        retval = EnabledSlots.Script().run(["--slots", "lhcb-test, lhcb-test2"])
         assert retval == 0
         assert sorted(generated_files()) == [
-            'slot-params-lhcb-test.txt', 'slot-params-lhcb-test2.txt'
+            "slot-params-lhcb-test.txt",
+            "slot-params-lhcb-test2.txt",
         ]
 
 
 def test_mr_builds():
     conf_data = {
-        'slot': 'lhcb-master',
-        'description': 'Test for unit test',
-        'projects': ['Rec'],
-        'default_platforms':
-        ['x86_64-slc6-gcc48-opt', 'x86_64-slc6-gcc46-opt'],
-        'USE_CMT': True
+        "slot": "lhcb-master",
+        "description": "Test for unit test",
+        "projects": ["Rec"],
+        "default_platforms": ["x86_64-slc6-gcc48-opt", "x86_64-slc6-gcc46-opt"],
+        "USE_CMT": True,
     }
     mr_token = {
         "sources": ["lhcb/Rec!1753"],
         "trigger": {
             "merge_request_iid": 1753,
             "project_id": 401,
             "discussion_id": "d708ea762deae76f7d718eb0eefbc9b66c134190",
-            "note_id": 2913001
+            "note_id": 2913001,
         },
         "platforms": None,
-        "merge": False
+        "merge": False,
     }
-    os.environ['MR_TOKEN'] = json.dumps(mr_token)
+    os.environ["MR_TOKEN"] = json.dumps(mr_token)
     with TmpDirWithConfig(chdir=True):
-        with open('configs/lhcb-master.json', 'w') as slot_file:
+        with open("configs/lhcb-master.json", "w") as slot_file:
             slot_file.write(json.dumps(conf_data))
-        retval = EnabledSlots.Script().run(['--resolve-mrs', '--no-submit'])
+        retval = EnabledSlots.Script().run(["--resolve-mrs", "--no-submit"])
         assert retval == 0
         assert sorted(generated_files()) == [
-            'slot-params-lhcb-master-mr.txt', 'slot-params-lhcb-master-ref.txt'
+            "slot-params-lhcb-master-mr.txt",
+            "slot-params-lhcb-master-ref.txt",
         ]
-    del os.environ['MR_TOKEN']
+    del os.environ["MR_TOKEN"]
 
 
-for n, f in locals().items():
-    if n.startswith('test'):
+for n, f in list(locals().items()):
+    if n.startswith("test"):
         f.setup = LbNightlyTools.Configuration.slots.clear
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_rel_gen_script.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_rel_gen_script.py`

 * *Files 20% similar despite different names*

```diff
@@ -6,24 +6,26 @@
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 
 # Uncomment to disable the tests.
-#__test__ = False
+# __test__ = False
 
-from LbNightlyTools.Scripts import Release
+from future import standard_library
 
-import os
+standard_library.install_aliases()
 import json
-
+import os
 from pprint import pprint
 from tempfile import mkstemp
 
+from LbNightlyTools.Scripts import Release
+
 _env_bk = dict(os.environ)
 
 
 def setup():
     global _env_bk
     _env_bk = dict(os.environ)
 
@@ -35,425 +37,364 @@
 
 
 def test_empty_config():
     tmpfd, tmpname = mkstemp()
     os.close(tmpfd)
     try:
         s = Release.ConfigGenerator()
-        s.run(['-o', tmpname])
+        s.run(["-o", tmpname])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['projects'] == []
-        assert output['build_tool'] == 'cmake'
-        assert output['no_patch'] is True
-        assert len(output['platforms']) == 0
+        assert output["slot"] == "lhcb-release"
+        assert output["projects"] == []
+        assert output["build_tool"] == "cmake"
+        assert output["no_patch"] is True
+        assert len(output["platforms"]) == 0
 
         assert output == s.genConfig()
 
     finally:
         os.remove(tmpname)
 
 
 def test_options_error():
     try:
         s = Release.ConfigGenerator()
-        s.run(['ProjA'])
-        assert False, 'the script did not fail'
+        s.run(["ProjA"])
+        assert False, "the script did not fail"
     except SystemExit:
         pass  # expected behavior
 
 
 def test_LHCb():
     tmpfd, tmpname = mkstemp()
     os.close(tmpfd)
     try:
         s = Release.ConfigGenerator()
-        s.run(['-o', tmpname, 'LHCb', 'v36r1'])
+        s.run(["-o", tmpname, "LHCb", "v36r1"])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['projects'] == [{
-            'name': 'LHCb',
-            'version': 'v36r1',
-            'checkout_opts': {
-                'export': True
-            }
-        }]
-        assert output['build_tool'] == 'cmake'
-        assert output['no_patch'] is True
+        assert output["slot"] == "lhcb-release"
+        assert output["projects"] == [
+            {"name": "LHCb", "version": "v36r1", "checkout_opts": {"export": True}}
+        ]
+        assert output["build_tool"] == "cmake"
+        assert output["no_patch"] is True
 
         assert output == s.genConfig()
 
     finally:
         os.remove(tmpname)
 
 
 def test_Gaudi():
     tmpfd, tmpname = mkstemp()
     os.close(tmpfd)
     try:
         s = Release.ConfigGenerator()
-        s.run(['-o', tmpname, 'Gaudi', 'v23r9'])
+        s.run(["-o", tmpname, "Gaudi", "v23r9"])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['projects'] == [{
-            'name': 'Gaudi',
-            'version': 'v23r9',
-            'checkout_opts': {
-                'export': True
-            }
-        }]
-        assert output['build_tool'] == 'cmake'
-        assert output['no_patch'] is True
+        assert output["slot"] == "lhcb-release"
+        assert output["projects"] == [
+            {"name": "Gaudi", "version": "v23r9", "checkout_opts": {"export": True}}
+        ]
+        assert output["build_tool"] == "cmake"
+        assert output["no_patch"] is True
 
         assert output == s.genConfig()
 
     finally:
         os.remove(tmpname)
 
 
 def test_Geant4():
     tmpfd, tmpname = mkstemp()
     os.close(tmpfd)
     try:
         s = Release.ConfigGenerator()
-        s.run(['-o', tmpname, 'Geant4', 'v95r2p7'])
+        s.run(["-o", tmpname, "Geant4", "v95r2p7"])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['projects'] == [{
-            'name': 'Geant4',
-            'version': 'v95r2p7',
-            'with_shared': True,
-            'checkout_opts': {
-                'export': True
+        assert output["slot"] == "lhcb-release"
+        assert output["projects"] == [
+            {
+                "name": "Geant4",
+                "version": "v95r2p7",
+                "with_shared": True,
+                "checkout_opts": {"export": True},
             }
-        }]
-        assert output['build_tool'] == 'cmake'
-        assert output['no_patch'] is True
+        ]
+        assert output["build_tool"] == "cmake"
+        assert output["no_patch"] is True
 
         assert output == s.genConfig()
 
     finally:
         os.remove(tmpname)
 
 
 def test_two_projects():
     tmpfd, tmpname = mkstemp()
     os.close(tmpfd)
     try:
         s = Release.ConfigGenerator()
-        s.run(['-o', tmpname, 'LHCb', 'v36r1', 'Lbcom', 'v14r1'])
+        s.run(["-o", tmpname, "LHCb", "v36r1", "Lbcom", "v14r1"])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['projects'] == [{
-            'name': 'LHCb',
-            'version': 'v36r1',
-            'checkout_opts': {
-                'export': True
-            }
-        },
-                                      {
-                                          'name': 'Lbcom',
-                                          'version': 'v14r1',
-                                          'checkout_opts': {
-                                              'export': True
-                                          }
-                                      }]
-        assert output['build_tool'] == 'cmake'
-        assert output['no_patch'] is True
+        assert output["slot"] == "lhcb-release"
+        assert output["projects"] == [
+            {"name": "LHCb", "version": "v36r1", "checkout_opts": {"export": True}},
+            {"name": "Lbcom", "version": "v14r1", "checkout_opts": {"export": True}},
+        ]
+        assert output["build_tool"] == "cmake"
+        assert output["no_patch"] is True
 
         assert output == s.genConfig()
 
     finally:
         os.remove(tmpname)
 
 
 def test_fixCase():
     tmpfd, tmpname = mkstemp()
     os.close(tmpfd)
     try:
         s = Release.ConfigGenerator()
-        s.run(['-o', tmpname, 'lhcb', 'v36r1', 'dAvinCi', 'v34r0'])
+        s.run(["-o", tmpname, "lhcb", "v36r1", "dAvinCi", "v34r0"])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['projects'] == [{
-            'name': 'LHCb',
-            'version': 'v36r1',
-            'checkout_opts': {
-                'export': True
-            }
-        },
-                                      {
-                                          'name': 'DaVinci',
-                                          'version': 'v34r0',
-                                          'checkout_opts': {
-                                              'export': True
-                                          }
-                                      }]
-        assert output['build_tool'] == 'cmake'
-        assert output['no_patch'] is True
+        assert output["slot"] == "lhcb-release"
+        assert output["projects"] == [
+            {"name": "LHCb", "version": "v36r1", "checkout_opts": {"export": True}},
+            {"name": "DaVinci", "version": "v34r0", "checkout_opts": {"export": True}},
+        ]
+        assert output["build_tool"] == "cmake"
+        assert output["no_patch"] is True
 
         assert output == s.genConfig()
 
     finally:
         os.remove(tmpname)
 
 
 def test_dup_projects():
     try:
         s = Release.ConfigGenerator()
-        s.run(['LHCb', 'v36r1', 'LHCb', 'v36r2'])
-        assert False, 'the script did not fail'
+        s.run(["LHCb", "v36r1", "LHCb", "v36r2"])
+        assert False, "the script did not fail"
     except SystemExit:
         pass  # expected behavior
 
 
 def test_stdout():
     tmpfd, tmpname = mkstemp()
     os.close(tmpfd)
     try:
         import sys
-        from StringIO import StringIO
+        from io import StringIO
+
         old_stdout = sys.stdout
         sys.stdout = StringIO()
 
         s = Release.ConfigGenerator()
-        s.run(['-o', '-', 'LHCb', 'v36r1'])
+        s.run(["-o", "-", "LHCb", "v36r1"])
 
         output = json.loads(sys.stdout.getvalue())
         sys.stdout = old_stdout
 
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['projects'] == [{
-            'name': 'LHCb',
-            'version': 'v36r1',
-            'checkout_opts': {
-                'export': True
-            }
-        }]
-        assert output['build_tool'] == 'cmake'
-        assert output['no_patch'] is True
+        assert output["slot"] == "lhcb-release"
+        assert output["projects"] == [
+            {"name": "LHCb", "version": "v36r1", "checkout_opts": {"export": True}}
+        ]
+        assert output["build_tool"] == "cmake"
+        assert output["no_patch"] is True
 
         assert output == s.genConfig()
 
     finally:
         os.remove(tmpname)
 
 
 def test_with_cmt():
     tmpfd, tmpname = mkstemp()
     os.close(tmpfd)
     try:
         s = Release.ConfigGenerator()
-        s.run(['--cmt', '-o', tmpname, 'LHCb', 'v36r1'])
+        s.run(["--cmt", "-o", tmpname, "LHCb", "v36r1"])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['projects'] == [{
-            'name': 'LHCb',
-            'version': 'v36r1',
-            'checkout_opts': {
-                'export': True
-            }
-        }]
-        assert output['build_tool'] == 'cmt'
-        assert output['no_patch'] is True
+        assert output["slot"] == "lhcb-release"
+        assert output["projects"] == [
+            {"name": "LHCb", "version": "v36r1", "checkout_opts": {"export": True}}
+        ]
+        assert output["build_tool"] == "cmt"
+        assert output["no_patch"] is True
 
         assert output == s.genConfig()
 
     finally:
         os.remove(tmpname)
 
 
 def test_with_build_tool_cmt():
     tmpfd, tmpname = mkstemp()
     os.close(tmpfd)
     try:
         s = Release.ConfigGenerator()
-        s.run(['--build-tool', 'cmt', '-o', tmpname, 'LHCb', 'v36r1'])
+        s.run(["--build-tool", "cmt", "-o", tmpname, "LHCb", "v36r1"])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['projects'] == [{
-            'name': 'LHCb',
-            'version': 'v36r1',
-            'checkout_opts': {
-                'export': True
-            }
-        }]
-        assert output['build_tool'] == 'cmt'
-        assert output['no_patch'] is True
+        assert output["slot"] == "lhcb-release"
+        assert output["projects"] == [
+            {"name": "LHCb", "version": "v36r1", "checkout_opts": {"export": True}}
+        ]
+        assert output["build_tool"] == "cmt"
+        assert output["no_patch"] is True
 
         assert output == s.genConfig()
 
     finally:
         os.remove(tmpname)
 
 
 def test_platforms():
     tmpfd, tmpname = mkstemp()
     os.close(tmpfd)
     try:
         s = Release.ConfigGenerator()
-        s.run([
-            '--platforms', ' x86_64-slc6-gcc48-opt x86_64-slc6-gcc48-dbg,'
-            'x86_64-slc6-gcc48-test', '-o', tmpname
-        ])
+        s.run(
+            [
+                "--platforms",
+                " x86_64-slc6-gcc48-opt x86_64-slc6-gcc48-dbg,"
+                "x86_64-slc6-gcc48-test",
+                "-o",
+                tmpname,
+            ]
+        )
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['no_patch'] is True
-        assert output['platforms'] == [
-            'x86_64-slc6-gcc48-opt', 'x86_64-slc6-gcc48-dbg',
-            'x86_64-slc6-gcc48-test'
+        assert output["slot"] == "lhcb-release"
+        assert output["no_patch"] is True
+        assert output["platforms"] == [
+            "x86_64-slc6-gcc48-opt",
+            "x86_64-slc6-gcc48-dbg",
+            "x86_64-slc6-gcc48-test",
         ]
 
         assert output == s.genConfig()
 
     finally:
         os.remove(tmpname)
 
 
 def test_packages():
     tmpfd, tmpname = mkstemp()
     os.close(tmpfd)
     try:
         s = Release.ConfigGenerator()
-        s.run(['--packages', '', '-o', tmpname])
+        s.run(["--packages", "", "-o", tmpname])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['no_patch'] is True
-        assert output['packages'] == []
+        assert output["slot"] == "lhcb-release"
+        assert output["no_patch"] is True
+        assert output["packages"] == []
 
         assert output == s.genConfig()
 
         s = Release.ConfigGenerator()
-        s.run(['--packages', 'MyPack v1r0', '-o', tmpname])
+        s.run(["--packages", "MyPack v1r0", "-o", tmpname])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['no_patch'] is True
-        assert output['packages'] == [{
-            'name': 'MyPack',
-            'version': 'v1r0',
-            'checkout_opts': {
-                'export': True
-            }
-        }]
+        assert output["slot"] == "lhcb-release"
+        assert output["no_patch"] is True
+        assert output["packages"] == [
+            {"name": "MyPack", "version": "v1r0", "checkout_opts": {"export": True}}
+        ]
 
         assert output == s.genConfig()
 
         s = Release.ConfigGenerator()
-        s.run(
-            ['--packages', 'MyPack v1r0 Some/OtherPack v9r99', '-o', tmpname])
+        s.run(["--packages", "MyPack v1r0 Some/OtherPack v9r99", "-o", tmpname])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['no_patch'] is True
-        assert output['packages'] == [{
-            'name': 'MyPack',
-            'version': 'v1r0',
-            'checkout_opts': {
-                'export': True
-            }
-        },
-                                      {
-                                          'name': 'Some/OtherPack',
-                                          'version': 'v9r99',
-                                          'checkout_opts': {
-                                              'export': True
-                                          }
-                                      }]
+        assert output["slot"] == "lhcb-release"
+        assert output["no_patch"] is True
+        assert output["packages"] == [
+            {"name": "MyPack", "version": "v1r0", "checkout_opts": {"export": True}},
+            {
+                "name": "Some/OtherPack",
+                "version": "v9r99",
+                "checkout_opts": {"export": True},
+            },
+        ]
 
         assert output == s.genConfig()
 
         s = Release.ConfigGenerator()
-        s.run([
-            '--packages', 'MyPack v1r0 MyPack v2r3 MyPack v1r0 ', '-o', tmpname
-        ])
+        s.run(["--packages", "MyPack v1r0 MyPack v2r3 MyPack v1r0 ", "-o", tmpname])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['no_patch'] is True
-        assert output['packages'] == [{
-            'name': 'MyPack',
-            'version': 'v1r0',
-            'checkout_opts': {
-                'export': True
-            }
-        },
-                                      {
-                                          'name': 'MyPack',
-                                          'version': 'v2r3',
-                                          'checkout_opts': {
-                                              'export': True
-                                          }
-                                      }]
+        assert output["slot"] == "lhcb-release"
+        assert output["no_patch"] is True
+        assert output["packages"] == [
+            {"name": "MyPack", "version": "v1r0", "checkout_opts": {"export": True}},
+            {"name": "MyPack", "version": "v2r3", "checkout_opts": {"export": True}},
+        ]
 
         assert output == s.genConfig()
 
         s = Release.ConfigGenerator()
-        s.run([
-            '--packages', 'DBASE:MyPack v1r0 PARAM:AnotherPack v2r3', '-o',
-            tmpname
-        ])
+        s.run(["--packages", "DBASE:MyPack v1r0 PARAM:AnotherPack v2r3", "-o", tmpname])
 
         output = json.load(open(tmpname))
         pprint(output)
 
-        assert output['slot'] == 'lhcb-release'
-        assert output['no_patch'] is True
-        assert output['packages'] == [{
-            'name': 'MyPack',
-            'version': 'v1r0',
-            'container': 'DBASE',
-            'checkout_opts': {
-                'export': True
-            }
-        },
-                                      {
-                                          'name': 'AnotherPack',
-                                          'version': 'v2r3',
-                                          'container': 'PARAM',
-                                          'checkout_opts': {
-                                              'export': True
-                                          }
-                                      }]
+        assert output["slot"] == "lhcb-release"
+        assert output["no_patch"] is True
+        assert output["packages"] == [
+            {
+                "name": "MyPack",
+                "version": "v1r0",
+                "container": "DBASE",
+                "checkout_opts": {"export": True},
+            },
+            {
+                "name": "AnotherPack",
+                "version": "v2r3",
+                "container": "PARAM",
+                "checkout_opts": {"export": True},
+            },
+        ]
 
         assert output == s.genConfig()
 
     finally:
         os.remove(tmpname)
```

### Comparing `LbNightlyTools-3.0.9/python/LbNightlyTools/tests/test_configuration.py` & `LbNightlyTools-4.0.0/python/LbNightlyTools/tests/test_configuration.py`

 * *Files 24% similar despite different names*

```diff
@@ -5,77 +5,87 @@
 # Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
 #                                                                             #
 # In applying this licence, CERN does not waive the privileges and immunities #
 # granted to it by virtue of its status as an Intergovernmental Organization  #
 # or submit itself to any jurisdiction.                                       #
 ###############################################################################
 # Uncomment to disable the tests.
-#__test__ = False
+# __test__ = False
 
-from LbNightlyTools.Configuration import (slots, Project, Package, Slot,
-                                          ProjectsList, DBASE, cloneSlot)
-import LbNightlyTools.BuildMethods as BM
+from future import standard_library
 
+standard_library.install_aliases()
 import os
 
+import LbNightlyTools.BuildMethods as BM
+from LbNightlyTools.Configuration import (
+    DBASE,
+    Package,
+    Project,
+    ProjectsList,
+    Slot,
+    cloneSlot,
+    slots,
+)
+
 
 def setup():
     slots.clear()
 
 
 def test_slots_dict():
-    s = Slot('slot1')
+    s = Slot("slot1")
     assert len(slots) == 1
-    assert slots['slot1'] is s
+    assert slots["slot1"] is s
 
-    s = Slot('slot2')
+    s = Slot("slot2")
     assert len(slots) == 2
-    assert slots['slot2'] is s
+    assert slots["slot2"] is s
 
-    s = Slot('slot1')
+    s = Slot("slot1")
     assert len(slots) == 2
-    assert slots['slot1'] is s
+    assert slots["slot1"] is s
 
 
 def test_ProjectsList():
     slot = object()  # dummy object for checking
     pl = ProjectsList(slot)
     assert len(pl) == 0
 
-    pl.insert(0, Project('a', 'v1r0'))
+    pl.insert(0, Project("a", "v1r0"))
     assert len(pl) == 1
-    a = pl['a']
+    a = pl["a"]
     assert a == pl[0]
-    assert a.name == 'a'
+    assert a.name == "a"
     assert a.slot is slot
 
-    pl.append(Project('b', 'v2r0'))
+    pl.append(Project("b", "v2r0"))
     assert len(pl) == 2
-    b = pl['b']
+    b = pl["b"]
     assert b == pl[1]
-    assert b.name == 'b'
+    assert b.name == "b"
     assert b.slot is slot
 
     del pl[0]
     assert len(pl) == 1
     assert a.slot is None
 
-    pl.append(Project('a/b', 'v3r0'))
+    pl.append(Project("a/b", "v3r0"))
     assert len(pl) == 2
-    a_b = pl['a/b']
+    a_b = pl["a/b"]
     assert a_b == pl[1]
-    assert a_b.name == 'a/b'
-    assert a_b == pl['a_b']
+    assert a_b.name == "a/b"
+    assert a_b == pl["a_b"]
 
     # works as iterable
-    assert [p.name for p in pl] == ['b', 'a/b']
+    assert [p.name for p in pl] == ["b", "a/b"]
 
 
 def test_slot_projects():
-    slot = Slot('test', projects=[Project('a', 'v1r0'), Project('b', 'v2r0')])
+    slot = Slot("test", projects=[Project("a", "v1r0"), Project("b", "v2r0")])
     assert len(slot.projects) == 2
     a, b = slot.projects
     assert a.slot == b.slot == slot
     assert a == slot.a
     assert b == slot.b
 
     del slot.b
@@ -87,481 +97,493 @@
     try:
         slot.projects = []
         assert False, '"slot.projects = []" should have failed'
     except:
         pass
 
     class SpecialSlot(Slot):
-        projects = [Project('a', 'v1r0'), Project('b', 'v2r0')]
+        projects = [Project("a", "v1r0"), Project("b", "v2r0")]
 
-    slot = SpecialSlot('test1')
+    slot = SpecialSlot("test1")
     assert len(slot.projects) == 2
     a, b = slot.projects
     assert a.slot == b.slot == slot
 
-    slot.projects.insert(0, Project('zero', 'v0r0'))
+    slot.projects.insert(0, Project("zero", "v0r0"))
     assert len(slot.projects) == 3
-    assert slot.projects['zero'].slot == slot
+    assert slot.projects["zero"].slot == slot
 
     try:
         slot.projects = []
         assert False, '"slot.projects = []" should have failed'
     except:
         pass
 
 
 def test_deps():
     # explicit dependencies
     slot = Slot(
-        'test',
+        "test",
         projects=[
-            Project('A', 'v1r0', dependencies=['Zero']),
-            Project('b', 'v2r0', dependencies=['c', 'a'])
-        ])
+            Project("A", "v1r0", dependencies=["Zero"]),
+            Project("b", "v2r0", dependencies=["c", "a"]),
+        ],
+    )
     # slot.checkout()
-    assert slot.A.dependencies() == ['Zero']
-    assert slot.b.dependencies() == ['A', 'c']
+    assert slot.A.dependencies() == ["Zero"]
+    assert slot.b.dependencies() == ["A", "c"]
 
     full_deps = slot.fullDependencies()
-    expected = {'b': ['A', 'c'], 'A': ['Zero']}
+    expected = {"b": ["A", "c"], "A": ["Zero"]}
     assert full_deps == expected, full_deps
 
     deps = slot.dependencies()
-    expected = {'A': [], 'b': ['A']}
+    expected = {"A": [], "b": ["A"]}
     assert deps == expected, deps
 
-    b = Project('b', 'v2r0', dependencies=['c', 'a'])
-    assert b.dependencies() == ['a', 'c']
+    b = Project("b", "v2r0", dependencies=["c", "a"])
+    assert b.dependencies() == ["a", "c"]
 
 
 def test_slot_def_args():
     # test default arguments
-    dummy = Slot('dummy')
+    dummy = Slot("dummy")
     assert len(dummy.projects) == 0
 
-    dummy = Slot('dummy', [Project('A', 'v1r0')])
+    dummy = Slot("dummy", [Project("A", "v1r0")])
     assert len(dummy.projects) == 1
-    assert dummy.A.version == 'v1r0'
+    assert dummy.A.version == "v1r0"
 
 
 def test_env():
     slot = Slot(
-        'test',
-        projects=[Project('a', 'v1r0', env=['proj=a'])],
-        env=['slot=test', 'proj=none'])
+        "test",
+        projects=[Project("a", "v1r0", env=["proj=a"])],
+        env=["slot=test", "proj=none"],
+    )
 
-    special = {'CMAKE_PREFIX_PATH': os.getcwd(), 'CMTPROJECTPATH': os.getcwd()}
+    special = {"CMAKE_PREFIX_PATH": os.getcwd(), "CMTPROJECTPATH": os.getcwd()}
 
     def expected(d):
-        '''hack to extend the expected dictionary with search paths'''
+        """hack to extend the expected dictionary with search paths"""
         d.update(special)
         return d
 
     # extend CMake and CMT search paths
-    initial = {'CMAKE_PREFIX_PATH': '/usr/local/bin:/usr/bin'}
+    initial = {"CMAKE_PREFIX_PATH": "/usr/local/bin:/usr/bin"}
     env = slot.environment(initial)
-    assert env['CMAKE_PREFIX_PATH'] == \
-        os.pathsep.join([os.getcwd(), initial['CMAKE_PREFIX_PATH']])
-    assert env['CMTPROJECTPATH'] == os.getcwd()
+    assert env["CMAKE_PREFIX_PATH"] == os.pathsep.join(
+        [os.getcwd(), initial["CMAKE_PREFIX_PATH"]]
+    )
+    assert env["CMTPROJECTPATH"] == os.getcwd()
 
-    initial = {'CMTPROJECTPATH': '/usr/local/bin:/usr/bin'}
+    initial = {"CMTPROJECTPATH": "/usr/local/bin:/usr/bin"}
     env = slot.environment(initial)
-    assert env['CMTPROJECTPATH'] == \
-        os.pathsep.join([os.getcwd(), initial['CMTPROJECTPATH']])
-    assert env['CMAKE_PREFIX_PATH'] == os.getcwd()
+    assert env["CMTPROJECTPATH"] == os.pathsep.join(
+        [os.getcwd(), initial["CMTPROJECTPATH"]]
+    )
+    assert env["CMAKE_PREFIX_PATH"] == os.getcwd()
 
     # with dummy env
     initial = {}
     env = slot.environment(initial)
-    assert env == expected({'slot': 'test', 'proj': 'none'}), \
-        (env, expected({'slot': 'test', 'proj': 'none'}))
+    assert env == expected({"slot": "test", "proj": "none"}), (
+        env,
+        expected({"slot": "test", "proj": "none"}),
+    )
     assert initial == {}
 
     env = slot.a.environment(initial)
-    assert env == expected({'slot': 'test', 'proj': 'a'})
+    assert env == expected({"slot": "test", "proj": "a"})
     assert initial == {}
 
     # with os.environ
-    key = 'USER'
+    key = "USER"
     if key not in os.environ:
-        os.environ[key] = 'dummy'
+        os.environ[key] = "dummy"
     value = os.environ[key]
 
     initial = dict(os.environ)
 
-    slot.env.append('me=${%s}' % key)
+    slot.env.append("me=${%s}" % key)
 
     env = slot.environment()
-    assert env['slot'] == 'test'
-    assert env['proj'] == 'none'
+    assert env["slot"] == "test"
+    assert env["proj"] == "none"
     assert env[key] == value
-    assert env['me'] == value
+    assert env["me"] == value
     assert os.environ == initial
 
     env = slot.a.environment()
-    assert env['slot'] == 'test'
-    assert env['proj'] == 'a'
+    assert env["slot"] == "test"
+    assert env["proj"] == "a"
     assert env[key] == value
-    assert env['me'] == value
+    assert env["me"] == value
     assert os.environ == initial
 
     # derived class
     class SpecialSlot(Slot):
         projects = []
-        env = ['slot=test', 'proj=none']
+        env = ["slot=test", "proj=none"]
 
-    slot = SpecialSlot('test')
+    slot = SpecialSlot("test")
 
     env = slot.environment({})
-    assert env == expected({'slot': 'test', 'proj': 'none'})
+    assert env == expected({"slot": "test", "proj": "none"})
 
-    slot.env.append('another=entry')
+    slot.env.append("another=entry")
     env = slot.environment({})
-    assert env == expected({
-        'slot': 'test',
-        'proj': 'none',
-        'another': 'entry'
-    })
+    assert env == expected({"slot": "test", "proj": "none", "another": "entry"})
     # ensure that touching the instance 'env' attribute does not change the
     # class
-    assert SpecialSlot.env == SpecialSlot.__env__ == ['slot=test', 'proj=none']
+    assert SpecialSlot.env == SpecialSlot.__env__ == ["slot=test", "proj=none"]
 
     # derived class
     class ExtendedSlot(SpecialSlot):
-        env = ['proj=dummy']
+        env = ["proj=dummy"]
 
-    slot = ExtendedSlot('test')
+    slot = ExtendedSlot("test")
 
     env = slot.environment({})
-    assert env == expected({'slot': 'test', 'proj': 'dummy'})
+    assert env == expected({"slot": "test", "proj": "dummy"})
 
 
 def test_slot_desc():
-    slot = Slot('test')
+    slot = Slot("test")
     assert slot.desc == Slot.__doc__.strip()
 
-    slot = Slot('test', desc='a test slot')
-    assert slot.desc == 'a test slot'
+    slot = Slot("test", desc="a test slot")
+    assert slot.desc == "a test slot"
 
     class MyTest(Slot):
-        '''
+        """
         This is My Test.
-        '''
+        """
 
-    slot = MyTest('test')
-    assert slot.desc == 'This is My Test.'
+    slot = MyTest("test")
+    assert slot.desc == "This is My Test."
 
     class NoDesc(Slot):
         pass
 
-    slot = NoDesc('test')
-    assert slot.desc == '<no description>'
+    slot = NoDesc("test")
+    assert slot.desc == "<no description>"
 
 
 def test_build_tool_prop():
     #######
-    p = Project('p', 'v')
+    p = Project("p", "v")
     assert p.__build_tool__ is None
     assert isinstance(p.build_tool, BM.default)
 
-    p.build_tool = 'echo'
+    p.build_tool = "echo"
     assert isinstance(p.build_tool, BM.echo)
 
     p.build_tool = BM.cmt
     assert isinstance(p.build_tool, BM.cmt)
 
     #######
     class MyProj(Project):
-        build_tool = 'echo'
+        build_tool = "echo"
 
-    mp = MyProj('v')
+    mp = MyProj("v")
     assert isinstance(mp.build_tool, BM.echo)
 
     mp.build_tool = BM.cmt
     assert isinstance(mp.build_tool, BM.cmt)
 
     #######
-    s = Slot('s')
+    s = Slot("s")
     assert s.__build_tool__ is None
     assert isinstance(s.build_tool, BM.default)
 
-    s.build_tool = 'echo'
+    s.build_tool = "echo"
     assert isinstance(s.build_tool, BM.echo)
 
     s.build_tool = BM.cmt
     assert isinstance(s.build_tool, BM.cmt)
 
     #######
     class MySlot(Slot):
-        build_tool = 'echo'
+        build_tool = "echo"
 
-    ms = MySlot('ms')
+    ms = MySlot("ms")
     assert isinstance(ms.build_tool, BM.echo)
 
     ms.build_tool = BM.cmt
     assert isinstance(ms.build_tool, BM.cmt)
 
     #######
     p.build_tool = BM.cmt
-    s.build_tool = 'echo'
+    s.build_tool = "echo"
     s.projects.append(p)
     assert isinstance(p.build_tool, BM.echo)
     try:
-        p.build_tool = 'cmake'
-        assert False, 'exception expected'
+        p.build_tool = "cmake"
+        assert False, "exception expected"
     except AttributeError:
         pass
     except:
-        assert False, 'AttributeError exception expected'
+        assert False, "AttributeError exception expected"
 
 
 def test_custom_projects():
     from LbNightlyTools.CheckoutMethods import ignore
 
     class LHCb(Project):
-        checkout = 'ignore'
+        checkout = "ignore"
 
-    p = LHCb('HEAD')
-    assert p.name == 'LHCb'
-    assert p.version == 'HEAD'
+    p = LHCb("HEAD")
+    assert p.name == "LHCb"
+    assert p.version == "HEAD"
     assert p._checkout == ignore, (p._checkout, ignore)
 
     class Gaudi(Project):
-        __url__ = 'https://gitlab.cern.ch/gaudi/Gaudi.git'
+        __url__ = "https://gitlab.cern.ch/gaudi/Gaudi.git"
 
         def commitId(self):
             import re
-            if self.version.lower() == 'head':
-                return 'master'
-            elif re.match(r'v[0-9]+', self.version):
-                return '{0}/{0}_{1}'.format(self.name.upper(), self.version)
-            return self.version.replace('/', '_')
+
+            if self.version.lower() == "head":
+                return "master"
+            elif re.match(r"v[0-9]+", self.version):
+                return "{0}/{0}_{1}".format(self.name.upper(), self.version)
+            return self.version.replace("/", "_")
 
         def checkout(self, **kwargs):
-            args = {'url': self.__url__, 'commit': self.commitId()}
+            args = {"url": self.__url__, "commit": self.commitId()}
             args.update(kwargs)
-            return (0, str(args), '')
+            return (0, str(args), "")
 
-    g = Gaudi('v26r1')
-    assert g.name == 'Gaudi'
-    assert g.version == 'v26r1'
-    assert g.commitId() == 'GAUDI/GAUDI_v26r1'
-    expected = (0,
-                str({
-                    'url': 'https://gitlab.cern.ch/gaudi/Gaudi.git',
-                    'commit': 'GAUDI/GAUDI_v26r1',
-                    'verbose': True
-                }), '')
+    g = Gaudi("v26r1")
+    assert g.name == "Gaudi"
+    assert g.version == "v26r1"
+    assert g.commitId() == "GAUDI/GAUDI_v26r1"
+    expected = (
+        0,
+        str(
+            {
+                "url": "https://gitlab.cern.ch/gaudi/Gaudi.git",
+                "commit": "GAUDI/GAUDI_v26r1",
+                "verbose": True,
+            }
+        ),
+        "",
+    )
     output = g.checkout(verbose=True)
     assert output == expected, (output, expected)
 
     class SpecialGaudi(Project):
-        name = 'Special'
+        name = "Special"
 
-    assert SpecialGaudi.__project_name__ == 'Special'
-    s = SpecialGaudi('HEAD')
-    assert s.name == 'Special', s.name
+    assert SpecialGaudi.__project_name__ == "Special"
+    s = SpecialGaudi("HEAD")
+    assert s.name == "Special", s.name
 
 
 def test_custom_projects_2():
     from LbNightlyTools.CheckoutMethods import ignore
 
     class CustomProject(Project):
-        checkout = 'ignore'
+        checkout = "ignore"
 
-    p = CustomProject('LHCb', 'HEAD')
-    assert p.name == 'LHCb'
-    assert p.version == 'HEAD'
+    p = CustomProject("LHCb", "HEAD")
+    assert p.name == "LHCb"
+    assert p.version == "HEAD"
     assert p._checkout == ignore, (p._checkout, ignore)
 
     class LHCb(CustomProject):
         pass
 
-    p = LHCb('HEAD')
-    assert p.name == 'LHCb'
-    assert p.version == 'HEAD'
+    p = LHCb("HEAD")
+    assert p.name == "LHCb"
+    assert p.version == "HEAD"
     assert p._checkout == ignore, (p._checkout, ignore)
 
 
 def test_dataproject():
     # test empty constructor
     DBASE()
 
-    name, version = 'AppConfig', 'v3r198'
+    name, version = "AppConfig", "v3r198"
     d = DBASE(packages=[Package(name, version)])
-    assert d.name == 'DBASE'
-    assert d.baseDir == 'DBASE'
+    assert d.name == "DBASE"
+    assert d.baseDir == "DBASE"
 
     assert len(d.packages) == 1
     ac = d.packages[0]
     assert ac.name == name
     assert ac.version == version
-    assert ac.baseDir == os.path.join('DBASE', name, version)
+    assert ac.baseDir == os.path.join("DBASE", name, version)
     assert d.AppConfig is ac
 
-    name, version = 'Gen/DecFiles', 'v27r39'
+    name, version = "Gen/DecFiles", "v27r39"
     d.packages.append(Package(name, version))
     assert len(d.packages) == 2
     ac = d.packages[name]
     assert ac.name == name
     assert ac.version == version
-    assert ac.baseDir == os.path.join('DBASE', name, version)
+    assert ac.baseDir == os.path.join("DBASE", name, version)
     assert d.Gen_DecFiles is ac
 
 
 def test_no_patch_flag():
-    s = Slot('lhcb-release')
+    s = Slot("lhcb-release")
     assert s.no_patch is False
 
     d = s.toDict()
-    assert d.get('no_patch', False) is False
+    assert d.get("no_patch", False) is False
 
     s = Slot.fromDict(d)
     assert s.no_patch is False
 
-    s = Slot('lhcb-release', no_patch=True)
+    s = Slot("lhcb-release", no_patch=True)
     assert s.no_patch is True
 
     d = s.toDict()
-    assert d.get('no_patch', False) is True
+    assert d.get("no_patch", False) is True
 
     s = Slot.fromDict(d)
     assert s.no_patch is True
 
     try:
-        from StringIO import StringIO
+        from io import StringIO
+
         s.patch(StringIO())
         assert False, "ValueError expected"
     except ValueError:
         pass
 
 
 def test_no_test_flag():
-    s = Slot('lhcb-no-test')
+    s = Slot("lhcb-no-test")
     assert s.no_test is False
 
     d = s.toDict()
-    assert d.get('no_test', False) is False
+    assert d.get("no_test", False) is False
 
     s = Slot.fromDict(d)
     assert s.no_test is False
 
-    s = Slot('lhcb-no-test', no_test=True)
+    s = Slot("lhcb-no-test", no_test=True)
     assert s.no_test is True
 
     d = s.toDict()
-    assert d.get('no_test', False) is True
+    assert d.get("no_test", False) is True
 
     s = Slot.fromDict(d)
     assert s.no_test is True
 
     try:
         s.test()
         assert False, "ValueError expected"
     except ValueError:
         pass
 
-    p = Project('Gaudi', 'HEAD')
+    p = Project("Gaudi", "HEAD")
     assert p.no_test is False
 
     d = p.toDict()
-    assert d.get('no_test', False) is False
+    assert d.get("no_test", False) is False
 
     s = Project.fromDict(d)
     assert s.no_test is False
 
-    p = Project('Gaudi', 'HEAD', no_test=True)
+    p = Project("Gaudi", "HEAD", no_test=True)
     assert p.no_test is True
 
     d = p.toDict()
-    assert d.get('no_test', False) is True
+    assert d.get("no_test", False) is True
 
     s = Project.fromDict(d)
     assert p.no_test is True
 
     p = DBASE()
     assert p.no_test is True
 
 
 def test_cloning():
     from copy import deepcopy
-    p = Project('Gaudi', 'HEAD', env=['v1=1'])
+
+    p = Project("Gaudi", "HEAD", env=["v1=1"])
     p1 = deepcopy(p)
-    p1.env.append('v2=2')
-    assert p.env == ['v1=1']
-    assert p1.env == ['v1=1', 'v2=2']
-
-    slot = Slot('test', projects=[Project('Gaudi', 'test')], env=['v1=1'])
-    copy = cloneSlot(slot, 'clone')
-    copy.Gaudi.version = 'copy'
-    copy.env.append('v2=2')
-    assert copy.Gaudi.version == 'copy'
-    assert copy.env == ['v1=1', 'v2=2']
-    assert slot.Gaudi.version == 'test'
-    assert slot.env == ['v1=1']
+    p1.env.append("v2=2")
+    assert p.env == ["v1=1"]
+    assert p1.env == ["v1=1", "v2=2"]
+
+    slot = Slot("test", projects=[Project("Gaudi", "test")], env=["v1=1"])
+    copy = cloneSlot(slot, "clone")
+    copy.Gaudi.version = "copy"
+    copy.env.append("v2=2")
+    assert copy.Gaudi.version == "copy"
+    assert copy.env == ["v1=1", "v2=2"]
+    assert slot.Gaudi.version == "test"
+    assert slot.env == ["v1=1"]
 
 
 def test_metadata():
-    s = Slot('lhcb-no-metadata')
+    s = Slot("lhcb-no-metadata")
     assert not s.metadata
 
     d = s.toDict()
-    assert 'metadata' not in d
+    assert "metadata" not in d
 
     s = Slot.fromDict(d)
     assert not s.metadata
 
-    s = Slot('lhcb-with-metadata', metadata={'key': 'value'})
-    assert s.metadata == {'key': 'value'}
+    s = Slot("lhcb-with-metadata", metadata={"key": "value"})
+    assert s.metadata == {"key": "value"}
 
     d = s.toDict()
-    assert d.get('metadata') == {'key': 'value'}
+    assert d.get("metadata") == {"key": "value"}
 
     s = Slot.fromDict(d)
-    assert s.metadata == {'key': 'value'}
+    assert s.metadata == {"key": "value"}
 
-    s = Slot('lhcb-extend-metadata')
+    s = Slot("lhcb-extend-metadata")
     assert not s.metadata
-    s.metadata['key'] = 'value'
-    assert s.metadata == {'key': 'value'}
+    s.metadata["key"] = "value"
+    assert s.metadata == {"key": "value"}
 
 
 def test_KeyTuple():
     from LbNightlyTools.Configuration import _parse_key
+
     cases = {
-        'nightly/lhcb-gaudi-head/1234/Gaudi':  #
-        ('nightly', 'lhcb-gaudi-head', 1234, 'Gaudi'),
-        'nightly/lhcb-gaudi-head/1234':  #
-        ('nightly', 'lhcb-gaudi-head', 1234, None),
-        'lhcb-gaudi-head/1234':  #
-        ('nightly', 'lhcb-gaudi-head', 1234, None),
-        'testing/lhcb-gaudi-head/1234/Gaudi':  #
-        ('testing', 'lhcb-gaudi-head', 1234, 'Gaudi'),
-        'lhcb-head/5432/LHCb':  #
-        ('nightly', 'lhcb-head', 5432, 'LHCb'),
-        'test-slot/Project':  #
-        ('nightly', 'test-slot', 0, 'Project'),
-        'dummy/test-slot/0':  #
-        ('dummy', 'test-slot', 0, None),
-        'just-slot':  #
-        ('nightly', 'just-slot', 0, None),
-        'flav/slot/proj':  #
-        ('flav', 'slot', 0, 'proj'),
+        "nightly/lhcb-gaudi-head/1234/Gaudi": (  #
+            "nightly",
+            "lhcb-gaudi-head",
+            1234,
+            "Gaudi",
+        ),
+        "nightly/lhcb-gaudi-head/1234": ("nightly", "lhcb-gaudi-head", 1234, None),  #
+        "lhcb-gaudi-head/1234": ("nightly", "lhcb-gaudi-head", 1234, None),  #
+        "testing/lhcb-gaudi-head/1234/Gaudi": (  #
+            "testing",
+            "lhcb-gaudi-head",
+            1234,
+            "Gaudi",
+        ),
+        "lhcb-head/5432/LHCb": ("nightly", "lhcb-head", 5432, "LHCb"),  #
+        "test-slot/Project": ("nightly", "test-slot", 0, "Project"),  #
+        "dummy/test-slot/0": ("dummy", "test-slot", 0, None),  #
+        "just-slot": ("nightly", "just-slot", 0, None),  #
+        "flav/slot/proj": ("flav", "slot", 0, "proj"),  #
     }
-    for key, expected in cases.items():
+    for key, expected in list(cases.items()):
         # check that we get what we expect
         parsed = _parse_key(key)
         assert parsed == expected
         # and make sure that conversion to string is stable
         assert _parse_key(str(parsed)) == expected
 
     try:
-        _parse_key('a/b/c/d')
-        assert False, 'ValueError expected'
+        _parse_key("a/b/c/d")
+        assert False, "ValueError expected"
     except ValueError:
         pass
 
     try:
-        _parse_key('a/b/0/d/e')
-        assert False, 'ValueError expected'
+        _parse_key("a/b/0/d/e")
+        assert False, "ValueError expected"
     except ValueError:
         pass
```

### Comparing `LbNightlyTools-3.0.9/setup.py` & `LbNightlyTools-4.0.0/setup.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,25 +1,26 @@
 """A setuptools based setup module.
 
 See:
 https://packaging.python.org/en/latest/distributing.html
 https://github.com/pypa/sampleproject
 """
 
-# Always prefer setuptools over distutils
-from setuptools import setup, find_packages
 # To use a consistent encoding
 from codecs import open
 from os import path
 from sys import version_info
 
+# Always prefer setuptools over distutils
+from setuptools import find_packages, setup
+
 here = path.abspath(path.dirname(__file__))
 
 # Get the long description from the README file
-with open(path.join(here, 'README.rst'), encoding='utf-8') as f:
+with open(path.join(here, "README.rst"), encoding="utf-8") as f:
     long_description = f.read()
 
 # Arguments marked as "Required" below must be included for upload to PyPI.
 # Fields marked as "Optional" may be commented out.
 
 setup(
     # This is the name of your project. The first time you publish this
@@ -29,219 +30,194 @@
     # $ pip install sampleproject
     #
     # And where it will live on PyPI: https://pypi.org/project/sampleproject/
     #
     # There are some restrictions on what makes a valid project name
     # specification here:
     # https://packaging.python.org/specifications/core-metadata/#name
-    name='LbNightlyTools',  # Required
-
+    name="LbNightlyTools",  # Required
     # Versions should comply with PEP 440:
     # https://www.python.org/dev/peps/pep-0440/
     #
     # For a discussion on single-sourcing the version across setup.py and the
     # project code, see
     # https://packaging.python.org/en/latest/single_source_version.html
     # version='0.0.1',  # Required
     use_scm_version=True,
-
     # This is a one-line description or tagline of what your project does. This
     # corresponds to the "Summary" metadata field:
     # https://packaging.python.org/specifications/core-metadata/#summary
-    description='LHCb Nightly tools',  # Required
-
+    description="LHCb Nightly tools",  # Required
     # This is an optional longer description of your project that represents
     # the body of text which users will see when they visit PyPI.
     #
     # Often, this is the same as your README, so you can just read it in from
     # that file directly (as we have already done above)
     #
     # This field corresponds to the "Description" metadata field:
     # https://packaging.python.org/specifications/core-metadata/#description-optional
     long_description=long_description,  # Optional
-
     # This should be a valid link to your project's main homepage.
     #
     # This field corresponds to the "Home-Page" metadata field:
     # https://packaging.python.org/specifications/core-metadata/#home-page-optional
-    url='https://gitlab.cern.ch/lhcb-core/LbNightlyTools',  # Optional
-
+    url="https://gitlab.cern.ch/lhcb-core/LbNightlyTools",  # Optional
     # This should be your name or the name of the organization which owns the
     # project.
-    author='CERN - LHCb Core Software',  # Optional
-
+    author="CERN - LHCb Core Software",  # Optional
     # This should be a valid email address corresponding to the author listed
     # above.
-    author_email='lhcb-core-soft@cern.ch',  # Optional
-
+    author_email="lhcb-core-soft@cern.ch",  # Optional
     # Classifiers help users find your project by categorizing it.
     #
     # For a list of valid classifiers, see
     # https://pypi.python.org/pypi?%3Aaction=list_classifiers
     classifiers=[  # Optional
         # How mature is this project? Common values are
         #   3 - Alpha
         #   4 - Beta
         #   5 - Production/Stable
-        'Development Status :: 4 - Beta',
-
+        "Development Status :: 4 - Beta",
         # Indicate who your project is intended for
-        'Intended Audience :: Developers',
-        'Topic :: Software Development :: Build Tools',
-
+        "Intended Audience :: Developers",
+        "Topic :: Software Development :: Build Tools",
         # Pick your license as you wish
-        'License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)',
-
+        "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
         # Specify the Python versions you support here. In particular, ensure
         # that you indicate whether you support Python 2, Python 3 or both.
-        'Programming Language :: Python :: 2',
-        'Programming Language :: Python :: 2.7',
-        'Programming Language :: Python :: 3',
-        'Programming Language :: Python :: 3.4',
-        'Programming Language :: Python :: 3.5',
-        'Programming Language :: Python :: 3.6',
+        "Programming Language :: Python :: 2",
+        "Programming Language :: Python :: 2.7",
+        "Programming Language :: Python :: 3",
+        "Programming Language :: Python :: 3.4",
+        "Programming Language :: Python :: 3.5",
+        "Programming Language :: Python :: 3.6",
     ],
-
     # This field adds keywords for your project which will appear on the
     # project page. What does your project relate to?
     #
     # Note that this is a string of words separated by whitespace, not a list.
     # keywords='LHCb Dirac LHCbDirac',  # Optional
-
     # You can just specify package directories manually here if your project is
     # simple. Or you can use find_packages().
     #
     # Alternatively, if you just want to distribute a single Python file, use
     # the `py_modules` argument instead as follows, which will expect a file
     # called `my_module.py` to exist:
     #
     #   py_modules=["my_module"],
     #
     packages=find_packages(
-        'python', exclude=['*.tests'] if version_info < (3, 0) else []),
-    package_dir={'': 'python'},
+        "python", exclude=["*.tests"] if version_info < (3, 0) else []
+    ),
+    package_dir={"": "python"},
     package_data={
-        'LbPeriodicTools': ['TestSchedule.xsd'],
-        'LbNightlyTools.Scripts': ['extract.php', 'listzip.php'],
+        "LbPeriodicTools": ["TestSchedule.xsd"],
+        "LbNightlyTools.Scripts": ["extract.php", "listzip.php"],
     },
-
     # This field lists other packages that your project depends on to run.
     # Any package you put here will be installed by pip when your project is
     # installed, so they must be valid existing projects.
     #
     # For an analysis of "install_requires" vs pip's requirements files see:
     # https://packaging.python.org/en/latest/requirements.html
     install_requires=[
         "LbEnv",
         "LbCommon>=0.0.7",
-        "LbSoftConfDb2Clients",
         "LbDevTools",
-        "python-gitlab" + ('<2' if version_info < (3, 0) else ''),
-        "pika>=1.0.0",
+        "lbinstall",
+        "python-gitlab" + ("<2" if version_info < (3, 0) else ""),
+        "pika==1.1.0",
         "CouchDB",
         "tabulate",
-        'GitPython' + ('<2.1.12' if version_info < (3, 0) else ''),
-        "networkx" + ('<2.3' if version_info < (3, 0) else ''),
+        "joblib",
+        "GitPython" + ("<2.1.12" if version_info < (3, 0) else ""),
+        "networkx" + ("<2.3" if version_info < (3, 0) else ""),
         # we do not directly depend on gitdb2, but we need to constrain the version
-        'gitdb2' + ('<3' if version_info < (3, 0) else ''),
-    ],
-
-    # see https://stackoverflow.com/a/30064248, needed for Python 2.6 (SLC6)
-    dependency_links=[
-        'https://lhcb-pypi.web.cern.ch/lhcb-pypi/simple/lbenv',
-        'https://lhcb-pypi.web.cern.ch/lhcb-pypi/simple/lbcommon',
-        'https://lhcb-pypi.web.cern.ch/lhcb-pypi/simple/lbsoftconfdb2clients/',
-        'https://lhcb-pypi.web.cern.ch/lhcb-pypi/simple/lbdevtools',
+        "gitdb2" + ("<3" if version_info < (3, 0) else ""),
+        "pyyaml",
+        "decorator" + ("<5" if version_info < (3, 0) else ""),
+        "future",
     ],
-
     # List additional groups of dependencies here (e.g. development
     # dependencies). Users will be able to install these using the "extras"
     # syntax, for example:
     #
     #   $ pip install sampleproject[dev]
     #
     # Similar to `install_requires` above, these must be valid existing
     # projects.
-    extras_require={  # Optional
-    },
-    tests_require=['coverage'],
-    setup_requires=['nose>=1.0', 'setuptools_scm'],
+    extras_require={},  # Optional
+    tests_require=[],
+    setup_requires=["setuptools_scm"],
     # If there are data files included in your packages that need to be
     # installed, specify them here.
     #
     # If using Python 2.6 or earlier, then these have to be included in
     # MANIFEST.in as well.
     # package_data={  # Optional
     #     'LbEnv': ['LICENSE', 'README.rst', 'share/platforms.txt',
     #               'share/projects.txt', 'toto'],
     # },
-
     # Although 'package_data' is the preferred approach, in some case you may
     # need to place data files outside of your packages. See:
     # http://docs.python.org/3.4/distutils/setupscript.html#installing-additional-files
     #
     # In this case, 'data_file' will be installed into '<sys.prefix>/my_data'
     # data_files=[('my_data', ['data/data_file'])],  # Optional
-
     # To provide executable scripts, use entry points in preference to the
     # "scripts" keyword. Entry points provide cross-platform support and allow
     # `pip` to create the appropriate form of executable for the target
     # platform.
     #
     # For example, the following would provide a command called `sample` which
     # executes the function `main` from this package when invoked:
     scripts=[
-        'scripts/lbn-get-configs',
-        'scripts/lbn-wrapcmd',
-        'scripts/lbpr-collect',
+        "scripts/lbn-get-configs",
+        "scripts/lbn-wrapcmd",
+        "scripts/lbpr-collect",
     ],
     entry_points={
-        'console_scripts': [
-            'lbn-ansi2html=LbNightlyTools.Scripts._entry_points:ansi2html',
-            'lbn-build=LbNightlyTools.Scripts.Build:run',
-            'lbn-build-legacy=LbNightlyTools.Scripts.Build:run',
-            'lbn-build-log-to-html=LbNightlyTools.Scripts._entry_points:build_log_to_html',
-            'lbn-check-config=LbNightlyTools.Configuration:check_config',
-            'lbn-checkout=LbNightlyTools.Scripts.Checkout:run',
-            'lbn-checkout-legacy=LbNightlyTools.Scripts.Checkout:run',
-            'lbn-check-preconditions=LbNightlyTools.Scripts._entry_points:check_preconditions',
-            'lbn-collect-build-logs=LbNightlyTools.Scripts._entry_points:collect_build_logs',
-            'lbn-enabled-slots=LbNightlyTools.Scripts._entry_points:enabled_slots',
-            'lbn-generate-compatspec=LbNightlyTools.Scripts._entry_points:generate_compatspec',
-            'lbn-generate-do0spec=LbNightlyTools.Scripts._entry_points:generate_do0spec',
-            'lbn-generate-extspec=LbNightlyTools.Scripts._entry_points:generate_extspec',
-            'lbn-generate-genericspec=LbNightlyTools.Scripts._entry_points:generate_genericspec',
-            'lbn-generate-lbscriptsspec=LbNightlyTools.Scripts._entry_points:generate_lbscriptsspec',
-            'lbn-generate-metaspec=LbNightlyTools.Scripts._entry_points:generate_metaspec',
-            'lbn-generate-spec=LbNightlyTools.Scripts._entry_points:generate_spec',
-            'lbn-gen-release-config=LbNightlyTools.Scripts._entry_points:gen_release_config',
-            'lbn-get-new-refs=LbNightlyTools.GetNightlyRefs:main',
-            'lbn-gitlab-mr=LbNightlyTools.Scripts.GitlabMR:main',
-            'lbn-index=LbNightlyTools.Scripts._entry_points:index',
-            'lbn-install=LbNightlyTools.Scripts._entry_points:install',
-            'lbn-list-platforms=LbNightlyTools.Scripts._entry_points:list_platforms',
-            'lbn-preconditions=LbNightlyTools.Scripts._entry_points:preconditions',
-            'lbn-release-poll=LbNightlyTools.Scripts._entry_points:release_poll',
-            'lbn-release-trigger=LbNightlyTools.Scripts._entry_points:release_trigger',
-            'lbn-reschedule-tests=LbNightlyTools.Scripts._entry_points:reschedule_tests',
-            'lbn-rpm=LbNightlyTools.Scripts._entry_points:rpm',
-            'lbn-rpm-validator=LbNightlyTools.Scripts._entry_points:rpm_validator',
-            'lbn-slots-by-deployment=LbNightlyTools.Scripts._entry_points:slots_by_deployment',
-            'lbn-test=LbNightlyTools.Scripts.Test:run',
-            'lbn-test-legacy=LbNightlyTools.Scripts.Test:run',
-            'lbn-test-poll=LbNightlyTools.Scripts._entry_points:test_poll',
-            'lbp-check-periodic-tests=LbPeriodicTools._entry_points:check_periodic_tests',
-            'lbp-check-periodic-tests-msg=LbPeriodicTools._entry_points:check_periodic_tests_msg',
-            'lbpr-get-command=LbPR._entry_points:get_command',
-            'lbq-builddone=LbNightlyTools.Scripts._entry_points:lbq_builddone',
-            'lbq-buildnotif=LbNightlyTools.Scripts._entry_points:lbq_buildnotif',
-            'lbq-getteststorun=LbNightlyTools.Scripts._entry_points:lbq_getteststorun',
-            'lbq-requesttest=LbNightlyTools.Scripts._entry_points:lbq_requesttest',
+        "console_scripts": [
+            "lbn-ansi2html=LbNightlyTools.Scripts._entry_points:ansi2html",
+            "lbn-build=LbNightlyTools.Scripts.Build:run",
+            "lbn-build-legacy=LbNightlyTools.Scripts.Build:run",
+            "lbn-build-log-to-html=LbNightlyTools.Scripts._entry_points:build_log_to_html",
+            "lbn-check-config=LbNightlyTools.Configuration:check_config",
+            "lbn-checkout=LbNightlyTools.Scripts.Checkout:run",
+            "lbn-checkout-legacy=LbNightlyTools.Scripts.Checkout:run",
+            "lbn-check-preconditions=LbNightlyTools.Scripts._entry_points:check_preconditions",
+            "lbn-collect-build-logs=LbNightlyTools.Scripts._entry_points:collect_build_logs",
+            "lbn-enabled-slots=LbNightlyTools.Scripts._entry_points:enabled_slots",
+            "lbn-generate-compatspec=LbNightlyTools.Scripts._entry_points:generate_compatspec",
+            "lbn-generate-do0spec=LbNightlyTools.Scripts._entry_points:generate_do0spec",
+            "lbn-generate-extspec=LbNightlyTools.Scripts._entry_points:generate_extspec",
+            "lbn-generate-genericspec=LbNightlyTools.Scripts._entry_points:generate_genericspec",
+            "lbn-generate-lbscriptsspec=LbNightlyTools.Scripts._entry_points:generate_lbscriptsspec",
+            "lbn-generate-metaspec=LbNightlyTools.Scripts._entry_points:generate_metaspec",
+            "lbn-generate-spec=LbNightlyTools.Scripts._entry_points:generate_spec",
+            "lbn-gen-release-config=LbNightlyTools.Scripts._entry_points:gen_release_config",
+            "lbn-get-new-refs=LbNightlyTools.GetNightlyRefs:main",
+            "lbn-gitlab-mr=LbNightlyTools.Scripts.GitlabMR:main",
+            "lbn-index=LbNightlyTools.Scripts._entry_points:index",
+            "lbn-install=LbNightlyTools.Scripts._entry_points:install",
+            "lbn-list-platforms=LbNightlyTools.Scripts._entry_points:list_platforms",
+            "lbn-preconditions=LbNightlyTools.Scripts._entry_points:preconditions",
+            "lbn-release-poll=LbNightlyTools.Scripts._entry_points:release_poll",
+            "lbn-release-trigger=LbNightlyTools.Scripts._entry_points:release_trigger",
+            "lbn-reschedule-tests=LbNightlyTools.Scripts._entry_points:reschedule_tests",
+            "lbn-rpm=LbNightlyTools.Scripts._entry_points:rpm",
+            "lbn-rpm-validator=LbNightlyTools.Scripts._entry_points:rpm_validator",
+            "lbn-test=LbNightlyTools.Scripts.Test:run",
+            "lbn-test-legacy=LbNightlyTools.Scripts.Test:run",
+            "lbn-test-poll=LbNightlyTools.Scripts._entry_points:test_poll",
+            "lbp-check-periodic-tests=LbPeriodicTools._entry_points:check_periodic_tests",
+            "lbp-check-periodic-tests-msg=LbPeriodicTools._entry_points:check_periodic_tests_msg",
+            "lbpr-get-command=LbPR._entry_points:get_command",
+            "lbq-builddone=LbNightlyTools.Scripts._entry_points:lbq_builddone",
+            "lbq-buildnotif=LbNightlyTools.Scripts._entry_points:lbq_buildnotif",
+            "lbq-getteststorun=LbNightlyTools.Scripts._entry_points:lbq_getteststorun",
+            "lbq-requesttest=LbNightlyTools.Scripts._entry_points:lbq_requesttest",
         ],
     },
-
     # The package can be safely distributed as a ZIP file
     zip_safe=False,
-
-    # Process files with 2to3 to run with Python 3
-    use_2to3=version_info >= (3, 0),
 )
```

